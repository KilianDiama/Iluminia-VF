import os
import logging
from typing import Union, Any, Dict, List, Tuple, Callable
import torch
from fastapi import FastAPI, Depends, HTTPException, status, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm
from qiskit import QuantumCircuit
from astropy.table import Table
from rasa_sdk.events import EventType
from astropy.coordinates import SkyCoord
from motor.motor_asyncio import AsyncIOMotorClient
from sklearn.pipeline import Pipeline
import dash
import streamlit as st
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from flask import Flask, request, jsonify, send_file, abort
import random
import motor.motor_asyncio
import albumentations

from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from dash import dcc, html
from albumentations import Compose, HorizontalFlip, RandomBrightnessContrast, Rotate
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from PIL import Image
from torchvision.models.detection import fasterrcnn_resnet50_fpn
#from brian2 import NeuronGroup, Synapses, run
from dash.dependencies import Input, Output
from PIL import Image
from io import BytesIO
import requests
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
import pandas as pd
import plotly.express as px
import networkx as nx
from cryptography.fernet import Fernet
from tpot import TPOTClassifier
from faker import Faker
import asyncio
from sentence_transformers import SentenceTransformer
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
import boto3
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import aiofiles
from rasa_sdk import Action
from rasa_sdk.executor import CollectingDispatcher
from rasa_sdk.events import SlotSet
from dask import dataframe as dd
#from qiskit import Aer, QuantumCircuit, transpile
from qiskit.circuit.library import RealAmplitudes
from qiskit_machine_learning.algorithms import VQC
#from qiskit_machine_learning.kernels import QuantumKernel
from sklearn.model_selection import train_test_split
from scipy.stats import ks_2samp
from cachetools import TTLCache
import joblib
import pandas as pd
import matplotlib.pyplot as plt
from io import BytesIO
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
import datetime
from collections import Counter
import spacy
from langdetect import detect
from joblib import Parallel, delayed
import time
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import GridSearchCV
import yaml
from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN
import hdbscan
from umap import UMAP
from typing import Optional
import plotly.graph_objects as go
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.backends import default_backend
from dotenv import load_dotenv
import base64
import numpy as np
from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes
from collections import defaultdict
from pydantic import BaseModel
from rasa_sdk import Tracker
from rasa_sdk.types import DomainDict
from sklearn.linear_model import LinearRegression
from imblearn.over_sampling import SMOTE
import shap
from datetime import datetime
from typing import Text
from sklearn.ensemble import RandomForestClassifier
from rasa.engine.graph import GraphComponent
from rasa.shared.nlu.training_data.training_data import TrainingData
from rasa.shared.nlu.constants import INTENT
#from rasa.nlu.model import Metadata
import tensorflow as tf
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
import pandas as pd
import argparse


import os
from Crypto.Cipher import AES
import sys

if len(sys.argv) < 2:
    print("Erreur : Aucun fichier sp√©cifi√©.")
    sys.exit(1)

chemin_fichier = sys.argv[1]  # R√©cup√®re le premier argument pass√© en ligne de commande
df = pd.read_csv(chemin_fichier)

# üîç R√©cup√©rer la cl√© depuis les variables d'environnement
key = os.getenv("SECRET_KEY")

# ‚ö†Ô∏è V√©rifier si la cl√© est bien r√©cup√©r√©e
if key is None:
    raise ValueError("üö® ERREUR : SECRET_KEY n'est pas d√©finie. V√©rifiez vos variables d'environnement.")

print("üîë Cl√© r√©cup√©r√©e :", key)

# üîß Corriger la longueur de la cl√© (AES accepte uniquement 16, 24 ou 32 bytes)
key = key.ljust(16, "0")[:16].encode("utf-8")  # Compl√®te avec des '0' si n√©cessaire

# ‚úÖ Initialiser AES
cipher = AES.new(key, AES.MODE_ECB)
print("‚úÖ AES initialis√© avec succ√®s !")

iv = os.urandom(16)  # G√©n√©rer un IV al√©atoire si besoin

try:
    chemin_fichier = "data.csv"
    df = pd.read_csv(chemin_fichier)
    if df.empty:
        raise ValueError("Le fichier CSV est vide.")
except pd.errors.EmptyDataError:
    print("Erreur : Le fichier CSV est vide ou corrompu.")
    
chemin_fichier = "C:/Users/diama/projet_RASA/actions/ILLUMINIA/mon_fichier.csv"
if not os.path.exists(chemin_fichier):
    raise FileNotFoundError(f"Le fichier {chemin_fichier} n'existe pas.")


parser = argparse.ArgumentParser()
parser.add_argument("--chemin_fichier", type=str, required=True)
args = parser.parse_args()

print(f"Chargement du fichier : {args.chemin_fichier}")
X_test = pd.read_csv('/kaggle/input/mon_fichier.csv')



chemin_fichier = "/kaggle/input/mon_fichier.csv"
mot_de_passe = "MonSuperMotDePasse123"

# D√©finir les donn√©es d'exemple
data = {
    "feature1": [5.6, 4.7, 6.1],
    "feature2": [3.2, 2.8, 3.0]
}

import argparse
import os
import pandas as pd

def main(chemin_fichier, fichier_analyse):
    if not os.path.exists(chemin_fichier):
        raise FileNotFoundError(f"Le fichier {chemin_fichier} n'existe pas.")

    if not os.path.exists(fichier_analyse):
        raise FileNotFoundError(f"Le fichier {fichier_analyse} n'existe pas.")

    # Charger et traiter les fichiers CSV
    print(f"‚úÖ Fichier principal charg√© : {chemin_fichier}")
    print(f"‚úÖ Fichier √† analyser charg√© : {fichier_analyse}")
    chemin_fichier = "data.csv"
    df = pd.read_csv(chemin_fichier)
    df_analyse = pd.read_csv(fichier_analyse)

    print("üìä Donn√©es du fichier principal :")
    print(df.head())

    print("üìä Donn√©es √† analyser :")
    print(df_analyse.head())

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Programme ILLUMINIA pour analyse de donn√©es.")
    parser.add_argument("--chemin_fichier", required=True, help="Chemin du fichier principal.")
    parser.add_argument("--fichier_analyse", default="C:/Users/diama/projet_RASA/actions/ILLUMINIA/fichier_a_analyser.csv", help="Chemin du fichier √† analyser")

    
    args = parser.parse_args()
    main(args.chemin_fichier, args.fichier_analyse)


# Cr√©er un DataFrame
df = pd.DataFrame(data)

# Enregistrer sous forme de CSV
file_path = "C:/Users/diama/projet_RASA/actions/ILLUMINIA/chemin_vers_ton_fichier_test.csv"
df.to_csv(file_path, index=False)

print(f"‚úÖ Fichier CSV cr√©√© avec succ√®s : {file_path}")


# D√©finition correcte du pipeline
pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

# Donn√©es fictives pour l'exemple
X_train = pd.DataFrame({
    'feature1': [1.0, 2.0, None],
    'feature2': [4.0, None, 6.0]
})

# Utilisation du pipeline
X_train_prepared = pipeline.fit_transform(X_train)
print(X_train_prepared)

# Charger les donn√©es de test depuis un fichier
X_test = pd.read_csv('chemin_vers_ton_fichier_test.csv')

# Assure-toi que les colonnes correspondent au pipeline
X_test = X_test[['feature1', 'feature2']]  # Ajuste en fonction de tes colonnes

X_test = X_test.rename(columns={
    "feature1": "sepal length (cm)",
    "feature2": "sepal width (cm)"
})

load_dotenv()
import tkinter as tk
from tkinter import filedialog, messagebox
import pandas as pd

def charger_fichier():
    fichier = filedialog.askopenfilename(filetypes=[("Fichiers CSV", "*.csv")])
    if fichier:
        label_fichier.config(text=f"Fichier s√©lectionn√© : {fichier}")
        global chemin_fichier
        chemin_fichier = fichier

def analyser_fichier():
    if not chemin_fichier:
        messagebox.showerror("Erreur", "Veuillez s√©lectionner un fichier CSV.")
        return
    chemin_fichier = "data.csv"
    df = pd.read_csv(chemin_fichier)
    messagebox.showinfo("Analyse r√©ussie", f"Le fichier contient {df.shape[0]} lignes et {df.shape[1]} colonnes.")

# Cr√©ation de la fen√™tre
root = tk.Tk()
root.title("ILLUMINIA - Analyse de donn√©es")

# Bouton pour charger un fichier
btn_charger = tk.Button(root, text="Choisir un fichier CSV", command=charger_fichier)
btn_charger.pack(pady=10)

# Label pour afficher le fichier s√©lectionn√©
label_fichier = tk.Label(root, text="Aucun fichier s√©lectionn√©", fg="blue")
label_fichier.pack(pady=5)

# Bouton pour analyser
btn_analyser = tk.Button(root, text="Analyser", command=analyser_fichier)
btn_analyser.pack(pady=10)

# D√©marrer la fen√™tre
root.mainloop()

# Configuration des constantes
ENCRYPTION_KEY = os.getenv("ENCRYPTION_KEY")
MASTER_PASSWORD = os.getenv("MASTER_PASSWORD")

if not ENCRYPTION_KEY or not MASTER_PASSWORD:
    raise ValueError("Les cl√©s ou mots de passe sont manquants dans les variables d'environnement.")

# Configuration du logger
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialisation de FastAPI
app = FastAPI()

# Middleware pour v√©rifier l'autorisation
@app.middleware("http")
async def check_authorization(request: Request, call_next):
    secret_key = request.headers.get("Authorization")
    logger.info(f"Authorization header received: {secret_key}")
    if not secret_key or secret_key != f"Bearer {MASTER_PASSWORD}":
        logger.warning("Unauthorized access attempt detected.")
        raise HTTPException(status_code=401, detail="Unauthorized")
    response = await call_next(request)
    return response

# Mod√®les pour FastAPI (utilis√©s dans les endpoints)
class WebhookPayload(BaseModel):
    signature: str
    payload: str

# Routes de l'application
@app.get("/test_env")
async def test_env():
    """
    Route pour tester les variables d'environnement charg√©es.
    """
    return {
        "ENCRYPTION_KEY": ENCRYPTION_KEY,
        "MASTER_PASSWORD": MASTER_PASSWORD,
    }

@app.post("/verify_webhook")
async def verify_webhook(payload: WebhookPayload):
    """
    V√©rifie la signature d'un webhook.
    """
    is_valid = verify_webhook_signature(payload.signature, payload.payload, MASTER_PASSWORD)
    if is_valid:
        return {"status": "valid"}
    else:
        raise HTTPException(status_code=400, detail="Invalid signature")

# Fonction pour g√©n√©rer un salt s√©curis√©
def generate_salt() -> bytes:
    return os.urandom(16)

# Fonction pour d√©river une cl√© √† partir d'un mot de passe ma√Ætre
def derive_key(master_password: str, salt: bytes) -> bytes:
    kdf = PBKDF2HMAC(
        algorithm=hashes.SHA256(),
        length=32,
        salt=salt,
        iterations=100000,
        backend=default_backend()
    )
    return kdf.derive(master_password.encode())

# Fonction pour crypter une cl√©
def encrypt_encryption_key(encryption_key: bytes, master_password: str) -> bytes:
    try:
        salt = generate_salt()
        master_key = derive_key(master_password, salt)
        cipher = Cipher(algorithms.AES(master_key), modes.GCM(os.urandom(12)), backend=default_backend())
        encryptor = cipher.encryptor()
        encrypted_key = encryptor.update(encryption_key) + encryptor.finalize()

        return salt + cipher.algorithm.iv + encryptor.tag + encrypted_key
    except Exception as e:
        logger.error(f"Erreur lors du chiffrement : {e}")
        raise

# Fonction pour d√©chiffrer une cl√©
def decrypt_encryption_key(encrypted_data: bytes, master_password: str) -> bytes:
    try:
        salt = encrypted_data[:16]
        iv = encrypted_data[16:28]
        tag = encrypted_data[28:44]
        encrypted_key = encrypted_data[44:]

        master_key = derive_key(master_password, salt)
        cipher = Cipher(algorithms.AES(master_key), modes.GCM(iv, tag), backend=default_backend())
        decryptor = cipher.decryptor()
        return decryptor.update(encrypted_key) + decryptor.finalize()
    except Exception as e:
        logger.error("Erreur lors du d√©chiffrement de la cl√© : %s", e)
        raise

# Fonction pour v√©rifier la signature d'un webhook
def verify_webhook_signature(signature: str, payload: str, secret_key: str) -> bool:
    """
    V√©rifie la signature HMAC d'un webhook pour s'assurer qu'il vient de la source autoris√©e.
    """
    expected_signature = hmac.new(secret_key.encode(), payload.encode(), hashlib.sha256).hexdigest()
    return hmac.compare_digest(signature, expected_signature)

# Exemple d'utilisation en ligne de commande
if __name__ == "__main__":
    try:
        # Demander un mot de passe ma√Ætre √† l'utilisateur
        master_password = input("Entrez votre mot de passe ma√Ætre pour s√©curiser la cl√© : ").strip()
        if len(master_password) < 8:
            raise ValueError("Le mot de passe ma√Ætre doit contenir au moins 8 caract√®res.")

        # G√©n√©ration d'une cl√© de chiffrement al√©atoire
        encryption_key = os.urandom(32)

        # Chiffrement de la cl√©
        encrypted_key = encrypt_encryption_key(encryption_key, master_password)
        logger.info(f"Cl√© chiffr√©e (base64) : {encrypted_key}")

        # Sauvegarde dans un fichier
        with open("encrypted_key.txt", "wb") as file:
            file.write(encrypted_key)

        # Lecture depuis le fichier
        with open("encrypted_key.txt", "rb") as file:
            stored_encrypted_key = file.read()

        # D√©chiffrement de la cl√©
        decrypted_key = decrypt_encryption_key(stored_encrypted_key, master_password)
        assert encryption_key == decrypted_key, "La cl√© d√©chiffr√©e ne correspond pas √† l'originale."
        logger.info("Chiffrement et d√©chiffrement r√©ussis.")
    except Exception as e:
        logger.error(f"Une erreur critique s'est produite : {e}")
        
class ActionGenerateVisualization(Action):
    def name(self) -> str:
        return "action_generate_visualization"

    def run(self, dispatcher: CollectingDispatcher,
            tracker: Tracker,
            domain: DomainDict) -> list:
        """
        G√©n√®re un graphique bas√© sur les donn√©es utilisateur ou des valeurs par d√©faut.
        Offre plusieurs types de graphiques selon la demande utilisateur.
        """
        user_message = tracker.latest_message.get('text', "").lower()
        logger.info(f"Message utilisateur re√ßu : {user_message}")

        try:
            # Extraction des donn√©es utilisateur
            if "donn√©es" in user_message:
                data = [int(num) for num in user_message.split() if num.isdigit()]
                logger.info(f"Donn√©es utilisateur extraites : {data}")
            else:
                data = [10, 20, 30, 40]  # Valeurs par d√©faut
                logger.info("Aucune donn√©e utilisateur d√©tect√©e, valeurs par d√©faut utilis√©es.")

            if not data:
                dispatcher.utter_message(text="Je n'ai pas trouv√© de donn√©es valides pour g√©n√©rer un graphique.")
                return []

            # Choix du type de graphique
            chart_type = "bar"
            if "ligne" in user_message:
                chart_type = "line"
            elif "camembert" in user_message:
                chart_type = "pie"

            # G√©n√©ration du graphique
            plt.figure(figsize=(6, 4))
            if chart_type == "bar":
                plt.bar(range(len(data)), data, color='blue')
                plt.xlabel("Index")
                plt.ylabel("Valeurs")
            elif chart_type == "line":
                plt.plot(range(len(data)), data, marker='o', color='green')
                plt.xlabel("Index")
                plt.ylabel("Valeurs")
            elif chart_type == "pie":
                plt.pie(data, labels=[f"Part {i+1}" for i in range(len(data))], autopct='%1.1f%%')
            plt.title("Visualisation des donn√©es utilisateur")

            # Sauvegarde du graphique en Base64
            buffer = BytesIO()
            plt.savefig(buffer, format="png")
            buffer.seek(0)
            image_base64 = base64.b64encode(buffer.read()).decode('utf-8')
            buffer.close()
            plt.close()
            logger.info("Graphique g√©n√©r√© et encod√© avec succ√®s.")

            # Envoi du graphique encod√© au format Base64
            dispatcher.utter_message(
                text=f"Voici votre graphique ({chart_type}) :",
                image=f"data:image/png;base64,{image_base64}"
            )
        except Exception as e:
            logger.error(f"Erreur lors de la g√©n√©ration du graphique : {e}")
            dispatcher.utter_message(text="Une erreur est survenue lors de la g√©n√©ration du graphique.")

        return []
class FileManager:
    """
    G√®re l'importation, l'exportation et l'organisation des fichiers.
    """

    def __init__(self, base_dir: str = "files"):
        """
        Initialise le gestionnaire de fichiers.

        Args:
            base_dir (str): R√©pertoire de base pour sauvegarder les fichiers.
        """
        self.base_dir = base_dir
        os.makedirs(self.base_dir, exist_ok=True)

    def save_csv(self, data: Union[pd.DataFrame, List[Dict]], file_name: str) -> str:
        """
        Sauvegarde des donn√©es au format CSV.

        Args:
            data (Union[pd.DataFrame, List[Dict]]): Donn√©es √† sauvegarder.
            file_name (str): Nom du fichier CSV.

        Returns:
            str: Chemin du fichier sauvegard√©.
        """
        if isinstance(data, list):
            data = pd.DataFrame(data)
        if not isinstance(data, pd.DataFrame):
            raise ValueError("Les donn√©es doivent √™tre un DataFrame ou une liste de dictionnaires.")

        file_path = os.path.join(self.base_dir, file_name)
        data.to_csv(file_path, index=False)
        return file_path

    def save_json(self, data: Dict, file_name: str) -> str:
        """
        Sauvegarde des donn√©es au format JSON.

        Args:
            data (Dict): Donn√©es √† sauvegarder.
            file_name (str): Nom du fichier JSON.

        Returns:
            str: Chemin du fichier sauvegard√©.
        """
        file_path = os.path.join(self.base_dir, file_name)
        with open(file_path, "w") as f:
            json.dump(data, f, indent=4)
        return file_path

    def load_csv(self, file_name: str) -> pd.DataFrame:
        """
        Charge des donn√©es √† partir d'un fichier CSV.

        Args:
            file_name (str): Nom du fichier CSV.

        Returns:
            pd.DataFrame: Donn√©es charg√©es.
        """
        file_path = os.path.join(self.base_dir, file_name)
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Fichier introuvable : {file_path}")
        return pd.read_csv(file_path)

    def load_json(self, file_name: str) -> Dict:
        """
        Charge des donn√©es √† partir d'un fichier JSON.

        Args:
            file_name (str): Nom du fichier JSON.

        Returns:
            Dict: Donn√©es charg√©es.
        """
        file_path = os.path.join(self.base_dir, file_name)
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Fichier introuvable : {file_path}")
        with open(file_path, "r") as f:
            return json.load(f)

class SecureFileManager:
    def __init__(self, master_password: str):
        self.master_password = master_password.encode()

    def _generate_salt(self) -> bytes:
        return os.urandom(16)

    def _derive_key(self, salt: bytes) -> bytes:
        kdf = PBKDF2HMAC(
            algorithm=hashes.SHA256(),
            length=32,
            salt=salt,
            iterations=100000,
            backend=default_backend(),
        )
        return kdf.derive(self.master_password)

    def encrypt_data(self, data: bytes) -> str:
        salt = self._generate_salt()
        key = self._derive_key(salt)
        iv = os.urandom(12)
        cipher = Cipher(algorithms.AES(key), modes.GCM(iv), backend=default_backend())
        encryptor = cipher.encryptor()
        encrypted_data = encryptor.update(data) + encryptor.finalize()
        return base64.b64encode(salt + iv + encryptor.tag + encrypted_data).decode("utf-8")

    def decrypt_data(self, encrypted_data: str) -> bytes:
        decoded_data = base64.b64decode(encrypted_data)
        salt = decoded_data[:16]
        iv = decoded_data[16:28]
        tag = decoded_data[28:44]
        ciphertext = decoded_data[44:]
        key = self._derive_key(salt)
        cipher = Cipher(algorithms.AES(key), modes.GCM(iv, tag), backend=default_backend())
        decryptor = cipher.decryptor()
        return decryptor.update(ciphertext) + decryptor.finalize()

async def global_exception_handler(request, exc):
    return JSONResponse(
        status_code=500,
        content={"message": "Une erreur interne est survenue. Veuillez r√©essayer plus tard."}
    )
if __name__ == "__main__":
    # Exemple d'utilisation
    original_data = "Exemple de texte √† chiffrer".encode("utf-8")
    master_password = "supersecur3password"
    manager = SecureFileManager(master_password)

    # Chiffrement
    encrypted = manager.encrypt_data(original_data)
    print(f"Encrypted Data: {encrypted}")

    # D√©chiffrement
    decrypted = manager.decrypt_data(encrypted)
    print(f"Decrypted Data: {decrypted.decode('utf-8')}")

nlp = spacy.load("en_core_web_sm")

try:

    response = "Voici votre message : {placeholder}"
except KeyError as e:
    logger.error(f"Variable manquante dans la r√©ponse : {e}")
    text = "Une erreur est survenue dans la g√©n√©ration de la r√©ponse."

# Fonction pour lire un fichier texte
def lire_fichier(fichier: str) -> Optional[str]:
    """Lire un fichier texte et retourner son contenu."""
    try:
        with open(fichier, 'r', encoding='utf-8') as f:
            contenu = f.read()
        return contenu
    except FileNotFoundError:
        print(f"Le fichier {fichier} n'a pas √©t√© trouv√©.")
    except Exception as e:
        print(f"Erreur lors de la lecture du fichier : {e}")
    return None


# Fonction pour lire un fichier JSON
def lire_fichier_json(fichier: str) -> Optional[Dict[str, Any]]:
    """Lire un fichier JSON et retourner les donn√©es sous forme de dictionnaire."""
    try:
        with open(fichier, 'r', encoding='utf-8') as f:
            donn√©es = json.load(f)
        return donn√©es
    except FileNotFoundError:
        print(f"Le fichier {fichier} n'a pas √©t√© trouv√©.")
    except json.JSONDecodeError:
        print(f"Erreur de d√©codage JSON dans le fichier {fichier}.")
    except Exception as e:
        print(f"Erreur lors de la lecture du fichier : {e}")
    return None


# Fonction pour lire un fichier CSV
def lire_fichier_csv(fichier: str) -> Optional[pd.DataFrame]:
    """Lire un fichier CSV et le charger dans un DataFrame pandas."""
    try:
        donn√©es_csv = pd.read_csv(fichier)
        return donn√©es_csv
    except FileNotFoundError:
        print(f"Le fichier {fichier} n'a pas √©t√© trouv√©.")
    except pd.errors.EmptyDataError:
        print(f"Le fichier {fichier} est vide.")
    except Exception as e:
        print(f"Erreur lors de la lecture du fichier : {e}")
    return None


# Fonction d'analyse de texte avec spaCy
def analyse_texte(texte: str):
    """Analyser un texte avec spaCy pour extraire des entit√©s et faire du POS tagging."""
    doc = nlp(texte)

    # Extraire les entit√©s nomm√©es
    entit√©s = [(ent.text, ent.label_) for ent in doc.ents]

    # Afficher les r√©sultats de l'analyse de texte
    print("Entit√©s nomm√©es :")
    for ent in entit√©s:
        print(f"Texte: {ent[0]}, Type: {ent[1]}")

    print("\nAnalyse des tokens (part-of-speech tagging) :")
    for token in doc:
        print(f"{token.text}: {token.pos_}")


# Exemple d'analyse avec un fichier
def traiter_fichier(fichier: str):
    """Traiter un fichier en fonction de son type (texte, CSV, JSON)."""
    if fichier.endswith(".txt"):
        contenu = lire_fichier(fichier)
        if contenu:
            print(f"Analyse du fichier texte {fichier}:\n")
            analyse_texte(contenu)

    elif fichier.endswith(".json"):
        donn√©es_json = lire_fichier_json(fichier)
        if donn√©es_json:
            print(f"Analyse du fichier JSON {fichier}:")
            print(donn√©es_json)

    elif fichier.endswith(".csv"):
        donn√©es_csv = lire_fichier_csv(fichier)
        if donn√©es_csv is not None:
            print(f"Analyse du fichier CSV {fichier}:")
            print(donn√©es_csv.head())  # Affiche les premi√®res lignes du CSV

    else:
        print(f"Format de fichier non pris en charge : {fichier}")


# Fonction principale pour ex√©cuter le script
def main():
    fichier = input("Entrez le chemin du fichier √† analyser : ")

    if os.path.exists(fichier):
        traiter_fichier(fichier)
    else:
        print(f"Le fichier {fichier} n'existe pas.")


# Lancer l'ex√©cution du programme
if __name__ == "__main__":
    main()



class CustomIntentClassifier(GraphComponent):
    def __init__(self, config=None):
        self.config = config or {}

    def train(self, training_data: TrainingData):
        sentences = [example.text for example in training_data.training_examples]
        intents = [example.get(INTENT) for example in training_data.training_examples]

        # Pr√©paration des donn√©es (simplifi√©e)
        self.vectorizer = tf.keras.layers.TextVectorization(max_tokens=10000, output_sequence_length=100)
        self.vectorizer.adapt(sentences)

        X = self.vectorizer(sentences)
        y = tf.keras.utils.to_categorical([training_data.intents.index(intent) for intent in intents])

        # Mod√®le TensorFlow
        self.model = tf.keras.Sequential([
            tf.keras.layers.Embedding(input_dim=10000, output_dim=64),
            tf.keras.layers.GlobalAveragePooling1D(),
            tf.keras.layers.Dense(64, activation="relu"),
            tf.keras.layers.Dense(len(training_data.intents), activation="softmax")
        ])
        self.model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])
        self.model.fit(X, y, epochs=5, batch_size=32)

    def process(self, message, **kwargs):
        sentence = tf.constant([message.text])
        X = self.vectorizer(sentence)
        probabilities = self.model.predict(X)
        intent_index = np.argmax(probabilities)
        intent_name = self.config["intents"][intent_index]

        # Mise √† jour du message avec l'intention d√©tect√©e
        message.set(INTENT, {"name": intent_name, "confidence": float(probabilities[0][intent_index])})

    @classmethod
    def create(cls, config, model_storage, resource, execution_context):
        return cls(config)


class APIIntegrationManager:
    """
    G√®re les int√©grations avec des APIs tierces, avec support pour le cache et les limites de taux.
    """

    def __init__(self, cache_ttl: int = 3600, rate_limit: int = 60):
        """
        Initialise le gestionnaire API.

        Args:
            cache_ttl (int): Temps de vie des entr√©es en cache en secondes.
            rate_limit (int): Limite des appels API par minute.
        """
        self.api_keys = {}
        self.api_endpoints = {}
        self.response_cache = TTLCache(maxsize=1000, ttl=cache_ttl)
        self.rate_limit = rate_limit
        self.last_call_time = {}
        logger.info("APIIntegrationManager initialized with caching and rate limiting.")

    def add_api(self, api_name: str, base_url: str, api_key: Optional[str] = None):
        """
        Ajoute une nouvelle API √† g√©rer.

        Args:
            api_name (str): Nom de l'API.
            base_url (str): URL de base de l'API.
            api_key (Optional[str]): Cl√© API si n√©cessaire.
        """
        self.api_endpoints[api_name] = base_url
        if api_key:
            self.api_keys[api_name] = api_key
        logger.info(f"API '{api_name}' added with base URL: {base_url}.")

    def rate_limiter(self, api_name: str):
        """
        Applique une limite de taux sur les appels API.

        Args:
            api_name (str): Nom de l'API.
        """
        if api_name in self.last_call_time:
            elapsed_time = time.time() - self.last_call_time[api_name]
            wait_time = max(0, (60 / self.rate_limit) - elapsed_time)
            if wait_time > 0:
                logger.info(f"Rate limit reached for API '{api_name}'. Waiting {wait_time:.2f} seconds...")
                time.sleep(wait_time)
        self.last_call_time[api_name] = time.time()

    def make_request(self, api_name: str, endpoint: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Effectue un appel API avec gestion des erreurs et mise en cache.

        Args:
            api_name (str): Nom de l'API.
            endpoint (str): Endpoint sp√©cifique.
            params (Optional[Dict[str, Any]]): Param√®tres de requ√™te.

        Returns:
            Dict[str, Any]: R√©ponse JSON de l'API.
        """
        try:
            if api_name not in self.api_endpoints:
                raise ValueError(f"API '{api_name}' is not configured.")

            base_url = self.api_endpoints[api_name]
            url = f"{base_url}/{endpoint}"
            params = params or {}

            # Ajouter la cl√© API si n√©cessaire
            if api_name in self.api_keys:
                params["api_key"] = self.api_keys[api_name]

            # Gestion du cache
            cache_key = f"{api_name}:{endpoint}:{str(params)}"
            if cache_key in self.response_cache:
                logger.info(f"Cache hit for API '{api_name}' and endpoint '{endpoint}'.")
                return self.response_cache[cache_key]

            # Appliquer la limite de taux
            self.rate_limiter(api_name)

            # Effectuer la requ√™te
            logger.info(f"Making request to API '{api_name}' at endpoint '{endpoint}'...")
            response = requests.get(url, params=params)
            response.raise_for_status()
            data = response.json()

            # Ajouter au cache
            self.response_cache[cache_key] = data
            logger.info(f"Request successful for API '{api_name}' at endpoint '{endpoint}'.")
            return data
        except requests.exceptions.RequestException as e:
            logger.error(f"Error during API request to '{api_name}': {e}")
            return {"error": "API request failed."}
        except Exception as e:
            logger.error(f"Unexpected error during API request to '{api_name}': {e}")
            return {"error": "An unexpected error occurred."}

    def get_cached_response(self, api_name: str, endpoint: str, params: Optional[Dict[str, Any]] = None) -> Optional[Dict[str, Any]]:
        """
        R√©cup√®re une r√©ponse mise en cache si disponible.

        Args:
            api_name (str): Nom de l'API.
            endpoint (str): Endpoint sp√©cifique.
            params (Optional[Dict[str, Any]]): Param√®tres de requ√™te.

        Returns:
            Optional[Dict[str, Any]]: R√©ponse mise en cache ou None si non trouv√©e.
        """
        cache_key = f"{api_name}:{endpoint}:{str(params)}"
        return self.response_cache.get(cache_key)

    def remove_cached_response(self, api_name: str, endpoint: str, params: Optional[Dict[str, Any]] = None):
        """
        Supprime une r√©ponse mise en cache.

        Args:
            api_name (str): Nom de l'API.
            endpoint (str): Endpoint sp√©cifique.
            params (Optional[Dict[str, Any]]): Param√®tres de requ√™te.
        """
        cache_key = f"{api_name}:{endpoint}:{str(params)}"
        if cache_key in self.response_cache:
            del self.response_cache[cache_key]
            logger.info(f"Cache entry removed for API '{api_name}' and endpoint '{endpoint}'.")

    def clear_cache(self):
        """
        Efface tout le cache.
        """
        self.response_cache.clear()
        logger.info("All API cache cleared.")

class VisualizationService:
    """
    Service pour cr√©er et exporter des visualisations interactives et statiques.
    """

    def __init__(self, output_dir: str = "visualizations"):
        """
        Initialise le service de visualisation.

        Args:
            output_dir (str): R√©pertoire pour sauvegarder les graphiques export√©s.
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        logger.info(f"VisualizationService initialized. Output directory: {output_dir}")

    def create_bar_chart(self, data: Dict[str, int], title: str = "Bar Chart") -> go.Figure:
        """
        Cr√©e un graphique en barres.

        Args:
            data (Dict[str, int]): Donn√©es au format {cat√©gorie: valeur}.
            title (str): Titre du graphique.

        Returns:
            go.Figure: Graphique interactif Plotly.
        """
        try:
            logger.info("Creating bar chart...")
            fig = go.Figure(data=[go.Bar(x=list(data.keys()), y=list(data.values()))])
            fig.update_layout(title=title, xaxis_title="Categories", yaxis_title="Values")
            logger.info("Bar chart created successfully.")
            return fig
        except Exception as e:
            logger.error(f"Error creating bar chart: {e}")
            return go.Figure()

    def create_pie_chart(self, data: Dict[str, int], title: str = "Pie Chart") -> go.Figure:
        """
        Cr√©e un graphique en camembert.

        Args:
            data (Dict[str, int]): Donn√©es au format {cat√©gorie: valeur}.
            title (str): Titre du graphique.

        Returns:
            go.Figure: Graphique interactif Plotly.
        """
        try:
            logger.info("Creating pie chart...")
            fig = go.Figure(data=[go.Pie(labels=list(data.keys()), values=list(data.values()))])
            fig.update_layout(title=title)
            logger.info("Pie chart created successfully.")
            return fig
        except Exception as e:
            logger.error(f"Error creating pie chart: {e}")
            return go.Figure()

    def create_scatter_plot(self, x: List[float], y: List[float], title: str = "Scatter Plot") -> go.Figure:
        """
        Cr√©e un graphique en nuage de points.

        Args:
            x (List[float]): Coordonn√©es X.
            y (List[float]): Coordonn√©es Y.
            title (str): Titre du graphique.

        Returns:
            go.Figure: Graphique interactif Plotly.
        """
        try:
            logger.info("Creating scatter plot...")
            fig = go.Figure(data=[go.Scatter(x=x, y=y, mode='markers')])
            fig.update_layout(title=title, xaxis_title="X Axis", yaxis_title="Y Axis")
            logger.info("Scatter plot created successfully.")
            return fig
        except Exception as e:
            logger.error(f"Error creating scatter plot: {e}")
            return go.Figure()

    def export_chart(self, fig: go.Figure, file_name: str = "chart.html", export_as_image: bool = False):
        """
        Exporte un graphique interactif au format HTML et optionnellement comme image.

        Args:
            fig (go.Figure): Graphique Plotly.
            file_name (str): Nom du fichier export√©.
            export_as_image (bool): Exporter aussi en tant qu'image (PNG).
        """
        try:
            output_path = os.path.join(self.output_dir, file_name)
            fig.write_html(output_path)
            logger.info(f"Chart exported to {output_path}.")

            if export_as_image:
                image_path = output_path.replace(".html", ".png")
                fig.write_image(image_path)
                logger.info(f"Chart exported as image to {image_path}.")
        except Exception as e:
            logger.error(f"Error exporting chart: {e}")

    def create_and_export_bar_chart(self, data: Dict[str, int], title: str, file_name: str):
        """
        Pipeline pour cr√©er et exporter un graphique en barres.

        Args:
            data (Dict[str, int]): Donn√©es au format {cat√©gorie: valeur}.
            title (str): Titre du graphique.
            file_name (str): Nom du fichier export√©.
        """
        fig = self.create_bar_chart(data, title)
        self.export_chart(fig, file_name)

    def visualize_dataframe(self, df: pd.DataFrame, x_column: str, y_column: str, chart_type: str = "scatter", title: str = "Chart"):
        """
        Cr√©e un graphique √† partir d'un DataFrame.

        Args:
            df (pd.DataFrame): DataFrame contenant les donn√©es.
            x_column (str): Colonne pour l'axe X.
            y_column (str): Colonne pour l'axe Y.
            chart_type (str): Type de graphique ("scatter", "bar").
            title (str): Titre du graphique.

        Returns:
            go.Figure: Graphique interactif.
        """
        try:
            logger.info(f"Creating {chart_type} chart from DataFrame...")
            if chart_type == "scatter":
                return self.create_scatter_plot(df[x_column].tolist(), df[y_column].tolist(), title)
            elif chart_type == "bar":
                data = df.groupby(x_column)[y_column].sum().to_dict()
                return self.create_bar_chart(data, title)
            else:
                logger.error(f"Unsupported chart type: {chart_type}")
                return go.Figure()
        except Exception as e:
            logger.error(f"Error visualizing DataFrame: {e}")
            return go.Figure()

class UserConsentManager:
    """
    G√®re les consentements des utilisateurs pour des actions sp√©cifiques.
    """

    def __init__(self, db_manager):
        """
        Initialise le gestionnaire de consentement.

        Args:
            db_manager: Gestionnaire de base de donn√©es pour stocker les consentements.
        """
        self.db_manager = db_manager
        logger.info("UserConsentManager initialized with database integration.")

    async def record_consent(self, user_id: str, consent_type: str, consent_value: bool):
        """
        Enregistre ou met √† jour un consentement pour un utilisateur.

        Args:
            user_id (str): ID utilisateur.
            consent_type (str): Type de consentement (e.g., "data_collection").
            consent_value (bool): Valeur du consentement (True ou False).
        """
        try:
            consent_record = {
                "user_id": user_id,
                "consent_type": consent_type,
                "consent_value": consent_value,
                "timestamp": datetime.datetime.utcnow()
            }
            await self.db_manager.save_consent(consent_record)
            logger.info(f"Consent recorded for user '{user_id}' and type '{consent_type}': {consent_value}")
        except Exception as e:
            logger.error(f"Error recording consent for user '{user_id}': {e}")

    async def validate_consent(self, user_id: str, consent_type: str) -> bool:
        """
        Valide si un utilisateur a donn√© son consentement pour une action sp√©cifique.

        Args:
            user_id (str): ID utilisateur.
            consent_type (str): Type de consentement requis.

        Returns:
            bool: True si le consentement est valide, sinon False.
        """
        try:
            consent = await self.db_manager.get_consent(user_id, consent_type)
            if consent and consent.get("consent_value"):
                logger.info(f"Valid consent found for user '{user_id}' and type '{consent_type}'.")
                return True
            logger.warning(f"No valid consent found for user '{user_id}' and type '{consent_type}'.")
            return False
        except Exception as e:
            logger.error(f"Error validating consent for user '{user_id}': {e}")
            return False

    async def revoke_consent(self, user_id: str, consent_type: Optional[str] = None):
        """
        R√©voque un ou tous les consentements d'un utilisateur.

        Args:
            user_id (str): ID utilisateur.
            consent_type (Optional[str]): Type sp√©cifique de consentement √† r√©voquer. Si None, r√©voque tous les consentements.
        """
        try:
            if consent_type:
                await self.db_manager.delete_consent(user_id, consent_type)
                logger.info(f"Consent revoked for user '{user_id}' and type '{consent_type}'.")
            else:
                await self.db_manager.delete_all_consents(user_id)
                logger.info(f"All consents revoked for user '{user_id}'.")
        except Exception as e:
            logger.error(f"Error revoking consent for user '{user_id}': {e}")

    async def list_user_consents(self, user_id: str) -> Dict[str, Any]:
        """
        R√©cup√®re tous les consentements d'un utilisateur.

        Args:
            user_id (str): ID utilisateur.

        Returns:
            Dict[str, Any]: Consentements de l'utilisateur.
        """
        try:
            consents = await self.db_manager.get_all_consents(user_id)
            logger.info(f"Listed consents for user '{user_id}': {consents}")
            return consents
        except Exception as e:
            logger.error(f"Error listing consents for user '{user_id}': {e}")
            return {}

    async def is_consent_required(self, user_id: str, consent_type: str) -> bool:
        """
        V√©rifie si un consentement est requis pour un utilisateur.

        Args:
            user_id (str): ID utilisateur.
            consent_type (str): Type de consentement.

        Returns:
            bool: True si le consentement est requis, sinon False.
        """
        try:
            required_consents = ["data_collection", "notifications"]  # Exemple de types requis
            if consent_type in required_consents:
                logger.info(f"Consent required for user '{user_id}' and type '{consent_type}'.")
                return True
            logger.info(f"Consent not required for user '{user_id}' and type '{consent_type}'.")
            return False
        except Exception as e:
            logger.error(f"Error checking if consent is required for user '{user_id}': {e}")
            return False

class InteractionLogger:
    """
    G√®re l'enregistrement et la r√©cup√©ration des interactions utilisateur.
    """

    def __init__(self, storage_type: str = "json", storage_path: str = "interactions", db_manager=None):
        """
        Initialise le logger d'interactions.

        Args:
            storage_type (str): Type de stockage ('json', 'database').
            storage_path (str): Chemin pour les fichiers JSON.
            db_manager: Gestionnaire de base de donn√©es (si 'database' est utilis√©).
        """
        self.storage_type = storage_type
        self.storage_path = storage_path
        self.db_manager = db_manager

        if storage_type == "json":
            os.makedirs(storage_path, exist_ok=True)
            logger.info(f"InteractionLogger initialized for JSON storage at '{storage_path}'.")
        elif storage_type == "database":
            if not db_manager:
                raise ValueError("A database manager must be provided for 'database' storage.")
            logger.info("InteractionLogger initialized for database storage.")

    def _get_json_file_path(self, user_id: str) -> str:
        """
        G√©n√®re le chemin du fichier JSON pour un utilisateur.

        Args:
            user_id (str): ID utilisateur.

        Returns:
            str: Chemin complet du fichier JSON.
        """
        return os.path.join(self.storage_path, f"{user_id}_interactions.json")

    def save_interaction(self, user_id: str, message: str, response: str, metadata: Optional[Dict[str, Any]] = None):
        """
        Enregistre une interaction utilisateur.

        Args:
            user_id (str): ID utilisateur.
            message (str): Message utilisateur.
            response (str): R√©ponse g√©n√©r√©e.
            metadata (Optional[Dict[str, Any]]): M√©tadonn√©es suppl√©mentaires.
        """
        try:
            interaction = {
                "user_id": user_id,
                "message": message,
                "response": response,
                "metadata": metadata or {},
                "timestamp": datetime.datetime.utcnow().isoformat()
            }

            if self.storage_type == "json":
                file_path = self._get_json_file_path(user_id)
                if os.path.exists(file_path):
                    with open(file_path, "r") as file:
                        interactions = json.load(file)
                else:
                    interactions = []
                interactions.append(interaction)
                with open(file_path, "w") as file:
                    json.dump(interactions, file, indent=4)
                logger.info(f"Interaction saved to JSON for user '{user_id}'.")
            elif self.storage_type == "database":
                self.db_manager.save_interaction(interaction)
                logger.info(f"Interaction saved to database for user '{user_id}'.")
        except Exception as e:
            logger.error(f"Error saving interaction for user '{user_id}': {e}")

    def get_interactions(self, user_id: str) -> List[Dict[str, Any]]:
        """
        R√©cup√®re les interactions d'un utilisateur.

        Args:
            user_id (str): ID utilisateur.

        Returns:
            List[Dict[str, Any]]: Liste des interactions.
        """
        try:
            if self.storage_type == "json":
                file_path = self._get_json_file_path(user_id)
                if os.path.exists(file_path):
                    with open(file_path, "r") as file:
                        interactions = json.load(file)
                    logger.info(f"Interactions retrieved from JSON for user '{user_id}'.")
                    return interactions
                else:
                    logger.warning(f"No interactions found for user '{user_id}' in JSON.")
                    return []
            elif self.storage_type == "database":
                interactions = self.db_manager.get_interactions(user_id)
                logger.info(f"Interactions retrieved from database for user '{user_id}'.")
                return interactions
        except Exception as e:
            logger.error(f"Error retrieving interactions for user '{user_id}': {e}")
            return []

    def search_interactions(self, user_id: str, keyword: str) -> List[Dict[str, Any]]:
        """
        Recherche des interactions contenant un mot-cl√©.

        Args:
            user_id (str): ID utilisateur.
            keyword (str): Mot-cl√© √† rechercher.

        Returns:
            List[Dict[str, Any]]: Liste des interactions correspondantes.
        """
        try:
            interactions = self.get_interactions(user_id)
            results = [i for i in interactions if keyword.lower() in i["message"].lower() or keyword.lower() in i["response"].lower()]
            logger.info(f"Found {len(results)} interactions for user '{user_id}' containing keyword '{keyword}'.")
            return results
        except Exception as e:
            logger.error(f"Error searching interactions for user '{user_id}': {e}")
            return []

    def delete_interactions(self, user_id: str):
        """
        Supprime toutes les interactions d'un utilisateur.

        Args:
            user_id (str): ID utilisateur.
        """
        try:
            if self.storage_type == "json":
                file_path = self._get_json_file_path(user_id)
                if os.path.exists(file_path):
                    os.remove(file_path)
                    logger.info(f"All interactions deleted for user '{user_id}' in JSON.")
                else:
                    logger.warning(f"No interactions to delete for user '{user_id}' in JSON.")
            elif self.storage_type == "database":
                self.db_manager.delete_interactions(user_id)
                logger.info(f"All interactions deleted for user '{user_id}' in database.")
        except Exception as e:
            logger.error(f"Error deleting interactions for user '{user_id}': {e}")

class UserPreferenceManager:
    """
    G√®re les pr√©f√©rences utilisateur pour la personnalisation des services.
    """

    def __init__(self, db_manager):
        """
        Initialise le gestionnaire de pr√©f√©rences utilisateur.

        Args:
            db_manager: Gestionnaire de base de donn√©es pour stocker les pr√©f√©rences.
        """
        self.db_manager = db_manager
        logger.info("UserPreferenceManager initialized with database integration.")

    async def set_preference(self, user_id: str, key: str, value: Any):
        """
        D√©finit ou met √† jour une pr√©f√©rence utilisateur.

        Args:
            user_id (str): ID utilisateur.
            key (str): Cl√© de la pr√©f√©rence.
            value (Any): Valeur associ√©e √† la pr√©f√©rence.
        """
        try:
            preference = {"user_id": user_id, "key": key, "value": value}
            await self.db_manager.save_preference(preference)
            logger.info(f"Preference set for user '{user_id}' with key '{key}' and value '{value}'.")
        except Exception as e:
            logger.error(f"Error setting preference for user '{user_id}': {e}")

    async def get_preference(self, user_id: str, key: str) -> Optional[Any]:
        """
        R√©cup√®re une pr√©f√©rence utilisateur.

        Args:
            user_id (str): ID utilisateur.
            key (str): Cl√© de la pr√©f√©rence.

        Returns:
            Optional[Any]: Valeur associ√©e √† la pr√©f√©rence ou None si non trouv√©e.
        """
        try:
            preference = await self.db_manager.get_preference(user_id, key)
            if preference:
                logger.info(f"Preference retrieved for user '{user_id}' with key '{key}': {preference['value']}")
                return preference["value"]
            logger.warning(f"No preference found for user '{user_id}' with key '{key}'.")
            return None
        except Exception as e:
            logger.error(f"Error retrieving preference for user '{user_id}': {e}")
            return None

    async def list_preferences(self, user_id: str) -> Dict[str, Any]:
        """
        R√©cup√®re toutes les pr√©f√©rences d'un utilisateur.

        Args:
            user_id (str): ID utilisateur.

        Returns:
            Dict[str, Any]: Dictionnaire des pr√©f√©rences utilisateur.
        """
        try:
            preferences = await self.db_manager.get_all_preferences(user_id)
            preferences_dict = {pref["key"]: pref["value"] for pref in preferences}
            logger.info(f"All preferences listed for user '{user_id}': {preferences_dict}")
            return preferences_dict
        except Exception as e:
            logger.error(f"Error listing preferences for user '{user_id}': {e}")
            return {}

    async def delete_preference(self, user_id: str, key: Optional[str] = None):
        """
        Supprime une ou toutes les pr√©f√©rences d'un utilisateur.

        Args:
            user_id (str): ID utilisateur.
            key (Optional[str]): Cl√© sp√©cifique de la pr√©f√©rence √† supprimer. Si None, toutes les pr√©f√©rences seront supprim√©es.
        """
        try:
            if key:
                await self.db_manager.delete_preference(user_id, key)
                logger.info(f"Preference with key '{key}' deleted for user '{user_id}'.")
            else:
                await self.db_manager.delete_all_preferences(user_id)
                logger.info(f"All preferences deleted for user '{user_id}'.")
        except Exception as e:
            logger.error(f"Error deleting preferences for user '{user_id}': {e}")

    async def has_preference(self, user_id: str, key: str) -> bool:
        """
        V√©rifie si un utilisateur a d√©fini une pr√©f√©rence sp√©cifique.

        Args:
            user_id (str): ID utilisateur.
            key (str): Cl√© de la pr√©f√©rence.

        Returns:
            bool: True si la pr√©f√©rence existe, sinon False.
        """
        try:
            preference = await self.db_manager.get_preference(user_id, key)
            exists = preference is not None
            logger.info(f"Preference existence check for user '{user_id}' and key '{key}': {exists}")
            return exists
        except Exception as e:
            logger.error(f"Error checking preference existence for user '{user_id}': {e}")
            return False



class ActionProvideFeedback(Action):
    """
    G√®re les feedbacks utilisateurs, analyse leur sentiment via des r√®gles, et met √† jour les slots.
    """

    def name(self) -> str:
        """
        Retourne le nom de l'action pour Rasa.
        """
        return "action_provide_feedback"

    async def run(self, dispatcher: CollectingDispatcher,
                  tracker: Tracker,
                  domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Traite le feedback utilisateur, analyse son sentiment, et met √† jour les slots.

        Args:
            dispatcher: Pour envoyer des messages √† l'utilisateur.
            tracker: Contient l'√©tat actuel du dialogue.
            domain: Le domaine de l'application.

        Returns:
            Une liste d'√©v√©nements pour mettre √† jour les slots.
        """
        try:
            # R√©cup√©rer le message utilisateur et les slots
            user_message = tracker.latest_message.get('text', "").strip()
            feedback_slot = tracker.get_slot("user_feedback")

            if not user_message:
                dispatcher.utter_message(text="Je n'ai pas re√ßu de feedback. Pouvez-vous r√©essayer‚ÄØ?")
                logger.warning("Message utilisateur vide.")
                return []

            # Analyser le sentiment du feedback
            sentiment = self.analyze_sentiment(user_message)

            # R√©ponse dynamique selon le sentiment
            if not feedback_slot:
                feedback_slot = user_message
                dispatcher.utter_message(text=f"Merci pour votre retour‚ÄØ: '{feedback_slot}'")
            else:
                dispatcher.utter_message(text=f"Votre feedback pr√©c√©dent √©tait‚ÄØ: '{feedback_slot}'")

            # Messages bas√©s sur le sentiment d√©tect√©
            sentiment_response = {
                "positif": "Merci pour vos encouragements‚ÄØ! Nous sommes ravis de vous satisfaire. üòä",
                "n√©gatif": "Je suis d√©sol√© pour cela. Pouvez-vous m'expliquer davantage pour que je puisse aider‚ÄØ?",
                "neutre": "Merci pour votre retour. Nous allons continuer √† nous am√©liorer‚ÄØ!"
            }
            dispatcher.utter_message(text=sentiment_response.get(sentiment, "Merci pour votre retour."))

            # Mettre √† jour les slots
            return [
                SlotSet("user_feedback", feedback_slot),
                SlotSet("feedback_sentiment", sentiment)
            ]

        except Exception as e:
            # Gestion des erreurs
            logger.error(f"Erreur lors du traitement du feedback : {e}")
            dispatcher.utter_message(text="Une erreur est survenue lors de l'analyse du feedback. Veuillez r√©essayer.")
            return []

    def analyze_sentiment(self, feedback: str) -> str:
        """
        Analyse le sentiment du feedback en utilisant une approche bas√©e sur des mots-cl√©s pond√©r√©s.

        Args:
            feedback: Texte du feedback utilisateur.

        Returns:
            str: Sentiment d√©tect√© ('positif', 'n√©gatif', ou 'neutre').
        """
        try:
            # D√©finir des mots-cl√©s et leurs pond√©rations
            keywords = {
                "positif": {"super": 2, "bien": 1, "merci": 1, "excellent": 3, "parfait": 3, "g√©nial": 2},
                "n√©gatif": {"mauvais": 2, "probl√®me": 3, "nul": 3, "terrible": 2, "horrible": 3, "pas bien": 2}
            }

            # Initialiser les scores
            positive_score = sum(weight for word, weight in keywords["positif"].items() if word in feedback.lower())
            negative_score = sum(weight for word, weight in keywords["n√©gatif"].items() if word in feedback.lower())

            # Identifier le sentiment
            if positive_score > negative_score:
                return "positif"
            elif negative_score > positive_score:
                return "n√©gatif"
            else:
                return "neutre"

        except Exception as e:
            logger.error(f"Erreur lors de l'analyse du sentiment : {e}")
            return "neutre"

class NotificationService:
    """
    Service de gestion et d'envoi de notifications multi-canaux (email, SMS, push, etc.).
    """

    def __init__(self, email_config: Dict[str, Any] = None, sms_config: Dict[str, Any] = None):
        """
        Initialise le service de notification avec des configurations d'email et de SMS.

        Args:
            email_config (Dict[str, Any]): Configuration pour l'email (smtp, username, password).
            sms_config (Dict[str, Any]): Configuration pour SMS (Twilio SID, token, etc.).
        """
        self.email_config = email_config or {}
        self.sms_config = sms_config or {}
        logger.info("NotificationService initialized.")

    def send_email(self, to: str, subject: str, body: str):
        """
        Envoie un email via SMTP.

        Args:
            to (str): Destinataire de l'email.
            subject (str): Sujet de l'email.
            body (str): Corps de l'email.
        """
        try:
            msg = MIMEMultipart()
            msg["From"] = self.email_config.get("sender_email")
            msg["To"] = to
            msg["Subject"] = subject
            msg.attach(MIMEText(body, "plain"))

            with smtplib.SMTP_SSL(self.email_config.get("smtp_server"), self.email_config.get("smtp_port")) as server:
                server.login(self.email_config.get("username"), self.email_config.get("password"))
                server.sendmail(self.email_config.get("sender_email"), to, msg.as_string())
            logger.info(f"Email sent to {to}.")
        except Exception as e:
            logger.error(f"Error sending email to {to}: {e}")

    def send_sms(self, to: str, message: str):
        """
        Envoie un SMS via Twilio.

        Args:
            to (str): Num√©ro de t√©l√©phone du destinataire.
            message (str): Corps du message.
        """
        try:
            client = Client(self.sms_config.get("sid"), self.sms_config.get("auth_token"))
            message = client.messages.create(
                body=message,
                from_=self.sms_config.get("from_number"),
                to=to
            )
            logger.info(f"SMS sent to {to}. SID: {message.sid}")
        except Exception as e:
            logger.error(f"Error sending SMS to {to}: {e}")

    def send_push_notification(self, user_id: str, message: str):
        """
        Envoie une notification push (exemple via un service externe).

        Args:
            user_id (str): ID utilisateur.
            message (str): Corps du message.
        """
        # Placeholder for push notification API
        try:
            # Example API call (depends on actual push service)
            # response = push_service.send_notification(user_id, message)
            logger.info(f"Push notification sent to user '{user_id}'.")
        except Exception as e:
            logger.error(f"Error sending push notification to user '{user_id}': {e}")

    def send_notification(self, user_id: str, channel: str, message: str):
        """
        Envoie une notification via le canal sp√©cifi√©.

        Args:
            user_id (str): ID utilisateur.
            channel (str): Canal de notification ('email', 'sms', 'push').
            message (str): Corps du message.
        """
        try:
            if channel == "email":
                # Email should be stored as user preference or fetched from user data
                to_email = "user@example.com"  # This should be dynamically fetched
                self.send_email(to_email, "Notification", message)
            elif channel == "sms":
                # SMS should be stored as user preference or fetched from user data
                to_phone = "+1234567890"  # This should be dynamically fetched
                self.send_sms(to_phone, message)
            elif channel == "push":
                self.send_push_notification(user_id, message)
            else:
                logger.warning(f"Unsupported notification channel: {channel}")
        except Exception as e:
            logger.error(f"Error sending notification to user '{user_id}' on channel '{channel}': {e}")

    def send_bulk_notifications(self, users: List[Dict[str, Any]], channel: str, message: str):
        """
        Envoie une notification en masse √† plusieurs utilisateurs.

        Args:
            users (List[Dict[str, Any]]): Liste d'utilisateurs avec leur ID et pr√©f√©rences de notification.
            channel (str): Canal de notification ('email', 'sms', 'push').
            message (str): Corps du message.
        """
        try:
            for user in users:
                user_id = user["user_id"]
                self.send_notification(user_id, channel, message)
            logger.info(f"Bulk notifications sent on channel '{channel}'.")
        except Exception as e:
            logger.error(f"Error sending bulk notifications: {e}")

class DataValidationService:
    """
    Service pour valider les donn√©es entrantes avant traitement.
    """

    def __init__(self):
        """
        Initialise le service de validation des donn√©es.
        """
        logger.info("DataValidationService initialized.")

    def validate_type(self, data: Any, expected_type: type) -> bool:
        """
        Valide le type de donn√©es.

        Args:
            data (Any): Donn√©e √† valider.
            expected_type (type): Type attendu.

        Returns:
            bool: True si le type correspond, sinon False.
        """
        if not isinstance(data, expected_type):
            logger.error(f"Data type validation failed. Expected {expected_type}, got {type(data)}.")
            return False
        return True

    def validate_required_fields(self, data: Dict[str, Any], required_fields: List[str]) -> bool:
        """
        Valide que les champs requis sont pr√©sents dans les donn√©es.

        Args:
            data (Dict[str, Any]): Donn√©es √† valider.
            required_fields (List[str]): Liste des champs requis.

        Returns:
            bool: True si tous les champs requis sont pr√©sents, sinon False.
        """
        missing_fields = [field for field in required_fields if field not in data]
        if missing_fields:
            logger.error(f"Missing required fields: {', '.join(missing_fields)}.")
            return False
        return True

    def validate_format(self, data: str, pattern: str) -> bool:
        """
        Valide un format de donn√©es (par exemple, email, t√©l√©phone) avec une expression r√©guli√®re.

        Args:
            data (str): Donn√©e √† valider.
            pattern (str): Expression r√©guli√®re pour valider le format.

        Returns:
            bool: True si le format est valide, sinon False.
        """
        import re
        if not re.match(pattern, data):
            logger.error(f"Data format validation failed for value: {data}. Expected pattern: {pattern}.")
            return False
        return True

    def validate_data(self, data: Dict[str, Any], validation_rules: Dict[str, Any]) -> bool:
        """
        Valide des donn√©es selon un ensemble de r√®gles de validation.

        Args:
            data (Dict[str, Any]): Donn√©es √† valider.
            validation_rules (Dict[str, Any]): R√®gles de validation sous forme de dictionnaire.

        Returns:
            bool: True si les donn√©es respectent les r√®gles, sinon False.
        """
        for field, rules in validation_rules.items():
            value = data.get(field)
            for rule, rule_value in rules.items():
                if rule == "required" and rule_value:
                    if value is None or value == "":
                        logger.error(f"Field '{field}' is required but missing or empty.")
                        return False
                if rule == "type" and not self.validate_type(value, rule_value):
                    logger.error(f"Field '{field}' has invalid type. Expected {rule_value}.")
                    return False
                if rule == "format" and not self.validate_format(value, rule_value):
                    logger.error(f"Field '{field}' has invalid format. Expected pattern: {rule_value}.")
                    return False
        logger.info("Data validation passed successfully.")
        return True

    def validate_nested_data(self, data: Dict[str, Any], validation_rules: Dict[str, Any]) -> bool:
        """
        Valide des donn√©es imbriqu√©es dans des structures complexes (par exemple, objets JSON imbriqu√©s).

        Args:
            data (Dict[str, Any]): Donn√©es √† valider.
            validation_rules (Dict[str, Any]): R√®gles de validation pour les donn√©es imbriqu√©es.

        Returns:
            bool: True si les donn√©es imbriqu√©es respectent les r√®gles, sinon False.
        """
        for field, sub_rules in validation_rules.items():
            value = data.get(field)
            if isinstance(value, dict):  # Si la valeur est un dictionnaire imbriqu√©
                if not self.validate_nested_data(value, sub_rules):  # Appel r√©cursif pour validation imbriqu√©e
                    logger.error(f"Nested data validation failed for field '{field}'.")
                    return False
            else:
                if not self.validate_data({field: value}, {field: sub_rules}):
                    logger.error(f"Data validation failed for field '{field}'.")
                    return False
        logger.info("Nested data validation passed successfully.")
        return True


class ReportGenerator:
    """
    G√®re la g√©n√©ration de rapports personnalis√©s √† partir des donn√©es.
    """

    def __init__(self, output_dir: str = "reports"):
        """
        Initialise le g√©n√©rateur de rapports.

        Args:
            output_dir (str): R√©pertoire pour sauvegarder les rapports g√©n√©r√©s.
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        logger.info(f"ReportGenerator initialized. Output directory: {output_dir}")

    def generate_pdf_report(self, data: pd.DataFrame, title: str = "Data Report") -> str:
        """
        G√©n√©re un rapport PDF √† partir des donn√©es.

        Args:
            data (pd.DataFrame): Donn√©es √† inclure dans le rapport.
            title (str): Titre du rapport.

        Returns:
            str: Chemin du fichier PDF g√©n√©r√©.
        """
        try:
            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", size=12)

            # Titre
            pdf.cell(200, 10, txt=title, ln=True, align="C")

            # Contenu
            for index, row in data.iterrows():
                row_str = ", ".join([str(cell) for cell in row])
                pdf.cell(200, 10, txt=row_str, ln=True)

            # Sauvegarde du rapport
            file_path = os.path.join(self.output_dir, f"{title.replace(' ', '_')}.pdf")
            pdf.output(file_path)
            logger.info(f"PDF report generated at {file_path}.")
            return file_path
        except Exception as e:
            logger.error(f"Error generating PDF report: {e}")
            return ""

    def generate_excel_report(self, data: pd.DataFrame, title: str = "Data Report") -> str:
        """
        G√©n√©re un rapport Excel √† partir des donn√©es.

        Args:
            data (pd.DataFrame): Donn√©es √† inclure dans le rapport.
            title (str): Titre du rapport.

        Returns:
            str: Chemin du fichier Excel g√©n√©r√©.
        """
        try:
            file_path = os.path.join(self.output_dir, f"{title.replace(' ', '_')}.xlsx")
            data.to_excel(file_path, index=False)
            logger.info(f"Excel report generated at {file_path}.")
            return file_path
        except Exception as e:
            logger.error(f"Error generating Excel report: {e}")
            return ""

    def generate_html_report(self, data: pd.DataFrame, title: str = "Data Report") -> str:
        """
        G√©n√©re un rapport HTML interactif √† partir des donn√©es.

        Args:
            data (pd.DataFrame): Donn√©es √† inclure dans le rapport.
            title (str): Titre du rapport.

        Returns:
            str: Chemin du fichier HTML g√©n√©r√©.
        """
        try:
            file_path = os.path.join(self.output_dir, f"{title.replace(' ', '_')}.html")
            data.to_html(file_path, index=False)
            logger.info(f"HTML report generated at {file_path}.")
            return file_path
        except Exception as e:
            logger.error(f"Error generating HTML report: {e}")
            return ""

    def generate_data_visualization(self, data: pd.DataFrame, chart_type: str = "bar",
                                    title: str = "Data Visualization") -> str:
        """
        G√©n√®re une visualisation des donn√©es sous forme de graphique.

        Args:
            data (pd.DataFrame): Donn√©es √† visualiser.
            chart_type (str): Type de graphique √† g√©n√©rer ('bar', 'line', 'scatter', etc.).
            title (str): Titre du graphique.

        Returns:
            str: Chemin du fichier image g√©n√©r√©.
        """
        try:
            plt.figure(figsize=(10, 6))
            if chart_type == "bar":
                data.plot(kind="bar")
            elif chart_type == "line":
                data.plot(kind="line")
            elif chart_type == "scatter":
                sns.scatterplot(x=data.columns[0], y=data.columns[1], data=data)
            else:
                logger.warning(f"Unsupported chart type: {chart_type}")

            # Sauvegarde du graphique
            chart_file_path = os.path.join(self.output_dir, f"{title.replace(' ', '_')}.png")
            plt.title(title)
            plt.savefig(chart_file_path)
            plt.close()
            logger.info(f"Data visualization saved as image at {chart_file_path}.")
            return chart_file_path
        except Exception as e:
            logger.error(f"Error generating data visualization: {e}")
            return ""

    def generate_and_export_report(self, data: pd.DataFrame, report_type: str = "pdf", title: str = "Data Report"):
        """
        G√©n√®re et exporte le rapport dans le format sp√©cifi√©.

        Args:
            data (pd.DataFrame): Donn√©es √† inclure dans le rapport.
            report_type (str): Type de rapport ('pdf', 'excel', 'html').
            title (str): Titre du rapport.
        """
        try:
            if report_type == "pdf":
                self.generate_pdf_report(data, title)
            elif report_type == "excel":
                self.generate_excel_report(data, title)
            elif report_type == "html":
                self.generate_html_report(data, title)
            else:
                logger.warning(f"Unsupported report type: {report_type}")
        except Exception as e:
            logger.error(f"Error generating and exporting report: {e}")

class AuditTrailManager:
    """
    G√®re les journaux d'audit pour suivre les actions utilisateurs et √©v√©nements syst√®me.
    """

    def __init__(self, storage_type: str = "json", storage_path: str = "audit_trails", db_manager=None):
        """
        Initialise le gestionnaire des journaux d‚Äôaudit.

        Args:
            storage_type (str): Type de stockage ('json' ou 'database').
            storage_path (str): R√©pertoire pour les fichiers JSON (si stockage en fichier).
            db_manager: Gestionnaire de base de donn√©es (si stockage en base).
        """
        self.storage_type = storage_type
        self.storage_path = storage_path
        self.db_manager = db_manager
        os.makedirs(storage_path, exist_ok=True)  # Pour stockage local dans des fichiers
        logger.info("AuditTrailManager initialized.")

    def _get_json_file_path(self) -> str:
        """
        G√©n√®re le chemin du fichier JSON o√π les logs seront stock√©s.

        Returns:
            str: Chemin du fichier de log.
        """
        return os.path.join(self.storage_path, f"audit_trail_{datetime.datetime.utcnow().strftime('%Y%m%d')}.json")

    def log_event(self, user_id: str, action: str, event_data: Optional[Dict[str, Any]] = None):
        """
        Enregistre un √©v√©nement dans le journal d‚Äôaudit.

        Args:
            user_id (str): ID utilisateur.
            action (str): Action effectu√©e par l‚Äôutilisateur.
            event_data (Optional[Dict[str, Any]]): Donn√©es suppl√©mentaires sur l'√©v√©nement.
        """
        event = {
            "user_id": user_id,
            "action": action,
            "event_data": event_data or {},
            "timestamp": datetime.datetime.utcnow().isoformat()
        }

        if self.storage_type == "json":
            file_path = self._get_json_file_path()
            try:
                if os.path.exists(file_path):
                    with open(file_path, "r") as file:
                        logs = json.load(file)
                else:
                    logs = []
                logs.append(event)
                with open(file_path, "w") as file:
                    json.dump(logs, file, indent=4)
                logger.info(f"Event logged to JSON: {event}")
            except Exception as e:
                logger.error(f"Error logging event to JSON: {e}")

        elif self.storage_type == "database" and self.db_manager:
            try:
                self.db_manager.save_event(event)
                logger.info(f"Event logged to database: {event}")
            except Exception as e:
                logger.error(f"Error logging event to database: {e}")

    def search_events(self, user_id: Optional[str] = None, action: Optional[str] = None,
                      start_date: Optional[str] = None, end_date: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        Recherche des √©v√©nements selon diff√©rents crit√®res (utilisateur, action, date).

        Args:
            user_id (Optional[str]): ID utilisateur (filtrage par utilisateur).
            action (Optional[str]): Type d'action (filtrage par action).
            start_date (Optional[str]): Date de d√©but du filtrage.
            end_date (Optional[str]): Date de fin du filtrage.

        Returns:
            List[Dict[str, Any]]: Liste des √©v√©nements correspondant aux crit√®res.
        """
        try:
            if self.storage_type == "json":
                file_path = self._get_json_file_path()
                if os.path.exists(file_path):
                    with open(file_path, "r") as file:
                        logs = json.load(file)
                    filtered_logs = [log for log in logs if self._matches_criteria(log, user_id, action, start_date, end_date)]
                    logger.info(f"Found {len(filtered_logs)} events matching criteria.")
                    return filtered_logs
                logger.warning("No log file found.")
                return []

            elif self.storage_type == "database" and self.db_manager:
                events = self.db_manager.get_events(user_id, action, start_date, end_date)
                logger.info(f"Found {len(events)} events in the database matching criteria.")
                return events

        except Exception as e:
            logger.error(f"Error searching events: {e}")
            return []

    def _matches_criteria(self, event: Dict[str, Any], user_id: Optional[str], action: Optional[str],
                          start_date: Optional[str], end_date: Optional[str]) -> bool:
        """
        V√©rifie si un √©v√©nement correspond aux crit√®res de recherche.

        Args:
            event (Dict[str, Any]): L'√©v√©nement √† v√©rifier.
            user_id (Optional[str]): ID utilisateur.
            action (Optional[str]): Type d'action.
            start_date (Optional[str]): Date de d√©but.
            end_date (Optional[str]): Date de fin.

        Returns:
            bool: True si l'√©v√©nement correspond aux crit√®res, sinon False.
        """
        if user_id and event["user_id"] != user_id:
            return False
        if action and event["action"] != action:
            return False
        if start_date and event["timestamp"] < start_date:
            return False
        if end_date and event["timestamp"] > end_date:
            return False
        return True

    def export_events(self, user_id: Optional[str] = None, start_date: Optional[str] = None,
                      end_date: Optional[str] = None, file_format: str = "json") -> str:
        """
        Exporte les √©v√©nements dans un format sp√©cifi√© (JSON, CSV).

        Args:
            user_id (Optional[str]): ID utilisateur.
            start_date (Optional[str]): Date de d√©but pour filtrer.
            end_date (Optional[str]): Date de fin pour filtrer.
            file_format (str): Format d'exportation ('json' ou 'csv').

        Returns:
            str: Chemin du fichier export√©.
        """
        events = self.search_events(user_id, None, start_date, end_date)
        if file_format == "json":
            file_path = os.path.join(self.storage_path, f"audit_trail_{datetime.datetime.utcnow().strftime('%Y%m%d')}.json")
            try:
                with open(file_path, "w") as file:
                    json.dump(events, file, indent=4)
                logger.info(f"Events exported to JSON at {file_path}.")
                return file_path
            except Exception as e:
                logger.error(f"Error exporting events to JSON: {e}")
                return ""

        elif file_format == "csv":
            file_path = os.path.join(self.storage_path, f"audit_trail_{datetime.datetime.utcnow().strftime('%Y%m%d')}.csv")
            try:
                import csv
                with open(file_path, mode="w", newline="") as file:
                    writer = csv.DictWriter(file, fieldnames=["user_id", "action", "event_data", "timestamp"])
                    writer.writeheader()
                    writer.writerows(events)
                logger.info(f"Events exported to CSV at {file_path}.")
                return file_path
            except Exception as e:
                logger.error(f"Error exporting events to CSV: {e}")
                return ""

        logger.error(f"Unsupported export format: {file_format}")
        return ""

class UserRequest(BaseModel):
    message: str
    tone: str = "friendly"

@app.post("/respond")
async def respond(request: UserRequest):
    """
    G√©n√®re une r√©ponse textuelle personnalis√©e.
    """
    try:
        # √âtape 1 : G√©n√©ration brute
        raw_response = nlp_processor.generate_response(request.message)

        # √âtape 2 : Validation √©thique
        refined_response = ethics_validator.validate_and_refine(raw_response)

        # √âtape 3 : Personnalisation du ton
        personalized_response = nlp_processor.adjust_tone(refined_response, request.tone)

        return {"response": personalized_response}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lors de la r√©ponse : {str(e)}")

@app.post("/speak")
async def speak(request: UserRequest):
    """
    G√©n√®re un fichier audio √† partir d'une r√©ponse textuelle.
    """
    try:
        # G√©n√©ration de la r√©ponse
        response = await respond(request)
        text_response = response["response"]

        # Conversion en audio
        audio_path = speech_synthesizer.text_to_speech(text_response)

        return {"message": "Audio g√©n√©r√© avec succ√®s", "audio_file": audio_path}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lors de la g√©n√©ration audio : {str(e)}")

class TaskQueueManager:
    """
    G√®re les t√¢ches dans une file d'attente et les ex√©cute de mani√®re asynchrone.
    """

    def __init__(self, max_concurrent_tasks: int = 5):
        """
        Initialise le gestionnaire de la file d'attente de t√¢ches.

        Args:
            max_concurrent_tasks (int): Nombre maximal de t√¢ches pouvant √™tre ex√©cut√©es en parall√®le.
        """
        self.queue = deque()
        self.running_tasks = set()
        self.max_concurrent_tasks = max_concurrent_tasks
        logger.info("TaskQueueManager initialized.")

    async def _execute_task(self, task_id: str, task: Callable[[], Any], metadata: Optional[Dict[str, Any]] = None):
        """
        Ex√©cute une t√¢che dans la file d'attente.

        Args:
            task_id (str): ID unique de la t√¢che.
            task (Callable[[], Any]): Fonction repr√©sentant la t√¢che √† ex√©cuter.
            metadata (Optional[Dict[str, Any]]): M√©tadonn√©es associ√©es √† la t√¢che.
        """
        try:
            logger.info(f"Starting task {task_id}.")
            result = await task()
            logger.info(f"Task {task_id} completed successfully. Result: {result}")
        except Exception as e:
            logger.error(f"Error executing task {task_id}: {e}")
            # Optionnel: Gestion des erreurs comme relancer la t√¢che
            metadata["status"] = "failed"
        finally:
            self.running_tasks.remove(task_id)
            await self._process_queue()

    async def _process_queue(self):
        """
        Traite les t√¢ches dans la file d'attente tant que la limite de t√¢ches concurrentes n'est pas atteinte.
        """
        while self.queue and len(self.running_tasks) < self.max_concurrent_tasks:
            task_id, task, metadata = self.queue.popleft()
            self.running_tasks.add(task_id)
            asyncio.create_task(self._execute_task(task_id, task, metadata))

    def add_task(self, task: Callable[[], Any], metadata: Optional[Dict[str, Any]] = None):
        """
        Ajoute une t√¢che √† la file d'attente.

        Args:
            task (Callable[[], Any]): Fonction repr√©sentant la t√¢che √† ajouter.
            metadata (Optional[Dict[str, Any]]): M√©tadonn√©es associ√©es √† la t√¢che.
        """
        task_id = str(uuid.uuid4())
        metadata = metadata or {}
        metadata["status"] = "queued"
        self.queue.append((task_id, task, metadata))
        logger.info(f"Task {task_id} added to the queue.")
        asyncio.create_task(self._process_queue())

    async def run_all_tasks(self):
        """
        Ex√©cute toutes les t√¢ches en attente dans la file d'attente jusqu'√† ce qu'elles soient termin√©es.
        """
        while self.queue or self.running_tasks:
            await asyncio.sleep(1)

    def get_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:
        """
        R√©cup√®re le statut d'une t√¢che en cours.

        Args:
            task_id (str): ID de la t√¢che.

        Returns:
            Optional[Dict[str, Any]]: M√©tadonn√©es associ√©es √† la t√¢che, y compris son statut.
        """
        for task_id_in_queue, task, metadata in self.queue:
            if task_id_in_queue == task_id:
                return metadata
        if task_id in self.running_tasks:
            return {"status": "running"}
        return None

    def cancel_task(self, task_id: str):
        """
        Annule une t√¢che en cours (si possible).

        Args:
            task_id (str): ID de la t√¢che √† annuler.
        """
        for task_id_in_queue, task, metadata in list(self.queue):
            if task_id_in_queue == task_id:
                self.queue.remove((task_id_in_queue, task, metadata))
                logger.info(f"Task {task_id} canceled.")
                break
        if task_id in self.running_tasks:
            # Ici, vous pouvez ajouter une logique pour annuler la t√¢che si n√©cessaire
            logger.info(f"Task {task_id} is currently running and cannot be canceled.")

    def list_tasks(self) -> List[Dict[str, Any]]:
        """
        Liste toutes les t√¢ches en attente ou en cours d'ex√©cution.

        Returns:
            List[Dict[str, Any]]: Liste des t√¢ches avec leur statut.
        """
        task_list = []
        for task_id_in_queue, task, metadata in self.queue:
            task_list.append(metadata)
        for task_id_in_running in self.running_tasks:
            task_list.append({"status": "running", "task_id": task_id_in_running})
        return task_list

class DataEncryptionManager:
    """
    G√®re le chiffrement et le d√©chiffrement des donn√©es sensibles avec support de plusieurs algorithmes.
    """

    def __init__(self, encryption_key: str = None):
        """
        Initialise le gestionnaire de chiffrement avec une cl√© sp√©cifi√©e.

        Args:
            encryption_key (str): Cl√© utilis√©e pour le chiffrement, si non fournie, une cl√© par d√©faut sera utilis√©e.
        """
        self.encryption_key = self._derive_key(encryption_key or os.getenv("ENCRYPTION_KEY", "default_secure_key"))
        logger.info("DataEncryptionManager initialized with AES encryption.")

    def _derive_key(self, passphrase: str) -> bytes:
        """
        D√©rive une cl√© de chiffrement √† partir d'une passphrase via PBKDF2.

        Args:
            passphrase (str): Passphrase pour g√©n√©rer la cl√©.

        Returns:
            bytes: Cl√© d√©riv√©e.
        """
        salt = b"data_encryption_salt"
        kdf = PBKDF2HMAC(
            algorithm=hashes.SHA256(),
            length=32,
            salt=salt,
            iterations=100000,
            backend=default_backend()
        )
        return base64.urlsafe_b64encode(kdf.derive(passphrase.encode()))

    def encrypt_data(self, data: str) -> str:
        """
        Chiffre les donn√©es en utilisant AES (CFB mode).

        Args:
            data (str): Donn√©es √† chiffrer.

        Returns:
            str: Donn√©es chiffr√©es au format base64.
        """
        try:
            iv = os.urandom(16)
            cipher = Cipher(algorithms.AES(self.encryption_key), modes.CFB(iv), backend=default_backend())
            encryptor = cipher.encryptor()
            encrypted_data = encryptor.update(data.encode()) + encryptor.finalize()
            encrypted_base64 = base64.b64encode(iv + encrypted_data).decode('utf-8')
            logger.info("Data encrypted successfully.")
            return encrypted_base64
        except Exception as e:
            logger.error(f"Error encrypting data: {e}")
            raise

    def decrypt_data(self, encrypted_data_base64: str) -> str:
        """
        D√©chiffre les donn√©es chiffr√©es en utilisant AES.

        Args:
            encrypted_data_base64 (str): Donn√©es chiffr√©es au format base64.

        Returns:
            str: Donn√©es d√©chiffr√©es.
        """
        try:
            encrypted_data = base64.b64decode(encrypted_data_base64)
            iv = encrypted_data[:16]
            encrypted_data = encrypted_data[16:]

            cipher = Cipher(algorithms.AES(self.encryption_key), modes.CFB(iv), backend=default_backend())
            decryptor = cipher.decryptor()
            decrypted_data = decryptor.update(encrypted_data) + decryptor.finalize()
            logger.info("Data decrypted successfully.")
            return decrypted_data.decode('utf-8')
        except Exception as e:
            logger.error(f"Error decrypting data: {e}")
            raise

    def generate_rsa_key_pair(self) -> Dict[str, Any]:
        """
        G√©n√®re une paire de cl√©s RSA (publique et priv√©e).

        Returns:
            Dict[str, Any]: Cl√© publique et cl√© priv√©e au format PEM.
        """
        try:
            private_key = rsa.generate_private_key(
                public_exponent=65537,
                key_size=2048,
                backend=default_backend()
            )
            private_pem = private_key.private_bytes(
                encoding=serialization.Encoding.PEM,
                format=serialization.PrivateFormat.TraditionalOpenSSL,
                encryption_algorithm=serialization.NoEncryption()
            )
            public_key = private_key.public_key()
            public_pem = public_key.public_bytes(
                encoding=serialization.Encoding.PEM,
                format=serialization.PublicFormat.SubjectPublicKeyInfo
            )
            logger.info("RSA key pair generated successfully.")
            return {"private_key": private_pem.decode('utf-8'), "public_key": public_pem.decode('utf-8')}
        except Exception as e:
            logger.error(f"Error generating RSA key pair: {e}")
            raise

    def encrypt_rsa(self, public_key_pem: str, data: str) -> str:
        """
        Chiffre les donn√©es avec une cl√© publique RSA.

        Args:
            public_key_pem (str): Cl√© publique en format PEM.
            data (str): Donn√©es √† chiffrer.

        Returns:
            str: Donn√©es chiffr√©es au format base64.
        """
        try:
            public_key = serialization.load_pem_public_key(public_key_pem.encode(), backend=default_backend())
            encrypted_data = public_key.encrypt(
                data.encode(),
                padding.PKCS1v15()
            )
            encrypted_base64 = base64.b64encode(encrypted_data).decode('utf-8')
            logger.info("Data encrypted with RSA successfully.")
            return encrypted_base64
        except Exception as e:
            logger.error(f"Error encrypting data with RSA: {e}")
            raise

    def decrypt_rsa(self, private_key_pem: str, encrypted_data_base64: str) -> str:
        """
        D√©chiffre les donn√©es avec une cl√© priv√©e RSA.

        Args:
            private_key_pem (str): Cl√© priv√©e en format PEM.
            encrypted_data_base64 (str): Donn√©es chiffr√©es en base64.

        Returns:
            str: Donn√©es d√©chiffr√©es.
        """
        try:
            private_key = serialization.load_pem_private_key(private_key_pem.encode(), password=None, backend=default_backend())
            encrypted_data = base64.b64decode(encrypted_data_base64)
            decrypted_data = private_key.decrypt(
                encrypted_data,
                padding.PKCS1v15()
            )
            logger.info("Data decrypted with RSA successfully.")
            return decrypted_data.decode('utf-8')
        except Exception as e:
            logger.error(f"Error decrypting data with RSA: {e}")
            raise


class SessionManager:
    """
    G√®re la cr√©ation, la validation et l'expiration des sessions utilisateurs.
    """

    def __init__(self, secret_key: str, session_timeout: int = 3600):
        """
        Initialise le gestionnaire de sessions.

        Args:
            secret_key (str): Cl√© secr√®te pour signer les jetons JWT.
            session_timeout (int): D√©lai d'expiration de la session en secondes (par d√©faut 1 heure).
        """
        self.secret_key = secret_key
        self.session_timeout = session_timeout
        self.sessions = {}  # Dictionnaire pour stocker les sessions actives (en m√©moire)
        logger.info("SessionManager initialized.")

    def create_session(self, user_id: str) -> str:
        """
        Cr√©e une nouvelle session pour un utilisateur.

        Args:
            user_id (str): ID de l'utilisateur pour lequel la session est cr√©√©e.

        Returns:
            str: Jeton JWT pour la session.
        """
        session_id = str(uuid.uuid4())
        expiration_time = datetime.utcnow() + timedelta(seconds=self.session_timeout)
        session_data = {
            "user_id": user_id,
            "session_id": session_id,
            "exp": expiration_time,
            "iat": datetime.utcnow()
        }

        # Cr√©er un jeton JWT sign√©
        token = jwt.encode(session_data, self.secret_key, algorithm="HS256")
        self.sessions[session_id] = session_data
        logger.info(f"Session created for user '{user_id}' with session ID '{session_id}'.")
        return token

    def validate_session(self, token: str) -> Optional[Dict[str, Any]]:
        """
        Valide une session en v√©rifiant son jeton JWT.

        Args:
            token (str): Le jeton JWT de la session.

        Returns:
            Optional[Dict[str, Any]]: Les donn√©es de la session si valide, sinon None.
        """
        try:
            # D√©coder et valider le jeton JWT
            session_data = jwt.decode(token, self.secret_key, algorithms=["HS256"])
            session_id = session_data.get("session_id")

            if session_id in self.sessions:
                stored_session = self.sessions[session_id]
                if stored_session["exp"] >= datetime.utcnow():
                    logger.info(
                        f"Session validated for user '{stored_session['user_id']}' with session ID '{session_id}'.")
                    return stored_session
                else:
                    logger.warning(f"Session expired for session ID '{session_id}'.")
                    self.expire_session(session_id)
                    return None
            else:
                logger.warning(f"Session not found for session ID '{session_id}'.")
                return None

        except jwt.ExpiredSignatureError:
            logger.warning("Session token has expired.")
            return None
        except jwt.InvalidTokenError:
            logger.warning("Invalid session token.")
            return None

    def expire_session(self, session_id: str):
        """
        Expire une session sp√©cifi√©e.

        Args:
            session_id (str): ID de la session √† expirer.
        """
        if session_id in self.sessions:
            del self.sessions[session_id]
            logger.info(f"Session with session ID '{session_id}' expired and removed.")

    def renew_session(self, token: str) -> Optional[str]:
        """
        Renouvelle une session en cr√©ant un nouveau jeton avec une nouvelle date d'expiration.

        Args:
            token (str): Le jeton JWT de la session.

        Returns:
            Optional[str]: Nouveau jeton JWT avec la session renouvel√©e, ou None si la session est invalide ou expir√©e.
        """
        session_data = self.validate_session(token)
        if session_data:
            user_id = session_data["user_id"]
            logger.info(f"Session renewed for user '{user_id}'.")
            return self.create_session(user_id)
        return None

    def list_active_sessions(self) -> Dict[str, Any]:
        """
        Liste toutes les sessions actives.

        Returns:
            Dict[str, Any]: Dictionnaire avec les donn√©es de toutes les sessions actives.
        """
        active_sessions = {session_id: data for session_id, data in self.sessions.items() if
                           data["exp"] >= datetime.utcnow()}
        logger.info(f"Active sessions: {len(active_sessions)} found.")
        return active_sessions

class UserActivityTracker:
    """
    Suivi des activit√©s des utilisateurs dans l'application.
    """

    def __init__(self, storage_type: str = "json", storage_path: str = "user_activities"):
        """
        Initialise le gestionnaire du suivi des activit√©s des utilisateurs.

        Args:
            storage_type (str): Type de stockage ('json' ou 'database').
            storage_path (str): R√©pertoire pour les fichiers JSON (si stockage en fichier).
        """
        self.storage_type = storage_type
        self.storage_path = storage_path
        os.makedirs(storage_path, exist_ok=True)
        logger.info("UserActivityTracker initialized.")

    def _get_json_file_path(self) -> str:
        """
        G√©n√®re le chemin du fichier JSON o√π les logs d'activit√©s seront stock√©s.

        Returns:
            str: Chemin du fichier de log.
        """
        return os.path.join(self.storage_path, f"user_activity_{datetime.utcnow().strftime('%Y%m%d')}.json")

    def record_activity(self, user_id: str, action: str, details: Optional[Dict[str, Any]] = None):
        """
        Enregistre une activit√© utilisateur dans le syst√®me.

        Args:
            user_id (str): ID utilisateur.
            action (str): Action r√©alis√©e par l'utilisateur (par exemple, "view_page", "click_button").
            details (Optional[Dict[str, Any]]): Donn√©es suppl√©mentaires sur l'action effectu√©e.
        """
        activity = {
            "user_id": user_id,
            "action": action,
            "details": details or {},
            "timestamp": datetime.utcnow().isoformat()
        }

        if self.storage_type == "json":
            file_path = self._get_json_file_path()
            try:
                if os.path.exists(file_path):
                    with open(file_path, "r") as file:
                        activities = json.load(file)
                else:
                    activities = []
                activities.append(activity)
                with open(file_path, "w") as file:
                    json.dump(activities, file, indent=4)
                logger.info(f"Activity recorded for user '{user_id}' with action '{action}'.")
            except Exception as e:
                logger.error(f"Error recording activity to JSON for user '{user_id}': {e}")

        elif self.storage_type == "database":
            # Placeholder for database integration (could be MongoDB, SQL, etc.)
            # self.db_manager.save_activity(activity)
            logger.info(f"Activity recorded to database for user '{user_id}' with action '{action}'.")
        else:
            logger.warning("Unsupported storage type for activities.")

    def get_activities(self, user_id: str, start_date: Optional[str] = None, end_date: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        R√©cup√®re les activit√©s d'un utilisateur selon un crit√®re de date.

        Args:
            user_id (str): ID utilisateur.
            start_date (Optional[str]): Date de d√©but du filtrage (au format 'YYYY-MM-DD').
            end_date (Optional[str]): Date de fin du filtrage (au format 'YYYY-MM-DD').

        Returns:
            List[Dict[str, Any]]: Liste des activit√©s de l'utilisateur.
        """
        try:
            if self.storage_type == "json":
                file_path = self._get_json_file_path()
                if os.path.exists(file_path):
                    with open(file_path, "r") as file:
                        activities = json.load(file)
                    filtered_activities = [
                        activity for activity in activities if activity["user_id"] == user_id
                        and (not start_date or activity["timestamp"] >= start_date)
                        and (not end_date or activity["timestamp"] <= end_date)
                    ]
                    logger.info(f"Found {len(filtered_activities)} activities for user '{user_id}'.")
                    return filtered_activities
                logger.warning(f"No activity log found for user '{user_id}'.")
                return []

            elif self.storage_type == "database":
                # Placeholder for database retrieval logic
                # activities = self.db_manager.get_activities(user_id, start_date, end_date)
                logger.info(f"Activities retrieved from database for user '{user_id}'.")
                return []
        except Exception as e:
            logger.error(f"Error retrieving activities for user '{user_id}': {e}")
            return []

    def export_activities(self, user_id: str, start_date: Optional[str] = None, end_date: Optional[str] = None, file_format: str = "json") -> str:
        """
        Exporte les activit√©s d'un utilisateur dans un format sp√©cifi√©.

        Args:
            user_id (str): ID utilisateur.
            start_date (Optional[str]): Date de d√©but pour filtrer les activit√©s.
            end_date (Optional[str]): Date de fin pour filtrer les activit√©s.
            file_format (str): Format d'exportation ('json' ou 'csv').

        Returns:
            str: Chemin du fichier export√©.
        """
        activities = self.get_activities(user_id, start_date, end_date)
        if file_format == "json":
            file_path = os.path.join(self.storage_path, f"user_activity_{datetime.utcnow().strftime('%Y%m%d')}.json")
            try:
                with open(file_path, "w") as file:
                    json.dump(activities, file, indent=4)
                logger.info(f"Activities exported to JSON at {file_path}.")
                return file_path
            except Exception as e:
                logger.error(f"Error exporting activities to JSON: {e}")
                return ""

        elif file_format == "csv":
            file_path = os.path.join(self.storage_path, f"user_activity_{datetime.utcnow().strftime('%Y%m%d')}.csv")
            try:
                import csv
                with open(file_path, mode="w", newline="") as file:
                    writer = csv.DictWriter(file, fieldnames=["user_id", "action", "details", "timestamp"])
                    writer.writeheader()
                    writer.writerows(activities)
                logger.info(f"Activities exported to CSV at {file_path}.")
                return file_path
            except Exception as e:
                logger.error(f"Error exporting activities to CSV: {e}")
                return ""

        logger.error(f"Unsupported export format: {file_format}")
        return ""


class AccessControlManager:
    """
    G√®re les r√¥les et permissions des utilisateurs pour assurer un contr√¥le d'acc√®s s√©curis√©.
    """

    def __init__(self):
        """
        Initialise le gestionnaire de contr√¥le d'acc√®s.
        Les r√¥les et permissions sont d√©finis par d√©faut, mais peuvent √™tre personnalis√©s.
        """
        # Exemple de r√¥les et permissions par d√©faut
        self.roles = {
            "admin": ["create", "read", "update", "delete"],
            "user": ["read"],
        }
        self.users = {}  # {user_id: role}
        logger.info("AccessControlManager initialized with default roles and permissions.")

    def assign_role(self, user_id: str, role: str):
        """
        Assigne un r√¥le √† un utilisateur.

        Args:
            user_id (str): ID de l'utilisateur.
            role (str): R√¥le √† assigner (par exemple, 'admin', 'user').
        """
        if role not in self.roles:
            logger.error(f"Attempt to assign invalid role '{role}' to user '{user_id}'.")
            raise ValueError(f"Role '{role}' does not exist.")
        self.users[user_id] = role
        logger.info(f"Role '{role}' assigned to user '{user_id}'.")

    def check_permission(self, user_id: str, action: str) -> bool:
        """
        V√©rifie si un utilisateur a la permission d'effectuer une action.

        Args:
            user_id (str): ID de l'utilisateur.
            action (str): Action √† v√©rifier (par exemple, 'read', 'delete').

        Returns:
            bool: True si l'utilisateur a la permission d'effectuer l'action, sinon False.
        """
        role = self.users.get(user_id)
        if not role:
            logger.warning(f"User '{user_id}' has no assigned role.")
            return False

        if action in self.roles.get(role, []):
            logger.info(f"User '{user_id}' is allowed to perform action '{action}'.")
            return True

        logger.warning(f"User '{user_id}' is not allowed to perform action '{action}'.")
        return False

    def get_user_permissions(self, user_id: str) -> List[str]:
        """
        R√©cup√®re les permissions d'un utilisateur.

        Args:
            user_id (str): ID de l'utilisateur.

        Returns:
            List[str]: Liste des actions que l'utilisateur est autoris√© √† effectuer.
        """
        role = self.users.get(user_id)
        if not role:
            logger.warning(f"User '{user_id}' has no assigned role.")
            return []

        permissions = self.roles.get(role, [])
        logger.info(f"User '{user_id}' has the following permissions: {permissions}.")
        return permissions

    def update_role_permissions(self, role: str, permissions: List[str]):
        """
        Met √† jour les permissions associ√©es √† un r√¥le.

        Args:
            role (str): Le r√¥le √† mettre √† jour.
            permissions (List[str]): Liste des nouvelles permissions pour le r√¥le.
        """
        if role not in self.roles:
            logger.error(f"Attempt to update invalid role '{role}'.")
            raise ValueError(f"Role '{role}' does not exist.")

        self.roles[role] = permissions
        logger.info(f"Permissions for role '{role}' updated to {permissions}.")

    def revoke_permission(self, user_id: str, permission: str):
        """
        R√©voque une permission sp√©cifique pour un utilisateur.

        Args:
            user_id (str): ID de l'utilisateur.
            permission (str): Permission √† r√©voquer.
        """
        role = self.users.get(user_id)
        if not role:
            logger.warning(f"User '{user_id}' has no assigned role.")
            return

        if permission in self.roles.get(role, []):
            self.roles[role].remove(permission)
            logger.info(f"Permission '{permission}' revoked from user '{user_id}'.")
        else:
            logger.warning(f"User '{user_id}' does not have permission '{permission}'.")

    def audit_permissions(self, user_id: str) -> Dict[str, Any]:
        """
        Effectue un audit des permissions d'un utilisateur.

        Args:
            user_id (str): ID de l'utilisateur.

        Returns:
            Dict[str, Any]: D√©tails des permissions de l'utilisateur et de son r√¥le.
        """
        role = self.users.get(user_id)
        if not role:
            logger.warning(f"User '{user_id}' has no assigned role.")
            return {}

        permissions = self.roles.get(role, [])
        logger.info(f"Audit for user '{user_id}': Role '{role}', Permissions {permissions}.")
        return {"user_id": user_id, "role": role, "permissions": permissions}

class NotificationQueueManager:
    """
    G√®re la file d'attente des notifications √† envoyer, avec gestion des priorit√©s et des √©checs.
    """

    def __init__(self, max_concurrent_notifications: int = 5):
        """
        Initialise le gestionnaire de la file d'attente des notifications.

        Args:
            max_concurrent_notifications (int): Nombre maximal de notifications pouvant √™tre envoy√©es simultan√©ment.
        """
        self.queue = deque()
        self.running_notifications = set()
        self.max_concurrent_notifications = max_concurrent_notifications
        logger.info("NotificationQueueManager initialized.")

    async def _send_notification(self, notification_id: str, send_function: Callable[[], Any], metadata: Dict[str, Any]):
        """
        Envoie une notification en ex√©cutant la fonction d'envoi associ√©e.

        Args:
            notification_id (str): ID unique de la notification.
            send_function (Callable[[], Any]): Fonction pour envoyer la notification.
            metadata (Dict[str, Any]): M√©tadonn√©es associ√©es √† la notification.
        """
        try:
            logger.info(f"Sending notification {notification_id}.")
            result = await send_function()
            logger.info(f"Notification {notification_id} sent successfully. Result: {result}")
        except Exception as e:
            logger.error(f"Error sending notification {notification_id}: {e}")
            metadata["status"] = "failed"
        finally:
            self.running_notifications.remove(notification_id)
            await self._process_queue()

    async def _process_queue(self):
        """
        Traite les notifications dans la file d'attente tant que le nombre de notifications en cours d'envoi est inf√©rieur √† la limite.
        """
        while self.queue and len(self.running_notifications) < self.max_concurrent_notifications:
            notification_id, send_function, metadata = self.queue.popleft()
            self.running_notifications.add(notification_id)
            asyncio.create_task(self._send_notification(notification_id, send_function, metadata))

    def add_notification(self, send_function: Callable[[], Any], metadata: Dict[str, Any] = None):
        """
        Ajoute une notification √† la file d'attente.

        Args:
            send_function (Callable[[], Any]): Fonction pour envoyer la notification.
            metadata (Dict[str, Any]): M√©tadonn√©es associ√©es √† la notification.
        """
        notification_id = str(time.time())
        metadata = metadata or {}
        metadata["status"] = "queued"
        self.queue.append((notification_id, send_function, metadata))
        logger.info(f"Notification {notification_id} added to the queue.")
        asyncio.create_task(self._process_queue())

    async def run_all_notifications(self):
        """
        Ex√©cute toutes les notifications en attente dans la file d'attente jusqu'√† ce qu'elles soient termin√©es.
        """
        while self.queue or self.running_notifications:
            await asyncio.sleep(1)

    def get_notification_status(self, notification_id: str) -> Dict[str, Any]:
        """
        R√©cup√®re l'√©tat actuel d'une notification.

        Args:
            notification_id (str): ID de la notification.

        Returns:
            Dict[str, Any]: M√©tadonn√©es associ√©es √† la notification, y compris son statut.
        """
        for notification_id_in_queue, send_function, metadata in self.queue:
            if notification_id_in_queue == notification_id:
                return metadata
        if notification_id in self.running_notifications:
            return {"status": "running"}
        return {"status": "not found"}

    def cancel_notification(self, notification_id: str):
        """
        Annule une notification en cours ou en attente.

        Args:
            notification_id (str): ID de la notification √† annuler.
        """
        for notification_id_in_queue, send_function, metadata in list(self.queue):
            if notification_id_in_queue == notification_id:
                self.queue.remove((notification_id_in_queue, send_function, metadata))
                logger.info(f"Notification {notification_id} canceled.")
                break
        if notification_id in self.running_notifications:
            # Ici, vous pouvez ajouter une logique pour annuler la notification si n√©cessaire
            logger.info(f"Notification {notification_id} is currently running and cannot be canceled.")

    def list_notifications(self) -> Dict[str, Any]:
        """
        Liste toutes les notifications en attente ou en cours d'envoi.

        Returns:
            Dict[str, Any]: D√©tails des notifications avec leur statut.
        """
        notification_list = []
        for notification_id_in_queue, send_function, metadata in self.queue:
            notification_list.append(metadata)
        for notification_id_in_running in self.running_notifications:
            notification_list.append({"status": "running", "notification_id": notification_id_in_running})
        logger.info(f"Notifications in queue or running: {len(notification_list)} found.")
        return notification_list

class ErrorHandlingManager:
    """
    G√®re les erreurs de l'application, capture les exceptions et les notifie en cas de besoin.
    """

    def __init__(self, email_config: Dict[str, str] = None):
        """
        Initialise le gestionnaire des erreurs.

        Args:
            email_config (Dict[str, str]): Configuration pour l'envoi des emails (host, port, sender_email, etc.).
        """
        self.email_config = email_config or {}
        logger.info("ErrorHandlingManager initialized.")

    def log_error(self, error: Exception, context: Optional[Dict[str, Any]] = None):
        """
        Enregistre une erreur dans les logs et notifie si n√©cessaire.

        Args:
            error (Exception): L'exception √† enregistrer.
            context (Optional[Dict[str, Any]]): M√©tadonn√©es contextuelles, telles que l'utilisateur ou l'action effectu√©e.
        """
        error_message = str(error)
        stack_trace = traceback.format_exc()
        log_message = f"Error: {error_message}\nStack trace: {stack_trace}"
        if context:
            log_message += f"\nContext: {context}"

        logger.error(log_message)
        self.send_email_notification(log_message)

    def send_email_notification(self, message: str):
        """
        Envoie un email pour notifier une erreur critique.

        Args:
            message (str): Le message d'erreur √† envoyer.
        """
        if not self.email_config:
            logger.warning("No email configuration found. Skipping email notification.")
            return

        try:
            msg = MIMEMultipart()
            msg['From'] = self.email_config.get("sender_email")
            msg['To'] = self.email_config.get("recipient_email")
            msg['Subject'] = "Critical Error Notification"
            msg.attach(MIMEText(message, 'plain'))

            with smtplib.SMTP_SSL(self.email_config.get("host"), self.email_config.get("port")) as server:
                server.login(self.email_config.get("username"), self.email_config.get("password"))
                server.sendmail(msg['From'], msg['To'], msg.as_string())

            logger.info("Error notification sent via email.")
        except Exception as e:
            logger.error(f"Failed to send error email: {e}")

    def handle_exception(self, error: Exception, context: Optional[Dict[str, Any]] = None):
        """
        G√®re une exception en l'enregistrant et en la notifiant si n√©cessaire.

        Args:
            error (Exception): L'exception √† g√©rer.
            context (Optional[Dict[str, Any]]): M√©tadonn√©es contextuelles pour enrichir le log d'erreur.
        """
        self.log_error(error, context)
        self.send_email_notification(f"A critical error occurred: {error}")

    def retry_failed_task(self, task_function: Callable[[], Any], retries: int = 3, delay: int = 5) -> Any:
        """
        R√©essaie une t√¢che √©chou√©e apr√®s un d√©lai donn√©.

        Args:
            task_function (Callable[[], Any]): Fonction de la t√¢che √† r√©essayer.
            retries (int): Nombre de tentatives avant d'abandonner.
            delay (int): D√©lai en secondes entre les tentatives.

        Returns:
            Any: Le r√©sultat de la t√¢che r√©ussie, ou l'exception si elle √©choue apr√®s le nombre de tentatives.
        """
        attempt = 0
        while attempt < retries:
            try:
                return task_function()
            except Exception as e:
                attempt += 1
                logger.error(f"Task failed on attempt {attempt}/{retries}: {e}")
                if attempt < retries:
                    logger.info(f"Retrying in {delay} seconds...")
                    time.sleep(delay)
                else:
                    logger.error("Maximum retries reached. Task failed permanently.")
                    raise e

    def retry_failed_task_with_backoff(self, task_function: Callable[[], Any], retries: int = 3, initial_delay: int = 2) -> Any:
        """
        R√©essaie une t√¢che √©chou√©e avec un d√©lai d'attente exponentiel entre les tentatives.

        Args:
            task_function (Callable[[], Any]): Fonction de la t√¢che √† r√©essayer.
            retries (int): Nombre de tentatives avant d'abandonner.
            initial_delay (int): D√©lai initial en secondes avant la premi√®re tentative.

        Returns:
            Any: Le r√©sultat de la t√¢che r√©ussie, ou l'exception si elle √©choue apr√®s le nombre de tentatives.
        """
        attempt = 0
        delay = initial_delay
        while attempt < retries:
            try:
                return task_function()
            except Exception as e:
                attempt += 1
                logger.error(f"Task failed on attempt {attempt}/{retries}: {e}")
                if attempt < retries:
                    logger.info(f"Retrying in {delay} seconds...")
                    time.sleep(delay)
                    delay *= 2  # Exponential backoff
                else:
                    logger.error("Maximum retries reached. Task failed permanently.")
                    raise e


class AnalyticsManager:
    """
    G√®re l'analyse des donn√©es des utilisateurs, la g√©n√©ration de rapports et la visualisation des donn√©es de performance.
    """

    def __init__(self):
        """
        Initialise le gestionnaire des analyses.
        """
        logger.info("AnalyticsManager initialized.")

    def collect_data(self, user_id: str, action: str, metadata: Dict[str, Any]):
        """
        Collecte les donn√©es d'interaction de l'utilisateur pour analyse.

        Args:
            user_id (str): L'ID de l'utilisateur.
            action (str): L'action effectu√©e par l'utilisateur (ex. "click", "view", etc.).
            metadata (Dict[str, Any]): Donn√©es contextuelles suppl√©mentaires sur l'action.
        """
        # Pour simplifier, on suppose que les donn√©es sont collect√©es dans une structure Pandas DataFrame
        data = {
            "user_id": user_id,
            "action": action,
            "metadata": metadata,
            "timestamp": datetime.utcnow()
        }
        logger.info(f"Data collected for user '{user_id}' performing action '{action}'.")

        return pd.DataFrame([data])

    def generate_statistics(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        G√©n√®re des statistiques sur les interactions des utilisateurs.

        Args:
            data (pd.DataFrame): Donn√©es d'interactions des utilisateurs √† analyser.

        Returns:
            Dict[str, Any]: Statistiques agr√©g√©es comme la moyenne, m√©diane, etc.
        """
        try:
            stats = {
                "total_interactions": len(data),
                "unique_users": data["user_id"].nunique(),
                "actions_count": data["action"].value_counts().to_dict(),
                "average_interaction_time": data["metadata"].apply(lambda x: x.get('interaction_time', 0)).mean(),
            }
            logger.info(f"Generated statistics: {stats}")
            return stats
        except Exception as e:
            logger.error(f"Error generating statistics: {e}")
            return {}

    def generate_report(self, data: pd.DataFrame) -> None:
        """
        G√©n√®re un rapport sur les interactions des utilisateurs.

        Args:
            data (pd.DataFrame): Donn√©es d'interactions des utilisateurs √† analyser.
        """
        try:
            stats = self.generate_statistics(data)
            logger.info("Generating report...")
            report_data = {
                "total_interactions": stats["total_interactions"],
                "unique_users": stats["unique_users"],
                "actions_count": stats["actions_count"],
                "average_interaction_time": stats["average_interaction_time"]
            }

            report_df = pd.DataFrame([report_data])
            report_df.to_csv("user_interaction_report.csv", index=False)
            logger.info("Report generated and saved to 'user_interaction_report.csv'.")
        except Exception as e:
            logger.error(f"Error generating report: {e}")

    def visualize_data(self, data: pd.DataFrame) -> None:
        """
        Cr√©e une visualisation des donn√©es d'interaction utilisateur (par exemple, actions par utilisateur).

        Args:
            data (pd.DataFrame): Donn√©es d'interactions des utilisateurs √† analyser.
        """
        try:
            logger.info("Generating visualizations...")

            # Visualisation des actions par utilisateur
            action_counts = data["action"].value_counts()
            plt.figure(figsize=(10, 6))
            sns.barplot(x=action_counts.index, y=action_counts.values)
            plt.title("Actions par utilisateur")
            plt.xlabel("Actions")
            plt.ylabel("Nombre d'actions")
            plt.savefig("user_action_distribution.png")
            plt.show()
            logger.info("Data visualizations saved and displayed.")
        except Exception as e:
            logger.error(f"Error visualizing data: {e}")

    def analyze_trends(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        Analyse les tendances dans les interactions des utilisateurs au fil du temps.

        Args:
            data (pd.DataFrame): Donn√©es d'interactions des utilisateurs √† analyser.

        Returns:
            Dict[str, Any]: Tendances identifi√©es, comme les pics d'activit√©.
        """
        try:
            data['timestamp'] = pd.to_datetime(data['timestamp'])
            trend_data = data.groupby(data['timestamp'].dt.date).size()

            trends = {
                "daily_activity_trends": trend_data.to_dict(),
                "max_activity_day": trend_data.idxmax(),
                "max_activity_count": trend_data.max()
            }

            logger.info(f"Trends identified: {trends}")
            return trends
        except Exception as e:
            logger.error(f"Error analyzing trends: {e}")
            return {}

class FileUploadManager:
    """
    G√®re le t√©l√©chargement et la gestion des fichiers dans l'application.
    """

    def __init__(self, upload_dir: str = "uploads", max_size: int = 10 * 1024 * 1024):
        """
        Initialise le gestionnaire de fichiers.

        Args:
            upload_dir (str): R√©pertoire o√π les fichiers seront stock√©s.
            max_size (int): Taille maximale des fichiers en octets (par d√©faut 10 Mo).
        """
        self.upload_dir = Path(upload_dir)
        self.upload_dir.mkdir(parents=True, exist_ok=True)
        self.max_size = max_size  # 10MB par d√©faut
        logger.info(f"FileUploadManager initialized with upload directory: {self.upload_dir}")

    def validate_file(self, file_path: str, allowed_extensions: Optional[List[str]] = None) -> bool:
        """
        Valide un fichier (taille et type).

        Args:
            file_path (str): Chemin du fichier √† valider.
            allowed_extensions (Optional[List[str]]): Liste des extensions autoris√©es (par exemple, ['.jpg', '.png']).

        Returns:
            bool: True si le fichier est valide, sinon False.
        """
        file_size = os.path.getsize(file_path)
        if file_size > self.max_size:
            logger.error(f"File '{file_path}' exceeds size limit of {self.max_size / 1024 / 1024} MB.")
            return False

        if allowed_extensions:
            _, file_extension = os.path.splitext(file_path)
            if file_extension.lower() not in allowed_extensions:
                logger.error(f"File '{file_path}' has an invalid extension '{file_extension}'.")
                return False

        # Validation des types MIME
        mime_type, _ = mimetypes.guess_type(file_path)
        if mime_type and not mime_type.startswith("image/") and not mime_type.startswith("application/"):
            logger.error(f"File '{file_path}' has an invalid MIME type '{mime_type}'.")
            return False

        return True

    def generate_unique_filename(self, original_filename: str) -> str:
        """
        G√©n√®re un nom de fichier unique pour √©viter les collisions.

        Args:
            original_filename (str): Nom du fichier original.

        Returns:
            str: Nouveau nom de fichier unique.
        """
        file_extension = Path(original_filename).suffix
        unique_filename = f"{uuid.uuid4().hex}{file_extension}"
        return unique_filename

    def upload_file(self, file_path: str, allowed_extensions: Optional[List[str]] = None) -> str:
        """
        T√©l√©charge un fichier apr√®s validation.

        Args:
            file_path (str): Chemin du fichier √† t√©l√©charger.
            allowed_extensions (Optional[List[str]]): Liste des extensions autoris√©es.

        Returns:
            str: Chemin du fichier t√©l√©charg√© ou une exception si l'√©chec.
        """
        if not self.validate_file(file_path, allowed_extensions):
            logger.error(f"File validation failed for '{file_path}'.")
            raise ValueError("File validation failed.")

        unique_filename = self.generate_unique_filename(file_path)
        destination_path = self.upload_dir / unique_filename

        try:
            os.rename(file_path, destination_path)  # D√©place le fichier vers le r√©pertoire de destination
            logger.info(f"File '{file_path}' uploaded successfully as '{unique_filename}'.")
            return str(destination_path)
        except Exception as e:
            logger.error(f"Error uploading file '{file_path}': {e}")
            raise

    def list_uploaded_files(self) -> List[str]:
        """
        Liste tous les fichiers t√©l√©charg√©s dans le r√©pertoire de stockage.

        Returns:
            List[str]: Liste des chemins des fichiers t√©l√©charg√©s.
        """
        files = [str(file) for file in self.upload_dir.iterdir() if file.is_file()]
        logger.info(f"List of uploaded files: {files}")
        return files

    def delete_file(self, file_name: str):
        """
        Supprime un fichier t√©l√©charg√©.

        Args:
            file_name (str): Nom du fichier √† supprimer.
        """
        file_path = self.upload_dir / file_name
        if file_path.exists() and file_path.is_file():
            try:
                os.remove(file_path)
                logger.info(f"File '{file_name}' deleted successfully.")
            except Exception as e:
                logger.error(f"Error deleting file '{file_name}': {e}")
                raise
        else:
            logger.warning(f"File '{file_name}' does not exist.")
            
class RedisCacheManager:
    """
    G√®re un cache distribu√© avec Redis et fallback local.
    """

    def __init__(self, redis_host: str = "localhost", redis_port: int = 6379, cache_dir: str = "cache", ttl: int = 3600):
        """
        Initialise le gestionnaire de cache.

        Args:
            redis_host (str): Adresse du serveur Redis.
            redis_port (int): Port du serveur Redis.
            cache_dir (str): R√©pertoire pour le fallback local.
            ttl (int): Temps de vie des entr√©es en secondes.
        """
        self.redis = Redis(host=redis_host, port=redis_port, db=0, decode_responses=True)
        self.cache_dir = cache_dir
        self.ttl = ttl
        os.makedirs(cache_dir, exist_ok=True)
        self.local_cache = TTLCache(maxsize=1000, ttl=ttl)
        logger.info(f"RedisCacheManager initialized. Redis at {redis_host}:{redis_port}, fallback in '{cache_dir}'.")

    def redis_available(self) -> bool:
        """
        V√©rifie si Redis est accessible.

        Returns:
            bool: True si Redis est disponible, sinon False.
        """
        try:
            self.redis.ping()
            return True
        except Exception as e:
            logger.warning(f"Redis unavailable: {e}")
            return False

    def get_cache(self, key: str) -> Optional[Any]:
        """
        R√©cup√®re une valeur du cache.

        Args:
            key (str): Cl√© de l'entr√©e dans le cache.

        Returns:
            Optional[Any]: Valeur associ√©e ou None si non trouv√©e.
        """
        # V√©rifier Redis
        if self.redis_available():
            try:
                value = self.redis.get(key)
                if value:
                    logger.info(f"Cache hit in Redis for key: {key}")
                    return json.loads(value)
            except Exception as e:
                logger.error(f"Error fetching key '{key}' from Redis: {e}")

        # V√©rifier le cache local
        if key in self.local_cache:
            logger.info(f"Cache hit in local memory for key: {key}")
            return self.local_cache[key]

        # V√©rifier le fallback local
        file_path = os.path.join(self.cache_dir, f"{key}.json")
        if os.path.exists(file_path):
            try:
                with open(file_path, "r") as file:
                    logger.info(f"Cache hit in local fallback for key: {key}")
                    return json.load(file)
            except Exception as e:
                logger.error(f"Error reading local cache file for key '{key}': {e}")

        logger.info(f"Cache miss for key: {key}")
        return None

    def set_cache(self, key: str, value: Any):
        """
        Ajoute une valeur au cache.

        Args:
            key (str): Cl√© de l'entr√©e.
            value (Any): Valeur associ√©e √† la cl√©.
        """
        # Ajouter dans Redis
        if self.redis_available():
            try:
                self.redis.setex(key, self.ttl, json.dumps(value))
                logger.info(f"Cache set in Redis for key: {key}")
            except Exception as e:
                logger.error(f"Error setting key '{key}' in Redis: {e}")

        # Ajouter dans le cache local
        self.local_cache[key] = value

        # Ajouter dans le fallback local
        file_path = os.path.join(self.cache_dir, f"{key}.json")
        try:
            with open(file_path, "w") as file:
                json.dump(value, file)
            logger.info(f"Cache set in local fallback for key: {key}")
        except Exception as e:
            logger.error(f"Error writing local cache file for key '{key}': {e}")

    def delete_cache(self, key: str):
        """
        Supprime une entr√©e du cache.

        Args:
            key (str): Cl√© de l'entr√©e √† supprimer.
        """
        # Supprimer de Redis
        if self.redis_available():
            try:
                self.redis.delete(key)
                logger.info(f"Cache key '{key}' deleted from Redis.")
            except Exception as e:
                logger.error(f"Error deleting key '{key}' from Redis: {e}")

        # Supprimer du cache local
        if key in self.local_cache:
            del self.local_cache[key]
            logger.info(f"Cache key '{key}' deleted from local memory.")

        # Supprimer du fallback local
        file_path = os.path.join(self.cache_dir, f"{key}.json")
        if os.path.exists(file_path):
            try:
                os.remove(file_path)
                logger.info(f"Cache file '{key}.json' deleted from local fallback.")
            except Exception as e:
                logger.error(f"Error deleting cache file '{key}.json': {e}")

    def clear_cache(self):
        """
        Supprime tout le cache, dans Redis et localement.
        """
        # Effacer Redis
        if self.redis_available():
            try:
                self.redis.flushdb()
                logger.info("All Redis cache cleared.")
            except Exception as e:
                logger.error(f"Error clearing Redis cache: {e}")

        # Effacer le cache local
        self.local_cache.clear()
        try:
            for file in os.listdir(self.cache_dir):
                os.remove(os.path.join(self.cache_dir, file))
            logger.info("All local fallback cache cleared.")
        except Exception as e:
            logger.error(f"Error clearing local cache: {e}")

class EndToEndPipeline:
    """
    Orchestration compl√®te du pipeline : pr√©traitement, clustering, √©valuation et visualisation.
    """

    def __init__(self, preprocessor, clustering_service, evaluator, dashboard_generator):
        """
        Initialise le pipeline avec les composants n√©cessaires.

        Args:
            preprocessor: Instance de DataPreprocessor.
            clustering_service: Instance de ClusteringService.
            evaluator: Instance de MetricsEvaluator.
            dashboard_generator: Instance de DashboardGenerator.
        """
        self.preprocessor = preprocessor
        self.clustering_service = clustering_service
        self.evaluator = evaluator
        self.dashboard_generator = dashboard_generator

    def process(self, data, clustering_method="kmeans", n_clusters=5):
        """
        Traite les donn√©es de bout en bout.

        Args:
            data: Donn√©es brutes.
            clustering_method (str): M√©thode de clustering ('kmeans', 'dbscan').
            n_clusters (int): Nombre de clusters (pour KMeans).

        Returns:
            dict: R√©sultats complets incluant l'√©valuation et les graphiques.
        """
        # √âtape 1 : Pr√©traitement
        processed_data = self.preprocessor.preprocess(data)

        # √âtape 2 : R√©duction et clustering
        reduced_data = self.clustering_service.reduce_dimensions(processed_data)
        clustering_results = self.clustering_service.cluster(reduced_data, method=clustering_method, n_clusters=n_clusters)

        # √âtape 3 : √âvaluation
        evaluation_results = self.evaluator.evaluate_clustering(reduced_data, clustering_results["labels"])

        # √âtape 4 : Visualisation
        bar_chart = self.dashboard_generator.create_bar_chart(
            data=evaluation_results, title="Cluster Evaluation Metrics"
        )
        scatter_plot = self.dashboard_generator.create_scatter_plot(
            x=reduced_data[:, 0], y=reduced_data[:, 1], labels=clustering_results["labels"], title="Cluster Scatter Plot"
        )
        dashboard_path = self.dashboard_generator.create_dashboard(
            insights={"Metrics": bar_chart, "Clusters": scatter_plot}, output_file="pipeline_dashboard.html"
        )

        return {
            "evaluation": evaluation_results,
            "dashboard": dashboard_path,
            "reduced_data": reduced_data,
            "clustering_labels": clustering_results["labels"],
        }

class InteractionManager:
    """
    G√®re les interactions utilisateur, incluant le cache, les mod√®les et les visualisations.
    """

    def __init__(self, pipeline_manager, cache_manager=None):
        """
        Initialise le gestionnaire d'interactions.

        Args:
            pipeline_manager: Instance d'AsyncPipelineManager ou √©quivalent.
            cache_manager: Instance de CacheManager (optionnel).
        """
        self.pipeline_manager = pipeline_manager
        self.cache_manager = cache_manager

    async def handle_request(self, user_id: str, data: Any, **kwargs) -> Dict[str, Any]:
        """
        G√®re une requ√™te utilisateur, avec support pour le cache.

        Args:
            user_id (str): Identifiant de l'utilisateur.
            data: Donn√©es brutes de la requ√™te.
            **kwargs: Param√®tres additionnels pour le pipeline.

        Returns:
            Dict[str, Any]: R√©sultats du traitement.
        """
        cache_key = f"user_{user_id}_request"
        if self.cache_manager:
            cached_result = self.cache_manager.get(cache_key)
            if cached_result:
                logger.info(f"Cache hit pour l'utilisateur {user_id}.")
                return cached_result

        logger.info(f"Traitement de la requ√™te pour l'utilisateur {user_id}...")
        result = await self.pipeline_manager.process_single(data, **kwargs)

        if self.cache_manager:
            self.cache_manager.set(cache_key, result)

        return result

    async def handle_batch_request(self, user_id: str, batch_data: List[Any], **kwargs) -> List[Dict[str, Any]]:
        """
        G√®re un lot de requ√™tes utilisateur.

        Args:
            user_id (str): Identifiant de l'utilisateur.
            batch_data (List[Any]): Liste des donn√©es brutes.
            **kwargs: Param√®tres additionnels pour le pipeline.

        Returns:
            List[Dict[str, Any]]: R√©sultats du traitement pour chaque entr√©e.
        """
        logger.info(f"Traitement d'un lot de requ√™tes pour l'utilisateur {user_id}...")
        return await self.pipeline_manager.process_batch(batch_data, **kwargs)
class TaskScheduler:
    """
    Planifie et ex√©cute des t√¢ches p√©riodiques ou programm√©es.
    """

    def __init__(self):
        """
        Initialise le gestionnaire de t√¢ches.
        """
        self.scheduler = AsyncIOScheduler()
        self.scheduler.start()
        logger.info("TaskScheduler initialized and started.")

    def schedule_task(self, func, interval_seconds: int, task_name: str = None, **kwargs):
        """
        Planifie une t√¢che p√©riodique.

        Args:
            func: Fonction √† ex√©cuter.
            interval_seconds (int): Intervalle entre les ex√©cutions (en secondes).
            task_name (str): Nom de la t√¢che (optionnel).
            **kwargs: Arguments pour la fonction.
        """
        try:
            self.scheduler.add_job(
                func,
                IntervalTrigger(seconds=interval_seconds),
                id=task_name or func.__name__,
                kwargs=kwargs,
            )
            logger.info(f"T√¢che '{task_name or func.__name__}' planifi√©e toutes les {interval_seconds} secondes.")
        except Exception as e:
            logger.error(f"Erreur lors de la planification de la t√¢che : {e}")

    def stop_task(self, task_name: str):
        """
        Arr√™te une t√¢che planifi√©e.

        Args:
            task_name (str): Nom de la t√¢che.
        """
        try:
            self.scheduler.remove_job(task_name)
            logger.info(f"T√¢che '{task_name}' arr√™t√©e avec succ√®s.")
        except Exception as e:
            logger.error(f"Erreur lors de l'arr√™t de la t√¢che '{task_name}' : {e}")

    def shutdown(self):
        """
        Arr√™te le planificateur.
        """
        self.scheduler.shutdown()
        logger.info("TaskScheduler arr√™t√© avec succ√®s.")
class AsyncPipelineManager:
    """
    G√®re des pipelines asynchrones pour traiter des ensembles de donn√©es ou des requ√™tes utilisateur volumineux.
    """

    def __init__(self, pipeline):
        """
        Initialise le gestionnaire avec un pipeline.

        Args:
            pipeline: Instance d'un pipeline (e.g., EndToEndPipeline).
        """
        self.pipeline = pipeline

    async def process_single(self, data: Any, **kwargs) -> Dict[str, Any]:
        """
        Traite une seule entr√©e via le pipeline.

        Args:
            data: Donn√©es brutes pour une entr√©e unique.
            **kwargs: Param√®tres additionnels pour le pipeline.

        Returns:
            Dict[str, Any]: R√©sultats du traitement.
        """
        try:
            return await asyncio.to_thread(self.pipeline.process, data, **kwargs)
        except Exception as e:
            return {"error": f"Erreur lors du traitement des donn√©es : {e}"}

    async def process_batch(self, batch_data: List[Any], **kwargs) -> List[Dict[str, Any]]:
        """
        Traite un lot de donn√©es en parall√®le.

        Args:
            batch_data (List[Any]): Liste des donn√©es brutes.
            **kwargs: Param√®tres additionnels pour le pipeline.

        Returns:
            List[Dict[str, Any]]: R√©sultats du traitement pour chaque entr√©e.
        """
        tasks = [self.process_single(data, **kwargs) for data in batch_data]
        return await asyncio.gather(*tasks)
from sklearn.datasets import load_iris
import pandas as pd

# Charger un jeu de donn√©es pour tester
iris = load_iris()
X_train = pd.DataFrame(iris.data, columns=iris.feature_names)

# Maintenant, applique le pipeline
X_train_prepared = pipeline.fit_transform(X_train)
class SentimentAnalyzer:
    """
    Analyse les sentiments des textes avec support multi-langue.
    """

    def __init__(self, model_name: str = "distilbert-base-uncased-finetuned-sst-2-english"):
        """
        Initialise le pipeline d'analyse de sentiment.

        Args:
            model_name (str): Nom du mod√®le transformers.
        """
        self.pipeline = pipeline("sentiment-analysis", model=model_name)
        self.translator = Translator()
        logger.info(f"SentimentAnalyzer initialized with model: {model_name}")

    def detect_language(self, text: str) -> str:
        """
        D√©tecte la langue d'un texte.

        Args:
            text (str): Texte brut.

        Returns:
            str: Code ISO de la langue d√©tect√©e.
        """
        try:
            language = detect(text)
            logger.info(f"Detected language: {language}")
            return language
        except Exception as e:
            logger.warning(f"Error detecting language: {e}")
            return "unknown"

    def translate_text(self, text: str, target_language: str = "en") -> str:
        """
        Traduit un texte dans une langue cible.

        Args:
            text (str): Texte brut.
            target_language (str): Langue cible.

        Returns:
            str: Texte traduit.
        """
        try:
            translated = self.translator.translate(text, dest=target_language).text
            logger.info(f"Text translated to {target_language}.")
            return translated
        except Exception as e:
            logger.error(f"Error translating text: {e}")
            return text

    def analyze_sentiment(self, text: str, target_language: str = "en") -> Dict[str, Any]:
        """
        Analyse le sentiment d'un texte donn√©.

        Args:
            text (str): Texte brut.
            target_language (str): Langue cible pour le pipeline d'analyse.

        Returns:
            Dict[str, Any]: R√©sultat contenant le label, le score, et la langue d√©tect√©e.
        """
        try:
            detected_language = self.detect_language(text)
            if detected_language != target_language:
                logger.info(f"Translating text from {detected_language} to {target_language}...")
                text = self.translate_text(text, target_language)

            logger.info("Running sentiment analysis...")
            result = self.pipeline(text)[0]
            logger.info(f"Sentiment result: {result}")
            return {"label": result["label"], "score": result["score"], "language": detected_language}
        except Exception as e:
            logger.error(f"Error analyzing sentiment: {e}")
            return {"label": "error", "score": 0.0, "language": "unknown"}

    def analyze_batch(self, texts: List[str], target_language: str = "en") -> List[Dict[str, Any]]:
        """
        Analyse les sentiments d'une liste de textes.

        Args:
            texts (List[str]): Liste des textes.
            target_language (str): Langue cible pour le pipeline d'analyse.

        Returns:
            List[Dict[str, Any]]: Liste des r√©sultats pour chaque texte.
        """
        results = []
        logger.info(f"Analyzing batch of {len(texts)} texts...")
        for text in texts:
            result = self.analyze_sentiment(text, target_language)
            results.append(result)
        logger.info("Batch sentiment analysis completed.")
        return results

class DashboardGenerator:
    """
    G√©n√®re des tableaux de bord interactifs avec support pour l‚Äôexportation.
    """

    def __init__(self, output_dir: str = "dashboards"):
        """
        Initialise la classe DashboardGenerator.

        Args:
            output_dir (str): R√©pertoire pour sauvegarder les tableaux de bord.
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        logger.info(f"DashboardGenerator initialized. Output directory: {output_dir}")

    def create_dashboard(
        self, data: Dict[str, Dict[str, int]], output_file: str = "dashboard.html"
    ) -> str:
        """
        Cr√©e un tableau de bord interactif bas√© sur les donn√©es fournies.

        Args:
            data (Dict[str, Dict[str, int]]): Donn√©es pour g√©n√©rer les graphiques.
            output_file (str): Nom du fichier HTML export√©.

        Returns:
            str: Chemin vers le fichier g√©n√©r√©.
        """
        try:
            logger.info("Creating dashboard...")
            fig = make_subplots(
                rows=1,
                cols=len(data),
                subplot_titles=[f"{key}" for key in data.keys()],
            )

            # Ajout des graphiques
            col = 1
            for title, values in data.items():
                fig.add_trace(
                    go.Bar(x=list(values.keys()), y=list(values.values()), name=title),
                    row=1,
                    col=col,
                )
                col += 1

            fig.update_layout(
                title="Dashboard",
                barmode="group",
                template="plotly_dark",
                height=600,
                width=1200,
            )

            # Exporter le tableau de bord
            output_path = os.path.join(self.output_dir, output_file)
            fig.write_html(output_path)
            logger.info(f"Dashboard exported to: {output_path}")
            return output_path
        except Exception as e:
            logger.error(f"Error creating dashboard: {e}")
            return ""

    def add_pie_chart(self, fig: go.Figure, data: Dict[str, int], title: str, row: int, col: int):
        """
        Ajoute un graphique en camembert au tableau de bord.

        Args:
            fig (go.Figure): Figure Plotly existante.
            data (Dict[str, int]): Donn√©es pour le camembert.
            title (str): Titre du graphique.
            row (int): Ligne cible.
            col (int): Colonne cible.
        """
        try:
            fig.add_trace(
                go.Pie(labels=list(data.keys()), values=list(data.values()), title=title),
                row=row,
                col=col,
            )
            logger.info(f"Pie chart added for: {title}")
        except Exception as e:
            logger.error(f"Error adding pie chart: {e}")

    def generate_sentiment_dashboard(
        self, sentiment_data: Dict[str, int], output_file: str = "sentiment_dashboard.html"
    ) -> str:
        """
        G√©n√®re un tableau de bord pour l'analyse des sentiments.

        Args:
            sentiment_data (Dict[str, int]): Donn√©es d‚Äôanalyse des sentiments.
            output_file (str): Nom du fichier export√©.

        Returns:
            str: Chemin vers le fichier g√©n√©r√©.
        """
        try:
            logger.info("Generating sentiment analysis dashboard...")
            fig = make_subplots(
                rows=1, cols=2, subplot_titles=["Sentiment Distribution", "Sentiment Details"]
            )

            # Ajouter un graphique en barre
            self.add_pie_chart(fig, sentiment_data, "Sentiment Distribution", row=1, col=1)

            # Ajouter un graphique d√©taill√©
            fig.add_trace(
                go.Bar(x=list(sentiment_data.keys()), y=list(sentiment_data.values()), name="Details"),
                row=1,
                col=2,
            )

            # Exporter le tableau de bord
            output_path = os.path.join(self.output_dir, output_file)
            fig.write_html(output_path)
            logger.info(f"Sentiment dashboard exported to: {output_path}")
            return output_path
        except Exception as e:
            logger.error(f"Error generating sentiment dashboard: {e}")
            return ""

    def export_to_image(self, input_file: str, output_file: str):
        """
        Exporte un tableau de bord HTML en image (PNG).

        Args:
            input_file (str): Chemin du fichier HTML d‚Äôentr√©e.
            output_file (str): Chemin du fichier image export√©.
        """
        try:
            from selenium import webdriver
            from PIL import Image

            # Charger le fichier HTML avec Selenium
            driver = webdriver.Chrome()
            driver.get(f"file://{os.path.abspath(input_file)}")
            screenshot = driver.get_screenshot_as_png()
            driver.quit()

            # Sauvegarder comme image
            image = Image.open(io.BytesIO(screenshot))
            image.save(output_file)
            logger.info(f"Dashboard exported to image: {output_file}")
        except Exception as e:
            logger.error(f"Error exporting dashboard to image: {e}")

# Sentiment Analysis Action
class ActionAdvancedSentimentAnalysis(Action):
    def name(self) -> str:
        return "action_advanced_sentiment_analysis"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer le message utilisateur
        user_message = tracker.latest_message.get("text")
        if not user_message:
            dispatcher.utter_message(text="Le message est vide ou invalide. Veuillez fournir un texte pour l'analyse.")
            return []

        try:
            # D√©finir des mots-cl√©s pond√©r√©s pour les sentiments
            sentiment_keywords = {
                "positive": {
                    "g√©nial": 2, "excellent": 3, "super": 2, "positif": 2, "joyeux": 1,
                    "j'adore": 3, "heureux": 2, "parfait": 3, "merveilleux": 2
                },
                "negative": {
                    "horrible": 3, "terrible": 3, "mal": 2, "d√©cevant": 2, "nul": 3,
                    "triste": 1, "je d√©teste": 3, "mauvais": 2, "pire": 2
                },
            }

            # Initialiser les scores
            positive_score = 0
            negative_score = 0

            # Analyser chaque mot-cl√© dans le message utilisateur
            for sentiment, words in sentiment_keywords.items():
                for word, weight in words.items():
                    if re.search(rf"\b{word}\b", user_message.lower()):
                        if sentiment == "positive":
                            positive_score += weight
                        elif sentiment == "negative":
                            negative_score += weight

            # Calculer les scores totaux et d√©terminer le sentiment
            total_score = positive_score + negative_score
            if total_score == 0:
                sentiment_label = "NEUTRAL"
                sentiment_confidence = 0.0
                dispatcher.utter_message(
                    text="Le message semble neutre, sans indication claire de sentiment."
                )
            else:
                sentiment_label = (
                    "POSITIVE" if positive_score > negative_score else "NEGATIVE"
                )
                sentiment_confidence = max(positive_score, negative_score) / total_score
                dispatcher.utter_message(
                    text=(
                        f"Sentiment d√©tect√© : {sentiment_label} "
                        f"(Confiance : {sentiment_confidence:.2f})."
                    )
                )

            # Log interne pour le d√©bogage
            logger.info(
                f"Analyse de sentiment : POSITIVE={positive_score}, NEGATIVE={negative_score}, TOTAL={total_score}"
            )

            # Mettre √† jour les slots pour une utilisation future
            return [
                SlotSet("sentiment_label", sentiment_label),
                SlotSet("sentiment_confidence", sentiment_confidence),
            ]

        except Exception as e:
            # Gestion des erreurs
            logger.error(f"Erreur lors de l'analyse des sentiments : {str(e)}")
            dispatcher.utter_message(
                text="Une erreur s'est produite lors de l'analyse des sentiments."
            )
            return []

class ActionEncryptSensitiveData(Action):
    def name(self) -> str:
        return "action_encrypt_sensitive_data"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer les donn√©es sensibles depuis le slot
        user_data = tracker.get_slot("sensitive_data")
        if not user_data:
            dispatcher.utter_message(text="Aucune donn√©e sensible √† chiffrer.")
            return []

        # V√©rifier la cl√© de chiffrement
        db_encryption_key = os.getenv("DB_ENCRYPTION_KEY")
        if not db_encryption_key:
            error_msg = "La cl√© de chiffrement n'est pas configur√©e. Veuillez d√©finir 'DB_ENCRYPTION_KEY' dans les variables d'environnement."
            logger.error(error_msg)
            dispatcher.utter_message(text=error_msg)
            return []

        try:
            # V√©rifier si la cl√© est valide pour Fernet
            if len(db_encryption_key.encode()) != 44:  # Cl√© Fernet doit √™tre de 44 caract√®res (32 bytes + encodage base64)
                raise ValueError("La cl√© de chiffrement fournie n'est pas valide.")

            # Initialiser Fernet avec la cl√© de chiffrement
            fernet = Fernet(db_encryption_key.encode())

            # Chiffrer les donn√©es sensibles
            encrypted_data = fernet.encrypt(user_data.encode()).decode()

            # Retourner les donn√©es chiffr√©es √† l'utilisateur
            dispatcher.utter_message(text="Donn√©es chiffr√©es avec succ√®s.")
            logger.info(f"Donn√©es utilisateur chiffr√©es avec succ√®s : {encrypted_data}")

            # Mettre √† jour le slot avec les donn√©es chiffr√©es
            return [SlotSet("encrypted_data", encrypted_data)]

        except ValueError as ve:
            error_msg = f"Erreur de validation de la cl√© de chiffrement : {ve}"
            logger.error(error_msg)
            dispatcher.utter_message(text=error_msg)

        except Exception as e:
            # Gestion des erreurs impr√©vues
            error_msg = f"Erreur lors du chiffrement des donn√©es : {e}"
            logger.error(error_msg)
            dispatcher.utter_message(text="Une erreur s'est produite lors du chiffrement des donn√©es.")

        return []

# Audio Response Generation Action
class ActionGenerateAudioResponse(Action):
    def name(self) -> str:
        return "action_generate_audio_response"

    async def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer le message utilisateur
        user_message = tracker.latest_message.get("text")
        if not user_message:
            dispatcher.utter_message(text="Je n'ai pas trouv√© de message √† convertir en audio.")
            return []

        try:
            # Configurer AWS Polly
            polly_client = boto3.client('polly', region_name='us-east-1')

            # Synth√®se vocale avec Polly
            response = polly_client.synthesize_speech(
                VoiceId='Joanna',  # Vous pouvez choisir une autre voix
                OutputFormat='mp3',
                Text=user_message
            )

            # Sauvegarder le fichier audio
            output_dir = "audio_responses"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "response.mp3")

            async with aiofiles.open(file_path, mode='wb') as file:
                await file.write(response['AudioStream'].read())

            # Envoyer l'audio en r√©ponse
            dispatcher.utter_message(
                text="Voici une r√©ponse vocale. Vous pouvez √©couter l'audio ici :",
                attachment={"type": "audio", "src": file_path}
            )

        except (BotoCoreError, ClientError) as error:
            logger.error(f"Erreur avec AWS Polly : {error}")
            dispatcher.utter_message(text="Une erreur s'est produite lors de la g√©n√©ration de la r√©ponse vocale.")

        except Exception as e:
            logger.error(f"Erreur inattendue : {e}")
            dispatcher.utter_message(text="Une erreur inattendue est survenue.")

        return []


class AdvancedVisualizer:
    """
    G√©n√®re des visualisations avanc√©es interactives et exportables.
    """

    def __init__(self, output_dir: str = "visualizations"):
        """
        Initialise le gestionnaire de visualisations.

        Args:
            output_dir (str): R√©pertoire de sortie pour sauvegarder les visualisations.
        """
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)

    def generate_heatmap(self, data: List[List[float]], x_labels: List[str], y_labels: List[str], title: str) -> go.Figure:
        """
        G√©n√®re une heatmap interactive.

        Args:
            data (List[List[float]]): Donn√©es pour la heatmap.
            x_labels (List[str]): Labels pour l'axe X.
            y_labels (List[str]): Labels pour l'axe Y.
            title (str): Titre du graphique.

        Returns:
            go.Figure: Graphique interactif.
        """
        if len(data) != len(y_labels) or any(len(row) != len(x_labels) for row in data):
            raise ValueError("Les dimensions des donn√©es et des labels doivent correspondre.")

        fig = go.Figure(data=go.Heatmap(z=data, x=x_labels, y=y_labels, colorscale="Viridis"))
        fig.update_layout(title=title, template="plotly_white")
        return fig

    def save_figure(self, fig: go.Figure, file_name: str):
        """
        Sauvegarde une figure Plotly au format HTML.

        Args:
            fig (go.Figure): Figure Plotly.
            file_name (str): Nom du fichier HTML.
        """
        file_path = os.path.join(self.output_dir, file_name)
        fig.write_html(file_path)
        return file_path

class MonitoringService:
    """
    Service de monitoring pour centraliser les m√©triques et logs.
    """

    def __init__(self):
        """
        Initialise le service de monitoring.
        """
        self.metrics = {}

    def log_metric(self, name: str, value: Any):
        """
        Enregistre une m√©trique avec son nom et sa valeur.

        Args:
            name (str): Nom de la m√©trique.
            value (Any): Valeur de la m√©trique.
        """
        self.metrics[name] = value
        logger.info(f"M√©trique enregistr√©e : {name} = {value}")

    def track_execution_time(self, func):
        """
        D√©corateur pour suivre le temps d'ex√©cution d'une fonction.

        Args:
            func: Fonction √† surveiller.

        Returns:
            Fonction d√©cor√©e.
        """
        def wrapper(*args, **kwargs):
            start_time = time.time()
            result = func(*args, **kwargs)
            elapsed_time = time.time() - start_time
            self.log_metric(f"{func.__name__}_execution_time", elapsed_time)
            logger.info(f"Temps d'ex√©cution pour {func.__name__} : {elapsed_time:.2f} secondes")
            return result
        return wrapper

    def get_metrics(self) -> Dict[str, Any]:
        """
        Retourne toutes les m√©triques enregistr√©es.

        Returns:
            Dict[str, Any]: Dictionnaire des m√©triques.
        """
        return self.metrics
class ClusteringService:
    """
    Service avanc√© pour la r√©duction de dimensions et le clustering, avec des visualisations interactives.
    """

    def __init__(self, n_neighbors: int = 15, min_dist: float = 0.1, n_components: int = 2, random_state: int = 42):
        """
        Initialise le service avec des param√®tres configurables pour UMAP.

        Args:
            n_neighbors (int): Nombre de voisins pour UMAP.
            min_dist (float): Distance minimale pour UMAP.
            n_components (int): Dimensions cibles pour UMAP (2D ou 3D).
            random_state (int): √âtat al√©atoire pour reproductibilit√©.
        """
        self.reducer = UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, random_state=random_state)
        logger.info(f"ClusteringService initialized with {n_components}D UMAP reducer.")

    def reduce_dimensions(self, embeddings: Union[List[List[float]], np.ndarray]) -> np.ndarray:
        """
        R√©duit les dimensions des donn√©es avec UMAP.

        Args:
            embeddings (Union[List[List[float]], np.ndarray]): Donn√©es haute dimension.

        Returns:
            np.ndarray: Donn√©es r√©duites.
        """
        embeddings = self._validate_and_convert_embeddings(embeddings)

        logger.info(f"Reducing dimensions to {self.reducer.n_components}D...")
        try:
            reduced_embeddings = self.reducer.fit_transform(embeddings)
            logger.info("Dimension reduction completed successfully.")
            return reduced_embeddings
        except Exception as e:
            logger.error(f"Error during dimension reduction: {e}")
            raise

    def apply_clustering(self, embeddings: np.ndarray, method: str = "kmeans", **kwargs) -> Dict[str, Any]:
        """
        Applique un clustering sur les donn√©es r√©duites.

        Args:
            embeddings (np.ndarray): Donn√©es r√©duites.
            method (str): M√©thode de clustering ('kmeans', 'dbscan', 'hdbscan').
            **kwargs: Param√®tres sp√©cifiques √† l'algorithme.

        Returns:
            Dict[str, Any]: R√©sultats avec les labels et le mod√®le utilis√©.
        """
        logger.info(f"Applying clustering using method: {method}...")
        try:
            if method == "kmeans":
                n_clusters = kwargs.get("n_clusters", 5)
                cluster_model = KMeans(n_clusters=n_clusters, random_state=42)
            elif method == "dbscan":
                eps = kwargs.get("eps", 0.5)
                min_samples = kwargs.get("min_samples", 5)
                cluster_model = DBSCAN(eps=eps, min_samples=min_samples, metric="euclidean")
            elif method == "hdbscan":
                min_cluster_size = kwargs.get("min_cluster_size", 5)
                cluster_model = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)
            else:
                raise ValueError(f"Unsupported clustering method: {method}")

            labels = cluster_model.fit_predict(embeddings)
            logger.info(f"Clustering completed. Found {len(set(labels)) - (1 if -1 in labels else 0)} clusters.")
            return {"labels": labels, "model": cluster_model}
        except Exception as e:
            logger.error(f"Error during clustering: {e}")
            raise

    def visualize_clusters(self, embeddings: np.ndarray, labels: List[int], interactive: bool = True, save_path: str = None):
        """
        Visualise les clusters en 2D avec des options interactives.

        Args:
            embeddings (np.ndarray): Donn√©es r√©duites en 2D.
            labels (List[int]): Labels des clusters.
            interactive (bool): G√©n√©rer une visualisation interactive (Plotly) ou statique (Matplotlib).
            save_path (str): Chemin pour enregistrer la visualisation (facultatif).
        """
        if embeddings.shape[1] != 2:
            raise ValueError("Embeddings must be 2D for visualization.")

        logger.info("Generating cluster visualization...")
        try:
            if interactive:
                # Utilisation de Plotly pour une visualisation interactive
                fig = px.scatter(
                    x=embeddings[:, 0],
                    y=embeddings[:, 1],
                    color=labels,
                    title="Interactive Cluster Visualization",
                    labels={"x": "UMAP Dim 1", "y": "UMAP Dim 2", "color": "Cluster"},
                )
                if save_path:
                    fig.write_html(save_path)
                    logger.info(f"Interactive cluster visualization saved to {save_path}.")
                fig.show()
            else:
                # Visualisation statique avec Matplotlib
                plt.figure(figsize=(10, 8))
                scatter = plt.scatter(embeddings[:, 0], embeddings[:, 1], c=labels, cmap="tab10", s=20)
                plt.title("Static Cluster Visualization")
                plt.xlabel("UMAP Dim 1")
                plt.ylabel("UMAP Dim 2")
                plt.colorbar(scatter, label="Cluster")
                if save_path:
                    plt.savefig(save_path)
                    logger.info(f"Static cluster visualization saved to {save_path}.")
                else:
                    plt.show()
        except Exception as e:
            logger.error(f"Error during cluster visualization: {e}")
            raise

    def cluster_and_visualize(
        self, embeddings: Union[List[List[float]], np.ndarray], method: str = "kmeans", interactive: bool = True, **kwargs
    ) -> Dict[str, Any]:
        """
        Pipeline complet pour r√©duire les dimensions, clusteriser et visualiser.

        Args:
            embeddings (Union[List[List[float]], np.ndarray]): Donn√©es haute dimension.
            method (str): M√©thode de clustering ('kmeans', 'dbscan', 'hdbscan').
            interactive (bool): G√©n√©rer une visualisation interactive ou statique.
            **kwargs: Param√®tres sp√©cifiques au clustering.

        Returns:
            Dict[str, Any]: R√©sultats du clustering.
        """
        logger.info("Starting full clustering pipeline...")
        try:
            reduced_embeddings = self.reduce_dimensions(embeddings)
            clustering_results = self.apply_clustering(reduced_embeddings, method, **kwargs)
            self.visualize_clusters(
                embeddings=reduced_embeddings,
                labels=clustering_results["labels"],
                interactive=interactive,
                save_path=kwargs.get("save_path", None),
            )
            return {"reduced_embeddings": reduced_embeddings, **clustering_results}
        except Exception as e:
            logger.error(f"Error in clustering pipeline: {e}")
            raise

    def _validate_and_convert_embeddings(self, embeddings: Any) -> np.ndarray:
        """
        Valide et convertit les embeddings en numpy array.

        Args:
            embeddings (Any): Donn√©es √† valider.

        Returns:
            np.ndarray: Donn√©es valid√©es et converties.
        """
        if isinstance(embeddings, list):
            embeddings = np.array(embeddings)
        if not isinstance(embeddings, np.ndarray) or embeddings.ndim != 2 or embeddings.size == 0:
            raise ValueError("Embeddings must be a non-empty 2D numpy array or a list of lists.")
        return embeddings


class DataPreprocessor:
    """
    G√®re le pr√©traitement des donn√©es pour le clustering ou les mod√®les.
    """

    def __init__(self, normalize: bool = True, standardize: bool = True):
        """
        Initialise les param√®tres de pr√©traitement.

        Args:
            normalize (bool): Normaliser les donn√©es (MinMax Scaling).
            standardize (bool): Standardiser les donn√©es (Moyenne=0, √âcart-type=1).
        """
        self.normalize = normalize
        self.standardize = standardize

    def preprocess(self, data: Union[List[List[float]], np.ndarray]) -> np.ndarray:
        """
        Applique le pr√©traitement sur les donn√©es.

        Args:
            data (Union[List[List[float]], np.ndarray]): Donn√©es brutes.

        Returns:
            np.ndarray: Donn√©es pr√©trait√©es.
        """
        data = self._validate_and_convert(data)

        if self.standardize:
            data = (data - np.mean(data, axis=0)) / np.std(data, axis=0)
        if self.normalize:
            data = (data - np.min(data, axis=0)) / (np.max(data, axis=0) - np.min(data, axis=0))

        return data

    def _validate_and_convert(self, data: Union[List[List[float]], np.ndarray]) -> np.ndarray:
        """
        Valide et convertit les donn√©es en numpy array.

        Args:
            data (Union[List[List[float]], np.ndarray]): Donn√©es brutes.

        Returns:
            np.ndarray: Donn√©es valid√©es.
        """
        if isinstance(data, list):
            data = np.array(data)
        if not isinstance(data, np.ndarray) or data.ndim != 2 or data.size == 0:
            raise ValueError("Les donn√©es doivent √™tre une liste 2D ou un tableau numpy non vide.")
        return data


class MetricsEvaluator:
    """
    √âvalue les clusters ou les mod√®les avec des m√©triques.
    """

    def evaluate_clustering(self, embeddings: np.ndarray, labels: List[int]) -> Dict[str, float]:
        """
        √âvalue la qualit√© des clusters avec des m√©triques.

        Args:
            embeddings (np.ndarray): Donn√©es r√©duites.
            labels (List[int]): Labels des clusters.

        Returns:
            Dict[str, float]: Scores calcul√©s.
        """
        if len(set(labels)) <= 1:
            raise ValueError("Impossible d'√©valuer le clustering avec moins de 2 clusters.")

        try:
            silhouette = silhouette_score(embeddings, labels)
            davies_bouldin = davies_bouldin_score(embeddings, labels)
            logger.info("Clustering evaluated successfully.")
            return {
                "silhouette_score": silhouette,
                "davies_bouldin_index": davies_bouldin
            }
        except Exception as e:
            logger.error(f"Erreur lors de l'√©valuation des clusters : {e}")
            raise

class MultiModelManager:
    """
    G√®re plusieurs mod√®les ONNX avec support pour validation, ex√©cution et gestion centralis√©e.
    """

    def __init__(self):
        """
        Initialise la classe avec un gestionnaire de mod√®les vide.
        """
        self.models = {}
        logger.info("MultiModelManager initialized with no models loaded.")

    def load_model(self, model_name: str, model_path: str, device: str = "auto"):
        """
        Charge un mod√®le ONNX dans le gestionnaire.

        Args:
            model_name (str): Nom du mod√®le.
            model_path (str): Chemin vers le fichier ONNX.
            device (str): Device √† utiliser ('cpu', 'gpu', ou 'auto').
        """
        try:
            device_provider = (
                "CUDAExecutionProvider" if (device == "gpu" or (device == "auto" and ort.get_device() == "GPU"))
                else "CPUExecutionProvider"
            )
            session = ort.InferenceSession(model_path, providers=[device_provider])
            self.models[model_name] = {
                "session": session,
                "input_metadata": {inp.name: inp.shape for inp in session.get_inputs()},
                "output_metadata": {out.name: out.shape for out in session.get_outputs()},
            }
            logger.info(f"Model '{model_name}' loaded from {model_path} on device: {device_provider}.")
        except Exception as e:
            logger.error(f"Error loading model '{model_name}' from {model_path}: {e}")

    def unload_model(self, model_name: str):
        """
        Supprime un mod√®le du gestionnaire.

        Args:
            model_name (str): Nom du mod√®le √† supprimer.
        """
        if model_name in self.models:
            del self.models[model_name]
            logger.info(f"Model '{model_name}' unloaded successfully.")
        else:
            logger.warning(f"Model '{model_name}' not found in manager.")

    def list_models(self) -> List[str]:
        """
        Liste les mod√®les actuellement charg√©s.

        Returns:
            List[str]: Noms des mod√®les charg√©s.
        """
        logger.info("Listing all loaded models.")
        return list(self.models.keys())

    def validate_input(self, model_name: str, input_data: Dict[str, Any]) -> bool:
        """
        Valide les donn√©es d'entr√©e pour un mod√®le sp√©cifique.

        Args:
            model_name (str): Nom du mod√®le.
            input_data (Dict[str, Any]): Donn√©es d'entr√©e.

        Returns:
            bool: True si les donn√©es sont valides, sinon False.
        """
        if model_name not in self.models:
            logger.error(f"Model '{model_name}' not found.")
            return False

        model = self.models[model_name]
        for key, value in input_data.items():
            if key not in model["input_metadata"]:
                logger.error(f"Invalid input key: {key}. Expected keys: {list(model['input_metadata'].keys())}.")
                return False
            if len(value.shape) != len(model["input_metadata"][key]):
                logger.error(f"Shape mismatch for input '{key}': {value.shape} != {model['input_metadata'][key]}.")
                return False

        logger.info(f"Input validation passed for model '{model_name}'.")
        return True

    def predict(self, model_name: str, input_data: Dict[str, Any]) -> List[Any]:
        """
        Effectue une pr√©diction avec un mod√®le sp√©cifique.

        Args:
            model_name (str): Nom du mod√®le.
            input_data (Dict[str, Any]): Donn√©es d'entr√©e.

        Returns:
            List[Any]: R√©sultats de la pr√©diction.
        """
        if not self.validate_input(model_name, input_data):
            raise ValueError(f"Invalid input data for model '{model_name}'.")

        try:
            logger.info(f"Running inference for model '{model_name}'...")
            session = self.models[model_name]["session"]
            outputs = session.run(None, input_data)
            logger.info(f"Inference completed for model '{model_name}'.")
            return outputs
        except Exception as e:
            logger.error(f"Error during inference for model '{model_name}': {e}")
            return []

    def predict_all(self, input_data: Dict[str, Dict[str, Any]]) -> Dict[str, List[Any]]:
        """
        Effectue des pr√©dictions pour tous les mod√®les charg√©s.

        Args:
            input_data (Dict[str, Dict[str, Any]]): Donn√©es d'entr√©e pour chaque mod√®le.

        Returns:
            Dict[str, List[Any]]: R√©sultats des pr√©dictions par mod√®le.
        """
        predictions = {}
        logger.info("Running predictions for all loaded models.")
        for model_name, data in input_data.items():
            if model_name in self.models:
                predictions[model_name] = self.predict(model_name, data)
            else:
                logger.warning(f"Model '{model_name}' not found.")
                predictions[model_name] = []
        return predictions

    def get_metadata(self, model_name: str) -> Dict[str, Any]:
        """
        R√©cup√®re les m√©tadonn√©es d'un mod√®le sp√©cifique.

        Args:
            model_name (str): Nom du mod√®le.

        Returns:
            Dict[str, Any]: M√©tadonn√©es du mod√®le.
        """
        if model_name not in self.models:
            logger.error(f"Model '{model_name}' not found.")
            return {}

        metadata = {
            "inputs": self.models[model_name]["input_metadata"],
            "outputs": self.models[model_name]["output_metadata"],
        }
        logger.info(f"Retrieved metadata for model '{model_name}': {metadata}")
        return metadata


class PredictionService:
    """
    Service centralis√© pour g√©rer les pr√©dictions des mod√®les.
    """

    def __init__(self, model_manager: Any):
        """
        Initialise le service avec un gestionnaire de mod√®les.

        Args:
            model_manager (Any): Instance de gestionnaire de mod√®les (e.g., MultiModelManager).
        """
        self.model_manager = model_manager

    def predict(self, model_name: str, input_data: Dict[str, Any]) -> Any:
        """
        Effectue une pr√©diction avec un mod√®le sp√©cifique.

        Args:
            model_name (str): Nom du mod√®le.
            input_data (Dict[str, Any]): Donn√©es d'entr√©e.

        Returns:
            Any: R√©sultats de la pr√©diction.
        """
        if model_name not in self.model_manager.list_models():
            raise ValueError(f"Le mod√®le '{model_name}' n'est pas charg√©.")

        try:
            logger.info(f"Pr√©diction en cours pour le mod√®le '{model_name}'...")
            return self.model_manager.predict(model_name, input_data)
        except Exception as e:
            logger.error(f"Erreur lors de la pr√©diction avec le mod√®le '{model_name}': {e}")
            raise


class NextLevelAISystem:
    """
    Syst√®me AI avanc√© avec gestion multi-mod√®le, cache Redis, et analyses enrichies.
    """

    def __init__(self):
        """
        Initialise le syst√®me AI de niveau sup√©rieur.
        """
        self.mongo_manager = MongoDBManager()
        self.cache_manager = CacheManager()
        self.nlp_processor = NLPProcessor()
        self.sentiment_analyzer = SentimentAnalyzer()
        self.data_organizer = DataOrganizer()
        self.dashboard_generator = DashboardGenerator()
        self.models = {
            "sentiment": ONNXModelWrapper("sentiment_model.onnx"),
            "intent": ONNXModelWrapper("intent_classification.onnx"),
        }
        logger.info("NextLevelAISystem initialized with advanced components.")

    async def process_message(self, user_id: str, user_message: str, language: str = "auto") -> Dict[str, Any]:
        """
        Traite un message utilisateur avec mod√®les ONNX et NLP.

        Args:
            user_id (str): ID utilisateur.
            user_message (str): Message envoy√© par l'utilisateur.
            language (str): Langue cible (par d√©faut d√©tect√©e automatiquement).

        Returns:
            Dict[str, Any]: R√©sultats du traitement (sentiment, intent, r√©ponse).
        """
        try:
            # V√©rifier le cache
            cache_key = f"message_{user_id}_{user_message}"
            cached_response = self.cache_manager.get_cache(cache_key)
            if cached_response:
                logger.info(f"Cache hit for key: {cache_key}")
                return cached_response

            # D√©tection de langue
            detected_language = self.nlp_processor.detect_language(user_message) if language == "auto" else language
            logger.info(f"Detected language: {detected_language}")

            # Pr√©traitement
            preprocessed_message = self.nlp_processor.preprocess_text(user_message, target_language="en")

            # Analyse de sentiment via ONNX
            sentiment = self.models["sentiment"].predict({"input_text": preprocessed_message})
            sentiment_result = {"label": "positive" if sentiment[0] > 0.5 else "negative", "score": sentiment[0]}

            # Classification d'intention via ONNX
            intent = self.models["intent"].predict({"input_text": preprocessed_message})
            intent_result = {"intent": "greeting" if intent[0] > 0.5 else "request", "score": intent[0]}

            # G√©n√©ration de la r√©ponse
            response = (
                f"Detected sentiment: {sentiment_result['label']} "
                f"(Confidence: {sentiment_result['score']:.2f}). "
                f"Intent: {intent_result['intent']}."
            )

            # Sauvegarde des interactions
            metadata = {
                "detected_language": detected_language,
                "sentiment": sentiment_result,
                "intent": intent_result,
            }
            await self.mongo_manager.save_interaction(user_id, user_message, response, metadata)

            # Sauvegarde dans le cache
            result = {"response": response, "sentiment": sentiment_result, "intent": intent_result}
            self.cache_manager.set_cache(cache_key, result)

            logger.info(f"Processed message for user {user_id}")
            return result
        except Exception as e:
            logger.error(f"Error processing message for user {user_id}: {e}")
            return {"response": "Error occurred.", "sentiment": None, "intent": None}

    async def process_batch(self, user_id: str, messages: List[str]) -> List[Dict[str, Any]]:
        """
        Traite un lot de messages utilisateur avec le cache.

        Args:
            user_id (str): ID utilisateur.
            messages (List[str]): Liste des messages utilisateur.

        Returns:
            List[Dict[str, Any]]: R√©sultats pour chaque message.
        """
        try:
            tasks = [self.process_message(user_id, message) for message in messages]
            results = await asyncio.gather(*tasks)
            logger.info(f"Batch processing completed for user {user_id}")
            return results
        except Exception as e:
            logger.error(f"Error processing batch for user {user_id}: {e}")
            return []

    async def cluster_texts(self, texts: List[str], method: str = "kmeans", **kwargs) -> Dict[str, Any]:
        """
        Organise et clusterise les textes avec des embeddings.

        Args:
            texts (List[str]): Liste des textes.
            method (str): M√©thode de clustering ('kmeans', 'dbscan', 'hdbscan').
            **kwargs: Param√®tres sp√©cifiques pour le clustering.

        Returns:
            Dict[str, Any]: R√©sum√© des clusters et chemin du fichier export√©.
        """
        try:
            embeddings = self.data_organizer.generate_embeddings(texts)
            clustered_data = self.data_organizer.apply_clustering(embeddings, method=method, **kwargs)
            export_path = self.data_organizer.export_clusters(clustered_data)
            logger.info("Texts clustered successfully.")
            return {"clusters": clustered_data["Cluster"].value_counts().to_dict(), "export_path": export_path}
        except Exception as e:
            logger.error(f"Error clustering texts: {e}")
            return {"clusters": {}, "export_path": None}

    async def generate_dashboard(self, user_id: str) -> str:
        """
        G√©n√®re un tableau de bord des interactions utilisateur.

        Args:
            user_id (str): ID utilisateur.

        Returns:
            str: Chemin vers le fichier HTML g√©n√©r√©.
        """
        try:
            interactions = await self.mongo_manager.fetch_interactions(user_id)
            sentiment_summary = {}
            for interaction in interactions:
                sentiment = interaction["metadata"].get("sentiment", {}).get("label", "unknown")
                sentiment_summary[sentiment] = sentiment_summary.get(sentiment, 0) + 1

            dashboard_path = self.dashboard_generator.create_dashboard(
                {"Sentiment Distribution": sentiment_summary}, output_file=f"{user_id}_dashboard.html"
            )
            logger.info(f"Dashboard generated for user {user_id}")
            return dashboard_path
        except Exception as e:
            logger.error(f"Error generating dashboard for user {user_id}: {e}")
            return ""



# Intent Classifier
class IntentClassifier:
    """
    Classifie les intentions utilisateur avec support pour plusieurs mod√®les et pipelines avanc√©s.
    """

    def __init__(self, embedding_model: str = "paraphrase-MiniLM-L6-v2", model_type: str = "random_forest"):
        """
        Initialise la classe IntentClassifier.

        Args:
            embedding_model (str): Mod√®le SentenceTransformers pour les embeddings avanc√©s.
            model_type (str): Type de mod√®le d'apprentissage ("random_forest" ou "svm").
        """
        self.embedding_model = SentenceTransformer(embedding_model)
        self.vectorizer = TfidfVectorizer(max_features=3000)
        self.model_type = model_type
        self.model = None
        logger.info(f"IntentClassifier initialized with model type: {model_type} and embedding model: {embedding_model}.")

    def prepare_data(self, data: pd.DataFrame, text_column: str = "text", label_column: str = "label") -> tuple:
        """
        Pr√©pare les donn√©es pour l'entra√Ænement.

        Args:
            data (pd.DataFrame): Jeu de donn√©es.
            text_column (str): Colonne contenant les textes.
            label_column (str): Colonne contenant les √©tiquettes.

        Returns:
            tuple: (X_train, X_test, y_train, y_test)
        """
        if text_column not in data.columns or label_column not in data.columns:
            logger.error(f"Columns '{text_column}' or '{label_column}' are missing from the dataset.")
            raise ValueError("Required columns are missing in the dataset.")

        logger.info("Generating embeddings for text data...")
        embeddings = self.embedding_model.encode(data[text_column].tolist(), show_progress_bar=True)
        X_train, X_test, y_train, y_test = train_test_split(embeddings, data[label_column], test_size=0.2, random_state=42)
        logger.info("Data preparation completed.")
        return X_train, X_test, y_train, y_test

    def train_model(self, X_train, y_train, hyperparameters: dict = None):
        """
        Entra√Æne le mod√®le s√©lectionn√©.

        Args:
            X_train: Donn√©es d'entra√Ænement.
            y_train: √âtiquettes d'entra√Ænement.
            hyperparameters (dict): Hyperparam√®tres pour le mod√®le.
        """
        hyperparameters = hyperparameters or {}
        logger.info(f"Training model: {self.model_type}...")

        if self.model_type == "random_forest":
            self.model = RandomForestClassifier(random_state=42, **hyperparameters)
        elif self.model_type == "svm":
            self.model = SVC(kernel="linear", probability=True, random_state=42, **hyperparameters)
        else:
            logger.error(f"Unsupported model type: {self.model_type}")
            raise ValueError(f"Model type '{self.model_type}' is not supported.")

        self.model.fit(X_train, y_train)
        logger.info("Model training completed.")

    def evaluate_model(self, X_test, y_test):
        """
        √âvalue le mod√®le avec des donn√©es de test.

        Args:
            X_test: Donn√©es de test.
            y_test: √âtiquettes de test.

        Returns:
            float: Pr√©cision du mod√®le.
        """
        logger.info("Evaluating model...")
        y_pred = self.model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        logger.info(f"Accuracy: {accuracy * 100:.2f}%")
        print(classification_report(y_test, y_pred))

        # Afficher la matrice de confusion
        cm = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(10, 8))
        plt.imshow(cm, interpolation="nearest", cmap=plt.cm.Blues)
        plt.title("Confusion Matrix")
        plt.colorbar()
        plt.ylabel("True Label")
        plt.xlabel("Predicted Label")
        plt.show()

        return accuracy

    def predict(self, texts: List[str]) -> List[str]:
        """
        Pr√©dictions pour des textes donn√©s.

        Args:
            texts (List[str]): Liste des textes.

        Returns:
            List[str]: Liste des pr√©dictions.
        """
        logger.info("Predicting intents...")
        embeddings = self.embedding_model.encode(texts, show_progress_bar=True)
        predictions = self.model.predict(embeddings)
        logger.info("Predictions completed.")
        return predictions

    def tune_hyperparameters(self, X_train, y_train, param_grid: dict):
        """
        Effectue une recherche des meilleurs hyperparam√®tres.

        Args:
            X_train: Donn√©es d'entra√Ænement.
            y_train: √âtiquettes d'entra√Ænement.
            param_grid (dict): Grille des hyperparam√®tres.

        Returns:
            dict: Meilleurs hyperparam√®tres.
        """
        logger.info("Tuning hyperparameters...")
        if self.model_type == "random_forest":
            model = RandomForestClassifier(random_state=42)
        elif self.model_type == "svm":
            model = SVC(kernel="linear", probability=True, random_state=42)
        else:
            logger.error(f"Unsupported model type for hyperparameter tuning: {self.model_type}")
            raise ValueError("Unsupported model type for hyperparameter tuning.")

        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring="accuracy", verbose=2, n_jobs=-1)
        grid_search.fit(X_train, y_train)
        self.model = grid_search.best_estimator_
        logger.info(f"Best hyperparameters found: {grid_search.best_params_}")
        return grid_search.best_params_
# NLP Processor

class NLPProcessor:
    """
    Pr√©traitement avanc√© des textes avec NLP multilingue.
    """

    def __init__(self, language_model: str = "en_core_web_sm", embedding_model: str = "all-MiniLM-L6-v2"):



        """
        Initialise le processeur NLP avec spaCy et SentenceTransformers.

        Args:
            language_model (str): Mod√®le linguistique spaCy.
            embedding_model (str): Mod√®le d'embedding SentenceTransformers.
        """
        self.nlp = spacy_load(language_model)
        self.translator = Translator()
        self.embedding_model = SentenceTransformer(embedding_model)
        self.tfidf_vectorizer = TfidfVectorizer(max_features=3000)
        logger.info(f"NLPProcessor initialized with spaCy model '{language_model}' and embedding model '{embedding_model}'.")

    def __init__(self):
        self.generator = pipeline("text-generation", model="gpt2")

    def generate_response(self, user_message: str) -> str:
        """
        G√©n√®re une r√©ponse brute √† partir du message utilisateur.
        """
        return self.generator(f"User: {user_message}\nBot:", max_length=100, do_sample=True)[0]["generated_text"]

    def adjust_tone(self, text: str, tone: str) -> str:
        """
        Ajuste le ton de la r√©ponse (amical, formel, etc.).
        """
        tone_prefix = {
            "friendly": "Paraphrase this in a friendly tone:",
            "formal": "Paraphrase this in a formal tone:"
        }
        command = f"{tone_prefix.get(tone, '')} {text}"
        return self.generator(command, max_length=100, do_sample=True)[0]["generated_text"]
    def detect_language(self, text: str) -> str:
        """
        D√©tecte la langue d'un texte.

        Args:
            text (str): Texte √† analyser.

        Returns:
            str: Code ISO de la langue d√©tect√©e.
        """
        try:
            language = detect(text)
            logger.info(f"Language detected: {language}")
            return language
        except Exception as e:
            logger.warning(f"Error detecting language: {e}")
            return "unknown"

    def translate_text(self, text: str, target_language: str = "en") -> str:
        """
        Traduit un texte dans une langue cible.

        Args:
            text (str): Texte brut.
            target_language (str): Langue cible.

        Returns:
            str: Texte traduit.
        """
        try:
            translated = self.translator.translate(text, dest=target_language).text
            logger.info(f"Text translated to {target_language}.")
            return translated
        except Exception as e:
            logger.error(f"Error translating text: {e}")
            return text

    def preprocess_text(self, text: str, target_language: str = "en", remove_stopwords: bool = True) -> str:
        """
        Pr√©traite un texte : traduction, lemmatisation, suppression des stopwords.

        Args:
            text (str): Texte brut.
            target_language (str): Langue cible.
            remove_stopwords (bool): Supprimer les stopwords ou non.

        Returns:
            str: Texte pr√©trait√©.
        """
        try:
            detected_language = self.detect_language(text)
            if detected_language != target_language:
                logger.info(f"Translating text from {detected_language} to {target_language}...")
                text = self.translate_text(text, target_language)

            doc = self.nlp(text)
            preprocessed = [
                token.lemma_ for token in doc if not token.is_punct and (not remove_stopwords or token.text.lower() not in STOP_WORDS)
            ]
            logger.info(f"Preprocessed text: {preprocessed[:5]}...")
            return " ".join(preprocessed)
        except Exception as e:
            logger.error(f"Error during text preprocessing: {e}")
            return ""

    def extract_entities(self, text: str) -> Dict[str, List[str]]:
        """
        Extrait les entit√©s nomm√©es d'un texte.

        Args:
            text (str): Texte brut.

        Returns:
            Dict[str, List[str]]: Dictionnaire des entit√©s nomm√©es par type.
        """
        try:
            doc = self.nlp(text)
            entities = {}
            for ent in doc.ents:
                entities.setdefault(ent.label_, []).append(ent.text)
            logger.info(f"Extracted entities: {entities}")
            return entities
        except Exception as e:
            logger.error(f"Error extracting entities: {e}")
            return {}

    def generate_embeddings(self, texts: List[str]) -> List[List[float]]:
        """
        G√©n√®re des embeddings pour une liste de textes.

        Args:
            texts (List[str]): Liste des textes.

        Returns:
            List[List[float]]: Embeddings vectoriels.
        """
        try:
            embeddings = self.embedding_model.encode(texts, show_progress_bar=True)
            logger.info(f"Generated embeddings for {len(texts)} texts.")
            return embeddings
        except Exception as e:
            logger.error(f"Error generating embeddings: {e}")
            return []

    def process_batch(self, texts: List[str], target_language: str = "en", remove_stopwords: bool = True) -> List[str]:
        """
        Pr√©traite un lot de textes en parall√®le.

        Args:
            texts (List[str]): Liste des textes.
            target_language (str): Langue cible.
            remove_stopwords (bool): Supprimer les stopwords ou non.

        Returns:
            List[str]: Textes pr√©trait√©s.
        """
        try:
            logger.info(f"Processing batch of {len(texts)} texts...")
            results = Parallel(n_jobs=-1)(
                delayed(self.preprocess_text)(text, target_language, remove_stopwords) for text in texts
            )
            logger.info("Batch processing completed.")
            return results
        except Exception as e:
            logger.error(f"Error processing batch: {e}")
            return []

class EliteAISystem:
    """
    Syst√®me centralis√© pour g√©rer l'IA avanc√©e, combinant MongoDB, ONNX, NLP et visualisation.
    """

    def __init__(self):
        """
        Initialise tous les composants du syst√®me Elite AI.
        """
        self.mongo_manager = MongoDBManager()
        self.onnx_model = ONNXModelWrapper("optimized_model.onnx")
        self.nlp_processor = NLPProcessor()
        self.sentiment_analyzer = SentimentAnalyzer()
        self.data_organizer = DataOrganizer()
        self.dashboard_generator = DashboardGenerator()
        logger.info("EliteAISystem initialized with all components.")

    async def process_message(self, user_id: str, user_message: str, language: str = "auto") -> str:
        """
        Traite un message utilisateur avec analyse de sentiment et sauvegarde.

        Args:
            user_id (str): ID utilisateur.
            user_message (str): Message envoy√© par l'utilisateur.
            language (str): Langue cible pour le traitement.

        Returns:
            str: R√©ponse g√©n√©r√©e pour l'utilisateur.
        """
        try:
            # D√©tection de la langue
            detected_language = self.nlp_processor.detect_language(user_message) if language == "auto" else language
            logger.info(f"Detected language: {detected_language}")

            # Pr√©traitement du message
            preprocessed_message = self.nlp_processor.preprocess_text(user_message, target_language="en")

            # Analyse de sentiment
            sentiment = self.sentiment_analyzer.analyze_sentiment(preprocessed_message, target_language="en")
            logger.info(f"Sentiment analysis result: {sentiment}")

            # G√©n√©ration d'une r√©ponse
            response = f"Your message sentiment: {sentiment['label']} (Confidence: {sentiment['score']:.2f})."
            logger.info(f"Generated response: {response}")

            # Sauvegarde dans MongoDB
            metadata = {"detected_language": detected_language, "sentiment": sentiment}
            await self.mongo_manager.save_interaction(user_id, user_message, response, metadata)
            return response
        except Exception as e:
            logger.error(f"Error processing message: {e}")
            return "Sorry, an error occurred while processing your message."

    async def process_batch(self, user_id: str, messages: List[str], language: str = "auto") -> List[str]:
        """
        Traite un lot de messages utilisateur.

        Args:
            user_id (str): ID utilisateur.
            messages (List[str]): Liste des messages utilisateur.
            language (str): Langue cible pour le traitement.

        Returns:
            List[str]: Liste des r√©ponses g√©n√©r√©es pour chaque message.
        """
        try:
            logger.info(f"Processing batch of {len(messages)} messages...")
            tasks = [self.process_message(user_id, message, language) for message in messages]
            responses = await asyncio.gather(*tasks)
            logger.info("Batch processing completed.")
            return responses
        except Exception as e:
            logger.error(f"Error processing batch: {e}")
            return ["Error processing batch."]

    async def generate_dashboard(self, insights: Dict[str, Dict[str, int]], output_file: str = "dashboard.html") -> str:
        """
        G√©n√®re un tableau de bord interactif √† partir des donn√©es.

        Args:
            insights (Dict[str, Dict[str, int]]): Donn√©es d'analyse pour g√©n√©rer un tableau de bord.
            output_file (str): Nom du fichier HTML √† g√©n√©rer.

        Returns:
            str: Chemin vers le fichier HTML g√©n√©r√©.
        """
        try:
            dashboard_path = self.dashboard_generator.create_dashboard(insights, output_file)
            logger.info(f"Dashboard generated: {dashboard_path}")
            return dashboard_path
        except Exception as e:
            logger.error(f"Error generating dashboard: {e}")
            return ""

    async def organize_and_cluster_data(self, texts: List[str], method: str = "kmeans", **kwargs) -> str:
        """
        Organise et clusterise des textes utilisateur.

        Args:
            texts (List[str]): Liste des textes.
            method (str): M√©thode de clustering ('kmeans', 'dbscan', 'hdbscan').
            **kwargs: Param√®tres sp√©cifiques √† chaque m√©thode.

        Returns:
            str: Chemin du fichier export√© contenant les clusters.
        """
        try:
            # G√©n√©rer les embeddings
            embeddings = self.data_organizer.generate_embeddings(texts)

            # Appliquer le clustering
            clustered_data = self.data_organizer.apply_clustering(embeddings, method=method, **kwargs)

            # Exporter les r√©sultats
            export_path = self.data_organizer.export_clusters(clustered_data)
            logger.info(f"Data organized and exported to: {export_path}")
            return export_path
        except Exception as e:
            logger.error(f"Error organizing and clustering data: {e}")
            return ""
        
# Data Organizer
class DataOrganizer:
    """
    Organise, clusterise et visualise des donn√©es haute dimension.
    """

    def __init__(self, output_dir: str = "data_output"):
        """
        Initialise le gestionnaire de donn√©es.

        Args:
            output_dir (str): R√©pertoire pour sauvegarder les r√©sultats.
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        logger.info(f"DataOrganizer initialized. Output directory: {output_dir}")

    def apply_clustering(self, embeddings: List[List[float]], method: str = "kmeans", **kwargs) -> pd.DataFrame:
        """
        Applique un clustering sur les embeddings.

        Args:
            embeddings (List[List[float]]): Donn√©es haute dimension.
            method (str): M√©thode de clustering ('kmeans', 'dbscan', 'hdbscan').
            **kwargs: Param√®tres sp√©cifiques pour l'algorithme choisi.

        Returns:
            pd.DataFrame: R√©sultats du clustering avec colonnes 'Text' et 'Cluster'.
        """
        logger.info(f"Applying clustering with method: {method}...")

        if method == "kmeans":
            n_clusters = kwargs.get("n_clusters", 5)
            cluster_model = KMeans(n_clusters=n_clusters, random_state=42)
        elif method == "dbscan":
            eps = kwargs.get("eps", 0.5)
            min_samples = kwargs.get("min_samples", 5)
            cluster_model = DBSCAN(eps=eps, min_samples=min_samples, metric="cosine")
        elif method == "hdbscan":
            min_cluster_size = kwargs.get("min_cluster_size", 5)
            cluster_model = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)
        else:
            logger.error(f"Unsupported clustering method: {method}")
            raise ValueError(f"Unsupported clustering method: {method}")

        labels = cluster_model.fit_predict(embeddings)
        logger.info(f"Clustering completed. Number of clusters: {len(set(labels)) - (1 if -1 in labels else 0)}")
        return pd.DataFrame({"Embedding": embeddings, "Cluster": labels})

    def reduce_dimensions(self, embeddings: List[List[float]], n_components: int = 2) -> List[List[float]]:
        """
        R√©duit les dimensions des embeddings avec UMAP.

        Args:
            embeddings (List[List[float]]): Donn√©es haute dimension.
            n_components (int): Nombre de dimensions cibles.

        Returns:
            List[List[float]]: Embeddings r√©duits.
        """
        logger.info(f"Reducing dimensions to {n_components}D with UMAP...")
        reducer = UMAP(n_neighbors=15, min_dist=0.1, n_components=n_components, random_state=42)
        reduced_embeddings = reducer.fit_transform(embeddings)
        logger.info("Dimension reduction completed.")
        return reduced_embeddings

    def visualize_clusters(self, reduced_embeddings: List[List[float]], labels: List[int]):
        """
        Visualise les clusters dans un graphique 2D.

        Args:
            reduced_embeddings (List[List[float]]): Donn√©es r√©duites en 2D.
            labels (List[int]): Labels des clusters.
        """
        logger.info("Visualizing clusters...")
        plt.figure(figsize=(10, 8))
        plt.scatter(
            [e[0] for e in reduced_embeddings],
            [e[1] for e in reduced_embeddings],
            c=labels,
            cmap="tab10",
            s=10
        )
        plt.title("Cluster Visualization")
        plt.xlabel("UMAP Dim 1")
        plt.ylabel("UMAP Dim 2")
        plt.colorbar()
        plt.show()

    def export_clusters(self, data: pd.DataFrame, file_name: str = "clusters.csv"):
        """
        Exporte les clusters dans un fichier CSV.

        Args:
            data (pd.DataFrame): Donn√©es des clusters.
            file_name (str): Nom du fichier export√©.
        """
        file_path = os.path.join(self.output_dir, file_name)
        try:
            data.to_csv(file_path, index=False)
            logger.info(f"Clusters exported to: {file_path}")
        except Exception as e:
            logger.error(f"Error exporting clusters: {e}")

    def process_and_cluster(
        self, embeddings: List[List[float]], method: str = "kmeans", n_components: int = 2, **kwargs
    ) -> Dict[str, Any]:
        """
        Pipeline complet : r√©duction de dimensions, clustering, et visualisation.

        Args:
            embeddings (List[List[float]]): Donn√©es haute dimension.
            method (str): M√©thode de clustering.
            n_components (int): Dimensions cibles pour la r√©duction.

        Returns:
            Dict[str, Any]: R√©sum√© des clusters et chemin du fichier export√©.
        """
        reduced_embeddings = self.reduce_dimensions(embeddings, n_components)
        clustered_data = self.apply_clustering(reduced_embeddings, method, **kwargs)
        labels = clustered_data["Cluster"].tolist()

        # Visualisation
        self.visualize_clusters(reduced_embeddings, labels)

        # Exportation
        export_path = os.path.join(self.output_dir, "clusters.csv")
        self.export_clusters(clustered_data, "clusters.csv")
        return {"clusters": clustered_data["Cluster"].value_counts().to_dict(), "export_path": export_path}

class CacheManager:
    """
    G√®re un cache distribu√© avec Redis et un fallback local.
    """

    def __init__(self, redis_host: str = "localhost", redis_port: int = 6379, cache_dir: str = "cache", ttl: int = 3600):
        """
        Initialise la classe CacheManager.

        Args:
            redis_host (str): Adresse du serveur Redis.
            redis_port (int): Port du serveur Redis.
            cache_dir (str): R√©pertoire local pour le fallback du cache.
            ttl (int): Temps de vie (en secondes) des entr√©es dans Redis.
        """
        self.redis = Redis(host=redis_host, port=redis_port, db=0, decode_responses=True)
        self.cache_dir = cache_dir
        self.ttl = ttl
        os.makedirs(cache_dir, exist_ok=True)
        logger.info(f"CacheManager initialized. Redis at {redis_host}:{redis_port}, local fallback in '{cache_dir}'.")

    def redis_available(self) -> bool:
        """
        V√©rifie si Redis est disponible.

        Returns:
            bool: True si Redis est accessible, sinon False.
        """
        try:
            self.redis.ping()
            return True
        except Exception as e:
            logger.warning(f"Redis unavailable: {e}")
            return False

    def get_cache(self, key: str) -> Optional[Any]:
        """
        R√©cup√®re une valeur du cache.

        Args:
            key (str): Cl√© de l'entr√©e dans le cache.

        Returns:
            Optional[Any]: Valeur associ√©e √† la cl√© ou None si non trouv√©e.
        """
        # V√©rifier Redis
        if self.redis_available():
            try:
                value = self.redis.get(key)
                if value:
                    logger.info(f"Cache hit in Redis for key: {key}")
                    return json.loads(value)
            except Exception as e:
                logger.error(f"Error fetching key '{key}' from Redis: {e}")

        # V√©rifier le cache local
        file_path = os.path.join(self.cache_dir, f"{key}.json")
        if os.path.exists(file_path):
            try:
                with open(file_path, "r") as file:
                    logger.info(f"Cache hit in local fallback for key: {key}")
                    return json.load(file)
            except Exception as e:
                logger.error(f"Error reading local cache file for key '{key}': {e}")

        logger.info(f"Cache miss for key: {key}")
        return None

    def set_cache(self, key: str, value: Any):
        """
        Ajoute une valeur au cache.

        Args:
            key (str): Cl√© de l'entr√©e.
            value (Any): Valeur associ√©e √† la cl√©.
        """
        # Ajouter dans Redis
        if self.redis_available():
            try:
                self.redis.setex(key, self.ttl, json.dumps(value))
                logger.info(f"Cache set in Redis for key: {key}")
            except Exception as e:
                logger.error(f"Error setting key '{key}' in Redis: {e}")

        # Ajouter dans le fallback local
        file_path = os.path.join(self.cache_dir, f"{key}.json")
        try:
            with open(file_path, "w") as file:
                json.dump(value, file)
            logger.info(f"Cache set in local fallback for key: {key}")
        except Exception as e:
            logger.error(f"Error writing local cache file for key '{key}': {e}")

    def delete_cache(self, key: str):
        """
        Supprime une entr√©e du cache.

        Args:
            key (str): Cl√© de l'entr√©e √† supprimer.
        """
        # Supprimer de Redis
        if self.redis_available():
            try:
                self.redis.delete(key)
                logger.info(f"Cache key '{key}' deleted from Redis.")
            except Exception as e:
                logger.error(f"Error deleting key '{key}' from Redis: {e}")

        # Supprimer du fallback local
        file_path = os.path.join(self.cache_dir, f"{key}.json")
        if os.path.exists(file_path):
            try:
                os.remove(file_path)
                logger.info(f"Cache file '{key}.json' deleted from local fallback.")
            except Exception as e:
                logger.error(f"Error deleting cache file '{key}.json': {e}")

    def clear_cache(self):
        """
        Supprime tout le cache, dans Redis et localement.
        """
        # Effacer Redis
        if self.redis_available():
            try:
                self.redis.flushdb()
                logger.info("All Redis cache cleared.")
            except Exception as e:
                logger.error(f"Error clearing Redis cache: {e}")

        # Effacer le cache local
        try:
            for file in os.listdir(self.cache_dir):
                os.remove(os.path.join(self.cache_dir, file))
            logger.info("All local cache cleared.")
        except Exception as e:
            logger.error(f"Error clearing local cache: {e}")

class ONNXModelWrapper:
    """
    Encapsulation pour les mod√®les ONNX avec support multi-device et gestion des erreurs.
    """

    def __init__(self, model_path: str, device_preference: str = "auto"):
        """
        Initialise la classe avec un chemin de mod√®le ONNX.

        Args:
            model_path (str): Chemin vers le fichier ONNX.
            device_preference (str): Pr√©f√©rence de device ('cpu', 'gpu', ou 'auto').
        """
        self.model_path = model_path
        self.device = self._select_device(device_preference)
        self.session = ort.InferenceSession(model_path, providers=[self.device])
        self.input_metadata = {input.name: input.shape for input in self.session.get_inputs()}
        self.output_metadata = {output.name: output.shape for output in self.session.get_outputs()}
        logger.info(f"Model loaded from {model_path} on device: {self.device}")

    def _select_device(self, preference: str) -> str:
        """
        S√©lectionne le device en fonction de la pr√©f√©rence et de la disponibilit√©.

        Args:
            preference (str): Pr√©f√©rence de device ('cpu', 'gpu', ou 'auto').

        Returns:
            str: Device s√©lectionn√©.
        """
        if preference == "gpu" or (preference == "auto" and ort.get_device() == "GPU"):
            return "CUDAExecutionProvider"
        return "CPUExecutionProvider"

    def validate_input(self, input_data: Dict[str, Any]) -> bool:
        """
        Valide les donn√©es d'entr√©e pour le mod√®le ONNX.

        Args:
            input_data (Dict[str, Any]): Donn√©es d'entr√©e.

        Returns:
            bool: True si les donn√©es sont valides, sinon False.
        """
        for key, value in input_data.items():
            if key not in self.input_metadata:
                logger.error(f"Invalid input key: {key}. Expected keys: {list(self.input_metadata.keys())}")
                return False
            if len(value.shape) != len(self.input_metadata[key]):
                logger.error(f"Shape mismatch for input '{key}': {value.shape} != {self.input_metadata[key]}")
                return False
        logger.info("Input validation passed.")
        return True

    def predict(self, input_data: Dict[str, Any]) -> List[Any]:
        """
        Effectue une pr√©diction avec le mod√®le ONNX.

        Args:
            input_data (Dict[str, Any]): Donn√©es d'entr√©e au mod√®le.

        Returns:
            List[Any]: R√©sultats de la pr√©diction.
        """
        if not self.validate_input(input_data):
            raise ValueError("Invalid input data provided.")

        try:
            logger.info(f"Running inference on model: {self.model_path}")
            outputs = self.session.run(None, input_data)
            logger.info("Inference completed successfully.")
            return outputs
        except Exception as e:
            logger.error(f"Error during inference: {e}")
            return []

    def get_model_metadata(self) -> Dict[str, Any]:
        """
        R√©cup√®re les m√©tadonn√©es du mod√®le ONNX.

        Returns:
            Dict[str, Any]: M√©tadonn√©es incluant les entr√©es et sorties.
        """
        metadata = {
            "inputs": self.input_metadata,
            "outputs": self.output_metadata,
        }
        logger.info(f"Model metadata: {metadata}")
        return metadata

    def warmup(self, sample_input: Dict[str, Any]):
        """
        R√©alise une pr√©-ex√©cution pour r√©duire la latence initiale.

        Args:
            sample_input (Dict[str, Any]): Exemple de donn√©es d'entr√©e.
        """
        try:
            logger.info("Warming up ONNX model...")
            self.predict(sample_input)
            logger.info("Warmup completed successfully.")
        except Exception as e:
            logger.error(f"Error during warmup: {e}")





class DashboardGenerator:
    """
    G√©n√©rateur de dashboards interactifs avec des graphiques personnalis√©s, dynamiques et flexibles.
    """

    def __init__(self, output_dir: str = "dashboards", template: str = "plotly_white"):
        """
        Initialise le g√©n√©rateur de dashboards.

        Args:
            output_dir (str): R√©pertoire pour sauvegarder les fichiers de dashboards.
            template (str): Th√®me par d√©faut pour les graphiques (Plotly template).
        """
        self.output_dir = output_dir
        self.template = template
        os.makedirs(self.output_dir, exist_ok=True)
        logger.info(f"DashboardGenerator initialized. Output directory: {output_dir}")

    def create_bar_chart(
            self,
            data: Dict[str, Union[int, float]],
            title: str = "Bar Chart",
            xaxis_title: str = "Categories",
            yaxis_title: str = "Values",
    ) -> go.Figure:
        """
        Cr√©e un graphique en barres.

        Args:
            data (Dict[str, Union[int, float]]): Donn√©es sous forme de {cat√©gorie: valeur}.
            title (str): Titre du graphique.
            xaxis_title (str): Titre de l'axe X.
            yaxis_title (str): Titre de l'axe Y.

        Returns:
            go.Figure: Graphique Plotly interactif.
        """
        if not isinstance(data, dict) or not data:
            raise ValueError("Les donn√©es pour le bar chart doivent √™tre un dictionnaire non vide.")

        try:
            fig = go.Figure()
            fig.add_trace(go.Bar(x=list(data.keys()), y=list(data.values())))
            fig.update_layout(
                title=title,
                xaxis_title=xaxis_title,
                yaxis_title=yaxis_title,
                template=self.template,
            )
            logger.info(f"Bar chart created with title: {title}")
            return fig
        except Exception as e:
            logger.error(f"Error creating bar chart: {e}")
            raise

    def create_scatter_plot(
            self,
            x: List[float],
            y: List[float],
            labels: Optional[List[str]] = None,
            title: str = "Scatter Plot",
            xaxis_title: str = "X-axis",
            yaxis_title: str = "Y-axis",
            marker_size: int = 10,
            color: Optional[List[str]] = None,
    ) -> go.Figure:
        """
        Cr√©e un nuage de points interactif.

        Args:
            x (List[float]): Coordonn√©es X.
            y (List[float]): Coordonn√©es Y.
            labels (Optional[List[str]]): Labels pour les points.
            title (str): Titre du graphique.
            xaxis_title (str): Titre de l'axe X.
            yaxis_title (str): Titre de l'axe Y.
            marker_size (int): Taille des marqueurs.
            color (Optional[List[str]]): Couleurs des points.

        Returns:
            go.Figure: Graphique Plotly interactif.
        """
        if not x or not y or len(x) != len(y):
            raise ValueError("Les listes X et Y doivent √™tre non vides et de m√™me longueur.")

        try:
            fig = go.Figure(
                data=go.Scatter(
                    x=x,
                    y=y,
                    mode="markers",
                    text=labels,
                    marker=dict(size=marker_size, color=color, showscale=True),
                )
            )
            fig.update_layout(
                title=title,
                xaxis_title=xaxis_title,
                yaxis_title=yaxis_title,
                template=self.template,
            )
            logger.info(f"Scatter plot created with title: {title}")
            return fig
        except Exception as e:
            logger.error(f"Error creating scatter plot: {e}")
            raise

    def create_dashboard(
            self,
            insights: Dict[str, go.Figure],
            output_file: str = "dashboard.html",
            rows: Optional[int] = None,
            cols: Optional[int] = None,
    ) -> str:
        """
        G√©n√®re un dashboard interactif √† partir d'un ensemble de graphiques.

        Args:
            insights (Dict[str, go.Figure]): Dictionnaire de graphiques {titre: figure}.
            output_file (str): Nom du fichier HTML √† g√©n√©rer.
            rows (Optional[int]): Nombre de lignes dans la disposition (optionnel).
            cols (Optional[int]): Nombre de colonnes dans la disposition (optionnel).

        Returns:
            str: Chemin du fichier HTML g√©n√©r√©.
        """
        if not insights or not isinstance(insights, dict):
            raise ValueError("Les insights doivent √™tre un dictionnaire non vide.")
        if rows is None or cols is None:
            rows, cols = self._auto_layout(len(insights))

        try:
            fig = make_subplots(
                rows=rows,
                cols=cols,
                subplot_titles=list(insights.keys()),
                horizontal_spacing=0.2,
                vertical_spacing=0.2,
            )

            for idx, (chart_title, chart_fig) in enumerate(insights.items()):
                row = idx // cols + 1
                col = idx % cols + 1
                for trace in chart_fig.data:
                    fig.add_trace(trace, row=row, col=col)

            fig.update_layout(
                title="Interactive Dashboard",
                template=self.template,
                showlegend=False,
                height=600 * rows,  # Dynamically scale height
            )

            file_path = os.path.join(self.output_dir, output_file)
            fig.write_html(file_path)
            logger.info(f"Dashboard generated and saved to: {file_path}")
            return file_path
        except Exception as e:
            logger.error(f"Error generating dashboard: {e}")
            raise

    def save_figure(self, fig: go.Figure, file_name: str):
        """
        Sauvegarde un graphique interactif au format HTML.

        Args:
            fig (go.Figure): Graphique Plotly.
            file_name (str): Nom du fichier HTML √† sauvegarder.
        """
        if not isinstance(fig, go.Figure):
            raise ValueError("L'objet fig doit √™tre une instance de plotly.graph_objects.Figure.")

        try:
            file_path = os.path.join(self.output_dir, file_name)
            fig.write_html(file_path)
            logger.info(f"Figure saved to: {file_path}")
        except Exception as e:
            logger.error(f"Error saving figure: {e}")
            raise

    @staticmethod
    def _auto_layout(num_charts: int) -> (int, int):
        """
        Calcule une disposition automatique pour les graphiques.

        Args:
            num_charts (int): Nombre total de graphiques.

        Returns:
            (int, int): Nombre de lignes et de colonnes.
        """
        import math
        cols = math.ceil(math.sqrt(num_charts))
        rows = math.ceil(num_charts / cols)
        return rows, cols


class LoggerService:
    """
    G√®re la configuration et l'utilisation centralis√©e des logs.
    """

    @staticmethod
    def configure_logger(name: str, log_file: str = "system.log", level: int = logging.INFO):
        """
        Configure le logger.

        Args:
            name (str): Nom du logger.
            log_file (str): Fichier de log.
            level (int): Niveau de logging.
        """
        logger = logging.getLogger(name)
        logger.setLevel(level)
        file_handler = logging.FileHandler(log_file)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
        logger.info(f"Logger '{name}' configur√© avec succ√®s.")
        return logger
class SecureAISystem:
    """
    Syst√®me AI s√©curis√© avec chiffrement AES et suppression conforme RGPD.
    """

    def __init__(self, encryption_key: str = None, db_manager=None):
        """
        Initialise le syst√®me AI s√©curis√©.

        Args:
            encryption_key (str): Cl√© AES pour le chiffrement.
            db_manager: Gestionnaire de base de donn√©es (MongoDB, PostgreSQL).
        """
        self.encryption_key = self._derive_key(encryption_key or os.getenv("SECURE_AI_KEY", "default_secure_key"))
        self.db_manager = db_manager
        logger.info("SecureAISystem initialized with encryption and secure data management.")

    def _derive_key(self, passphrase: str) -> bytes:
        """
        G√©n√©re une cl√© AES √† partir d'une passphrase.

        Args:
            passphrase (str): Passphrase utilis√©e pour g√©n√©rer la cl√©.

        Returns:
            bytes: Cl√© d√©riv√©e.
        """
        salt = b"secure_salt"
        kdf = PBKDF2HMAC(
            algorithm=hashes.SHA256(),
            length=32,
            salt=salt,
            iterations=100000,
            backend=default_backend()
        )
        return base64.urlsafe_b64encode(kdf.derive(passphrase.encode()))

    def encrypt_data(self, data: str) -> str:
        """
        Chiffre une cha√Æne de caract√®res.

        Args:
            data (str): Donn√©es √† chiffrer.

        Returns:
            str: Donn√©es chiffr√©es en base64.
        """
        iv = os.urandom(16)
        cipher = Cipher(algorithms.AES(self.encryption_key), modes.CFB(iv), backend=default_backend())
        encryptor = cipher.encryptor()
        encrypted_data = encryptor.update(data.encode()) + encryptor.finalize()
        return base64.b64encode(iv + encrypted_data).decode()

    def decrypt_data(self, encrypted_data: str) -> str:
        """
        D√©chiffre une cha√Æne de caract√®res.

        Args:
            encrypted_data (str): Donn√©es chiffr√©es en base64.

        Returns:
            str: Donn√©es d√©chiffr√©es.
        """
        encrypted_bytes = base64.b64decode(encrypted_data)
        iv = encrypted_bytes[:16]
        cipher = Cipher(algorithms.AES(self.encryption_key), modes.CFB(iv), backend=default_backend())
        decryptor = cipher.decryptor()
        decrypted_data = decryptor.update(encrypted_bytes[16:]) + decryptor.finalize()
        return decrypted_data.decode()

    async def save_interaction(self, user_id: str, message: str, response: str, metadata: Dict[str, Any] = None):
        """
        Sauvegarde une interaction utilisateur avec chiffrement.

        Args:
            user_id (str): ID utilisateur.
            message (str): Message utilisateur.
            response (str): R√©ponse g√©n√©r√©e.
            metadata (Dict[str, Any]): M√©tadonn√©es suppl√©mentaires.
        """
        try:
            encrypted_message = self.encrypt_data(message)
            encrypted_response = self.encrypt_data(response)
            metadata = metadata or {}
            metadata.update({"timestamp": asyncio.get_event_loop().time()})

            await self.db_manager.save_interaction(user_id, encrypted_message, encrypted_response, metadata)
            logger.info(f"Encrypted interaction saved for user: {user_id}")
        except Exception as e:
            logger.error(f"Error saving interaction: {e}")

    async def fetch_interactions(self, user_id: str) -> Dict[str, Any]:
        """
        R√©cup√®re et d√©chiffre les interactions utilisateur.

        Args:
            user_id (str): ID utilisateur.

        Returns:
            Dict[str, Any]: Interactions d√©chiffr√©es.
        """
        try:
            interactions = await self.db_manager.fetch_interactions(user_id)
            for interaction in interactions:
                interaction["message"] = self.decrypt_data(interaction["message"])
                interaction["response"] = self.decrypt_data(interaction["response"])
            logger.info(f"Fetched {len(interactions)} interactions for user: {user_id}")
            return interactions
        except Exception as e:
            logger.error(f"Error fetching interactions: {e}")
            return []

    async def delete_user_data(self, user_id: str):
        """
        Supprime toutes les donn√©es associ√©es √† un utilisateur.

        Args:
            user_id (str): ID utilisateur.
        """
        try:
            await self.db_manager.delete_user_data(user_id)
            logger.info(f"All data deleted for user: {user_id}")
        except Exception as e:
            logger.error(f"Error deleting user data: {e}")


class NextGenAISystem:
    """
    Syst√®me AI avanc√© avec gestion multi-base, NLP, clustering et visualisation.
    """

    def __init__(self, use_postgres: bool = False, embedding_model: str = "all-MiniLM-L6-v2"):
        """
        Initialise le syst√®me AI de nouvelle g√©n√©ration.

        Args:
            use_postgres (bool): D√©finit si PostgreSQL doit √™tre utilis√©.
            embedding_model (str): Mod√®le SentenceTransformers pour les embeddings.
        """
        self.db_manager = (
            PostgreSQLManager(db_name="nextgen_ai", user="postgres", password="securepassword")
            if use_postgres
            else MongoDBManager(db_name="nextgen_ai")
        )
        self.nlp_processor = NLPProcessor(embedding_model=embedding_model)
        self.sentiment_analyzer = SentimentAnalyzer()
        self.data_organizer = DataOrganizer()
        self.dashboard_generator = DashboardGenerator()
        self.models = {
            "sentiment": ONNXModelWrapper("sentiment_model.onnx"),
            "intent": ONNXModelWrapper("intent_classification.onnx"),
        }
        logger.info("NextGenAISystem initialized.")

    async def process_message(self, user_id: str, user_message: str, language: str = "auto") -> Dict[str, Any]:
        """
        Traite un message utilisateur avec NLP et mod√®les ONNX.

        Args:
            user_id (str): ID utilisateur.
            user_message (str): Message envoy√© par l'utilisateur.
            language (str): Langue cible (d√©tect√©e automatiquement si "auto").

        Returns:
            Dict[str, Any]: R√©sultats du traitement (sentiment, intent, r√©ponse).
        """
        try:
            logger.info(f"Processing message for user {user_id}...")

            # Pr√©traitement du texte
            preprocessed_message = self.nlp_processor.preprocess_text(user_message, target_language="en")

            # Analyse de sentiment avec ONNX
            sentiment_result = self.models["sentiment"].predict({"input_text": preprocessed_message})
            sentiment_label = "positive" if sentiment_result[0] > 0.5 else "negative"

            # Classification d'intention
            intent_result = self.models["intent"].predict({"input_text": preprocessed_message})
            intent_label = "greeting" if intent_result[0] > 0.5 else "request"

            # R√©ponse g√©n√©r√©e
            response = (
                f"Sentiment: {sentiment_label} (Confidence: {sentiment_result[0]:.2f}), "
                f"Intent: {intent_label}."
            )

            # Sauvegarder l'interaction
            metadata = {
                "sentiment": {"label": sentiment_label, "confidence": sentiment_result[0]},
                "intent": {"label": intent_label, "confidence": intent_result[0]},
            }
            await self.db_manager.save_interaction(user_id, user_message, response, metadata)
            logger.info(f"Message processed for user {user_id}.")
            return {"response": response, "sentiment": sentiment_label, "intent": intent_label}
        except Exception as e:
            logger.error(f"Error processing message for user {user_id}: {e}")
            return {"response": "Error occurred.", "sentiment": None, "intent": None}

    async def process_batch(self, user_id: str, messages: List[str]) -> List[Dict[str, Any]]:
        """
        Traite un lot de messages utilisateur.

        Args:
            user_id (str): ID utilisateur.
            messages (List[str]): Liste des messages utilisateur.

        Returns:
            List[Dict[str, Any]]: R√©sultats pour chaque message.
        """
        try:
            logger.info(f"Processing batch for user {user_id}...")
            tasks = [self.process_message(user_id, message) for message in messages]
            results = await asyncio.gather(*tasks)
            logger.info(f"Batch processing completed for user {user_id}.")
            return results
        except Exception as e:
            logger.error(f"Error processing batch for user {user_id}: {e}")
            return []

    async def generate_dashboard(self, user_id: str) -> str:
        """
        G√©n√®re un tableau de bord des interactions utilisateur.

        Args:
            user_id (str): ID utilisateur.

        Returns:
            str: Chemin vers le tableau de bord HTML g√©n√©r√©.
        """
        try:
            interactions = await self.db_manager.fetch_interactions(user_id)
            sentiment_summary = {}
            for interaction in interactions:
                sentiment = interaction["metadata"].get("sentiment", {}).get("label", "unknown")
                sentiment_summary[sentiment] = sentiment_summary.get(sentiment, 0) + 1

            dashboard_path = self.dashboard_generator.generate_sentiment_dashboard(
                sentiment_summary, output_file=f"{user_id}_dashboard.html"
            )
            logger.info(f"Dashboard generated for user {user_id}.")
            return dashboard_path
        except Exception as e:
            logger.error(f"Error generating dashboard for user {user_id}: {e}")
            return ""


class EmotionContextualizer(Action):
    def name(self) -> str:
        return "action_emotion_contextualizer"

    def __init__(self):
        # Historique des √©motions, index√© par utilisateur
        self.emotion_history = defaultdict(list)

    def detect_emotion(self, user_message: str) -> str:
        """
        D√©tection simple d'√©motions bas√©e sur des mots-cl√©s.
        √Ä remplacer par un mod√®le NLP si n√©cessaire.
        """
        if any(word in user_message for word in ["bien", "heureux", "joyeux"]):
            return "positif"
        elif any(word in user_message for word in ["triste", "fatigu√©", "stress√©"]):
            return "n√©gatif"
        else:
            return "neutre"

    def calculate_trend(self, emotions: List[str]) -> str:
        """
        Analyse la tendance des √©motions sur les 5 derniers messages.
        """
        recent_emotions = emotions[-5:]  # Derniers 5 messages
        positive_count = recent_emotions.count("positif")
        negative_count = recent_emotions.count("n√©gatif")

        if positive_count > 3:
            return "tendance positive"
        elif negative_count > 3:
            return "tendance n√©gative"
        else:
            return "tendance √©quilibr√©e"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        user_id = tracker.sender_id
        user_message = tracker.latest_message.get("text")

        # √âtape 1 : D√©tecter l'√©motion actuelle
        current_emotion = self.detect_emotion(user_message)
        self.emotion_history[user_id].append(current_emotion)

        # √âtape 2 : Calculer la tendance
        trend = self.calculate_trend(self.emotion_history[user_id])

        # √âtape 3 : R√©pondre en fonction de la tendance
        if trend == "tendance positive":
            dispatcher.utter_message(text="Vous semblez dans une belle √©nergie ! Continuons comme √ßa. üòä")
        elif trend == "tendance n√©gative":
            dispatcher.utter_message(text="Je ressens un peu de tension dans nos √©changes. Puis-je vous aider √† all√©ger cela ? üòî")
        else:
            dispatcher.utter_message(text="Votre √©tat √©motionnel est assez √©quilibr√©. Continuons notre conversation. üòå")

        # Optionnel : Stocker la tendance dans un slot
        return [SlotSet("emotion_trend", trend)]

class EthicalDecisionAdvisor(Action):
    def name(self) -> str:
        return "action_ethical_decision_advisor"

    def __init__(self):
        # Grille √©thique : Actions accept√©es ou refus√©es
        self.ethical_rules = {
            "action_share_sensitive_data": False,
            "action_encrypt_sensitive_data": True,
            "action_advanced_sentiment_analysis": True,
            "action_generate_audio_response": True,
        }

    def evaluate_action(self, action_name: str) -> bool:
        """
        √âvalue si une action est autoris√©e selon la grille √©thique.
        """
        return self.ethical_rules.get(action_name, True)  # Par d√©faut : accept√©

    def explain_decision(self, action_name: str) -> str:
        """
        Donne une explication claire de la d√©cision.
        """
        if not self.ethical_rules.get(action_name, True):
            return f"L'action '{action_name}' a √©t√© rejet√©e car elle pourrait violer les principes √©thiques (ex. : vie priv√©e, s√©curit√©)."
        return f"L'action '{action_name}' est approuv√©e conform√©ment √† nos r√®gles √©thiques."

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Obtenir l'action demand√©e depuis le slot
        requested_action = tracker.get_slot("requested_action")

        if not requested_action:
            dispatcher.utter_message(text="Aucune action n'a √©t√© demand√©e.")
            return []

        # √âtape 1 : √âvaluer l'action demand√©e
        is_ethical = self.evaluate_action(requested_action)

        # √âtape 2 : Fournir une explication
        explanation = self.explain_decision(requested_action)
        dispatcher.utter_message(text=explanation)

        # Optionnel : Marquer l'action comme refus√©e dans un slot
        return [SlotSet("is_action_ethical", is_ethical)]

class PersonalizedMindfulnessAssistant(Action):
    def name(self) -> str:
        return "action_personalized_mindfulness"

    def suggest_exercise(self, emotion: str) -> str:
        """
        Propose un exercice de pleine conscience bas√© sur l'√©motion d√©tect√©e.
        """
        exercises = {
            "stress": "Prenez un moment pour respirer profond√©ment : inspirez 4 secondes, retenez votre souffle 4 secondes, puis expirez lentement pendant 4 secondes. R√©p√©tez cela 5 fois.",
            "positif": "Prenez un moment pour r√©fl√©chir √† ce qui vous rend heureux aujourd'hui. √âcrivez-le si vous le souhaitez. üòä",
            "n√©gatif": "Essayez cet exercice de visualisation : imaginez un endroit paisible o√π vous vous sentez en s√©curit√© et d√©tendu, comme une plage ou une for√™t.",
            "neutre": "Faites une pause d'une minute en fermant les yeux. Concentrez-vous sur les sons autour de vous et laissez vos pens√©es passer sans jugement.",
        }
        return exercises.get(emotion, "Prenez une pause et buvez un verre d'eau pour vous recentrer.")

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer l'√©motion d√©tect√©e
        emotion = tracker.get_slot("emotion") or "neutre"  # Par d√©faut : neutre

        # Proposer un exercice bas√© sur l'√©motion
        exercise = self.suggest_exercise(emotion)
        dispatcher.utter_message(text=exercise)

        # Retourner un slot avec l'exercice propos√©
        return [SlotSet("suggested_exercise", exercise)]

class AI_EmpathyEnhancer(Action):
    def name(self) -> str:
        return "action_empathy_enhancer"

    def generate_empathic_response(self, user_message: str) -> str:
        """
        G√©n√®re une r√©ponse empathique bas√©e sur le message de l'utilisateur.
        """
        if any(word in user_message for word in ["fatigu√©", "stress√©", "triste"]):
            return "Je comprends que cela peut √™tre difficile. Prenez un moment pour vous d√©tendre, je suis l√† pour vous aider. üåø"
        elif any(word in user_message for word in ["heureux", "joyeux", "bien"]):
            return "C'est g√©nial √† entendre ! Continuons sur cette belle √©nergie. üòä"
        elif any(word in user_message for word in ["col√®re", "√©nerv√©"]):
            return "Je vois que vous √™tes contrari√©. Souhaitez-vous que je vous aide √† r√©soudre ce probl√®me ? üòî"
        else:
            return "Merci de partager cela avec moi. Je suis l√† pour rendre les choses plus faciles pour vous. üòå"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer le dernier message de l'utilisateur
        user_message = tracker.latest_message.get("text")

        # G√©n√©rer une r√©ponse empathique
        response = self.generate_empathic_response(user_message)

        # Envoyer la r√©ponse √† l'utilisateur
        dispatcher.utter_message(text=response)

        # Pas de slots mis √† jour, retour vide
        return []

class DynamicClusterVisualizer(Action):
    def name(self) -> str:
        return "action_dynamic_cluster_visualizer"

    def generate_cluster_plot(self, clusters: Dict[str, List[str]]) -> str:
        """
        G√©n√®re un graphique repr√©sentant les clusters.
        Retourne une image encod√©e en base64 pour un affichage direct.
        """
        try:
            # Initialisation du graphique
            fig, ax = plt.subplots(figsize=(8, 6))

            # Couleurs et styles
            colors = ['red', 'blue', 'green', 'orange', 'purple']
            markers = ['o', 's', 'D', '^', 'v']

            for i, (cluster_label, items) in enumerate(clusters.items()):
                x = [i] * len(items)
                y = list(range(len(items)))
                ax.scatter(x, y, label=cluster_label, color=colors[i % len(colors)], marker=markers[i % len(markers)])
                for j, item in enumerate(items):
                    ax.text(i, j, item, fontsize=9, ha='right')

            # Ajout des labels et du titre
            ax.set_title("Visualisation des Clusters")
            ax.set_xticks(range(len(clusters)))
            ax.set_xticklabels(clusters.keys())
            ax.set_xlabel("Clusters")
            ax.set_ylabel("√âl√©ments")
            ax.legend()

            # Conversion en image base64
            buf = io.BytesIO()
            plt.savefig(buf, format="png")
            buf.seek(0)
            image_base64 = base64.b64encode(buf.read()).decode('utf-8')
            buf.close()
            plt.close(fig)

            return f"data:image/png;base64,{image_base64}"
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la g√©n√©ration du graphique : {e}")

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de clusters (√† remplacer par vos donn√©es)
        clusters = {
            "Cluster 1": ["√âl√©ment A", "√âl√©ment B", "√âl√©ment C"],
            "Cluster 2": ["√âl√©ment D", "√âl√©ment E"],
            "Cluster 3": ["√âl√©ment F", "√âl√©ment G", "√âl√©ment H", "√âl√©ment I"]
        }

        try:
            # G√©n√©rer le graphique
            image_base64 = self.generate_cluster_plot(clusters)

            # Envoyer le graphique √† l'utilisateur
            dispatcher.utter_message(text="Voici la visualisation des clusters g√©n√©r√©e :", image=image_base64)

            # Mettre √† jour un slot avec les clusters pour un suivi
            return [SlotSet("cluster_data", clusters)]
        except Exception as e:
            dispatcher.utter_message(text=f"Je n'ai pas pu g√©n√©rer le graphique en raison de l'erreur suivante : {e}")
            return []

class ActionTrainAndOptimizeModel(Action):
    def name(self) -> str:
        return "action_train_and_optimize_model"

    def train_and_optimize(self, X: np.ndarray, y: np.ndarray) -> Dict[str, Any]:
        """
        Entra√Æne et optimise un mod√®le RandomForestClassifier avec GridSearchCV.

        Args:
            X (np.ndarray): Caract√©ristiques d'entr√©e.
            y (np.ndarray): Cibles associ√©es.

        Returns:
            Dict[str, Any]: Mod√®le optimis√©, meilleurs param√®tres et score associ√©.
        """
        try:
            logger.info("D√©marrage de l'entra√Ænement et de l'optimisation du mod√®le.")

            # D√©finir les hyperparam√®tres √† tester
            param_grid = {
                'n_estimators': [50, 100, 200],
                'max_depth': [None, 10, 20],
                'min_samples_split': [2, 5, 10]
            }

            # Instancier le mod√®le et GridSearch
            model = RandomForestClassifier(random_state=42)
            grid_search = GridSearchCV(
                estimator=model,
                param_grid=param_grid,
                cv=5,
                scoring='accuracy',
                n_jobs=-1,
                verbose=1
            )

            # Optimiser le mod√®le
            grid_search.fit(X, y)

            best_model = grid_search.best_estimator_
            best_params = grid_search.best_params_
            best_score = grid_search.best_score_

            logger.info(f"Optimisation r√©ussie. Meilleurs param√®tres : {best_params}. Score : {best_score:.4f}")

            return {
                "model": best_model,
                "best_params": best_params,
                "best_score": best_score
            }

        except ValueError as ve:
            logger.error(f"Erreur dans les donn√©es fournies : {ve}")
            raise ValueError("V√©rifiez les dimensions et la validit√© des donn√©es d'entr√©e.")
        except Exception as e:
            logger.error(f"Erreur lors de l'optimisation du mod√®le : {e}")
            raise RuntimeError("Impossible d'optimiser le mod√®le.")

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        """
        Ex√©cute l'action pour entra√Æner et optimiser un mod√®le.

        Args:
            dispatcher: Pour envoyer des messages √† l'utilisateur.
            tracker: Suivi de l'√©tat de la conversation.
            domain: Domaine de l'application.

        Returns:
            List[Dict[str, Any]]: Slots mis √† jour avec les meilleurs param√®tres et score.
        """
        try:
            # Simulation de donn√©es utilisateur (√† remplacer par des donn√©es r√©elles)
            X = np.random.rand(100, 5)  # 100 √©chantillons, 5 caract√©ristiques
            y = np.random.choice([0, 1], size=100)  # Classes binaires

            logger.info("Donn√©es g√©n√©r√©es pour le mod√®le.")

            # Entra√Æner et optimiser le mod√®le
            optimization_result = self.train_and_optimize(X, y)

            # Pr√©parer la r√©ponse
            best_params = optimization_result["best_params"]
            best_score = optimization_result["best_score"]

            response = (
                f"Mod√®le entra√Æn√© avec succ√®s ! üéâ\n"
                f"Meilleurs hyperparam√®tres : {best_params}\n"
                f"Meilleure pr√©cision obtenue : {best_score:.2f}"
            )
            dispatcher.utter_message(text=response)

            # Sauvegarde du mod√®le optimis√© pour r√©utilisation
            with open("best_random_forest_model.pkl", "wb") as f:
                pickle.dump(optimization_result["model"], f)
            logger.info("Mod√®le optimis√© sauvegard√© sous 'best_random_forest_model.pkl'.")

            # Retourner les param√®tres pour usage futur
            return [
                SlotSet("best_model_params", best_params),
                SlotSet("best_model_score", best_score)
            ]

        except Exception as e:
            logger.error(f"Erreur lors de l'ex√©cution de l'action : {e}")
            dispatcher.utter_message(text=f"Une erreur est survenue lors de l'entra√Ænement du mod√®le : {e}")
            return []

class AdaptiveUserInsightsManager(Action):
    def name(self) -> str:
        return "action_adaptive_user_insights_manager"

    def analyze_behavior(self, user_message: str) -> str:
        """
        Analyse le message utilisateur pour d√©tecter des besoins implicites.
        """
        if "?" in user_message or "aide" in user_message:
            return "h√©sitation"
        elif any(word in user_message for word in ["urgent", "vite", "imm√©diat"]):
            return "besoin imm√©diat"
        elif any(word in user_message for word in ["merci", "parfait", "cool"]):
            return "satisfaction"
        else:
            return "neutre"

    def generate_recommendation(self, behavior: str) -> str:
        """
        G√©n√®re une recommandation bas√©e sur le comportement d√©tect√©.
        """
        recommendations = {
            "h√©sitation": [
                "Souhaitez-vous que je vous explique cela plus en d√©tail ? üòä",
                "Je peux vous guider pas √† pas si vous le souhaitez."
            ],
            "besoin imm√©diat": [
                "D'accord, je vais traiter cela tout de suite pour vous. üöÄ",
                "Je m'en charge imm√©diatement, restez d√©tendu !"
            ],
            "satisfaction": [
                "Merci pour votre retour positif, √ßa me motive √† continuer √† vous aider. üòÑ",
                "Je suis ravi que tout se passe bien. Continuons comme √ßa !"
            ],
            "neutre": [
                "Comment puis-je vous aider davantage ?",
                "N'h√©sitez pas √† poser une question ou √† demander une assistance."
            ]
        }
        return random.choice(recommendations.get(behavior, ["Je suis l√† pour vous aider."]))

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer le dernier message utilisateur
        user_message = tracker.latest_message.get("text")

        try:
            # Analyse du comportement
            detected_behavior = self.analyze_behavior(user_message)
            logger.info(f"Comportement d√©tect√© : {detected_behavior}")

            # G√©n√©ration de recommandation
            recommendation = self.generate_recommendation(detected_behavior)

            # R√©ponse au message utilisateur
            dispatcher.utter_message(text=recommendation)

            # Optionnel : enregistrer les insights dans un slot
            return [SlotSet("detected_behavior", detected_behavior)]
        except Exception as e:
            logger.error(f"Erreur lors de l'analyse du comportement : {e}")
            dispatcher.utter_message(text="Je n'ai pas pu analyser votre demande, d√©sol√©.")
            return []

class ActionRealTimeSuggestions(Action):
    def name(self) -> str:
        return "action_real_time_suggestions"

    def suggest_action(self, user_data: Dict[str, Any]) -> str:
        """
        G√©n√®re une suggestion d'action bas√©e sur les donn√©es utilisateur.
        """
        # Exemple de logique bas√©e sur les donn√©es utilisateur
        if user_data.get("frequent_intent") == "order_pizza":
            return "Souhaitez-vous commander une pizza √† nouveau ? üçï"
        elif user_data.get("last_emotion") == "stress":
            return "Vous semblez stress√© r√©cemment. Puis-je vous proposer un exercice de relaxation ? üåø"
        elif user_data.get("frequent_intent") == "check_balance":
            return "Voulez-vous v√©rifier votre solde bancaire √† nouveau ? üí∞"
        else:
            return "Puis-je vous aider avec quelque chose de sp√©cifique ? üòä"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer les donn√©es utilisateur depuis les slots
        user_data = {
            "frequent_intent": tracker.get_slot("frequent_intent"),
            "last_emotion": tracker.get_slot("last_emotion"),
        }

        # G√©n√©rer une suggestion
        try:
            suggestion = self.suggest_action(user_data)
            logger.info(f"Suggestion g√©n√©r√©e : {suggestion}")

            # Envoyer la suggestion √† l'utilisateur
            dispatcher.utter_message(text=suggestion)

            # Retourner les donn√©es mises √† jour si n√©cessaire
            return [SlotSet("last_suggestion", suggestion)]
        except Exception as e:
            logger.error(f"Erreur lors de la g√©n√©ration de suggestion : {e}")
            dispatcher.utter_message(text="Je n'ai pas pu g√©n√©rer une suggestion, d√©sol√©.")
            return []

class ExistencePhilosopher(Action):
    def name(self) -> str:
        return "action_existence_philosopher"

    def generate_philosophical_response(self, user_message: str) -> str:
        """
        Analyse le message utilisateur et retourne une r√©ponse philosophique.
        """
        # R√©ponses bas√©es sur des th√®mes philosophiques
        existential_themes = {
            "sens": [
                "Le sens de la vie n‚Äôest pas une r√©ponse universelle, mais une qu√™te personnelle. Quelle est votre qu√™te ?",
                "Peut-√™tre que le sens est simplement ce que nous cr√©ons √† travers nos actions et nos relations."
            ],
            "bonheur": [
                "Le bonheur est souvent trouv√© dans les petites choses. Quel moment r√©cent vous a fait sourire ?",
                "Pensez-vous que le bonheur est un objectif, ou une mani√®re de voyager ?"
            ],
            "choix": [
                "Faire un choix peut √™tre difficile, mais chaque d√©cision ouvre une nouvelle porte. Quelle porte voulez-vous ouvrir ?",
                "M√™me ne pas choisir est un choix en soi. Quelle est votre r√©flexion sur cela ?"
            ],
            "√©thique": [
                "L‚Äô√©thique est la lumi√®re qui guide nos actions. Pensez-vous que vos d√©cisions refl√®tent vos valeurs profondes ?",
                "Agir avec √©thique, c‚Äôest choisir ce qui est juste, m√™me lorsque personne ne regarde. Qu‚Äôen pensez-vous ?"
            ]
        }

        # Identifier le th√®me du message utilisateur
        if any(word in user_message.lower() for word in ["sens", "vie", "objectif"]):
            theme = "sens"
        elif any(word in user_message.lower() for word in ["bonheur", "heureux"]):
            theme = "bonheur"
        elif any(word in user_message.lower() for word in ["choix", "d√©cision"]):
            theme = "choix"
        elif any(word in user_message.lower() for word in ["√©thique", "morale"]):
            theme = "√©thique"
        else:
            return "La philosophie est vaste. Quelle question avez-vous en t√™te ?"

        # Choisir une r√©ponse al√©atoire dans le th√®me
        return random.choice(existential_themes[theme])

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer le dernier message utilisateur
        user_message = tracker.latest_message.get("text")

        # G√©n√©rer une r√©ponse philosophique
        response = self.generate_philosophical_response(user_message)

        # Envoyer la r√©ponse √† l'utilisateur
        dispatcher.utter_message(text=response)

        # Pas de mise √† jour de slot n√©cessaire
        return []




class TextSummaryOptimizer(Action):
    def name(self) -> str:
        return "action_text_summary_optimizer"

    def summarize_text(self, text: str) -> str:
        """
        R√©sume un texte en utilisant un mod√®le NLP de r√©sum√©.
        """
        try:
            summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
            summary = summarizer(text, max_length=50, min_length=25, do_sample=False)
            return summary[0]["summary_text"]
        except Exception as e:
            return f"Erreur lors du r√©sum√© : {str(e)}"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        user_text = tracker.latest_message.get("text")
        if not user_text or len(user_text.split()) < 30:
            dispatcher.utter_message(
                text="Votre texte est trop court pour √™tre r√©sum√©. Veuillez fournir un texte plus long."
            )
            return []
        summary = self.summarize_text(user_text)
        dispatcher.utter_message(text=f"Voici un r√©sum√© de votre texte :\n\n{summary}")
        return []


class ConversationalParaphraser(Action):
    def name(self) -> str:
        return "action_conversational_paraphraser"

    def paraphrase_text(self, text: str, tone: str = "neutral") -> str:
        """
        Reformule un texte avec un mod√®le NLP, ajustant le ton si n√©cessaire.
        """
        try:
            # Charger un pipeline de reformulation
            paraphraser = pipeline("text2text-generation", model="t5-small")

            # Pr√©parer la commande pour ajuster le ton
            if tone == "friendly":
                command = f"paraphrase: {text} in a friendly tone"
            elif tone == "formal":
                command = f"paraphrase: {text} in a formal tone"
            else:
                command = f"paraphrase: {text}"

            # G√©n√©rer le texte reformul√©
            paraphrased_text = paraphraser(command, max_length=50, num_return_sequences=1)
            return paraphrased_text[0]["generated_text"]
        except Exception as e:
            return f"Erreur lors de la reformulation : {str(e)}"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer le texte et le ton depuis les slots ou le dernier message
        user_text = tracker.latest_message.get("text")
        tone = tracker.get_slot("tone_preference") or "neutral"

        if not user_text:
            dispatcher.utter_message(text="Je n'ai re√ßu aucun texte √† reformuler.")
            return []

        # Reformuler le texte
        paraphrased_text = self.paraphrase_text(user_text, tone)

        # R√©pondre √† l'utilisateur avec le texte reformul√©
        dispatcher.utter_message(text=f"Voici une reformulation de votre message :\n\n{paraphrased_text}")

        # Optionnel : stocker le texte reformul√©
        return [SlotSet("paraphrased_text", paraphrased_text)]

class ContextualMemoryArchitect(Action):
    def name(self) -> str:
        return "action_contextual_memory_architect"

    def update_contextual_memory(self, tracker, memory: Dict[str, Any]) -> Dict[str, Any]:
        """
        Met √† jour la m√©moire contextuelle avec les derni√®res interactions utilisateur.
        """
        user_message = tracker.latest_message.get("text")
        user_intent = tracker.latest_message.get("intent", {}).get("name", "unknown")
        user_entities = tracker.latest_message.get("entities", [])

        # Mise √† jour de la m√©moire avec les nouvelles informations
        memory["recent_messages"].append(user_message)
        memory["recent_intents"].append(user_intent)

        for entity in user_entities:
            memory["entities"][entity["entity"]] = entity["value"]

        # Limiter la taille des messages/intents stock√©s pour √©viter une surcharge
        memory["recent_messages"] = memory["recent_messages"][-10:]
        memory["recent_intents"] = memory["recent_intents"][-10:]

        return memory

    def generate_personalized_response(self, memory: Dict[str, Any]) -> str:
        """
        G√©n√®re une r√©ponse bas√©e sur la m√©moire contextuelle.
        """
        if memory["recent_intents"][-1] == "order_pizza":
            return "Je vois que vous avez command√© une pizza r√©cemment. Souhaitez-vous la m√™me chose ou essayer une nouvelle recette ? üçï"
        elif memory["recent_intents"][-1] == "check_balance":
            return "Vous avez r√©cemment v√©rifi√© votre solde. Puis-je vous aider avec une autre op√©ration bancaire ? üí∞"
        elif len(memory["recent_messages"]) > 0 and "merci" in memory["recent_messages"][-1].lower():
            return "De rien ! Je suis toujours l√† pour vous aider. üòä"
        else:
            return "Je suis ici pour vous aider. Que puis-je faire pour vous ?"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer la m√©moire contextuelle depuis un slot
        memory = tracker.get_slot("contextual_memory") or {
            "recent_messages": [],
            "recent_intents": [],
            "entities": {}
        }

        # Mettre √† jour la m√©moire avec les derni√®res interactions
        updated_memory = self.update_contextual_memory(tracker, memory)

        # G√©n√©rer une r√©ponse personnalis√©e
        personalized_response = self.generate_personalized_response(updated_memory)

        # Envoyer la r√©ponse √† l'utilisateur
        dispatcher.utter_message(text=personalized_response)

        # Retourner la m√©moire mise √† jour pour la conversation future
        return [SlotSet("contextual_memory", updated_memory)]

class MultilingualIntentEnhancer(Action):
    def name(self) -> str:
        return "action_multilingual_intent_enhancer"

    def detect_language(self, text: str) -> str:
        """
        D√©tecte la langue d'un texte √† l'aide de langdetect.
        """
        try:
            return detect(text)
        except Exception as e:
            return "unknown"

    def translate_intent(self, intent: str, language: str) -> str:
        """
        Traduit l'intention en anglais pour la traiter (simulation).
        """
        translations = {
            "fr": {
                "commander_pizza": "order_pizza",
                "v√©rifier_solde": "check_balance",
                "poser_question": "ask_question"
            },
            "es": {
                "pedir_pizza": "order_pizza",
                "consultar_saldo": "check_balance",
                "hacer_pregunta": "ask_question"
            }
        }
        return translations.get(language, {}).get(intent, intent)

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer le dernier message utilisateur
        user_message = tracker.latest_message.get("text")
        user_intent = tracker.latest_message.get("intent", {}).get("name", "unknown")

        # D√©tecter la langue
        detected_language = self.detect_language(user_message)
        dispatcher.utter_message(text=f"Langue d√©tect√©e : {detected_language}")

        # Si la langue est autre que l'anglais, traduire l'intention
        if detected_language != "en":
            translated_intent = self.translate_intent(user_intent, detected_language)
            dispatcher.utter_message(
                text=f"Votre intention '{user_intent}' a √©t√© traduite en anglais : '{translated_intent}'."
            )
            return [SlotSet("detected_language", detected_language), SlotSet("translated_intent", translated_intent)]
        else:
            dispatcher.utter_message(text="Votre intention est d√©j√† en anglais. Pas de traduction n√©cessaire.")
            return [SlotSet("detected_language", detected_language)]

class EthicalLanguageNormalizer(Action):
    def name(self) -> str:
        return "action_ethical_language_normalizer"

    def analyze_and_normalize(self, text: str) -> Dict[str, Any]:
        """
        Analyse un texte pour d√©tecter des termes non √©thiques et propose une reformulation.
        """
        # Liste simplifi√©e de mots/expressions √† surveiller
        flagged_terms = {
            "insulte": ["stupide", "idiot", "nul"],
            "discrimination": ["femme au volant", "il/elle ne vaut rien"],
            "agressivit√©": ["tais-toi", "d√©gage"]
        }

        # Remplacements recommand√©s
        replacements = {
            "stupide": "mal avis√©",
            "idiot": "malin dans d'autres contextes",
            "nul": "√† am√©liorer",
            "tais-toi": "pourrais-tu rester silencieux un instant ?",
            "d√©gage": "pourrais-tu t'√©carter, s'il te pla√Æt ?"
        }

        # Analyse et suggestions
        flagged_detected = []
        normalized_text = text

        for category, terms in flagged_terms.items():
            for term in terms:
                if term in text.lower():
                    flagged_detected.append((category, term))
                    normalized_text = normalized_text.replace(term, replacements.get(term, "[terme √† remplacer]"))

        return {
            "flagged_detected": flagged_detected,
            "normalized_text": normalized_text
        }

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer le message utilisateur
        user_message = tracker.latest_message.get("text")

        if not user_message:
            dispatcher.utter_message(text="Je n'ai pas re√ßu de texte √† analyser.")
            return []

        # Analyse et reformulation
        analysis_result = self.analyze_and_normalize(user_message)

        # Pr√©parer la r√©ponse
        if analysis_result["flagged_detected"]:
            flagged_terms = ", ".join([term[1] for term in analysis_result["flagged_detected"]])
            response = (
                f"J'ai d√©tect√© des termes sensibles ou non √©thiques dans votre message : {flagged_terms}.\n"
                f"Voici une reformulation plus appropri√©e :\n\n{analysis_result['normalized_text']}"
            )
        else:
            response = "Votre message semble respecter toutes les normes √©thiques. üòä"

        # Envoyer la r√©ponse
        dispatcher.utter_message(text=response)

        # Retourner les termes d√©tect√©s pour suivi (facultatif)
        return [SlotSet("flagged_terms", analysis_result["flagged_detected"])]




class summarizeText(Action):
    def name(self) -> str:
        return "action_summarize_text"

    def run(self, dispatcher: CollectingDispatcher,
            tracker: Tracker,
            domain: DomainDict) -> list:
        # R√©cup√©rer le texte utilisateur
        user_message = tracker.latest_message.get('text', None)

        if not user_message:
            dispatcher.utter_message(
                text="Je n'ai pas trouv√© de texte √† r√©sumer. Pouvez-vous r√©essayer avec plus d'informations‚ÄØ?")
            return []

        # V√©rification de la longueur du texte
        if len(user_message.split()) < 30:  # Minimum requis pour un r√©sum√© coh√©rent
            dispatcher.utter_message(
                text="Le texte est trop court pour √™tre r√©sum√©. Pouvez-vous fournir un contenu plus long‚ÄØ?")
            return []

        try:
            # G√©n√©ration du r√©sum√© avec `transformers`
            summarized_text = summarizer(user_message, max_length=130, min_length=30, do_sample=False)
            summary = summarized_text[0]['summary_text']

            if not summary.strip():  # V√©rifie si le r√©sum√© est vide
                dispatcher.utter_message(text="Je n'ai pas pu g√©n√©rer un r√©sum√© utile. Essayez avec un autre texte.")
            else:
                dispatcher.utter_message(text=f"Voici le r√©sum√© :\n{summary}")

        except Exception as e:
            dispatcher.utter_message(text="Une erreur s'est produite lors du r√©sum√©. Merci de r√©essayer.")

        return []
class SelfContainedNLPAnalyzer(Action):
    def name(self) -> str:
        return "action_self_contained_nlp_analyzer"

    def analyze_text(self, text: str) -> Dict[str, Any]:
        """
        Analyse un texte pour d√©tecter des patterns simples et en extraire des informations.
        """
        # Exemple de d√©tection de mots-cl√©s ou expressions sp√©cifiques
        keywords = {
            "commande": ["commander", "acheter", "r√©server"],
            "information": ["infos", "information", "d√©tails"],
            "probl√®me": ["erreur", "probl√®me", "bug"]
        }

        detected_categories = []

        for category, words in keywords.items():
            for word in words:
                if re.search(rf"\b{word}\b", text.lower()):
                    detected_categories.append(category)

        return {
            "categories": detected_categories,
            "text_length": len(text.split())
        }

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer le message utilisateur
        user_message = tracker.latest_message.get("text")

        if not user_message:
            dispatcher.utter_message(text="Je n'ai pas re√ßu de texte √† analyser.")
            return []

        # Analyser le texte
        analysis_result = self.analyze_text(user_message)

        # R√©pondre √† l'utilisateur avec les cat√©gories d√©tect√©es
        if analysis_result["categories"]:
            response = f"J'ai d√©tect√© les cat√©gories suivantes dans votre message : {', '.join(analysis_result['categories'])}."
        else:
            response = "Je n'ai d√©tect√© aucune cat√©gorie particuli√®re dans votre message."

        dispatcher.utter_message(text=response)

        # Retourner un slot mis √† jour pour suivi
        return [SlotSet("analyzed_categories", analysis_result["categories"])]
class PostgreSQLManager:
    """
    G√®re PostgreSQL avec chiffrement et validation des donn√©es.
    """

    def __init__(self, db_name: str, user: str, password: str, host: str = "localhost", port: int = 5432, encryption_enabled: bool = True):
        """
        Initialise la connexion PostgreSQL.

        Args:
            db_name (str): Nom de la base de donn√©es.
            user (str): Utilisateur PostgreSQL.
            password (str): Mot de passe PostgreSQL.
            host (str): H√¥te du serveur PostgreSQL.
            port (int): Port de PostgreSQL.
            encryption_enabled (bool): Activer ou d√©sactiver le chiffrement des donn√©es sensibles.
        """
        try:
            self.connection = psycopg2.connect(
                dbname=db_name,
                user=user,
                password=password,
                host=host,
                port=port,
                cursor_factory=RealDictCursor
            )
            self.cursor = self.connection.cursor()
            self.encryption_enabled = encryption_enabled
            self.encryption_key = os.getenv("DB_ENCRYPTION_KEY", "thisisaverysecurekey").encode()
            logger.info(f"PostgreSQLManager connected to DB: {db_name} on {host}:{port}")
            asyncio.run(self.initialize_tables())
        except Exception as e:
            logger.error(f"Error connecting to PostgreSQL: {e}")
            raise

    def encrypt_data(self, data: str) -> bytes:
        """
        Chiffre une cha√Æne de caract√®res.

        Args:
            data (str): Donn√©es √† chiffrer.

        Returns:
            bytes: Donn√©es chiffr√©es.
        """
        iv = secrets.token_bytes(16)  # G√©n√®re un IV al√©atoire de 16 octets
        cipher = Cipher(algorithms.AES(self.encryption_key), modes.CFB(iv), backend=default_backend())
        encryptor = cipher.encryptor()
        encrypted_data = encryptor.update(data.encode()) + encryptor.finalize()
        return iv + encrypted_data  # Combine IV et donn√©es chiffr√©es

    def decrypt_data(self, encrypted_data: bytes) -> str:
        """
        D√©chiffre une cha√Æne de caract√®res.

        Args:
            encrypted_data (bytes): Donn√©es chiffr√©es.

        Returns:
            str: Donn√©es d√©chiffr√©es.
        """
        iv = encrypted_data[:16]  # Extraire l'IV
        data = encrypted_data[16:]  # Extraire les donn√©es chiffr√©es
        cipher = Cipher(algorithms.AES(self.encryption_key), modes.CFB(iv), backend=default_backend())
        decryptor = cipher.decryptor()
        return decryptor.update(data).decode()

    async def initialize_tables(self):
        """
        Initialise les tables n√©cessaires dans la base de donn√©es si elles n'existent pas.
        """
        query = """
        CREATE TABLE IF NOT EXISTS interactions (
            id SERIAL PRIMARY KEY,
            user_id VARCHAR(255),
            message BYTEA,
            response BYTEA,
            metadata JSONB,
            timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        """
        await asyncio.to_thread(self.cursor.execute, query)
        self.connection.commit()
        logger.info("Tables initialized successfully.")

    async def save_interaction(self, user_id: str, message: str, response: str, metadata: dict = {}):
        """
        Sauvegarde une interaction utilisateur.

        Args:
            user_id (str): ID utilisateur.
            message (str): Message envoy√© par l'utilisateur.
            response (str): R√©ponse g√©n√©r√©e.
            metadata (dict): M√©tadonn√©es suppl√©mentaires.
        """
        try:
            if self.encryption_enabled:
                message = self.encrypt_data(message)
                response = self.encrypt_data(response)

            query = """
            INSERT INTO interactions (user_id, message, response, metadata)
            VALUES (%s, %s, %s, %s);
            """
            await asyncio.to_thread(self.cursor.execute, query, (user_id, message, response, metadata))
            self.connection.commit()
            logger.info(f"Interaction saved for user: {user_id}")
        except Exception as e:
            logger.error(f"Error saving interaction for user {user_id}: {e}")

    async def fetch_interactions(self, user_id: str, limit: int = 10, offset: int = 0) -> list:
        """
        R√©cup√®re toutes les interactions d'un utilisateur.

        Args:
            user_id (str): ID utilisateur.
            limit (int): Nombre maximum de r√©sultats.
            offset (int): D√©calage pour la pagination.

        Returns:
            list: Liste des interactions.
        """
        try:
            query = """
            SELECT id, user_id, message, response, metadata, timestamp
            FROM interactions
            WHERE user_id = %s
            ORDER BY timestamp DESC
            LIMIT %s OFFSET %s;
            """
            await asyncio.to_thread(self.cursor.execute, query, (user_id, limit, offset))
            records = self.cursor.fetchall()

            results = []
            for record in records:
                if self.encryption_enabled:
                    record["message"] = self.decrypt_data(record["message"])
                    record["response"] = self.decrypt_data(record["response"])
                results.append(record)

            logger.info(f"Fetched {len(results)} interactions for user: {user_id}")
            return results
        except Exception as e:
            logger.error(f"Error fetching interactions for user {user_id}: {e}")
            return []
class SentimentAndToneBalancer(Action):
    def name(self) -> str:
        return "action_sentiment_and_tone_balancer"

    def detect_tone(self, text: str) -> str:
        """
        D√©tecte un ton √©motionnel simple bas√© sur des mots-cl√©s.
        """
        tone_keywords = {
            "positif": ["merci", "super", "g√©nial", "excellent"],
            "n√©gatif": ["nul", "probl√®me", "d√©√ßu", "fatigu√©"],
            "neutre": ["ok", "d'accord", "normal"]
        }

        for tone, keywords in tone_keywords.items():
            for keyword in keywords:
                if keyword in text.lower():
                    return tone

        return "inconnu"

    def generate_balanced_response(self, tone: str) -> str:
        """
        Propose une r√©ponse en √©quilibrant le ton d√©tect√©.
        """
        responses = {
            "positif": "Merci pour votre retour positif ! Je suis ravi de vous aider. üòä",
            "n√©gatif": "Je suis d√©sol√© si quelque chose vous d√©√ßoit. Que puis-je faire pour am√©liorer cela ?",
            "neutre": "Merci pour votre retour. Comment puis-je vous aider davantage ?",
            "inconnu": "Pouvez-vous m‚Äôen dire plus pour que je comprenne mieux votre besoin ?"
        }
        return responses.get(tone, "Je suis l√† pour vous aider.")

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer le message utilisateur
        user_message = tracker.latest_message.get("text")

        if not user_message:
            dispatcher.utter_message(text="Je n'ai pas re√ßu de texte √† analyser.")
            return []

        # D√©tecter le ton du message
        detected_tone = self.detect_tone(user_message)

        # G√©n√©rer une r√©ponse √©quilibr√©e
        balanced_response = self.generate_balanced_response(detected_tone)

        # Envoyer la r√©ponse
        dispatcher.utter_message(text=balanced_response)

        # Optionnel : Retourner un slot mis √† jour avec le ton d√©tect√©
        return [SlotSet("detected_tone", detected_tone)]

class BiasDetectionManager(Action):
    def name(self) -> str:
        return "action_bias_detection_manager"

    def detect_bias(self, text: str) -> Dict[str, Any]:
        """
        Analyse un texte pour d√©tecter des biais implicites (discriminations, st√©r√©otypes).
        """
        # Dictionnaire de mots-cl√©s li√©s √† des biais
        bias_keywords = {
            "genre": [
                r"\bhomme\b", r"\bfemme\b", r"\bsexe faible\b", r"\bdominant\b",
                r"\bf√©minin\b", r"\bmasculin\b"
            ],
            "origine": [
                r"\b√©tranger\b", r"\bimmigr√©\b", r"\brace\b", r"\bethnie\b", r"\bnationalit√©\b"
            ],
            "√¢ge": [
                r"\bvieux\b", r"\bjeune\b", r"\bg√©n√©ration Z\b", r"\bboomer\b"
            ],
            "statut social": [
                r"\bch√¥meur\b", r"\bpr√©carit√©\b", r"\briche\b", r"\bclasse moyenne\b"
            ],
            "orientation sexuelle": [
                r"\bhomosexuel\b", r"\blgbt\b", r"\btransgenre\b", r"\bh√©t√©ro\b"
            ]
        }

        flagged_terms = []

        for category, patterns in bias_keywords.items():
            for pattern in patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    flagged_terms.append((category, match.group()))

        return {"flagged_terms": flagged_terms, "text": text}

    def generate_response(self, flagged_terms: List[Tuple[str, str]]) -> str:
        """
        G√©n√®re une r√©ponse en fonction des biais d√©tect√©s.
        """
        if not flagged_terms:
            return "Votre message est exempt de biais d√©tect√©s. Merci pour votre langage respectueux‚ÄØ! üòä"

        details = "\n".join(
            [f"- Terme : '{term[1]}' (Cat√©gorie : {term[0]})" for term in flagged_terms]
        )
        suggestions = (
            "Essayez d'utiliser des termes plus neutres ou inclusifs pour √©viter les malentendus. "
            "Par exemple : remplacez 'sexe faible' par 'genre sous-repr√©sent√©'. üòä"
        )
        return f"J'ai d√©tect√© des termes potentiellement biais√©s‚ÄØ:\n{details}\n\n{suggestions}"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer le message utilisateur
        user_message = tracker.latest_message.get("text")

        if not user_message:
            dispatcher.utter_message(text="Je n'ai pas re√ßu de texte √† analyser. Veuillez r√©essayer.")
            return []

        # Analyse des biais
        bias_result = self.detect_bias(user_message)

        # G√©n√©ration de la r√©ponse
        response = self.generate_response(bias_result["flagged_terms"])
        dispatcher.utter_message(text=response)

        # Retour des biais d√©tect√©s (optionnel pour logs ou interface avanc√©e)
        return [SlotSet("bias_detected", bias_result["flagged_terms"])]

class JusticeDecisionAssistant(Action):
    def name(self) -> str:
        return "action_justice_decision_assistant"

    def evaluate_arguments(self, arguments: List[str]) -> str:
        """
        Analyse une liste d'arguments et retourne une recommandation impartiale.
        """
        # Simplification‚ÄØ: Compte les arguments positifs et n√©gatifs
        positive_keywords = ["bien", "avantage", "utile", "juste", "√©quitable"]
        negative_keywords = ["mal", "injustice", "probl√®me", "d√©savantage", "discrimination"]

        scores = {"positif": 0, "n√©gatif": 0}

        for argument in arguments:
            for word in positive_keywords:
                if word in argument.lower():
                    scores["positif"] += 1
            for word in negative_keywords:
                if word in argument.lower():
                    scores["n√©gatif"] += 1

        if scores["positif"] > scores["n√©gatif"]:
            return "Apr√®s analyse, les arguments en faveur de cette action semblent l'emporter."
        elif scores["n√©gatif"] > scores["positif"]:
            return "Apr√®s analyse, les arguments contre cette action semblent l'emporter."
        else:
            return "Les arguments semblent √©quilibr√©s. Je recommande une discussion suppl√©mentaire pour trancher."

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple d'arguments (peut √™tre remplac√© par des slots utilisateur)
        arguments = tracker.get_slot("arguments_list") or [
            "C'est bien pour tout le monde.",
            "Cela cr√©e une injustice.",
            "C'est utile pour r√©soudre un probl√®me."
        ]

        # √âvaluer les arguments
        recommendation = self.evaluate_arguments(arguments)

        # R√©ponse utilisateur
        dispatcher.utter_message(text=f"Analyse des arguments : {recommendation}")

        return []

class ActionShowOptions(Action):
    def name(self) -> str:
        return "action_show_options"

    def run(
        self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        # D√©finition des options (peut √™tre dynamique)
        options = [
            {"title": "Option 1", "payload": "/choose_option_1"},
            {"title": "Option 2", "payload": "/choose_option_2"},
            {"title": "Option 3", "payload": "/choose_option_3"},
        ]

        # G√©n√©rer les boutons
        buttons = [
            {"title": option["title"], "payload": option["payload"]}
            for option in options
        ]

        # Envoyer les options avec des boutons interactifs
        dispatcher.utter_message(
            text="Voici les options disponibles :",
            buttons=buttons
        )

        return []

class ConflictResolutionAdvisor(Action):
    def name(self) -> str:
        return "action_conflict_resolution_advisor"

    def propose_resolution(self, conflict_points: List[Dict[str, Any]]) -> str:
        """
        Analyse les points de conflit et propose une solution √©quilibr√©e.
        """
        solutions = []

        for point in conflict_points:
            issue = point.get("issue")
            perspectives = point.get("perspectives", {})

            # Trouver les int√©r√™ts communs ou compromis possibles
            common_interests = [
                interest for interest in perspectives.get("side_a", [])
                if interest in perspectives.get("side_b", [])
            ]

            if common_interests:
                solutions.append(f"Pour '{issue}', les deux parties partagent des int√©r√™ts communs : {', '.join(common_interests)}.")
            else:
                solutions.append(f"Pour '{issue}', il serait utile d'explorer des compromis ou int√©r√™ts partag√©s.")

        if solutions:
            return "\n".join(solutions)
        else:
            return "Je n'ai pas assez d'informations pour proposer une r√©solution. Pouvez-vous fournir plus de d√©tails ?"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de points de conflit (peut √™tre remplac√© par des slots utilisateur)
        conflict_points = tracker.get_slot("conflict_points") or [
            {
                "issue": "Prolongation des d√©lais",
                "perspectives": {
                    "side_a": ["plus de temps pour bien faire", "moins de pression"],
                    "side_b": ["respect des d√©lais", "impact sur les livraisons"]
                }
            },
            {
                "issue": "R√©partition des t√¢ches",
                "perspectives": {
                    "side_a": ["√©quit√© dans les efforts"],
                    "side_b": ["comp√©tences sp√©cialis√©es"]
                }
            }
        ]

        # Proposer une r√©solution bas√©e sur les points de conflit
        resolution = self.propose_resolution(conflict_points)

        # R√©ponse utilisateur
        dispatcher.utter_message(text=f"Voici mes propositions pour r√©soudre ces conflits :\n\n{resolution}")

        return []

class FairResourceAllocator(Action):
    def name(self) -> str:
        return "action_fair_resource_allocator"

    def allocate_resources(self, requests: List[Dict[str, Any]], total_resources: int = 100) -> Dict[str, Any]:
        """
        Alloue des ressources √©quitablement entre plusieurs demandes, avec gestion des priorit√©s.
        """
        # Trier les demandes par priorit√© d√©croissante
        sorted_requests = sorted(requests, key=lambda x: x.get("priority", 0), reverse=True)
        allocation = {}

        # Calculer le total des priorit√©s pour l'allocation proportionnelle
        total_priority = sum(request.get("priority", 1) for request in sorted_requests)
        if total_priority == 0:
            total_priority = len(sorted_requests)  # √âviter division par 0

        for request in sorted_requests:
            user_id = request.get("user_id")
            requested = request.get("amount", 0)
            priority = request.get("priority", 0)

            # Allocation proportionnelle bas√©e sur les priorit√©s
            share = (priority / total_priority) * total_resources
            allocated = min(requested, int(share))
            allocation[user_id] = {
                "requested": requested,
                "allocated": allocated,
                "priority": priority
            }

            # R√©duire les ressources restantes
            total_resources -= allocated
            if total_resources <= 0:
                break

        return allocation

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # R√©cup√©rer les demandes depuis un slot (ou exemple par d√©faut)
        requests = tracker.get_slot("resource_requests") or [
            {"user_id": "user_1", "amount": 50, "priority": 3},
            {"user_id": "user_2", "amount": 30, "priority": 2},
            {"user_id": "user_3", "amount": 40, "priority": 1}
        ]

        # Allouer les ressources
        total_resources = tracker.get_slot("total_resources") or 100
        allocation = self.allocate_resources(requests, total_resources)

        # Pr√©parer une r√©ponse utilisateur
        response = "Voici l'allocation des ressources‚ÄØ:\n"
        for user_id, details in allocation.items():
            response += (
                f"- Utilisateur {user_id} : demand√© {details['requested']}, "
                f"attribu√© {details['allocated']} (priorit√© {details['priority']}).\n"
            )

        if total_resources > 0:
            response += f"\nRessources restantes : {total_resources} unit√©s.\n"
        else:
            response += "\nToutes les ressources ont √©t√© allou√©es.\n"

        dispatcher.utter_message(text=response)

        # Retourner les allocations pour suivi (facultatif)
        return [
            SlotSet("resource_allocation", allocation),
            SlotSet("remaining_resources", total_resources)
        ]

class JusticeFeedbackAnalyzer(Action):
    def name(self) -> str:
        return "action_justice_feedback_analyzer"

    def analyze_feedback(self, feedbacks: List[Dict[str, Any]]) -> Dict[str, int]:
        """
        Analyse les retours utilisateurs pour identifier les perceptions d'injustice.
        """
        results = {"positive": 0, "negative": 0}

        for feedback in feedbacks:
            if feedback.get("sentiment") == "positive":
                results["positive"] += 1
            elif feedback.get("sentiment") == "negative":
                results["negative"] += 1

        return results

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de feedbacks collect√©s (peut venir de slots ou d'une base)
        feedbacks = tracker.get_slot("feedbacks") or [
            {"user_id": "user_1", "sentiment": "positive"},
            {"user_id": "user_2", "sentiment": "negative"}
        ]

        # Analyser les feedbacks
        results = self.analyze_feedback(feedbacks)

        # Pr√©parer une r√©ponse
        response = (
            f"J'ai re√ßu {results['positive']} retours positifs et {results['negative']} retours n√©gatifs. "
            "Je vais ajuster mes d√©cisions pour mieux correspondre √† vos attentes."
        )

        dispatcher.utter_message(text=response)

        # Retourner les r√©sultats pour ajustement (optionnel)
        return [SlotSet("feedback_analysis", results)]

class EqualityAuditManager(Action):
    def name(self) -> str:
        return "action_equality_audit_manager"

    def audit_interactions(self, logs: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Audite les interactions pour v√©rifier l'√©quit√© entre les utilisateurs.
        """
        user_stats = {}

        for log in logs:
            user_id = log.get("user_id")
            if user_id not in user_stats:
                user_stats[user_id] = {"total_interactions": 0, "resources_allocated": 0}
            user_stats[user_id]["total_interactions"] += 1
            user_stats[user_id]["resources_allocated"] += log.get("resources", 0)

        # V√©rifier les d√©s√©quilibres
        fairness_issues = [
            user_id for user_id, stats in user_stats.items()
            if stats["resources_allocated"] < 10  # Exemple de seuil
        ]

        return {"user_stats": user_stats, "fairness_issues": fairness_issues}

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de logs d'interactions
        logs = tracker.get_slot("interaction_logs") or [
            {"user_id": "user_1", "resources": 50},
            {"user_id": "user_2", "resources": 5},
            {"user_id": "user_3", "resources": 15}
        ]

        # Effectuer l'audit
        audit_result = self.audit_interactions(logs)

        # Pr√©parer une r√©ponse
        if audit_result["fairness_issues"]:
            response = (
                f"Des d√©s√©quilibres ont √©t√© d√©tect√©s pour les utilisateurs suivants : {', '.join(audit_result['fairness_issues'])}. "
                "Des ajustements seront effectu√©s."
            )
        else:
            response = "Aucun d√©s√©quilibre d√©tect√©. Les ressources semblent r√©parties √©quitablement."

        dispatcher.utter_message(text=response)

        # Retourner les r√©sultats pour suivi
        return [SlotSet("audit_results", audit_result)]

class EthicsDrivenRecommendation(Action):
    """
    Propose des recommandations bas√©es sur les pr√©f√©rences utilisateur, en respectant des crit√®res √©thiques.
    """

    def name(self) -> str:
        return "action_ethics_driven_recommendation"

    def filter_unethical_recommendations(self, recommendations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Filtre les recommandations qui pourraient √™tre contraires aux principes √©thiques.

        Args:
            recommendations (List[Dict[str, Any]]): Liste des recommandations possibles.

        Returns:
            List[Dict[str, Any]]: Liste filtr√©e des recommandations √©thiques.
        """
        return [rec for rec in recommendations if rec.get("ethical", True)]

    def rank_recommendations(self, recommendations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Classe les recommandations par pertinence.

        Args:
            recommendations (List[Dict[str, Any]]): Liste des recommandations filtr√©es.

        Returns:
            List[Dict[str, Any]]: Liste des recommandations tri√©es.
        """
        return sorted(recommendations, key=lambda x: x.get("priority", 0), reverse=True)

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemples de recommandations r√©cup√©r√©es (peuvent venir de bases de donn√©es ou d'APIs)
        raw_recommendations = [
            {"title": "Adopter une routine sportive", "priority": 10, "ethical": True},
            {"title": "Investir dans un portefeuille √† risque √©lev√©", "priority": 5, "ethical": False},
            {"title": "M√©diter quotidiennement", "priority": 8, "ethical": True}
        ]

        # Filtrer et classer les recommandations
        ethical_recommendations = self.filter_unethical_recommendations(raw_recommendations)
        ranked_recommendations = self.rank_recommendations(ethical_recommendations)

        # R√©ponse pour l'utilisateur
        if ranked_recommendations:
            recommendations_text = "\n".join([rec["title"] for rec in ranked_recommendations])
            dispatcher.utter_message(text=f"Voici mes recommandations :\n{recommendations_text}")
        else:
            dispatcher.utter_message(text="Je n'ai trouv√© aucune recommandation √©thique adapt√©e.")

        return []

class TransparencyResponseManager(Action):
    """
    Fournit des explications d√©taill√©es sur les d√©cisions ou recommandations prises par le bot.
    """

    def name(self) -> str:
        return "action_transparency_response_manager"

    def generate_explanation(self, decision_context: Dict[str, Any]) -> str:
        """
        G√©n√®re une explication bas√©e sur le contexte de la d√©cision.

        Args:
            decision_context (Dict[str, Any]): Contexte contenant les crit√®res de d√©cision.

        Returns:
            str: Explication claire pour l'utilisateur.
        """
        reason = decision_context.get("reason", "Aucune raison sp√©cifi√©e.")
        criteria = decision_context.get("criteria", [])

        explanation = f"La d√©cision a √©t√© prise pour la raison suivante : {reason}.\n"
        if criteria:
            explanation += "Voici les crit√®res utilis√©s dans cette d√©cision :\n"
            explanation += "\n".join([f"- {criterion}" for criterion in criteria])
        else:
            explanation += "Aucun crit√®re sp√©cifique n'a √©t√© utilis√©."

        return explanation

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de contexte de d√©cision (rempla√ßable par des slots ou une API)
        decision_context = tracker.get_slot("decision_context") or {
            "reason": "Priorit√© √©lev√©e et conformit√© aux principes √©thiques.",
            "criteria": ["Pertinence √©lev√©e", "Impact positif sur l'utilisateur"]
        }

        # G√©n√©rer une explication bas√©e sur le contexte
        explanation = self.generate_explanation(decision_context)

        # R√©ponse utilisateur
        dispatcher.utter_message(text=f"Voici pourquoi cette d√©cision a √©t√© prise :\n\n{explanation}")

        # Optionnel : retour du contexte d'explication
        return [SlotSet("explanation_generated", explanation)]

class UserFeedbackLoop(Action):
    """
    G√®re une boucle de feedback utilisateur pour ajuster les d√©cisions ou recommandations.
    """

    def name(self) -> str:
        return "action_user_feedback_loop"

    def collect_feedback(self, feedback: Dict[str, str]) -> Dict[str, int]:
        """
        Analyse les retours des utilisateurs.

        Args:
            feedback (Dict[str, str]): Feedback utilisateur avec une note (positive ou n√©gative).

        Returns:
            Dict[str, int]: Compte des feedbacks positifs et n√©gatifs.
        """
        positive = 0
        negative = 0

        for response in feedback.values():
            if response.lower() in ["positif", "bien", "ok"]:
                positive += 1
            elif response.lower() in ["n√©gatif", "pas bien", "mauvais"]:
                negative += 1

        return {"positive": positive, "negative": negative}

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de feedbacks utilisateur (peut √™tre remplac√© par des slots ou des logs)
        feedback = tracker.get_slot("user_feedback") or {
            "recommendation_1": "positif",
            "recommendation_2": "n√©gatif",
            "recommendation_3": "positif"
        }

        # Analyser les feedbacks
        feedback_summary = self.collect_feedback(feedback)

        # Pr√©parer une r√©ponse utilisateur
        response = (
            f"Merci pour vos retours ! Voici un r√©sum√© :\n"
            f"- Feedbacks positifs : {feedback_summary['positive']}\n"
            f"- Feedbacks n√©gatifs : {feedback_summary['negative']}\n"
        )
        if feedback_summary["negative"] > 0:
            response += "Je vais ajuster mes recommandations pour mieux r√©pondre √† vos attentes."

        dispatcher.utter_message(text=response)

        # Retour facultatif pour suivre les feedbacks
        return [SlotSet("feedback_summary", feedback_summary)]

class DecisionAuditTrail(Action):
    """
    Cr√©e un historique des d√©cisions prises par le bot.
    """

    def name(self) -> str:
        return "action_decision_audit_trail"

    def log_decision(self, decision: Dict[str, Any], audit_log: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Ajoute une d√©cision au journal d'audit.

        Args:
            decision (Dict[str, Any]): D√©tails de la d√©cision √† enregistrer.
            audit_log (List[Dict[str, Any]]): Journal d'audit existant.

        Returns:
            List[Dict[str, Any]]: Journal d'audit mis √† jour.
        """
        audit_log.append(decision)
        return audit_log[-100:]  # Limite √† 100 entr√©es pour √©viter la surcharge

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de d√©cision √† enregistrer (peut √™tre remplac√© par des slots ou logs)
        decision = tracker.get_slot("current_decision") or {
            "type": "recommendation",
            "details": "Recommander une activit√© physique",
            "timestamp": "2024-11-12T12:00:00Z",
            "criteria": ["pertinence √©lev√©e", "impact positif"]
        }

        # Charger le journal d'audit existant
        audit_log = tracker.get_slot("audit_log") or []

        # Enregistrer la d√©cision
        updated_audit_log = self.log_decision(decision, audit_log)

        # Confirmer l'ajout au journal
        dispatcher.utter_message(text="La d√©cision a √©t√© enregistr√©e dans le journal d'audit.")

        # Retourner le journal mis √† jour
        return [SlotSet("audit_log", updated_audit_log)]

class EthicalRiskMonitor(Action):
    """
    Surveille les d√©cisions pour d√©tecter des risques √©thiques potentiels.
    """

    def name(self) -> str:
        return "action_ethical_risk_monitor"

    def check_risks(self, decision: Dict[str, Any]) -> bool:
        """
        V√©rifie si une d√©cision pr√©sente des risques √©thiques.

        Args:
            decision (Dict[str, Any]): D√©tails de la d√©cision.

        Returns:
            bool: True si des risques sont d√©tect√©s, False sinon.
        """
        prohibited_criteria = ["impact n√©gatif", "non conforme", "discrimination"]
        return any(criterion in decision.get("criteria", []) for criterion in prohibited_criteria)

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de d√©cision actuelle
        decision = tracker.get_slot("current_decision") or {
            "type": "allocation",
            "details": "Allouer des ressources suppl√©mentaires",
            "criteria": ["impact positif", "non conforme"]
        }

        # V√©rifier les risques
        risk_detected = self.check_risks(decision)

        if risk_detected:
            dispatcher.utter_message(
                text="Attention : Une d√©cision a √©t√© d√©tect√©e comme potentiellement non conforme aux principes √©thiques."
            )
        else:
            dispatcher.utter_message(
                text="Aucun risque √©thique d√©tect√© pour cette d√©cision."
            )

        return [SlotSet("risk_detected", risk_detected)]

class AdaptiveBehaviorManager(Action):
    """
    G√®re l'adaptation dynamique du comportement du bot en fonction du contexte et des pr√©f√©rences utilisateur.
    """

    def name(self) -> str:
        return "action_adaptive_behavior_manager"

    def determine_behavior(self, user_profile: Dict[str, Any]) -> str:
        """
        D√©termine le comportement optimal en fonction du profil utilisateur.

        Args:
            user_profile (Dict[str, Any]): Profil utilisateur avec des pr√©f√©rences.

        Returns:
            str: Comportement adapt√© (exemple : "formel", "amical").
        """
        if user_profile.get("interaction_frequency", 0) > 10:
            return "amical"
        elif user_profile.get("feedback_score", 0) < 5:
            return "formel"
        else:
            return "neutre"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Charger le profil utilisateur (peut √™tre aliment√© par des slots ou une base)
        user_profile = tracker.get_slot("user_profile") or {
            "interaction_frequency": 15,
            "feedback_score": 7,
            "preferred_tone": "amical"
        }

        # D√©terminer le comportement appropri√©
        behavior = self.determine_behavior(user_profile)

        # R√©ponse utilisateur selon le comportement
        if behavior == "amical":
            dispatcher.utter_message(text="Salut ! Content de te revoir ! üòä Comment puis-je t‚Äôaider aujourd‚Äôhui ?")
        elif behavior == "formel":
            dispatcher.utter_message(text="Bonjour. Je suis ici pour r√©pondre √† vos questions. Comment puis-je vous aider ?")
        else:
            dispatcher.utter_message(text="Bonjour ! Que puis-je faire pour vous ?")

        # Retourner le comportement pour suivi
        return [SlotSet("user_behavior", behavior)]

class ProactiveEngagementManager(Action):
    """
    Propose des actions ou des suggestions bas√©es sur le comportement et l'historique utilisateur.
    """

    def name(self) -> str:
        return "action_proactive_engagement_manager"

    def generate_proactive_suggestion(self, user_history: Dict[str, Any]) -> str:
        """
        G√©n√®re une suggestion proactive bas√©e sur l'historique utilisateur.

        Args:
            user_history (Dict[str, Any]): Historique des interactions utilisateur.

        Returns:
            str: Suggestion proactive.
        """
        if user_history.get("last_action") == "check_balance":
            return "Souhaitez-vous aussi v√©rifier les transactions r√©centes  ?"
        elif user_history.get("last_action") == "order_pizza":
            return "La derni√®re fois, vous avez command√© une pizza. Voulez-vous la m√™me aujourd‚Äôhui ?"
        else:
            return "Puis-je vous proposer une assistance suppl√©mentaire ?"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Charger l'historique utilisateur (peut √™tre aliment√© par des slots ou une base)
        user_history = tracker.get_slot("user_history") or {
            "last_action": "check_balance",
            "last_interaction": "2024-11-10"
        }

        # G√©n√©rer une suggestion proactive
        suggestion = self.generate_proactive_suggestion(user_history)

        # Envoyer la suggestion
        dispatcher.utter_message(text=suggestion)

        # Retourner une mise √† jour de l'historique (facultatif)
        return [SlotSet("last_suggestion", suggestion)]

class SentimentTrendAnalyzer(Action):
    """
    Analyse les tendances des sentiments des utilisateurs sur une p√©riode donn√©e.
    """

    def name(self) -> str:
        return "action_sentiment_trend_analyzer"

    def calculate_sentiment_trend(self, sentiment_logs: List[int]) -> str:
        """
        Analyse les tendances des sentiments.

        Args:
            sentiment_logs (List[int]): Liste des scores de sentiment sur une p√©riode.

        Returns:
            str: R√©sultat de l'analyse de tendance (positif, n√©gatif, stable).
        """
        if len(sentiment_logs) < 2:
            return "Donn√©es insuffisantes pour analyser les tendances."

        trend = sentiment_logs[-1] - sentiment_logs[0]

        if trend > 0:
            return "positif"
        elif trend < 0:
            return "n√©gatif"
        else:
            return "stable"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de logs de sentiment (peut venir de slots ou d'une base)
        sentiment_logs = tracker.get_slot("sentiment_logs") or [3, 4, 5, 5, 6]

        # Calculer la tendance
        trend = self.calculate_sentiment_trend(sentiment_logs)

        # Pr√©parer une r√©ponse utilisateur
        if trend == "positif":
            response = "Les retours montrent une am√©lioration continue. Merci pour votre confiance ! üòä"
        elif trend == "n√©gatif":
            response = "Les retours indiquent une frustration croissante. Que puis-je faire pour m'am√©liorer  ?"
        else:
            response = "Les retours sont stables. Continuons sur cette lanc√©e."

        dispatcher.utter_message(text=response)

        # Retour facultatif des tendances analys√©es
        return [SlotSet("sentiment_trend", trend)]

class ContextualKnowledgeEnhancer(Action):
    """
    Enrichit les r√©ponses avec des informations contextuelles pertinentes.
    """

    def name(self) -> str:
        return "action_contextual_knowledge_enhancer"

    def enrich_response(self, user_context: Dict[str, Any], base_response: str) -> str:
        """
        Ajoute des informations contextuelles √† une r√©ponse de base.

        Args:
            user_context (Dict[str, Any]): Contexte utilisateur.
            base_response (str): R√©ponse de base.

        Returns:
            str: R√©ponse enrichie.
        """
        # Enrichir en fonction de la langue
        if user_context.get("preferred_language") == "fran√ßais":
            base_response += " (R√©ponse adapt√©e √† votre langue pr√©f√©r√©e : fran√ßais.)"
        elif user_context.get("preferred_language") == "anglais":
            base_response += " (Response adapted to your preferred language: English.)"

        # Ajouter un enrichissement li√© au sujet r√©cent
        recent_topic = user_context.get("recent_topic")
        if recent_topic:
            if recent_topic == "sant√©":
                base_response += " J'ai remarqu√© que vous vous int√©ressez √† la sant√©. Voici quelques conseils pour un mode de vie sain."
            elif recent_topic == "technologie":
                base_response += " Vous semblez int√©ress√© par la technologie. Puis-je vous parler des derni√®res tendances ?"

        # Ajouter une personnalisation avec le nom
        if user_context.get("name"):
            base_response = f"{user_context['name']}, " + base_response

        return base_response

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Exemple de contexte utilisateur (peut √™tre issu de slots ou API)
        user_context = tracker.get_slot("user_context") or {
            "preferred_language": "fran√ßais",
            "recent_topic": "sant√©",
            "name": "Jean"
        }

        # R√©ponse de base
        base_response = "Je suis ici pour vous aider avec toutes vos questions."

        # Enrichir la r√©ponse avec le contexte utilisateur
        enriched_response = self.enrich_response(user_context, base_response)

        # R√©pondre √† l'utilisateur
        dispatcher.utter_message(text=enriched_response)

        # Retourner le contexte mis √† jour (facultatif)
        return []

class MultiUserPriorityBalancer(Action):
    """
    G√®re les priorit√©s entre plusieurs utilisateurs pour r√©partir √©quitablement les ressources.
    """

    def name(self) -> str:
        return "action_multi_user_priority_balancer"

    def allocate_priority(self, users: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Attribue les priorit√©s aux utilisateurs en fonction de leur contexte.

        Args:
            users (List[Dict[str, Any]]): Liste des utilisateurs avec leur contexte.

        Returns:
            List[Dict[str, Any]]: Liste tri√©e par priorit√©.
        """
        return sorted(users, key=lambda x: x.get("priority", 0), reverse=True)

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de liste d'utilisateurs (peut √™tre remplac√© par des donn√©es r√©elles)
        users = tracker.get_slot("user_list") or [
            {"user_id": "user_1", "priority": 10},
            {"user_id": "user_2", "priority": 5},
            {"user_id": "user_3", "priority": 8}
        ]

        # Allouer les priorit√©s
        sorted_users = self.allocate_priority(users)

        # R√©ponse pour l'utilisateur principal
        dispatcher.utter_message(
            text="Voici les priorit√©s actuelles :\n" +
            "\n".join([f"Utilisateur {u['user_id']} - Priorit√© {u['priority']}" for u in sorted_users])
        )

        return []

class PredictiveTaskAssigner(Action):
    """
    Pr√©dit les t√¢ches ou questions futures des utilisateurs pour proposer des solutions proactives.
    """

    def name(self) -> str:
        return "action_predictive_task_assigner"

    def predict_next_task(self, user_history: Dict[str, Any]) -> str:
        """
        Pr√©dit la prochaine t√¢che probable de l'utilisateur.

        Args:
            user_history (Dict[str, Any]): Historique des interactions utilisateur.

        Returns:
            str: T√¢che ou question pr√©dite.
        """
        if user_history.get("last_action") == "check_balance":
            return "v√©rifier les transactions r√©centes"
        elif user_history.get("last_action") == "order_pizza":
            return "suivre la livraison de la commande"
        else:
            return "poser une question g√©n√©rale"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Historique utilisateur (peut √™tre remplac√© par une base ou des slots)
        user_history = tracker.get_slot("user_history") or {
            "last_action": "check_balance"
        }

        # Pr√©dire la prochaine t√¢che
        predicted_task = self.predict_next_task(user_history)

        # R√©ponse utilisateur
        dispatcher.utter_message(
            text=f"Je pr√©vois que vous pourriez vouloir {predicted_task}. Souhaitez-vous que je vous aide ?"
        )

        return []

class DynamicIntentRedirector(Action):
    """
    Redirige dynamiquement les intentions utilisateur vers des services plus pr√©cis.
    """

    def name(self) -> str:
        return "action_dynamic_intent_redirector"

    def map_intent(self, intent: str) -> str:
        """
        Associe une intention g√©n√©rique √† une intention sp√©cifique.

        Args:
            intent (str): Intention d√©tect√©e.

        Returns:
            str: Intention redirig√©e.
        """
        intent_mapping = {
            "help": "provide_support",
            "order": "order_pizza",
            "check": "check_balance",
            "general_question": "faq_general"
        }
        return intent_mapping.get(intent, "fallback")

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer l'intention d√©tect√©e
        detected_intent = tracker.latest_message.get("intent", {}).get("name", "unknown")

        # Rediriger l'intention
        redirected_intent = self.map_intent(detected_intent)

        # R√©ponse utilisateur
        dispatcher.utter_message(
            text=f"Votre demande a √©t√© redirig√©e vers le service correspondant : {redirected_intent}."
        )

        # Retourner l'intention redirig√©e pour suivi
        return [SlotSet("redirected_intent", redirected_intent)]

class EthicalLanguageRefiner(Action):
    """
    Affine le langage utilis√© par le bot pour garantir des r√©ponses √©thiques et adapt√©es.
    """

    def name(self) -> str:
        return "action_ethical_language_refiner"

    def refine_message(self, message: str) -> str:
        """
        Affine une r√©ponse pour garantir son √©thique.

        Args:
            message (str): Message initial.

        Returns:
            str: Message raffin√©.
        """
        # Liste de mots ou expressions √† remplacer
        refinements = {
            "stupide": "mal avis√©",
            "idiot": "peu optimal",
            "probl√®me": "d√©fi"
        }

        refined_message = message
        for word, replacement in refinements.items():
            refined_message = refined_message.replace(word, replacement)

        return refined_message

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer le dernier message g√©n√©r√© par le bot
        bot_message = tracker.get_slot("bot_message") or "Ce choix est stupide et cr√©e un probl√®me."

        # Affiner le message
        refined_message = self.refine_message(bot_message)

        # R√©pondre √† l'utilisateur avec le message raffin√©
        dispatcher.utter_message(text=refined_message)

        # Retourner le message raffin√© pour suivi
        return [SlotSet("refined_message", refined_message)]
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler

# Pipeline pour pr√©paration des donn√©es
pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

# Pr√©paration des donn√©es
X_train_prepared = pipeline.fit_transform(X_train)
X_test_prepared = pipeline.transform(X_test)

# Encodage cibl√©
train['target_mean'] = train.groupby('category')['target'].transform('mean')
test['target_mean'] = test['category'].map(train.groupby('category')['target'].mean())

from lightgbm import LGBMRegressor

# Mod√®le LightGBM
model = LGBMRegressor(n_estimators=1000, learning_rate=0.05, max_depth=10)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

# R√©seau simple
model = Sequential([
    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.2),
    Dense(1, activation='linear')
])

model.compile(optimizer='adam', loss='mse')
model.fit(X_train, y_train, epochs=50, batch_size=32)

from sklearn.model_selection import GridSearchCV

param_grid = {
    'learning_rate': [0.01, 0.05, 0.1],
    'max_depth': [5, 10, 15]
}

grid_search = GridSearchCV(estimator=LGBMRegressor(), param_grid=param_grid, cv=5)
grid_search.fit(X_train, y_train)
print("Best Parameters:", grid_search.best_params_)

from sklearn.ensemble import StackingRegressor

# Stacking
stack = StackingRegressor(estimators=[
    ('xgb', XGBRegressor(n_estimators=500)),
    ('lgbm', LGBMRegressor(n_estimators=500))
], final_estimator=Ridge())

stack.fit(X_train, y_train)
y_pred = stack.predict(X_test)
import pandas as pd

# G√©n√©ration du fichier de soumission
submission = pd.DataFrame({
    'Id': test['Id'],
    'Target': y_pred
})
submission.to_csv('submission.csv', index=False)

from sklearn.model_selection import KFold

kf = KFold(n_splits=5)
for train_index, val_index in kf.split(X):
    X_train, X_val = X[train_index], X[val_index]
    y_train, y_val = y[train_index], y[val_index]
    model.fit(X_train, y_train)
    val_pred = model.predict(X_val)

from transformers import BertTokenizer, TFBertForSequenceClassification

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

tokens = tokenizer(X_train.tolist(), padding=True, truncation=True, return_tensors="tf")
model.fit(tokens['input_ids'], y_train, epochs=3)
from tensorflow.keras.applications import EfficientNetB0

model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

import mlflow

mlflow.start_run()
mlflow.log_param("learning_rate", 0.05)
mlflow.log_metric("accuracy", 0.95)
mlflow.end_run()

class MultiStepActionHandler(Action):
    """
    G√®re les actions n√©cessitant plusieurs √©tapes pour une ex√©cution compl√®te.
    """

    def name(self) -> str:
        return "action_multi_step_action_handler"

    def execute_step(self, step: int) -> str:
        """
        Ex√©cute une √©tape sp√©cifique.

        Args:
            step (int): Num√©ro de l'√©tape.

        Returns:
            str: R√©sultat de l'√©tape.
        """
        steps = {
            1: "√âtape 1 : V√©rification des informations.",
            2: "√âtape 2 : Confirmation des d√©tails.",
            3: "√âtape 3 : Ex√©cution de l'action."
        }
        return steps.get(step, "√âtape inconnue.")

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer l'√©tape actuelle
        current_step = tracker.get_slot("current_step") or 1

        # Ex√©cuter l'√©tape
        step_result = self.execute_step(current_step)

        # Pr√©parer la r√©ponse
        dispatcher.utter_message(text=step_result)

        # Passer √† l'√©tape suivante
        next_step = current_step + 1 if current_step < 3 else None

        return [SlotSet("current_step", next_step)]

class AdvancedInteractionAnalyzer:
    """
    Analyse les interactions utilisateur pour d√©tecter des tendances et des comportements.
    """

    def __init__(self, db_manager):
        """
        Initialise l'analyseur avec un gestionnaire de base de donn√©es.

        Args:
            db_manager: Gestionnaire de base de donn√©es pour r√©cup√©rer les interactions.
        """
        self.db_manager = db_manager
        logger.info("AdvancedInteractionAnalyzer initialized.")

    async def analyze_user_trends(self, user_id: str) -> Dict[str, Any]:
        """
        Analyse les tendances des interactions utilisateur.

        Args:
            user_id (str): ID utilisateur.

        Returns:
            Dict[str, Any]: Tendances d√©tect√©es.
        """
        interactions = await self.db_manager.fetch_interactions(user_id)
        topics = [interaction["metadata"].get("topic") for interaction in interactions if "topic" in interaction["metadata"]]
        topic_counts = Counter(topics)
        logger.info(f"User trends for {user_id}: {topic_counts}")
        return dict(topic_counts)

    async def recommend_actions(self, user_id: str) -> str:
        """
        Recommande une action bas√©e sur les tendances utilisateur.

        Args:
            user_id (str): ID utilisateur.

        Returns:
            str: Recommandation.
        """
        trends = await self.analyze_user_trends(user_id)
        if trends.get("finance", 0) > 5:
            return "Proposer des conseils financiers."
        elif trends.get("health", 0) > 3:
            return "Partager des astuces sant√©."
        return "Aucune recommandation sp√©cifique."

class MultiTenantManager:
    """
    G√®re les donn√©es et configurations pour des utilisateurs ou organisations multiples.
    """

    def __init__(self):
        """
        Initialise le gestionnaire multi-tenant.
        """
        self.tenants = {}
        logger.info("MultiTenantManager initialized.")

    def add_tenant(self, tenant_id: str, config: Dict[str, Any]):
        """
        Ajoute une organisation ou un utilisateur au syst√®me.

        Args:
            tenant_id (str): ID unique de l'organisation/utilisateur.
            config (Dict[str, Any]): Configuration sp√©cifique.
        """
        self.tenants[tenant_id] = config
        logger.info(f"Tenant {tenant_id} added.")

    def get_tenant_config(self, tenant_id: str) -> Optional[Dict[str, Any]]:
        """
        R√©cup√®re la configuration d'une organisation/utilisateur.

        Args:
            tenant_id (str): ID unique.

        Returns:
            Optional[Dict[str, Any]]: Configuration, ou None si non trouv√©.
        """
        return self.tenants.get(tenant_id)

    def list_tenants(self) -> List[str]:
        """
        Liste tous les tenants dans le syst√®me.

        Returns:
            List[str]: Liste des IDs de tenants.
        """
        return list(self.tenants.keys())

class EthicalAIValidator:
    """
    Valide les r√©ponses et actions pour s'assurer qu'elles respectent les normes √©thiques.
    """

    def __init__(self):
        """
        Initialise le validateur √©thique.
        """
        logger.info("EthicalAIValidator initialized.")

    def validate_response(self, response: str) -> bool:
        """
        Valide une r√©ponse.

        Args:
            response (str): R√©ponse √† valider.

        Returns:
            bool: True si la r√©ponse est √©thique, sinon False.
        """
        unethical_phrases = ["offensive", "discriminatory"]
        for phrase in unethical_phrases:
            if phrase in response.lower():
                logger.warning(f"Unethical content detected in response: {response}")
                return False
        return True

    def enforce_policy(self, response: str) -> str:
        """
        Applique des corrections aux r√©ponses non conformes.

        Args:
            response (str): R√©ponse initiale.

        Returns:
            str: R√©ponse corrig√©e.
        """
        if not self.validate_response(response):
            return "Je suis d√©sol√©, je ne peux pas r√©pondre √† cette demande."
        return response



class ActionAnalyzeSentiment(Action):
    def name(self) -> str:
        return "action_analyze_sentiment"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer le message utilisateur
        user_message = tracker.latest_message.get("text")
        if not user_message:
            dispatcher.utter_message(text="Le message est vide ou invalide.")
            return []

        try:
            # Charger un pipeline pr√©-entra√Æn√© pour l'analyse de sentiments
            sentiment_analyzer = pipeline("sentiment-analysis", model="bert-base-uncased-finetuned-sst-2-english")
            sentiment = sentiment_analyzer(user_message)[0]

            # Envoyer le sentiment d√©tect√© et son score de confiance √† l'utilisateur
            dispatcher.utter_message(
                text=f"Sentiment d√©tect√© : {sentiment['label']} (Score : {sentiment['score']:.2f})"
            )

            # Optionnel : stocker le sentiment dans un slot pour un usage futur
            return [SlotSet("sentiment", sentiment["label"])]

        except Exception as e:
            # Loguer l'erreur et informer l'utilisateur
            logger.error(f"Erreur dans l'analyse des sentiments : {e}")
            dispatcher.utter_message(text="Erreur lors de l'analyse des sentiments.")
            return []



class ActionMathOperations(Action):
    def name(self) -> str:
        return "action_math_operations"

    def identify_operation(self, user_message: str) -> str:
        """
        Identifie l'op√©ration math√©matique demand√©e √† partir du message utilisateur.
        """
        operations = {
            "addition": ["plus", "addition"],
            "soustraction": ["moins", "soustraction"],
            "multiplication": ["multiplie", "fois", "multiplication"],
            "division": ["divise", "division"],
            "puissance": ["puissance", "exposant"],
            "modulo": ["modulo"],
            "racine carr√©e": ["racine carr√©e", "sqrt"],
            "logarithme": ["logarithme", "log"],
            "factorielle": ["factorielle"]
        }

        for operation, keywords in operations.items():
            if any(keyword in user_message for keyword in keywords):
                return operation
        return ""

    def perform_operation(self, operation: str, number1: float, number2: float = None) -> str:
        """
        Effectue l'op√©ration math√©matique sp√©cifi√©e.

        Args:
            operation (str): Type d'op√©ration.
            number1 (float): Premier nombre.
            number2 (float, optional): Deuxi√®me nombre.

        Returns:
            str: R√©sultat ou message d'erreur.
        """
        try:
            if operation == "addition":
                return f"{number1 + number2:.2f}"
            elif operation == "soustraction":
                return f"{number1 - number2:.2f}"
            elif operation == "multiplication":
                return f"{number1 * number2:.2f}"
            elif operation == "division":
                if number2 == 0:
                    return "Erreur : division par z√©ro."
                return f"{number1 / number2:.2f}"
            elif operation == "puissance":
                return f"{number1 ** number2:.2f}"
            elif operation == "modulo":
                if number2 == 0:
                    return "Erreur : modulo par z√©ro."
                return f"{number1 % number2:.2f}"
            elif operation == "racine carr√©e":
                if number1 < 0:
                    return "Erreur : racine carr√©e d'un nombre n√©gatif."
                return f"{math.sqrt(number1):.2f}"
            elif operation == "logarithme":
                if number1 <= 0 or (number2 is not None and number2 <= 0):
                    return "Erreur : logarithme d'un nombre n√©gatif ou base invalide."
                base = number2 if number2 else math.e
                return f"{math.log(number1, base):.2f}"
            elif operation == "factorielle":
                if number1 < 0 or not float(number1).is_integer():
                    return "Erreur : factorielle d'un nombre n√©gatif ou non entier."
                return f"{math.factorial(int(number1))}"
            else:
                return "Je n'ai pas compris l'op√©ration demand√©e."
        except Exception as e:
            return f"Une erreur s'est produite lors du calcul : {str(e)}"

    def run(
        self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        # R√©cup√©ration des donn√©es utilisateur
        user_message = tracker.latest_message.get("text", "").lower()
        number1 = tracker.get_slot("number1")
        number2 = tracker.get_slot("number2")

        # V√©rification des donn√©es n√©cessaires
        if number1 is None:
            dispatcher.utter_message(text="Veuillez fournir au moins un nombre pour effectuer le calcul.")
            return []

        # Identifier l'op√©ration
        operation = self.identify_operation(user_message)
        if not operation:
            dispatcher.utter_message(text="Je n'ai pas compris l'op√©ration que vous voulez effectuer.")
            return []

        # Effectuer l'op√©ration
        result = self.perform_operation(operation, number1, number2)

        # Envoyer le r√©sultat
        dispatcher.utter_message(
            text=f"Le r√©sultat de l'op√©ration {operation} est : {result}" if "Erreur" not in result else result
        )

        return []

class PredictiveInsightGenerator(Action):
    def name(self) -> str:
        return "action_predictive_insight_generator"

    def train_model(self) -> LinearRegression:
        """
        Entra√Æne un mod√®le simple de r√©gression lin√©aire.
        Dans une application r√©elle, le mod√®le pourrait √™tre charg√© depuis un fichier pr√©-entra√Æn√©.
        """
        # Exemple de donn√©es fictives
        data = pd.DataFrame({
            "feature_1": [1, 2, 3, 4, 5],
            "feature_2": [10, 20, 30, 40, 50],
            "target": [100, 200, 300, 400, 500]
        })

        # Entra√Æner un mod√®le de r√©gression lin√©aire
        model = LinearRegression()
        model.fit(data[["feature_1", "feature_2"]], data["target"])
        return model

    def validate_features(self, feature_1: Any, feature_2: Any) -> bool:
        """
        Valide les entr√©es utilisateur pour s'assurer qu'elles sont des nombres.
        """
        try:
            float(feature_1)
            float(feature_2)
            return True
        except (TypeError, ValueError):
            return False

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Charger ou entra√Æner le mod√®le
        model = self.train_model()

        # Extraire les donn√©es utilisateur
        feature_1 = tracker.get_slot("feature_1")
        feature_2 = tracker.get_slot("feature_2")

        # Valider les entr√©es utilisateur
        if not self.validate_features(feature_1, feature_2):
            dispatcher.utter_message(text="Les donn√©es fournies ne sont pas valides. Assurez-vous de fournir des nombres.")
            return []

        # Convertir les donn√©es en float
        feature_1 = float(feature_1)
        feature_2 = float(feature_2)

        # Effectuer une pr√©diction
        try:
            prediction = model.predict([[feature_1, feature_2]])[0]
        except Exception as e:
            dispatcher.utter_message(
                text=f"Une erreur est survenue lors de la pr√©diction : {str(e)}."
            )
            return []

        # Retourner la pr√©diction √† l'utilisateur
        dispatcher.utter_message(
            text=f"Bas√© sur vos donn√©es ({feature_1}, {feature_2}), la pr√©diction est : {prediction:.2f}."
        )
        return []

class AnomalyDetector(Action):
    def name(self) -> str:
        return "action_anomaly_detector"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        # Extraire les donn√©es utilisateur √† partir des slots
        raw_data = tracker.get_slot("data_points")

        if not raw_data:
            dispatcher.utter_message(text="Je n'ai pas re√ßu de donn√©es √† analyser. Veuillez fournir vos points de donn√©es.")
            return []

        try:
            # Convertir les donn√©es utilisateur en liste
            data = np.array(ast.literal_eval(raw_data))  # Exemple : "[[10, 20], [12, 21], [1000, 2000]]"
            if data.ndim == 1:  # Si les donn√©es sont 1D, les transformer en 2D
                data = data.reshape(-1, 1)

            # Appliquer Isolation Forest pour d√©tecter les anomalies
            model = IsolationForest(contamination=0.1, random_state=42)
            predictions = model.fit_predict(data)

            # Identifier les anomalies
            anomalies = data[predictions == -1]
            anomalies_list = anomalies.tolist()

            if len(anomalies_list) == 0:
                dispatcher.utter_message(text="Aucune anomalie n'a √©t√© d√©tect√©e dans vos donn√©es.")
            else:
                dispatcher.utter_message(
                    text=f"J'ai d√©tect√© des anomalies dans vos donn√©es : {anomalies_list}"
                )

        except Exception as e:
            dispatcher.utter_message(
                text=f"Une erreur s'est produite lors de l'analyse des anomalies : {str(e)}"
            )

        return []


class StatisticalSummaryGenerator(Action):
    def name(self) -> str:
        return "action_statistical_summary_generator"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Extraire les donn√©es utilisateur
        raw_data = tracker.get_slot("numeric_data")

        if not raw_data:
            dispatcher.utter_message(
                text="Je n'ai pas re√ßu de donn√©es √† analyser. Veuillez fournir une liste de nombres.")
            return []

        try:
            # Convertir les donn√©es utilisateur en une liste de nombres
            data = np.array(ast.literal_eval(raw_data))  # Exemple : "[10, 12, 23, 23, 17, 19, 23, 29, 31]"

            # V√©rifier si les donn√©es sont valides
            if data.size == 0:
                dispatcher.utter_message(
                    text="Les donn√©es fournies sont vides. Veuillez fournir une liste valide de nombres.")
                return []

            if not np.issubdtype(data.dtype, np.number):
                dispatcher.utter_message(text="Les donn√©es doivent √™tre num√©riques. Veuillez r√©essayer.")
                return []

            # Calculer les statistiques descriptives
            mean = np.mean(data)
            median = np.median(data)
            std_dev = np.std(data)
            quartiles = np.percentile(data, [25, 50, 75])
            min_val = np.min(data)
            max_val = np.max(data)

            # Identifier les valeurs aberrantes (par m√©thode des IQR)
            q1, q3 = quartiles[0], quartiles[2]
            iqr = q3 - q1
            lower_bound = q1 - 1.5 * iqr
            upper_bound = q3 + 1.5 * iqr
            outliers = data[(data < lower_bound) | (data > upper_bound)]

            # G√©n√©rer une visualisation des donn√©es
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "statistical_summary_visualization.png")

            plt.figure(figsize=(8, 5))
            plt.boxplot(data, vert=False, patch_artist=True, boxprops=dict(facecolor="lightblue"))
            plt.title("Distribution des donn√©es")
            plt.xlabel("Valeurs")
            plt.savefig(file_path)
            plt.close()

            # Construire la r√©ponse
            summary = (
                f"Voici les statistiques des donn√©es fournies :\n"
                f"- Moyenne : {mean:.2f}\n"
                f"- M√©diane : {median:.2f}\n"
                f"- √âcart-type : {std_dev:.2f}\n"
                f"- Min : {min_val}, Max : {max_val}\n"
                f"- Quartiles : Q1={quartiles[0]}, Q2={quartiles[1]}, Q3={quartiles[2]}\n"
            )

            if len(outliers) > 0:
                summary += f"- Valeurs aberrantes d√©tect√©es : {list(outliers)}\n"
            else:
                summary += "- Aucune valeur aberrante d√©tect√©e.\n"

            dispatcher.utter_message(text=summary)
            dispatcher.utter_message(
                text=f"Une visualisation de la distribution a √©t√© g√©n√©r√©e et sauvegard√©e : {file_path}")

        except ValueError as ve:
            dispatcher.utter_message(
                text=f"Les donn√©es fournies ne sont pas valides. Veuillez fournir une liste de nombres. D√©tail : {str(ve)}")
        except Exception as e:
            dispatcher.utter_message(text=f"Une erreur s'est produite lors de l'analyse des donn√©es : {str(e)}")

        return []

class ClusterVisualizer(Action):
    def name(self) -> str:
        return "action_cluster_visualizer"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Extraire les donn√©es utilisateur
        raw_data = tracker.get_slot("clustering_data")
        n_clusters = tracker.get_slot("n_clusters") or 2  # Nombre de clusters par d√©faut : 2

        if not raw_data:
            dispatcher.utter_message(text="Je n'ai pas re√ßu de donn√©es √† analyser. Veuillez fournir une liste de points.")
            return []

        try:
            # Convertir les donn√©es utilisateur en un tableau numpy
            data = np.array(ast.literal_eval(raw_data))  # Exemple : "[[1, 2], [2, 3], [8, 9], [10, 11]]"

            # V√©rifier si les donn√©es sont valides
            if data.ndim != 2 or data.shape[0] < n_clusters:
                dispatcher.utter_message(text="Les donn√©es doivent √™tre une liste de points avec au moins autant de points que de clusters.")
                return []

            # R√©duction des dimensions si n√©cessaire
            if data.shape[1] > 2:
                dispatcher.utter_message(text="R√©duction des dimensions pour visualiser les clusters...")
                reducer = PCA(n_components=2)
                reduced_data = reducer.fit_transform(data)
            else:
                reduced_data = data

            # Appliquer KMeans pour le clustering
            n_clusters = int(n_clusters)
            model = KMeans(n_clusters=n_clusters, random_state=42)
            labels = model.fit_predict(reduced_data)

            # G√©n√©rer un graphique des clusters
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "cluster_visualization.png")

            plt.figure(figsize=(8, 6))
            plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=labels, cmap="viridis", s=50, alpha=0.8)
            plt.title(f"Clustering avec {n_clusters} clusters")
            plt.xlabel("Dimension 1")
            plt.ylabel("Dimension 2")
            plt.colorbar(label="Cluster")
            plt.savefig(file_path)
            plt.close()

            # Construire la r√©ponse
            dispatcher.utter_message(
                text=f"Clustering effectu√© avec succ√®s‚ÄØ! Les donn√©es ont √©t√© regroup√©es en {n_clusters} clusters."
            )
            dispatcher.utter_message(
                text=f"Un graphique des clusters a √©t√© g√©n√©r√© et sauvegard√© : {file_path}"
            )

        except ValueError as ve:
            dispatcher.utter_message(text=f"Erreur dans les donn√©es fournies : {str(ve)}")
        except Exception as e:
            dispatcher.utter_message(
                text=f"Une erreur s'est produite lors du clustering : {str(e)}"
            )

        return []

class AdvancedDataInsightGenerator(Action):
    def name(self) -> str:
        return "action_advanced_data_insight_generator"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # R√©cup√©rer les donn√©es utilisateur
        numeric_data = tracker.get_slot("numeric_data")
        data_series = tracker.get_slot("data_series")
        analysis_type = tracker.get_slot("analysis_type")

        # Analyse Statistique
        if analysis_type == "statistique" and numeric_data:
            return self.analyze_statistics(numeric_data, dispatcher)

        # Pr√©visions temporelles
        elif analysis_type == "pr√©vision" and data_series:
            return self.forecast_time_series(data_series, dispatcher)

        # D√©tection des anomalies
        elif analysis_type == "anomalie" and numeric_data:
            return self.detect_anomalies(numeric_data, dispatcher)

        # Si aucun cas ne correspond
        dispatcher.utter_message(
            text="Je n'ai pas compris votre demande ou les donn√©es sont manquantes. Veuillez r√©essayer."
        )
        return []

    def analyze_statistics(self, numeric_data: str, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Analyse statistique des donn√©es num√©riques."""
        try:
            data = np.array(ast.literal_eval(numeric_data))

            if data.size == 0:
                dispatcher.utter_message(text="Les donn√©es fournies sont vides. Veuillez fournir une liste de nombres.")
                return []

            # Calcul des statistiques descriptives
            mean = np.mean(data)
            median = np.median(data)
            std_dev = np.std(data)
            variance = np.var(data)
            min_val = np.min(data)
            max_val = np.max(data)
            quartiles = np.percentile(data, [25, 50, 75])

            # R√©sum√© des statistiques
            summary = (
                f"Voici les statistiques des donn√©es fournies :\n"
                f"- Moyenne : {mean:.2f}\n"
                f"- M√©diane : {median:.2f}\n"
                f"- √âcart-type : {std_dev:.2f}\n"
                f"- Variance : {variance:.2f}\n"
                f"- Min : {min_val}, Max : {max_val}\n"
                f"- Quartiles : Q1={quartiles[0]}, Q2={quartiles[1]}, Q3={quartiles[2]}\n"
            )

            # G√©n√©rer un graphique
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "statistics_visualization.png")
            plt.figure(figsize=(8, 5))
            plt.boxplot(data, vert=False, patch_artist=True, boxprops=dict(facecolor="lightblue"))
            plt.title("Distribution des donn√©es")
            plt.xlabel("Valeurs")
            plt.savefig(file_path)
            plt.close()

            dispatcher.utter_message(text=summary)
            dispatcher.utter_message(
                text=f"Un graphique illustrant la distribution des donn√©es a √©t√© sauvegard√© : {file_path}"
            )

        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de l'analyse statistique : {str(e)}")

        return []

    def forecast_time_series(self, data_series: str, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Pr√©vision de s√©ries temporelles."""
        try:
            # Convertir les donn√©es utilisateur en DataFrame
            data = pd.DataFrame(ast.literal_eval(data_series), columns=["ds", "y"])
            data["ds"] = pd.to_datetime(data["ds"])

            # Construire le mod√®le Prophet
            model = Prophet()
            model.fit(data)

            # Faire une pr√©diction pour les 7 prochains jours
            future = model.make_future_dataframe(periods=7)
            forecast = model.predict(future)

            # Extraire les pr√©visions
            predictions = forecast[["ds", "yhat"]].tail(7)

            # G√©n√©rer un graphique
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "forecast_visualization.png")
            fig = model.plot(forecast)
            plt.title("Pr√©visions pour les 7 prochains jours")
            plt.savefig(file_path)
            plt.close()

            dispatcher.utter_message(text=f"Voici les pr√©visions pour les 7 prochains jours :\n{predictions.to_string(index=False)}")
            dispatcher.utter_message(
                text=f"Un graphique des pr√©visions a √©t√© g√©n√©r√© et sauvegard√© : {file_path}"
            )

        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de la pr√©vision des s√©ries temporelles : {str(e)}")

        return []

    def detect_anomalies(self, numeric_data: str, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """D√©tection des anomalies dans les donn√©es num√©riques."""
        try:
            data = np.array(ast.literal_eval(numeric_data))

            if data.size == 0:
                dispatcher.utter_message(text="Les donn√©es fournies sont vides. Veuillez fournir une liste de nombres.")
                return []

            # Appliquer Isolation Forest pour d√©tecter les anomalies
            model = IsolationForest(contamination=0.1, random_state=42)
            predictions = model.fit_predict(data.reshape(-1, 1))

            # Identifier les anomalies
            anomalies = data[predictions == -1]
            anomalies_list = anomalies.tolist()

            if len(anomalies_list) == 0:
                dispatcher.utter_message(text="Aucune anomalie d√©tect√©e dans vos donn√©es.")
            else:
                dispatcher.utter_message(text=f"Anomalies d√©tect√©es : {anomalies_list}")

            # G√©n√©rer un graphique
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "anomaly_detection.png")
            plt.figure(figsize=(8, 5))
            plt.scatter(range(len(data)), data, c=(predictions == -1), cmap="coolwarm", s=50)
            plt.title("D√©tection des anomalies")
            plt.xlabel("Index")
            plt.ylabel("Valeur")
            plt.savefig(file_path)
            plt.close()

            dispatcher.utter_message(
                text=f"Un graphique des anomalies d√©tect√©es a √©t√© sauvegard√© : {file_path}"
            )

        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de la d√©tection des anomalies : {str(e)}")

        return []

class FeatureImportanceExplainer(Action):
    def name(self) -> str:
        return "action_feature_importance_explainer"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # R√©cup√©rer les donn√©es utilisateur
        raw_data = tracker.get_slot("input_features")
        target_variable = tracker.get_slot("target_variable")
        model_type = tracker.get_slot("model_type") or "random_forest"

        if not raw_data or not target_variable:
            dispatcher.utter_message(text="Je n'ai pas re√ßu de donn√©es suffisantes pour effectuer l'analyse. Fournissez les caract√©ristiques et la variable cible.")
            return []

        try:
            # Convertir les donn√©es utilisateur en DataFrame
            data = pd.DataFrame(ast.literal_eval(raw_data))

            if target_variable not in data.columns:
                dispatcher.utter_message(text=f"La variable cible '{target_variable}' n'est pas pr√©sente dans les donn√©es fournies.")
                return []

            features = data.drop(columns=[target_variable])
            target = data[target_variable]

            # V√©rifier qu'il y a au moins deux colonnes
            if features.shape[1] < 1:
                dispatcher.utter_message(text="Les donn√©es doivent contenir au moins une caract√©ristique pour effectuer l'analyse.")
                return []

            # Construire le mod√®le
            if model_type == "linear_regression":
                model = LinearRegression()
            elif model_type == "random_forest":
                model = RandomForestRegressor(random_state=42)
            else:
                dispatcher.utter_message(text=f"Mod√®le '{model_type}' non pris en charge. Utilisez 'linear_regression' ou 'random_forest'.")
                return []

            model.fit(features, target)

            # Appliquer SHAP pour expliquer les pr√©dictions
            explainer = shap.Explainer(model, features)
            shap_values = explainer(features)

            # Cr√©er un r√©pertoire pour sauvegarder les visualisations
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)

            # G√©n√©rer des graphiques SHAP
            bar_plot_path = os.path.join(output_dir, "feature_importance_bar.png")
            summary_plot_path = os.path.join(output_dir, "feature_importance_summary.png")

            shap.summary_plot(shap_values, features, plot_type="bar", show=False)
            plt.savefig(bar_plot_path)
            plt.close()

            shap.summary_plot(shap_values, features, show=False)
            plt.savefig(summary_plot_path)
            plt.close()

            # R√©sum√© des explications
            feature_importance = pd.DataFrame({
                "Feature": features.columns,
                "Importance": np.abs(shap_values.values).mean(axis=0)
            }).sort_values(by="Importance", ascending=False)

            summary = (
                f"Analyse termin√©e ! Voici les caract√©ristiques les plus importantes pour pr√©dire '{target_variable}' :\n"
                f"{feature_importance.head(5).to_string(index=False)}\n\n"
                f"Deux graphiques ont √©t√© g√©n√©r√©s pour explorer plus en d√©tail :\n"
                f"- '{bar_plot_path}' : Importances moyennes des variables.\n"
                f"- '{summary_plot_path}' : Distribution des impacts SHAP sur les pr√©dictions."
            )

            dispatcher.utter_message(text=summary)

        except ValueError as ve:
            dispatcher.utter_message(text=f"Erreur dans les donn√©es fournies : {str(ve)}")
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de l'analyse des caract√©ristiques : {str(e)}")

        return []

class UltimateDataAnalyzer(Action):
    def name(self) -> str:
        return "action_ultimate_data_analyzer"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Extraire les donn√©es utilisateur
        data_input = tracker.get_slot("data_input")
        analysis_goal = tracker.get_slot("analysis_goal") or "exploration"
        prediction_target = tracker.get_slot("prediction_target")
        model_type = tracker.get_slot("model_type") or "random_forest"

        if not data_input:
            dispatcher.utter_message(text="Je n'ai pas re√ßu de donn√©es √† analyser. Veuillez fournir vos donn√©es.")
            return []

        try:
            # Convertir les donn√©es utilisateur
            data = pd.DataFrame(ast.literal_eval(data_input))

            # V√©rifier l'objectif de l'analyse
            if analysis_goal == "exploration":
                return self.perform_eda(data, dispatcher)
            elif analysis_goal == "anomalie":
                return self.detect_anomalies(data, dispatcher)
            elif analysis_goal == "pr√©vision" and {"ds", "y"}.issubset(data.columns):
                return self.forecast_time_series(data, dispatcher)
            elif analysis_goal == "pr√©diction" and prediction_target:
                return self.predict_with_explanation(data, prediction_target, model_type, dispatcher)
            else:
                dispatcher.utter_message(text="Je n'ai pas compris votre demande. Veuillez pr√©ciser votre objectif.")
                return []

        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors du traitement : {str(e)}")
            return []

    def perform_eda(self, data: pd.DataFrame, dispatcher: CollectingDispatcher):
        """Analyse exploratoire des donn√©es."""
        try:
            description = data.describe().to_string()
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "pairplot.png")

            sns.pairplot(data)
            plt.savefig(file_path)
            plt.close()

            dispatcher.utter_message(
                text=f"Analyse exploratoire effectu√©e. Voici un r√©sum√© :\n{description}\nUn graphique des relations a √©t√© sauvegard√© sous '{file_path}'."
            )
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de l'analyse exploratoire : {str(e)}")
        return []

    def detect_anomalies(self, data: pd.DataFrame, dispatcher: CollectingDispatcher):
        """D√©tection des anomalies avec Isolation Forest."""
        try:
            reshaped_data = data.values.reshape(-1, 1) if data.shape[1] == 1 else data.values
            model = IsolationForest(contamination=0.1, random_state=42)
            predictions = model.fit_predict(reshaped_data)
            anomalies = data[predictions == -1]

            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "anomalies.png")

            sns.scatterplot(x=data.index, y=data.values[:, 0], hue=predictions, palette="coolwarm", s=50)
            plt.title("D√©tection des anomalies")
            plt.savefig(file_path)
            plt.close()

            if anomalies.empty:
                dispatcher.utter_message(text="Aucune anomalie d√©tect√©e.")
            else:
                dispatcher.utter_message(
                    text=f"Anomalies d√©tect√©es :\n{anomalies.to_string()}\nUn graphique a √©t√© sauvegard√© sous '{file_path}'."
                )
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de la d√©tection des anomalies : {str(e)}")
        return []

    def forecast_time_series(self, data: pd.DataFrame, dispatcher: CollectingDispatcher):
        """Pr√©visions temporelles avec Prophet."""
        try:
            model = Prophet()
            model.fit(data)
            future = model.make_future_dataframe(periods=7)
            forecast = model.predict(future)

            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "forecast.png")

            fig = model.plot(forecast)
            plt.title("Pr√©visions pour les 7 prochains jours")
            plt.savefig(file_path)
            plt.close()

            dispatcher.utter_message(
                text=f"Pr√©visions effectu√©es. Un graphique des pr√©visions a √©t√© sauvegard√© sous '{file_path}'."
            )
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de la pr√©vision des s√©ries temporelles : {str(e)}")
        return []

    def predict_with_explanation(self, data: pd.DataFrame, target: str, model_type: str, dispatcher: CollectingDispatcher):
        """Pr√©dictions avec explicabilit√© (SHAP)."""
        try:
            features = data.drop(columns=[target])
            target_data = data[target]

            if model_type == "random_forest":
                model = RandomForestRegressor(random_state=42)
            elif model_type == "linear_regression":
                model = LinearRegression()
            else:
                dispatcher.utter_message(text=f"Mod√®le {model_type} non pris en charge.")
                return []

            model.fit(features, target_data)

            explainer = shap.Explainer(model, features)
            shap_values = explainer(features)

            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "shap_bar.png")

            shap.summary_plot(shap_values, features, plot_type="bar", show=False)
            plt.savefig(file_path)
            plt.close()

            dispatcher.utter_message(
                text=f"Pr√©dictions et analyse des caract√©ristiques effectu√©es. Un graphique explicatif a √©t√© sauvegard√© sous '{file_path}'."
            )
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de l'analyse des caract√©ristiques : {str(e)}")
        return []

class AutomatedDataPipeline(Action):
    def name(self) -> str:
        return "action_automated_data_pipeline"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # R√©cup√©rer les donn√©es utilisateur
        pipeline_data = tracker.get_slot("pipeline_data")
        target_variable = tracker.get_slot("target_variable")
        analysis_goal = tracker.get_slot("analysis_goal")
        export_format = tracker.get_slot("export_format") or "PDF"

        if not pipeline_data:
            dispatcher.utter_message(text="Je n'ai pas re√ßu de donn√©es pour le pipeline. Veuillez fournir vos donn√©es.")
            return []

        try:
            # Convertir les donn√©es utilisateur
            data = pd.DataFrame(ast.literal_eval(pipeline_data))

            # Cr√©er un r√©pertoire pour les visualisations
            output_dir = "pipeline_visualizations"
            os.makedirs(output_dir, exist_ok=True)

            # √âtape 1 : Analyse exploratoire
            self.perform_eda(data, output_dir)

            # √âtape 2 : D√©tection des anomalies
            anomalies = self.detect_anomalies(data, output_dir)

            # √âtape 3 : Pr√©dictions ou pr√©visions
            predictions = None
            if analysis_goal == "pr√©vision" and {"ds", "y"}.issubset(data.columns):
                predictions = self.forecast_time_series(data, output_dir)
            elif analysis_goal == "pr√©diction" and target_variable:
                predictions = self.predict_with_explanation(data, target_variable, output_dir)

            # √âtape 4 : G√©n√©rer un rapport
            report_path = self.generate_report(data, anomalies, predictions, export_format, output_dir)

            dispatcher.utter_message(
                text=f"Pipeline termin√© avec succ√®s ! Le rapport consolid√© a √©t√© g√©n√©r√© : {report_path}"
            )
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors du pipeline : {str(e)}")
        return []

    def perform_eda(self, data: pd.DataFrame, output_dir: str):
        """Analyse exploratoire des donn√©es."""
        try:
            sns.pairplot(data)
            eda_path = os.path.join(output_dir, "pairplot.png")
            plt.savefig(eda_path)
            plt.close()
        except Exception as e:
            print(f"Erreur dans l'analyse exploratoire : {str(e)}")

    def detect_anomalies(self, data: pd.DataFrame, output_dir: str):
        """D√©tection des anomalies avec Isolation Forest."""
        try:
            model = IsolationForest(contamination=0.1, random_state=42)
            predictions = model.fit_predict(data.values)
            anomalies = data[predictions == -1]

            anomaly_path = os.path.join(output_dir, "anomalies.png")
            sns.scatterplot(x=range(len(data)), y=data.values[:, 0], hue=predictions, palette="coolwarm", s=50)
            plt.savefig(anomaly_path)
            plt.close()
            return anomalies
        except Exception as e:
            print(f"Erreur lors de la d√©tection des anomalies : {str(e)}")
            return None

    def forecast_time_series(self, data: pd.DataFrame, output_dir: str):
        """Pr√©visions temporelles avec Prophet."""
        try:
            model = Prophet()
            model.fit(data)
            future = model.make_future_dataframe(periods=7)
            forecast = model.predict(future)

            forecast_path = os.path.join(output_dir, "forecast.png")
            model.plot(forecast)
            plt.savefig(forecast_path)
            plt.close()
            return forecast[["ds", "yhat"]].tail(7)
        except Exception as e:
            print(f"Erreur dans les pr√©visions temporelles : {str(e)}")
            return None

    def predict_with_explanation(self, data: pd.DataFrame, target: str, output_dir: str):
        """Pr√©dictions avec explicabilit√© (SHAP)."""
        try:
            features = data.drop(columns=[target])
            target_data = data[target]
            model = RandomForestRegressor(random_state=42)
            model.fit(features, target_data)
            explainer = shap.Explainer(model, features)
            shap_values = explainer(features)

            shap_path = os.path.join(output_dir, "shap_bar.png")
            shap.summary_plot(shap_values, features, plot_type="bar", show=False)
            plt.savefig(shap_path)
            plt.close()
            return shap_values
        except Exception as e:
            print(f"Erreur dans les pr√©dictions explicables : {str(e)}")
            return None

    def generate_report(self, data, anomalies, predictions, export_format, output_dir):
        """G√©n√©rer un rapport consolid√©."""
        try:
            if export_format.lower() == "pdf":
                pdf = FPDF()
                pdf.add_page()
                pdf.set_font("Arial", size=12)

                pdf.cell(200, 10, txt="Rapport Consolid√©", ln=True, align="C")
                pdf.ln(10)

                # Section 1 : Analyse exploratoire
                pdf.cell(200, 10, txt="1. Analyse Exploratoire", ln=True)
                eda_path = os.path.join(output_dir, "pairplot.png")
                pdf.image(eda_path, x=10, y=40, w=180)

                # Section 2 : D√©tection des anomalies
                pdf.add_page()
                pdf.cell(200, 10, txt="2. D√©tection des Anomalies", ln=True)
                anomaly_path = os.path.join(output_dir, "anomalies.png")
                pdf.image(anomaly_path, x=10, y=40, w=180)

                # Section 3 : Pr√©dictions
                if predictions is not None:
                    pdf.add_page()
                    pdf.cell(200, 10, txt="3. Pr√©dictions", ln=True)
                    forecast_path = os.path.join(output_dir, "forecast.png")
                    pdf.image(forecast_path, x=10, y=40, w=180)

                # Sauvegarder le fichier PDF
                report_path = os.path.join(output_dir, "pipeline_report.pdf")
                pdf.output(report_path)
                return report_path

            # Formats CSV ou autres peuvent √™tre ajout√©s ici
        except Exception as e:
            print(f"Erreur lors de la g√©n√©ration du rapport : {str(e)}")
            return None

class LanguageProcessor:
    """
    G√®re la d√©tection, la traduction et la gestion multilingue.
    """

    def __init__(self, target_language: str = "en"):
        """
        Initialise le gestionnaire multilingue.

        Args:
            target_language (str): Langue cible pour la traduction.
        """
        self.translator = Translator()
        self.target_language = target_language

    def detect_language(self, text: str) -> str:
        """
        D√©tecte la langue d'un texte.

        Args:
            text (str): Texte brut.

        Returns:
            str: Code ISO de la langue d√©tect√©e.
        """
        try:
            return self.translator.detect(text).lang
        except Exception as e:
            return "unknown"

    def translate_to_target(self, text: str, source_language: str = None) -> str:
        """
        Traduit un texte vers la langue cible.

        Args:
            text (str): Texte brut.
            source_language (str): Langue source (optionnel).

        Returns:
            str: Texte traduit.
        """
        try:
            translated = self.translator.translate(text, src=source_language, dest=self.target_language)
            return translated.text
        except Exception as e:
            return text

    def process(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """
        Traduit une requ√™te compl√®te dans la langue cible.

        Args:
            request (Dict[str, Any]): Requ√™te utilisateur.

        Returns:
            Dict[str, Any]: Requ√™te trait√©e.
        """
        if "text" in request:
            source_language = self.detect_language(request["text"])
            request["text"] = self.translate_to_target(request["text"], source_language)
            request["source_language"] = source_language
        return request

class TestSuite:
    """
    Suite de tests pour valider les actions et pipelines.
    """

    def __init__(self, orchestrator, test_cases: List[Dict[str, Any]]):
        """
        Initialise la suite de tests.

        Args:
            orchestrator: Orchestrateur global √† tester.
            test_cases (List[Dict[str, Any]]): Cas de test.
        """
        self.orchestrator = orchestrator
        self.test_cases = test_cases

    def run_tests(self) -> Dict[str, Any]:
        """
        Ex√©cute tous les tests et retourne les r√©sultats.

        Returns:
            Dict[str, Any]: R√©sultats des tests.
        """
        results = {}
        for idx, test_case in enumerate(self.test_cases):
            try:
                response = self.orchestrator.process_request(test_case["input"])
                results[f"Test {idx + 1}"] = {
                    "input": test_case["input"],
                    "expected_output": test_case["expected_output"],
                    "actual_output": response,
                    "success": response == test_case["expected_output"],
                }
            except Exception as e:
                results[f"Test {idx + 1}"] = {"error": str(e), "success": False}
        return results
class PipelineOrchestrator:
    """
    Orchestration des pipelines utilisateur, actions et r√©sultats.
    """

    def __init__(self, actions: Dict[str, Any], cache_manager=None, language_processor=None):
        """
        Initialise l'orchestrateur.

        Args:
            actions (Dict[str, Any]): Actions disponibles dans le syst√®me.
            cache_manager: Gestionnaire de cache pour optimiser les appels.
            language_processor: Gestionnaire multilingue (optionnel).
        """
        self.actions = actions
        self.cache_manager = cache_manager
        self.language_processor = language_processor

    def process_request(self, user_request: Dict[str, Any]) -> Dict[str, Any]:
        """
        G√®re une requ√™te utilisateur.

        Args:
            user_request (Dict[str, Any]): D√©tails de la requ√™te utilisateur.

        Returns:
            Dict[str, Any]: R√©sultats de la requ√™te.
        """
        try:
            action_name = user_request.get("action")
            if not action_name or action_name not in self.actions:
                raise ValueError(f"Action inconnue : {action_name}")

            # Gestion du cache si activ√©
            cache_key = f"user_{user_request['user_id']}_action_{action_name}"
            if self.cache_manager:
                cached_result = self.cache_manager.get(cache_key)
                if cached_result:
                    return cached_result

            # Pr√©traitement multilingue
            if self.language_processor:
                user_request = self.language_processor.process(user_request)

            # Appel de l'action demand√©e
            result = self.actions[action_name].run(user_request)

            # Sauvegarde dans le cache
            if self.cache_manager:
                self.cache_manager.set(cache_key, result)

            return result
        except Exception as e:
            return {"error": f"Erreur lors du traitement de la requ√™te : {e}"}

class DynamicPipelineOrchestrator(Action):
    def name(self) -> str:
        return "action_dynamic_pipeline_orchestrator"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        raw_data = tracker.get_slot("raw_data")
        auto_detect = tracker.get_slot("auto_detect") or True

        if not raw_data:
            dispatcher.utter_message(text="Aucune donn√©e fournie. Veuillez fournir vos donn√©es.")
            return []

        try:
            # Convertir les donn√©es utilisateur
            data = pd.DataFrame(ast.literal_eval(raw_data))

            # √âtape 1 : D√©tection automatique des donn√©es
            if auto_detect:
                analysis_plan = self.auto_detect_pipeline(data)
                dispatcher.utter_message(text=f"Pipeline d√©tect√© automatiquement : {analysis_plan}")

            # √âtape 2 : Ex√©cution des √©tapes du pipeline
            results = self.execute_pipeline(data, analysis_plan)
            dispatcher.utter_message(text=f"Pipeline termin√© avec succ√®s. R√©sultats : {results}")

        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors du pipeline dynamique : {str(e)}")
        return []

    def auto_detect_pipeline(self, data: pd.DataFrame) -> dict:
        """D√©tecte automatiquement les besoins en fonction des donn√©es."""
        plan = {}
        if "ds" in data.columns and "y" in data.columns:
            plan["step"] = "forecast"
        elif data.dtypes.value_counts().get("object", 0) > 0:
            plan["step"] = "categorical_analysis"
        elif data.select_dtypes(include=["number"]).shape[1] > 0:
            plan["step"] = "numerical_analysis"
        else:
            plan["step"] = "unsupervised_analysis"
        return plan

    def execute_pipeline(self, data: pd.DataFrame, plan: dict) -> dict:
        """Ex√©cute les √©tapes du pipeline en fonction du plan."""
        if plan["step"] == "forecast":
            return self.forecast_time_series(data)
        elif plan["step"] == "categorical_analysis":
            return self.analyze_categorical(data)
        elif plan["step"] == "numerical_analysis":
            return self.analyze_numerical(data)
        elif plan["step"] == "unsupervised_analysis":
            return self.unsupervised_clustering(data)
        return {"error": "Plan non reconnu."}

    def forecast_time_series(self, data: pd.DataFrame) -> dict:
        """Pr√©visions temporelles."""
        model = Prophet()
        model.fit(data)
        future = model.make_future_dataframe(periods=7)
        forecast = model.predict(future)
        return forecast[["ds", "yhat"]].tail(7).to_dict()

    def analyze_categorical(self, data: pd.DataFrame) -> dict:
        """Analyse des donn√©es cat√©goriques."""
        encoded_data = {}
        for col in data.select_dtypes(include=["object"]).columns:
            encoder = LabelEncoder()
            encoded_data[col] = encoder.fit_transform(data[col]).tolist()
        return encoded_data

    def analyze_numerical(self, data: pd.DataFrame) -> dict:
        """Analyse des donn√©es num√©riques."""
        summary = data.describe().to_dict()
        scaler = StandardScaler()
        scaled_data = scaler.fit_transform(data.select_dtypes(include=["number"]))
        return {"summary": summary, "scaled_data": scaled_data.tolist()}

    def unsupervised_clustering(self, data: pd.DataFrame) -> dict:
        """Clustering non supervis√©."""
        from sklearn.cluster import KMeans
        model = KMeans(n_clusters=3, random_state=42)
        clusters = model.fit_predict(data)
        return {"clusters": clusters.tolist()}
    
class IntelligentPipelineManager(Action):
    def name(self) -> str:
        return "action_intelligent_pipeline_manager"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Extraire les √©tapes du pipeline
        pipeline_steps = tracker.get_slot("pipeline_steps") or []
        user_feedback = tracker.get_slot("user_feedback")

        # Si l'utilisateur donne un feedback
        if user_feedback:
            pipeline_steps = self.modify_pipeline(pipeline_steps, user_feedback)
            dispatcher.utter_message(text=f"Pipeline mis √† jour : {pipeline_steps}")
            return []

        # Si le pipeline est vide, recommander des √©tapes
        if not pipeline_steps:
            recommended_steps = self.recommend_pipeline_steps(tracker)
            dispatcher.utter_message(
                text=f"Voici les √©tapes recommand√©es pour vos donn√©es : {recommended_steps}\n"
                     f"Souhaitez-vous les modifier ?"
            )
            return []

        # Ex√©cuter le pipeline
        try:
            results = self.execute_pipeline(pipeline_steps, tracker)
            dispatcher.utter_message(text=f"Pipeline ex√©cut√© avec succ√®s. R√©sultats consolid√©s : {results}")
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de l'ex√©cution du pipeline : {str(e)}")

        return []

    def recommend_pipeline_steps(self, tracker: Tracker) -> List[str]:
        """Recommande des √©tapes en fonction des donn√©es utilisateur."""
        raw_data = tracker.get_slot("raw_data")
        if not raw_data:
            return ["collect_data"]
        try:
            data = pd.DataFrame(ast.literal_eval(raw_data))
            steps = []
            if {"ds", "y"}.issubset(data.columns):
                steps.append("forecast_time_series")
            if data.select_dtypes(include=["number"]).shape[1] > 0:
                steps.extend(["detect_anomalies", "analyze_numerical"])
            if data.select_dtypes(include=["object"]).shape[1] > 0:
                steps.append("analyze_categorical")
            return steps
        except Exception:
            return ["collect_data"]

    def modify_pipeline(self, steps: List[str], feedback: str) -> List[str]:
        """Modifie le pipeline selon les retours utilisateur."""
        if "ajoute" in feedback or "ajouter" in feedback:
            if "anomalie" in feedback:
                steps.append("detect_anomalies")
            if "pr√©vision" in feedback:
                steps.append("forecast_time_series")
        elif "supprime" in feedback or "retire" in feedback:
            if "anomalie" in feedback:
                steps = [step for step in steps if step != "detect_anomalies"]
            if "pr√©vision" in feedback:
                steps = [step for step in steps if step != "forecast_time_series"]
        return steps

    def execute_pipeline(self, steps: List[str], tracker: Tracker) -> Dict[str, Any]:
        """Ex√©cute les √©tapes du pipeline."""
        raw_data = tracker.get_slot("raw_data")
        if not raw_data:
            raise ValueError("Aucune donn√©e fournie pour ex√©cuter le pipeline.")

        data = pd.DataFrame(ast.literal_eval(raw_data))
        results = {}
        for step in steps:
            if step == "forecast_time_series":
                results["forecast"] = self.forecast_time_series(data)
            elif step == "detect_anomalies":
                results["anomalies"] = self.detect_anomalies(data)
            elif step == "analyze_numerical":
                results["numerical_analysis"] = self.analyze_numerical(data)
            elif step == "analyze_categorical":
                results["categorical_analysis"] = self.analyze_categorical(data)
        return results

    def forecast_time_series(self, data: pd.DataFrame) -> Dict[str, Any]:
        """Pr√©visions temporelles."""
        try:
            model = Prophet()
            model.fit(data)
            future = model.make_future_dataframe(periods=7)
            forecast = model.predict(future)
            return forecast[["ds", "yhat"]].tail(7).to_dict(orient="records")
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la pr√©vision des s√©ries temporelles : {str(e)}")

    def detect_anomalies(self, data: pd.DataFrame) -> Dict[str, Any]:
        """D√©tection des anomalies."""
        try:
            model = IsolationForest(contamination=0.1, random_state=42)
            predictions = model.fit_predict(data.values)
            anomalies = data[predictions == -1]
            return anomalies.to_dict(orient="records")
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la d√©tection des anomalies : {str(e)}")

    def analyze_numerical(self, data: pd.DataFrame) -> Dict[str, Any]:
        """Analyse des donn√©es num√©riques."""
        try:
            summary = data.describe().to_dict()
            return summary
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'analyse num√©rique : {str(e)}")

    def analyze_categorical(self, data: pd.DataFrame) -> Dict[str, Any]:
        """Analyse des donn√©es cat√©goriques."""
        try:
            encoded_data = {}
            for col in data.select_dtypes(include=["object"]).columns:
                encoder = LabelEncoder()
                encoded_data[col] = encoder.fit_transform(data[col]).tolist()
            return encoded_data
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'analyse cat√©gorique : {str(e)}")

class RealTimeTranslator(Action):
    def name(self) -> str:
        return "action_real_time_translator"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        # R√©cup√©rer les slots n√©cessaires
        text_to_translate = tracker.get_slot("text_to_translate")
        target_language = tracker.get_slot("target_language") or "en"

        if not text_to_translate:
            dispatcher.utter_message(text="Je n'ai pas trouv√© de texte √† traduire. Peux-tu me le donner ?")
            return []

        if target_language not in LANGUAGES.keys():
            dispatcher.utter_message(
                text=f"La langue cible '{target_language}' n'est pas prise en charge. Veuillez en choisir une autre."
            )
            return []

        try:
            # Initialiser le traducteur
            translator = Translator()

            # D√©tecter la langue source
            detected_language = translator.detect(text_to_translate).lang
            if detected_language == target_language:
                dispatcher.utter_message(text="Le texte est d√©j√† dans la langue cible.")
                return [SlotSet("translated_text", text_to_translate)]

            # Traduire le texte
            translated_text = translator.translate(text_to_translate, src=detected_language, dest=target_language).text

            # Retourner les informations √† l'utilisateur
            dispatcher.utter_message(
                text=(
                    f"Texte d√©tect√© en langue '{LANGUAGES[detected_language]}'.\n"
                    f"Traduction en '{LANGUAGES[target_language]}': {translated_text}"
                )
            )
            return [
                SlotSet("translated_text", translated_text),
                SlotSet("detected_language", detected_language),
            ]

        except Exception as e:
            dispatcher.utter_message(text=f"Une erreur s'est produite lors de la traduction : {str(e)}")
            return []


class CustomKnowledgeBaseAnswerer(Action):
    def name(self) -> str:
        return "action_custom_knowledge_base_answerer"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Charger une base de donn√©es simul√©e
        data = {
            "Product": ["Laptop", "Phone", "Tablet"],
            "Price": [1000, 500, 300],
            "Stock": [50, 200, 150],
            "Description": [
                "Un ordinateur portable performant pour les professionnels.",
                "Un smartphone avec une excellente autonomie.",
                "Une tablette id√©ale pour les loisirs et la productivit√©.",
            ],
        }
        df = pd.DataFrame(data)

        # Extraire la requ√™te de l‚Äôutilisateur
        query = tracker.get_slot("user_query")
        if not query:
            dispatcher.utter_message(text="Je n'ai pas compris votre question. Veuillez reformuler.")
            return []

        # Rechercher dans la base
        try:
            # Recherche intelligente (correspondance partielle sur le nom du produit)
            result = df[df["Product"].str.contains(query, case=False, na=False)].to_dict("records")

            # Si aucun r√©sultat n'est trouv√©
            if not result:
                dispatcher.utter_message(
                    text="Je n'ai trouv√© aucun produit correspondant √† votre requ√™te. "
                         "Pouvez-vous pr√©ciser votre demande ?"
                )
                return []

            # Pr√©parer une r√©ponse format√©e
            response = "Voici les informations disponibles :\n"
            for item in result:
                response += (
                    f"- **Produit** : {item['Product']}\n"
                    f"  - **Prix** : {item['Price']} ‚Ç¨\n"
                    f"  - **Stock** : {item['Stock']} unit√©s disponibles\n"
                    f"  - **Description** : {item['Description']}\n\n"
                )

            dispatcher.utter_message(text=response)

        except Exception as e:
            dispatcher.utter_message(text=f"Une erreur est survenue lors de la recherche : {str(e)}")

        return []


class MathCompetitionManager(Action):
    def name(self) -> str:
        return "action_math_competition_manager"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # R√©cup√©rer le probl√®me math√©matique soumis par l'utilisateur
        math_problem = tracker.get_slot("math_problem")

        if not math_problem:
            dispatcher.utter_message(
                text="Je n'ai pas trouv√© de probl√®me math√©matique √† r√©soudre. Peux-tu m'en donner un‚ÄØ?"
            )
            return []

        try:
            # Analyser et valider le probl√®me math√©matique
            parsed_problem = sp.sympify(math_problem)
            result = None

            if isinstance(parsed_problem, sp.Equality):  # √âquation
                solutions = sp.solve(parsed_problem)
                result = f"Les solutions de l'√©quation '{math_problem}' sont : {solutions}"
                slot_value = str(solutions)

            elif "Integral" in str(parsed_problem):  # Int√©grale
                integral = sp.integrate(parsed_problem)
                result = f"L'int√©grale de '{math_problem}' est : {integral}"
                slot_value = str(integral)

            elif "Derivative" in str(parsed_problem):  # D√©riv√©e
                derivative = sp.diff(parsed_problem)
                result = f"La d√©riv√©e de '{math_problem}' est : {derivative}"
                slot_value = str(derivative)

            elif isinstance(parsed_problem, sp.Sum):  # S√©rie
                summation = sp.summation(parsed_problem)
                result = f"La somme de la s√©rie '{math_problem}' est : {summation}"
                slot_value = str(summation)

            elif isinstance(parsed_problem, sp.Limit):  # Limite
                limit = sp.limit(parsed_problem)
                result = f"La limite de '{math_problem}' est : {limit}"
                slot_value = str(limit)

            else:  # Simplification ou √©valuation d'une expression
                simplified_result = sp.simplify(parsed_problem)
                result = f"Le r√©sultat de '{math_problem}' est : {simplified_result}"
                slot_value = str(simplified_result)

            dispatcher.utter_message(text=result)
            return [SlotSet("math_result", slot_value)]

        except sp.SympifyError:
            dispatcher.utter_message(
                text=(
                    "Je n'ai pas pu comprendre votre probl√®me math√©matique. "
                    "Assurez-vous qu'il est bien formul√© avec des symboles valides. Exemple : x**2 + 2*x - 8 = 0"
                )
            )
            return []
        except Exception as e:
            dispatcher.utter_message(
                text=f"Une erreur est survenue lors de la r√©solution du probl√®me math√©matique : {str(e)}"
            )
            return []


class QuizCompetitionManager(Action):
    def name(self) -> str:
        return "action_quiz_competition_manager"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        # Exemple de questions (peut √™tre extrait d'une base de donn√©es)
        questions = [
            {"question": "Quelle est la capitale de la France?", "answer": "Paris"},
            {"question": "Combien de continents y a-t-il?", "answer": "7"},
            {"question": "Quel est l'√©l√©ment chimique dont le symbole est H?", "answer": "Hydrog√®ne"},
            {"question": "En quelle ann√©e l'homme a-t-il march√© sur la Lune?", "answer": "1969"},
            {"question": "Qui a peint la Joconde?", "answer": "L√©onard de Vinci"},
        ]

        # Choisir une question al√©atoire
        question = random.choice(questions)

        # Enregistrer la question et sa r√©ponse correcte dans les slots
        dispatcher.utter_message(text=f"Voici une question : {question['question']}")
        return [
            SlotSet("current_quiz_question", question["question"]),
            SlotSet("current_quiz_answer", question["answer"]),
        ]

class ValidateQuizAnswer(Action):
    def name(self) -> str:
        return "action_validate_quiz_answer"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        user_answer = tracker.get_slot("user_answer")
        correct_answer = tracker.get_slot("current_quiz_answer")

        if not user_answer:
            dispatcher.utter_message(text="Je n'ai pas re√ßu ta r√©ponse. Peux-tu la r√©p√©ter?")
            return []

        if user_answer.lower() == correct_answer.lower():
            dispatcher.utter_message(text="Bravo! Ta r√©ponse est correcte üéâ.")
            return [SlotSet("quiz_score", tracker.get_slot("quiz_score") + 1)]
        else:
            dispatcher.utter_message(
                text=f"Dommage, la r√©ponse correcte √©tait : {correct_answer}. On continue?"
            )
            return []

        return "action_strategy_competition_manager"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        # Exemple de jeu de type "X et O" (tic-tac-toe) ou autre jeu simple
        game_state = tracker.get_slot("game_state") or [" "]*9  # Plateau de jeu

        # V√©rifier si le jeu est termin√©
        winner = self.check_winner(game_state)
        if winner:
            dispatcher.utter_message(text=f"Le jeu est termin√© ! Le gagnant est : {winner}.")
            return [SlotSet("game_state", game_state)]

        # Calculer le meilleur coup
        best_move = self.calculate_best_move(game_state)
        game_state[best_move] = "O"  # Le bot joue "O"
        dispatcher.utter_message(text=f"Je joue ma strat√©gie. Voici mon coup : {best_move}.")

        # Retourner l'√©tat mis √† jour
        return [SlotSet("game_state", game_state)]

    def check_winner(self, game_state):
        # V√©rifie les lignes gagnantes dans le jeu
        winning_positions = [
            [0, 1, 2], [3, 4, 5], [6, 7, 8],  # Lignes
            [0, 3, 6], [1, 4, 7], [2, 5, 8],  # Colonnes
            [0, 4, 8], [2, 4, 6],            # Diagonales
        ]
        for line in winning_positions:
            if game_state[line[0]] == game_state[line[1]] == game_state[line[2]] != " ":
                return game_state[line[0]]  # Retourne "X" ou "O"
        return None

    def calculate_best_move(self, game_state):
        # Strat√©gie simple : choisir la premi√®re case vide
        for i in range(len(game_state)):
            if game_state[i] == " ":
                return i
        return None


class AdvancedStrategySimulator(Action):
    def name(self) -> str:
        return "action_advanced_strategy_simulator"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        # R√©cup√©rer l'√©tat du jeu
        game_state = tracker.get_slot("game_state") or [" "] * 9  # Plateau 3x3
        player_symbol = "X"  # Joueur humain
        bot_symbol = "O"  # Bot

        # V√©rifier si le jeu est termin√©
        winner = self.check_winner(game_state)
        if winner:
            dispatcher.utter_message(text=f"Le jeu est termin√© ! Le gagnant est : {winner}.")
            return [SlotSet("game_state", game_state)]

        # Calculer le meilleur coup avec l'algorithme Minimax
        best_move = self.minimax(game_state, bot_symbol)["position"]
        game_state[best_move] = bot_symbol
        dispatcher.utter_message(text=f"Je joue ma strat√©gie ! Voici mon coup : {best_move + 1}.")

        # V√©rifier apr√®s le coup du bot
        winner_after_bot = self.check_winner(game_state)
        if winner_after_bot:
            dispatcher.utter_message(text=f"Le jeu est termin√© ! Le gagnant est : {winner_after_bot}.")

        return [SlotSet("game_state", game_state)]

    def check_winner(self, game_state):
        # V√©rifie les lignes gagnantes
        winning_positions = [
            [0, 1, 2], [3, 4, 5], [6, 7, 8],  # Lignes
            [0, 3, 6], [1, 4, 7], [2, 5, 8],  # Colonnes
            [0, 4, 8], [2, 4, 6],  # Diagonales
        ]
        for line in winning_positions:
            if game_state[line[0]] == game_state[line[1]] == game_state[line[2]] != " ":
                return game_state[line[0]]
        return None

    def minimax(self, game_state, current_symbol):
        opponent_symbol = "X" if current_symbol == "O" else "O"
        winner = self.check_winner(game_state)

        # Base : si le jeu est termin√©
        if winner == "O":
            return {"score": 1}  # Bot gagne
        elif winner == "X":
            return {"score": -1}  # Joueur gagne
        elif " " not in game_state:
            return {"score": 0}  # Match nul

        # Initialiser les mouvements possibles
        moves = []
        for i in range(len(game_state)):
            if game_state[i] == " ":
                # Simuler le coup
                game_state[i] = current_symbol
                result = self.minimax(game_state, opponent_symbol)
                moves.append({"position": i, "score": result["score"]})
                game_state[i] = " "  # Annuler le coup simul√©

        # Choisir le meilleur mouvement
        if current_symbol == "O":  # Maximiser pour le bot
            best_move = max(moves, key=lambda x: x["score"])
        else:  # Minimiser pour l'adversaire
            best_move = min(moves, key=lambda x: x["score"])
        return best_move

class CompetitorAnalyzer(Action):
    def name(self) -> str:
        return "action_competitor_analyzer"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        # R√©cup√©rer les donn√©es des comp√©titeurs (fichier CSV simul√©)
        competitor_data_path = "data/competitors.csv"  # Remplace par ton fichier r√©el
        try:
            df = pd.read_csv(competitor_data_path)

            # Analyse des statistiques (exemple : score moyen et performance maximale)
            avg_score = df["score"].mean()
            max_performance = df["performance"].max()
            best_competitor = df.loc[df["performance"].idxmax(), "name"]

            strategy = f"Concentrez-vous sur les comp√©titeurs avec un score sup√©rieur √† {avg_score:.2f}. " \
                       f"Le meilleur comp√©titeur est {best_competitor} avec une performance de {max_performance}."

            dispatcher.utter_message(text=f"Analyse termin√©e : {strategy}")
            return [SlotSet("strategy_output", strategy)]
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de l'analyse : {str(e)}")
            return []
        
class PerformancePredictor(Action):
    def name(self) -> str:
        return "action_performance_predictor"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        # R√©cup√©rer les donn√©es utilisateur
        user_data = tracker.get_slot("user_data")
        if not user_data:
            dispatcher.utter_message(
                text="Je n'ai pas trouv√© de donn√©es utilisateur pour effectuer une pr√©diction."
            )
            return []

        try:
            # Charger un mod√®le pr√©-entra√Æn√© (par ex., mod√®le h√©berg√© ou int√©gr√©)
            pre_trained_model_path = "pretrained/performance_model.pkl"
            model = joblib.load(pre_trained_model_path)

            # Charger les donn√©es utilisateur dans un DataFrame
            user_df = pd.DataFrame([user_data])

            # Effectuer une pr√©diction
            prediction = model.predict(user_df)
            probability = model.predict_proba(user_df).max()

            # Retourner une pr√©diction avec explications
            if prediction[0] == 1:
                dispatcher.utter_message(
                    text=f"F√©licitations ! Tes chances de succ√®s sont √©lev√©es ({probability * 100:.2f}%). üéâ"
                )
            else:
                dispatcher.utter_message(
                    text=f"Tes chances de succ√®s sont limit√©es ({probability * 100:.2f}%). "
                         f"Peut-√™tre que tu peux t'am√©liorer avec plus de pratique."
                )
            return [SlotSet("performance_prediction", prediction[0])]

        except Exception as e:
            dispatcher.utter_message(
                text=f"Une erreur s'est produite lors de la pr√©diction : {str(e)}"
            )
            return []

class MasteryOptimizer(Action):
    def name(self) -> str:
        return "action_mastery_optimizer"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        # R√©cup√©rer les performances utilisateur depuis les slots
        user_performance = {
            "accuracy": tracker.get_slot("accuracy") or random.uniform(0.5, 0.9),
            "speed": tracker.get_slot("speed") or random.uniform(1, 3),  # Temps moyen pour r√©pondre (en secondes)
            "consistency": tracker.get_slot("consistency") or random.uniform(0.7, 0.95),
        }

        # Analyse des performances
        weaknesses = []
        scores = {
            "accuracy": user_performance["accuracy"] * 100,  # Convertir en pourcentage
            "speed": max(0, 100 - user_performance["speed"] * 30),  # Inverser la logique pour la vitesse
            "consistency": user_performance["consistency"] * 100,
        }
        total_score = (scores["accuracy"] + scores["speed"] + scores["consistency"]) / 3

        if scores["accuracy"] < 80:
            weaknesses.append(
                "Pr√©cision : Travaille sur la reconnaissance des erreurs en pratiquant avec des exercices cibl√©s."
            )
        if scores["speed"] < 60:
            weaknesses.append(
                "Vitesse : Pratique des quiz chronom√©tr√©s pour am√©liorer tes temps de r√©ponse."
            )
        if scores["consistency"] < 85:
            weaknesses.append(
                "Coh√©rence : R√©vise r√©guli√®rement pour maintenir une performance stable."
            )

        # Plan d'am√©lioration
        if weaknesses:
            improvement_plan = (
                f"Plan d'am√©lioration (Score global : {total_score:.2f}/100) :\n- "
                + "\n- ".join(weaknesses)
            )
        else:
            improvement_plan = (
                f"F√©licitations ! Ton score global est de {total_score:.2f}/100. Continue comme √ßa, tu es sur la bonne voie !"
            )

        # G√©n√©ration de simulations pour l'entra√Ænement
        simulated_opponents = self.generate_opponents()
        training_suggestion = self.generate_training_suggestions(simulated_opponents)

        # Retour interactif
        dispatcher.utter_message(text=f"{improvement_plan}\n\n{training_suggestion}")

        return [
            SlotSet("improvement_plan", improvement_plan),
            SlotSet("simulated_opponents", simulated_opponents),
        ]

    def generate_opponents(self):
        """Cr√©e une liste d'adversaires simul√©s avec des niveaux vari√©s."""
        levels = ["Facile", "Moyen", "Difficile"]
        return [
            {"name": f"Adversaire {i+1}", "level": random.choice(levels), "score": random.randint(50, 100)}
            for i in range(3)
        ]

    def generate_training_suggestions(self, opponents):
        """G√©n√®re des suggestions pour battre les adversaires simul√©s."""
        suggestions = []
        for opponent in opponents:
            if opponent["level"] == "Facile":
                suggestions.append(
                    f"{opponent['name']} ({opponent['level']}) : Id√©al pour travailler ta pr√©cision."
                )
            elif opponent["level"] == "Moyen":
                suggestions.append(
                    f"{opponent['name']} ({opponent['level']}) : Entra√Æne-toi sur des questions chronom√©tr√©es."
                )
            else:
                suggestions.append(
                    f"{opponent['name']} ({opponent['level']}) : Challenge difficile ! Reste coh√©rent sous pression."
                )
        return "Voici tes adversaires simul√©s et des strat√©gies pour les battre :\n" + "\n".join(suggestions)

class CompetitionMasterySuite(Action):
    def name(self) -> str:
        return "action_competition_mastery_suite"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        # Analyse des performances pass√©es
        user_score = tracker.get_slot("accuracy") or random.uniform(0.6, 0.9)
        user_speed = tracker.get_slot("speed") or random.uniform(1, 3)
        user_consistency = tracker.get_slot("consistency") or random.uniform(0.7, 0.95)

        # Analyse des adversaires
        competitor_data_path = "data/competitors.csv"  # Simuler les donn√©es
        try:
            competitors = pd.read_csv(competitor_data_path)
        except:
            competitors = pd.DataFrame({
                "name": ["Alice", "Bob", "Charlie"],
                "score": [random.randint(70, 95) for _ in range(3)],
                "speed": [random.uniform(1, 2.5) for _ in range(3)],
                "consistency": [random.uniform(0.6, 0.9) for _ in range(3)],
            })

        # Calculer des comparaisons
        avg_competitor_score = competitors["score"].mean()
        avg_competitor_speed = competitors["speed"].mean()
        avg_competitor_consistency = competitors["consistency"].mean()

        # Suggestions de strat√©gie
        strategy = []
        if user_score < avg_competitor_score:
            strategy.append("Am√©liorer la pr√©cision en analysant les questions des concurrents.")
        if user_speed > avg_competitor_speed:
            strategy.append("R√©duire le temps de r√©ponse avec des entra√Ænements chronom√©tr√©s.")
        if user_consistency < avg_competitor_consistency:
            strategy.append("Augmenter la r√©gularit√© en simulant des comp√©titions longues.")

        # G√©n√©rer un plan d'entra√Ænement
        training_plan = "\n".join(f"- {s}" for s in strategy) if strategy else "Tu es d√©j√† au top !"

        # Simuler les chances de victoire
        chance_of_victory = np.clip((user_score * 0.4 + user_consistency * 0.4 + (1 / user_speed) * 0.2) * 100, 0, 100)

        # Retourner le r√©sultat
        dispatcher.utter_message(
            text=f"Analyse termin√©e.\n"
                 f"Plan d'entra√Ænement personnalis√© :\n{training_plan}\n\n"
                 f"Chances de victoire actuelles : {chance_of_victory:.2f}%.\n"
                 f"Pr√©pare-toi √† simuler une comp√©tition !"
        )
        return [
            SlotSet("training_plan", training_plan),
            SlotSet("chance_of_victory", chance_of_victory)
        ]

class ActionStatisticalSummary(Action):
    def name(self) -> str:
        return "action_statistical_summary"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict]:
        # R√©cup√©rer les donn√©es utilisateur
        raw_data = tracker.get_slot("numeric_data")

        if not raw_data:
            dispatcher.utter_message(text="Je n'ai pas re√ßu de donn√©es √† analyser. Veuillez fournir une liste de nombres.")
            return []

        try:
            # Validation et conversion des donn√©es utilisateur
            try:
                data = np.array(eval(raw_data))  # Transformation en numpy array
                if not isinstance(data, np.ndarray) or data.size == 0:
                    raise ValueError("Les donn√©es fournies ne sont pas valides.")
            except Exception as e:
                dispatcher.utter_message(text="Les donn√©es fournies ne sont pas valides. Veuillez fournir une liste de nombres comme [10, 20, 30].")
                return []

            # V√©rifier que les donn√©es sont num√©riques
            if not np.issubdtype(data.dtype, np.number):
                dispatcher.utter_message(text="Les donn√©es doivent contenir uniquement des nombres.")
                return []

            # Statistiques descriptives
            mean = np.mean(data)
            median = np.median(data)
            std_dev = np.std(data)
            min_val = np.min(data)
            max_val = np.max(data)
            quartiles = np.percentile(data, [25, 50, 75])

            # D√©tection des valeurs aberrantes (IQR Method)
            iqr = quartiles[2] - quartiles[0]
            lower_bound = quartiles[0] - 1.5 * iqr
            upper_bound = quartiles[2] + 1.5 * iqr
            outliers = data[(data < lower_bound) | (data > upper_bound)]

            # G√©n√©ration d'une visualisation (Boxplot)
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "statistical_summary_boxplot.png")
            plt.figure(figsize=(10, 6))
            plt.boxplot(data, vert=False, patch_artist=True, boxprops=dict(facecolor="lightblue"))
            plt.title("Boxplot des donn√©es")
            plt.xlabel("Valeurs")
            plt.savefig(file_path)
            plt.close()

            # R√©sum√© des statistiques
            summary = (
                f"Voici les statistiques calcul√©es :\n"
                f"- Moyenne : {mean:.2f}\n"
                f"- M√©diane : {median:.2f}\n"
                f"- √âcart-type : {std_dev:.2f}\n"
                f"- Min : {min_val}, Max : {max_val}\n"
                f"- Quartiles : Q1={quartiles[0]:.2f}, Q2={quartiles[1]:.2f}, Q3={quartiles[2]:.2f}\n"
                f"- Valeurs aberrantes : {list(outliers)}\n\n"
                f"Un graphique de boxplot a √©t√© g√©n√©r√© : {file_path}"
            )

            # R√©ponse √† l'utilisateur
            dispatcher.utter_message(text=summary)

        except Exception as e:
            logger.error(f"Erreur dans l'analyse statistique : {e}")
            dispatcher.utter_message(text="Une erreur est survenue lors de l'analyse des donn√©es.")
            return []

        return []
class ActionClustering(Action):
    def name(self) -> str:
        return "action_clustering"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict]:
        # R√©cup√©rer les donn√©es utilisateur ou g√©n√©rer des donn√©es fictives
        raw_data = tracker.get_slot("numeric_data")
        if not raw_data:
            dispatcher.utter_message("Aucune donn√©e fournie, des donn√©es fictives seront utilis√©es pour le clustering.")
            data, _ = make_blobs(n_samples=100, centers=3, random_state=42)
        else:
            try:
                data = np.array(eval(raw_data))
                if data.ndim != 2:
                    raise ValueError("Les donn√©es doivent √™tre de forme (n_samples, n_features).")
            except Exception as e:
                dispatcher.utter_message("Les donn√©es fournies ne sont pas valides. Fournissez une liste de points en 2D ou plus.")
                logger.error(f"Erreur lors de l'analyse des donn√©es : {e}")
                return []

        try:
            # R√©duction des dimensions si n√©cessaire
            if data.shape[1] > 2:
                dispatcher.utter_message("R√©duction des dimensions des donn√©es en cours...")
                reducer = UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)
                reduced_data = reducer.fit_transform(data)
            else:
                reduced_data = data

            # Application de KMeans
            n_clusters = 3
            kmeans = KMeans(n_clusters=n_clusters, random_state=42)
            labels = kmeans.fit_predict(reduced_data)

            # Visualisation des clusters
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "clustering_result.png")
            plt.figure(figsize=(10, 6))
            plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=labels, cmap="tab10", s=50, alpha=0.8)
            plt.title("R√©sultat du clustering")
            plt.xlabel("Dimension 1")
            plt.ylabel("Dimension 2")
            plt.colorbar(label="Cluster")
            plt.savefig(file_path)
            plt.close()

            # R√©sum√© des clusters
            cluster_counts = np.bincount(labels)
            centroids = kmeans.cluster_centers_
            summary = (
                f"Clustering effectu√© avec succ√®s.\n"
                f"Nombre de points par cluster : {cluster_counts.tolist()}.\n"
                f"Centroides des clusters : {centroids.tolist()}.\n"
                f"Un graphique des clusters a √©t√© g√©n√©r√© : {file_path}."
            )
            dispatcher.utter_message(text=summary)

        except Exception as e:
            dispatcher.utter_message("Une erreur est survenue lors du clustering. Veuillez v√©rifier vos donn√©es.")
            logger.error(f"Erreur lors du clustering : {e}")
            return []

        return []

class ActionGenerateDashboard(Action):
    def name(self) -> str:
        return "action_generate_dashboard"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict]:
        # R√©cup√©rer les donn√©es utilisateur
        raw_data = tracker.get_slot("data_frame")
        if not raw_data:
            dispatcher.utter_message("Aucune donn√©e disponible pour g√©n√©rer un tableau de bord. Veuillez fournir des donn√©es.")
            return []

        try:
            # Validation et conversion des donn√©es
            try:
                data = pd.DataFrame(eval(raw_data))
                if data.empty:
                    raise ValueError("Les donn√©es fournies sont vides.")
            except Exception as e:
                dispatcher.utter_message("Les donn√©es fournies ne sont pas valides. Fournissez un DataFrame valide.")
                logger.error(f"Erreur dans l'√©valuation des donn√©es : {e}")
                return []

            # V√©rification des colonnes
            if data.shape[1] < 1:
                dispatcher.utter_message("Les donn√©es fournies ne contiennent pas suffisamment de colonnes.")
                return []

            # G√©n√©ration des graphiques
            fig = make_subplots(rows=1, cols=2, subplot_titles=["Histogramme", "Bo√Æte √† moustaches"])

            # Histogramme
            fig.add_trace(go.Histogram(x=data.iloc[:, 0], name="Histogramme", marker=dict(color='blue')), row=1, col=1)

            # Boxplot
            fig.add_trace(go.Box(y=data.iloc[:, 0], name="Boxplot", boxmean=True, marker=dict(color='red')), row=1, col=2)

            # Mise en forme du tableau de bord
            fig.update_layout(
                title="Tableau de bord interactif",
                height=600,
                showlegend=False,
                margin=dict(l=40, r=40, t=40, b=40),
                paper_bgcolor="white"
            )

            # Sauvegarde du tableau de bord
            output_dir = "dashboards"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "dashboard.html")
            fig.write_html(file_path)

            # R√©ponse utilisateur
            dispatcher.utter_message("Tableau de bord g√©n√©r√© avec succ√®s.")
            dispatcher.utter_message(f"Le tableau de bord est accessible ici : {file_path}")

        except Exception as e:
            logger.error(f"Erreur lors de la g√©n√©ration du tableau de bord : {e}")
            dispatcher.utter_message("Une erreur est survenue lors de la g√©n√©ration du tableau de bord.")
            return []

        return []

class ActionFeatureSelection(Action):
    def name(self) -> str:
        return "action_feature_selection"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        raw_data = tracker.get_slot("preprocessed_data")
        if not raw_data:
            dispatcher.utter_message(text="Aucune donn√©e pr√©trait√©e √† analyser.")
            return []

        try:
            # Convertir les donn√©es en DataFrame
            data = pd.DataFrame(raw_data)

            # S√©lectionner les meilleures caract√©ristiques (par exemple, en utilisant un mod√®le comme RandomForest)
            from sklearn.ensemble import RandomForestClassifier
            model = RandomForestClassifier()
            model.fit(data.drop(columns=["target"]), data["target"])

            # Obtenir l'importance des caract√©ristiques
            importances = model.feature_importances_
            features = data.columns.drop("target")
            important_features = [features[i] for i in range(len(features)) if importances[i] > 0.1]

            dispatcher.utter_message(text=f"Les caract√©ristiques s√©lectionn√©es sont : {important_features}")
            return [SlotSet("important_features", important_features)]
        except Exception as e:
            dispatcher.utter_message(text="Erreur lors de la s√©lection des caract√©ristiques.")
            return []

class ActionModelEvaluation(Action):
    def name(self) -> str:
        return "action_model_evaluation"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        model = tracker.get_slot("model")
        X_test = tracker.get_slot("X_test")
        y_test = tracker.get_slot("y_test")

        if not model or not X_test or not y_test:
            dispatcher.utter_message(text="Aucune information sur le mod√®le ou les donn√©es de test.")
            return []

        try:
            # Pr√©dictions du mod√®le
            y_pred = model.predict(X_test)

            # Calcul de la pr√©cision
            accuracy = accuracy_score(y_test, y_pred)

            dispatcher.utter_message(text=f"Pr√©cision du mod√®le : {accuracy * 100:.2f}%")
            return [SlotSet("model_accuracy", accuracy)]
        except Exception as e:
            dispatcher.utter_message(text="Erreur lors de l'√©valuation du mod√®le.")
            return []


class ActionHyperparameterTuning(Action):
    def name(self) -> str:
        return "action_hyperparameter_tuning"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer les donn√©es d'entr√©e pour l'entra√Ænement
        raw_data = tracker.get_slot("training_data")
        if not raw_data:
            dispatcher.utter_message(text="Donn√©es d'entra√Ænement non disponibles.")
            return []

        # D√©finir la grille des hyperparam√®tres √† tester
        param_grid = {
            'n_estimators': [50, 100, 200],
            'max_depth': [5, 10, 20],
            'min_samples_split': [2, 5, 10]
        }

        try:
            # Charger les donn√©es et entra√Æner le mod√®le
            data = pd.DataFrame(eval(raw_data))
            X_train, X_test, y_train, y_test = train_test_split(data.drop(columns="target"), data["target"],
                                                                test_size=0.2)

            # Instancier le mod√®le
            model = RandomForestClassifier(random_state=42)

            # Rechercher les meilleurs hyperparam√®tres
            grid_search = GridSearchCV(model, param_grid, cv=3)
            grid_search.fit(X_train, y_train)

            best_params = grid_search.best_params_
            dispatcher.utter_message(text=f"Les meilleurs hyperparam√®tres sont : {best_params}")
            return [SlotSet("best_hyperparameters", best_params)]

        except Exception as e:
            dispatcher.utter_message(text="Erreur lors de l'ajustement des hyperparam√®tres.")
            return []

class ActionModelPerformanceVisualization(Action):
    def name(self) -> str:
        return "action_model_performance_visualization"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        model = tracker.get_slot("model")
        X_test = tracker.get_slot("X_test")
        y_test = tracker.get_slot("y_test")

        if not model or not X_test or not y_test:
            dispatcher.utter_message(text="Aucune information sur le mod√®le ou les donn√©es de test.")
            return []

        try:
            # Matrice de confusion
            y_pred = model.predict(X_test)
            cm = confusion_matrix(y_test, y_pred)

            plt.figure(figsize=(8, 6))
            plt.imshow(cm, interpolation="nearest", cmap=plt.cm.Blues)
            plt.title("Matrice de confusion")
            plt.colorbar()
            plt.ylabel("True Label")
            plt.xlabel("Predicted Label")
            plt.savefig("confusion_matrix.png")
            plt.close()

            dispatcher.utter_message(text="Matrice de confusion g√©n√©r√©e avec succ√®s.")
            return [SlotSet("confusion_matrix", "confusion_matrix.png")]
        except Exception as e:
            dispatcher.utter_message(text="Erreur lors de la visualisation des performances.")
            return []

class ActionHandleMissingData(Action):
    def name(self) -> str:
        return "action_handle_missing_data"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        raw_data = tracker.get_slot("raw_data")
        if not raw_data:
            dispatcher.utter_message(text="Aucune donn√©e √† traiter.")
            return []

        try:
            # Convertir les donn√©es brutes en DataFrame
            data = pd.DataFrame(eval(raw_data))

            # G√©rer les valeurs manquantes (exemple : imputer avec la moyenne)
            data.fillna(data.mean(), inplace=True)

            dispatcher.utter_message(text="Les donn√©es manquantes ont √©t√© trait√©es avec succ√®s.")
            return [SlotSet("processed_data", data.to_dict())]
        except Exception as e:
            dispatcher.utter_message(text="Erreur lors du traitement des donn√©es manquantes.")
            return []

class ActionPreprocessData(Action):
    def name(self) -> str:
        return "action_preprocess_data"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        raw_data = tracker.get_slot("raw_data")
        if not raw_data:
            dispatcher.utter_message(text="Aucune donn√©e √† traiter. Veuillez fournir les donn√©es brutes.")
            return []

        try:
            # Convertir les donn√©es brutes en DataFrame
            data = pd.DataFrame(eval(raw_data))

            # Pr√©traitement : g√©rer les valeurs manquantes, normaliser, etc.
            data.fillna(data.mean(), inplace=True)  # Exemple pour g√©rer les valeurs manquantes
            data = (data - data.mean()) / data.std()  # Normalisation

            dispatcher.utter_message(text="Donn√©es pr√©trait√©es avec succ√®s.")
            return [SlotSet("preprocessed_data", data.to_dict())]
        except Exception as e:
            dispatcher.utter_message(text="Une erreur s'est produite lors du pr√©traitement des donn√©es.")
            return []

class ActionBiasDetection(Action):
    def name(self) -> str:
        return "action_bias_detection"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de r√©cup√©ration de donn√©es de pr√©diction
        predictions = tracker.get_slot("model_predictions")
        ground_truth = tracker.get_slot("true_labels")

        if not predictions or not ground_truth:
            dispatcher.utter_message(text="Aucune donn√©e de pr√©diction disponible pour analyser les biais.")
            return []

        try:
            # Analyser le biais en fonction des diff√©rences de pr√©diction entre les groupes
            from sklearn.metrics import confusion_matrix
            cm = confusion_matrix(ground_truth, predictions)
            # Analyse des biais √† travers la matrice de confusion ou d'autres m√©triques
            dispatcher.utter_message(text="Analyse de biais effectu√©e avec succ√®s.")
            return [SlotSet("bias_analysis", cm)]
        except Exception as e:
            dispatcher.utter_message(text="Erreur lors de l'analyse des biais.")
            return []
class ActionPerformanceOptimization(Action):
    def name(self) -> str:
        return "action_performance_optimization"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        model = tracker.get_slot("model")
        X_train = tracker.get_slot("X_train")
        y_train = tracker.get_slot("y_train")

        if not model or X_train is None or y_train is None:
            dispatcher.utter_message(text="Aucune donn√©e ou mod√®le disponible pour l'optimisation des performances.")
            return []

        try:
            # Exemple d'optimisation avec RandomizedSearchCV
            from sklearn.model_selection import RandomizedSearchCV
            param_distributions = {
                'n_estimators': [50, 100, 200],
                'max_depth': [5, 10, 20],
                'min_samples_split': [2, 5, 10]
            }
            search = RandomizedSearchCV(model, param_distributions, n_iter=10, cv=5, random_state=42)
            search.fit(X_train, y_train)

            best_model = search.best_estimator_
            best_params = search.best_params_
            best_score = search.best_score_

            dispatcher.utter_message(text=f"Mod√®le optimis√© avec succ√®s ! Meilleurs param√®tres : {best_params}, Meilleur score : {best_score}")
            return [SlotSet("optimized_model", best_model), SlotSet("best_params", best_params)]
        except Exception as e:
            dispatcher.utter_message(text="Erreur lors de l'optimisation des performances.")
            return []

class ActionHandleImbalancedData(Action):
    def name(self) -> str:
        return "action_handle_imbalanced_data"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        X_train = tracker.get_slot("X_train")
        y_train = tracker.get_slot("y_train")

        if X_train is None or y_train is None:
            dispatcher.utter_message(text="Aucune donn√©e disponible pour traiter l'√©quilibre des classes.")
            return []

        try:
            # Appliquer SMOTE pour sur√©chantillonner les classes minoritaires
            from imblearn.over_sampling import SMOTE
            smote = SMOTE(random_state=42)
            X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

            dispatcher.utter_message(text="Les donn√©es d√©s√©quilibr√©es ont √©t√© trait√©es avec succ√®s.")
            return [SlotSet("X_resampled", X_resampled), SlotSet("y_resampled", y_resampled)]
        except Exception as e:
            dispatcher.utter_message(text="Erreur lors du traitement des donn√©es d√©s√©quilibr√©es.")
            return []

class ActionDetectOutliers(Action):
    def name(self) -> str:
        return "action_detect_outliers"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        data = tracker.get_slot("data")

        if not data:
            dispatcher.utter_message(text="Aucune donn√©e √† analyser pour les valeurs aberrantes.")
            return []

        try:
            # Convertir les donn√©es en DataFrame
            data = pd.DataFrame(eval(data))

            # D√©tection des outliers avec l'IQR
            Q1 = data.quantile(0.25)
            Q3 = data.quantile(0.75)
            IQR = Q3 - Q1
            outliers = ((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR)))

            # R√©sum√© des outliers
            outliers_summary = outliers.sum()

            dispatcher.utter_message(
                text=f"Valeurs aberrantes d√©tect√©es :\n{outliers_summary}"
            )
            return [SlotSet("outliers_summary", outliers_summary)]
        except Exception as e:
            logger.error(f"Erreur lors de la d√©tection des outliers : {e}")
            dispatcher.utter_message(text="Erreur lors de la d√©tection des valeurs aberrantes.")
            return []

class ActionEnsemblePrediction(Action):
    def name(self) -> str:
        return "action_ensemble_prediction"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer les donn√©es utilisateur
        X = tracker.get_slot("X_data")
        if not X:
            dispatcher.utter_message(text="Aucune donn√©e disponible pour la pr√©diction.")
            return []

        try:
            # Mod√®les pr√©charg√©s ou instanci√©s
            rf_model = tracker.get_slot("rf_model")
            xgb_model = tracker.get_slot("xgb_model")

            if not rf_model or not xgb_model:
                dispatcher.utter_message(text="Les mod√®les ne sont pas charg√©s.")
                return []

            # Pr√©diction avec les deux mod√®les
            rf_pred = rf_model.predict(X)
            xgb_pred = xgb_model.predict(X)

            # Combinaison des pr√©dictions (par exemple, moyenne ou majorit√©)
            final_prediction = (rf_pred + xgb_pred) / 2

            dispatcher.utter_message(
                text=f"Pr√©diction combin√©e des mod√®les : {final_prediction}"
            )
            return [SlotSet("ensemble_prediction", final_prediction)]
        except Exception as e:
            logger.error(f"Erreur lors de la pr√©diction avec les mod√®les d'ensemble : {e}")
            dispatcher.utter_message(text="Erreur lors de la pr√©diction avec les mod√®les.")
            return []

class ActionFeatureEngineering(Action):
    def name(self) -> str:
        return "action_feature_engineering"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        data = tracker.get_slot("data")

        if not data:
            dispatcher.utter_message(text="Aucune donn√©e disponible pour l'ing√©nierie des caract√©ristiques.")
            return []

        try:
            # Convertir les donn√©es en DataFrame
            data = pd.DataFrame(eval(data))

            # Cr√©ation de nouvelles fonctionnalit√©s (exemples : interactions, transformations log)
            data["log_feature"] = data["feature1"].apply(np.log)
            data["interaction_feature"] = data["feature1"] * data["feature2"]

            dispatcher.utter_message(
                text=f"Nouvelles caract√©ristiques cr√©√©es : log_feature, interaction_feature"
            )

            return [SlotSet("data_with_features", data.to_dict())]
        except Exception as e:
            logger.error(f"Erreur lors de l'ing√©nierie des caract√©ristiques : {e}")
            dispatcher.utter_message(text="Erreur lors de l'ing√©nierie des caract√©ristiques.")
            return []

class ActionRealTimePrediction(Action):
    def name(self) -> str:
        return "action_real_time_prediction"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # R√©cup√©rer les donn√©es utilisateur
        real_time_data = tracker.get_slot("real_time_data")

        if not real_time_data:
            dispatcher.utter_message(text="Aucune donn√©e disponible pour la pr√©diction en temps r√©el.")
            return []

        try:
            # Charger un mod√®le pour effectuer la pr√©diction
            model = tracker.get_slot("model")

            if not model:
                dispatcher.utter_message(text="Le mod√®le n'est pas charg√©.")
                return []

            # Pr√©diction en temps r√©el
            prediction = model.predict([real_time_data])

            dispatcher.utter_message(text=f"Pr√©diction en temps r√©el : {prediction}")
            return [SlotSet("real_time_prediction", prediction)]
        except Exception as e:
            logger.error(f"Erreur lors de la pr√©diction en temps r√©el : {e}")
            dispatcher.utter_message(text="Erreur lors de la pr√©diction en temps r√©el.")
            return []

class ActionModelMonitoring(Action):
    def name(self) -> str:
        return "action_model_monitoring"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        model = tracker.get_slot("model")
        X_test = tracker.get_slot("X_test")
        y_test = tracker.get_slot("y_test")

        if not model or X_test is None or y_test is None:
            dispatcher.utter_message(text="Mod√®le ou donn√©es de test manquants pour la surveillance.")
            return []

        try:
            from sklearn.metrics import accuracy_score

            # Pr√©dire sur les donn√©es de test
            y_pred = model.predict(X_test)

            # Calculer la pr√©cision
            accuracy = accuracy_score(y_test, y_pred)
            dispatcher.utter_message(text=f"Pr√©cision du mod√®le : {accuracy * 100:.2f}%")

            # Surveillance continue
            if accuracy < 0.7:  # Si la pr√©cision descend en dessous de 70%, alerte
                dispatcher.utter_message(text="Alerte : la performance du mod√®le est faible. Envisagez une mise √† jour.")

            return [SlotSet("model_accuracy", accuracy)]
        except Exception as e:
            logger.error(f"Erreur dans la surveillance du mod√®le : {e}")
            dispatcher.utter_message(text="Erreur lors de la surveillance du mod√®le.")
            return []

class ActionActiveLearningDataPreparation(Action):
    def name(self) -> str:
        return "action_active_learning_data_preparation"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        data = tracker.get_slot("unlabeled_data")

        if not data:
            dispatcher.utter_message(text="Aucune donn√©e disponible pour l'apprentissage actif.")
            return []

        try:
            # Utiliser un mod√®le pr√©-entra√Æn√© pour identifier les points les plus incertains
            model = tracker.get_slot("model")

            if not model:
                dispatcher.utter_message(text="Le mod√®le n'est pas charg√©.")
                return []

            # Identifier les instances les plus incertaines
            uncertainty_scores = model.predict_proba(data)  # Probabilit√©s pour chaque classe
            uncertain_samples = data[np.argmax(uncertainty_scores, axis=1) < 0.5]

            dispatcher.utter_message(
                text=f"Instances s√©lectionn√©es pour l'apprentissage actif : {uncertain_samples}"
            )

            return [SlotSet("active_learning_data", uncertain_samples)]
        except Exception as e:
            logger.error(f"Erreur dans la pr√©paration des donn√©es pour l'apprentissage actif : {e}")
            dispatcher.utter_message(text="Erreur lors de la pr√©paration des donn√©es.")
            return []

class ActionModelCrossValidation(Action):
    def name(self) -> str:
        return "action_model_cross_validation"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        model = tracker.get_slot("model")
        X_train = tracker.get_slot("X_train")
        y_train = tracker.get_slot("y_train")

        if not model or X_train is None or y_train is None:
            dispatcher.utter_message(text="Le mod√®le ou les donn√©es d'entra√Ænement manquent.")
            return []

        try:
            from sklearn.model_selection import cross_val_score

            # Validation crois√©e du mod√®le
            scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
            mean_score = scores.mean()

            dispatcher.utter_message(text=f"Validation crois√©e effectu√©e. Pr√©cision moyenne : {mean_score:.2f}")

            return [SlotSet("cross_val_score", mean_score)]
        except Exception as e:
            logger.error(f"Erreur lors de la validation crois√©e : {e}")
            dispatcher.utter_message(text="Erreur lors de la validation crois√©e du mod√®le.")
            return []

class ActionDynamicModelAdjustment(Action):
    def name(self) -> str:
        return "action_dynamic_model_adjustment"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        model = tracker.get_slot("model")
        X_train = tracker.get_slot("X_train")
        y_train = tracker.get_slot("y_train")
        score_threshold = tracker.get_slot("score_threshold") or 0.8

        if not model or X_train is None or y_train is None:
            dispatcher.utter_message(text="Le mod√®le ou les donn√©es d'entra√Ænement manquent.")
            return []

        try:
            model.fit(X_train, y_train)
            accuracy = model.score(X_train, y_train)

            # Ajuster les hyperparam√®tres si n√©cessaire
            if accuracy < score_threshold:
                # Par exemple, ajuster le nombre d'arbres dans Random Forest
                model.set_params(n_estimators=200)
                model.fit(X_train, y_train)
                dispatcher.utter_message(
                    text=f"Pr√©cision faible ({accuracy * 100:.2f}%). Le mod√®le a √©t√© ajust√©. Nouvelle pr√©cision : {model.score(X_train, y_train) * 100:.2f}%"
                )
            else:
                dispatcher.utter_message(
                    text=f"Pr√©cision satisfaisante ({accuracy * 100:.2f}%). Aucune modification n√©cessaire."
                )

            return [SlotSet("adjusted_model", model)]
        except Exception as e:
            logger.error(f"Erreur lors de l'ajustement dynamique du mod√®le : {e}")
            dispatcher.utter_message(text="Erreur lors de l'ajustement du mod√®le.")
            return []

class ActionMultiLabelPrediction(Action):
    def name(self) -> str:
        return "action_multi_label_prediction"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        model = tracker.get_slot("model")
        X_input = tracker.get_slot("X_input")

        if not model or X_input is None:
            dispatcher.utter_message(text="Le mod√®le ou les donn√©es d'entr√©e manquent.")
            return []

        try:
            from sklearn.preprocessing import MultiLabelBinarizer

            # Effectuer la pr√©diction multi-label
            predictions = model.predict(X_input)
            mlb = MultiLabelBinarizer()

            # Appliquer la transformation multi-label sur les pr√©dictions
            labels = mlb.fit_transform(predictions)
            dispatcher.utter_message(text=f"Pr√©diction multi-label effectu√©e : {labels}")

            return [SlotSet("multi_label_predictions", labels)]
        except Exception as e:
            logger.error(f"Erreur lors de la pr√©diction multi-label : {e}")
            dispatcher.utter_message(text="Erreur lors de la pr√©diction multi-label.")
            return []

class ActionSelectBestModel(Action):
    def name(self) -> str:
        return "action_select_best_model"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        models = tracker.get_slot("models")  # Liste des mod√®les d√©j√† entra√Æn√©s
        X_val = tracker.get_slot("X_val")    # Donn√©es de validation
        y_val = tracker.get_slot("y_val")    # √âtiquettes de validation

        if not models or X_val is None or y_val is None:
            dispatcher.utter_message(text="Les mod√®les ou les donn√©es de validation manquent.")
            return []

        try:
            best_model = None
            best_score = 0

            for model in models:
                model_score = model.score(X_val, y_val)
                if model_score > best_score:
                    best_model = model
                    best_score = model_score

            dispatcher.utter_message(text=f"Le meilleur mod√®le est : {best_model.__class__.__name__} avec une pr√©cision de {best_score * 100:.2f}%.")

            return [SlotSet("best_model", best_model)]
        except Exception as e:
            logger.error(f"Erreur lors de la s√©lection du meilleur mod√®le : {e}")
            dispatcher.utter_message(text="Erreur lors de la s√©lection du meilleur mod√®le.")
            return []

class ActionModelValidationAndRetraining(Action):
    def name(self) -> str:
        return "action_model_validation_and_retraining"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        model = tracker.get_slot("model")
        X_new_data = tracker.get_slot("X_new_data")
        y_new_data = tracker.get_slot("y_new_data")
        accuracy_threshold = tracker.get_slot("accuracy_threshold") or 0.8

        if not model or X_new_data is None or y_new_data is None:
            dispatcher.utter_message(text="Le mod√®le ou les nouvelles donn√©es manquent.")
            return []

        try:
            # Pr√©diction sur les nouvelles donn√©es
            new_accuracy = model.score(X_new_data, y_new_data)

            if new_accuracy < accuracy_threshold:
                # R√©entra√Æner le mod√®le si la pr√©cision est en dessous du seuil
                model.fit(X_new_data, y_new_data)
                dispatcher.utter_message(text=f"Le mod√®le a √©t√© r√©entra√Æn√© pour am√©liorer la pr√©cision. Nouvelle pr√©cision : {new_accuracy * 100:.2f}%.")
            else:
                dispatcher.utter_message(text=f"Le mod√®le est performant avec une pr√©cision de {new_accuracy * 100:.2f}%. Aucun r√©entra√Ænement n√©cessaire.")

            return [SlotSet("model", model)]
        except Exception as e:
            logger.error(f"Erreur lors de la validation et du r√©entra√Ænement du mod√®le : {e}")
            dispatcher.utter_message(text="Erreur lors de la validation et du r√©entra√Ænement du mod√®le.")
            return []

class ActionAutomaticDataPreprocessing(Action):
    def name(self) -> str:
        return "action_automatic_data_preprocessing"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        raw_data = tracker.get_slot("raw_data")
        if not raw_data:
            dispatcher.utter_message("Aucune donn√©e brute fournie.")
            return []

        try:
            data = pd.DataFrame(eval(raw_data))

            # Pr√©traitement automatique
            data = data.dropna()  # Suppression des valeurs manquantes
            data = pd.get_dummies(data)  # Encodage des variables cat√©gorielles
            data = (data - data.mean()) / data.std()  # Normalisation des donn√©es

            dispatcher.utter_message(f"Pr√©traitement des donn√©es effectu√© :\n{data.head()}")
            return [SlotSet("preprocessed_data", data)]

        except Exception as e:
            logger.error(f"Erreur lors du pr√©traitement des donn√©es : {e}")
            dispatcher.utter_message("Une erreur est survenue lors du pr√©traitement des donn√©es.")
            return []

class ActionModelEnsemble(Action):
    def name(self) -> str:
        return "action_model_ensemble"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        models = tracker.get_slot("models")  # Liste de mod√®les √† combiner
        X_train = tracker.get_slot("X_train")
        y_train = tracker.get_slot("y_train")

        if not models or X_train is None or y_train is None:
            dispatcher.utter_message("Mod√®les ou donn√©es manquants.")
            return []

        try:
            from sklearn.ensemble import VotingClassifier

            # Cr√©er un mod√®le d'ensemble
            ensemble_model = VotingClassifier(estimators=[(f"model{i}", model) for i, model in enumerate(models)], voting="hard")
            ensemble_model.fit(X_train, y_train)

            # √âvaluer le mod√®le d'ensemble
            accuracy = ensemble_model.score(X_train, y_train)
            dispatcher.utter_message(f"Mod√®le d'ensemble cr√©√© avec succ√®s. Pr√©cision : {accuracy:.2f}")
            return [SlotSet("ensemble_model", ensemble_model)]

        except Exception as e:
            logger.error(f"Erreur lors de la cr√©ation du mod√®le d'ensemble : {e}")
            dispatcher.utter_message("Erreur lors de la cr√©ation du mod√®le d'ensemble.")
            return []


class ActionModelEvaluationVisualization(Action):
    def name(self) -> str:
        return "action_model_evaluation_visualization"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        model = tracker.get_slot("model")
        X_test = tracker.get_slot("X_test")
        y_test = tracker.get_slot("y_test")

        if not model or X_test is None or y_test is None:
            dispatcher.utter_message("Mod√®le ou donn√©es de test manquants.")
            return []

        try:
            from sklearn.metrics import roc_curve, confusion_matrix, auc
            import seaborn as sns

            # Pr√©diction et √©valuation
            y_pred = model.predict(X_test)
            cm = confusion_matrix(y_test, y_pred)

            # Courbe ROC
            fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])
            roc_auc = auc(fpr, tpr)

            # Visualisation de la matrice de confusion
            sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
            plt.title("Matrice de Confusion")
            plt.savefig("confusion_matrix.png")
            plt.close()

            # Visualisation de la courbe ROC
            plt.figure()
            plt.plot(fpr, tpr, color="darkorange", lw=2, label=f"ROC curve (area = {roc_auc:.2f})")
            plt.plot([0, 1], [0, 1], color="navy", lw=2, linestyle="--")
            plt.xlim([0.0, 1.0])
            plt.ylim([0.0, 1.05])
            plt.xlabel("False Positive Rate")
            plt.ylabel("True Positive Rate")
            plt.title("Receiver Operating Characteristic (ROC) Curve")
            plt.savefig("roc_curve.png")
            plt.close()

            dispatcher.utter_message("√âvaluation du mod√®le effectu√©e. Graphiques g√©n√©r√©s : confusion_matrix.png, roc_curve.png.")
            return []

        except Exception as e:
            logger.error(f"Erreur lors de l'√©valuation du mod√®le : {e}")
            dispatcher.utter_message("Erreur lors de l'√©valuation du mod√®le.")
            return []



class AdvancedDataInsightGenerator:
    """
    Classe pour analyser des donn√©es avanc√©es, avec des fonctionnalit√©s modulaires telles que :
    - Analyse statistique
    - D√©tection des anomalies
    - Pr√©vision temporelle
    """

    def __init__(self):
        # Configuration du r√©pertoire pour les visualisations
        self.visualization_dir = "visualizations"
        os.makedirs(self.visualization_dir, exist_ok=True)
        logging.basicConfig(level=logging.INFO)

    def analyze_statistics(self, data: np.ndarray) -> dict:
        """
        Calcule des statistiques descriptives de base.

        Args:
            data (np.ndarray): Tableau numpy contenant les donn√©es.

        Returns:
            dict: R√©sum√© des statistiques descriptives.
        """
        try:
            if data.size == 0:
                raise ValueError("Les donn√©es fournies sont vides.")

            statistics = {
                "mean": np.mean(data),
                "median": np.median(data),
                "std_dev": np.std(data),
                "variance": np.var(data),
                "min": np.min(data),
                "max": np.max(data),
                "quartiles": np.percentile(data, [25, 50, 75]),
            }

            # G√©n√©rer un graphique de boxplot
            file_path = os.path.join(self.visualization_dir, "statistics_boxplot.png")
            self._generate_boxplot(data, "Distribution des Donn√©es", file_path)

            statistics["boxplot_path"] = file_path
            logging.info("Analyse statistique termin√©e.")
            return statistics
        except Exception as e:
            logging.error(f"Erreur lors de l'analyse statistique : {e}")
            return {"error": str(e)}

    def detect_anomalies(self, data: np.ndarray, contamination: float = 0.1) -> dict:
        """
        D√©tecte des anomalies dans les donn√©es √† l'aide de Isolation Forest.

        Args:
            data (np.ndarray): Tableau numpy contenant les donn√©es.
            contamination (float): Proportion de donn√©es suspect√©es d'√™tre des anomalies.

        Returns:
            dict: R√©sum√© des anomalies d√©tect√©es.
        """
        try:
            if data.size == 0:
                raise ValueError("Les donn√©es fournies sont vides.")

            # Normalisation des donn√©es
            scaler = StandardScaler()
            data_scaled = scaler.fit_transform(data.reshape(-1, 1))

            # Isolation Forest
            model = IsolationForest(contamination=contamination, random_state=42)
            predictions = model.fit_predict(data_scaled)
            anomalies = data[predictions == -1]

            # G√©n√©rer un graphique des anomalies
            file_path = os.path.join(self.visualization_dir, "anomalies_scatter.png")
            self._generate_scatter_plot(data, predictions, "D√©tection des Anomalies", file_path)

            logging.info("D√©tection des anomalies termin√©e.")
            return {
                "anomalies": anomalies.tolist(),
                "total_anomalies": len(anomalies),
                "scatterplot_path": file_path,
            }
        except Exception as e:
            logging.error(f"Erreur lors de la d√©tection des anomalies : {e}")
            return {"error": str(e)}

    def forecast_time_series(self, data_series: pd.DataFrame, periods: int = 7) -> dict:
        """
        Effectue une pr√©vision temporelle avec Prophet.

        Args:
            data_series (pd.DataFrame): S√©rie temporelle au format DataFrame (colonnes 'ds', 'y').
            periods (int): Nombre de p√©riodes √† pr√©voir.

        Returns:
            dict: R√©sultats des pr√©visions.
        """
        try:
            if not {"ds", "y"}.issubset(data_series.columns):
                raise ValueError("Les colonnes requises ('ds', 'y') ne sont pas pr√©sentes.")

            # Mod√®le Prophet
            model = Prophet()
            model.fit(data_series)

            # Pr√©vision
            future = model.make_future_dataframe(periods=periods)
            forecast = model.predict(future)

            # G√©n√©rer un graphique des pr√©visions
            file_path = os.path.join(self.visualization_dir, "forecast_plot.png")
            fig = model.plot(forecast)
            plt.title("Pr√©visions avec Prophet")
            plt.savefig(file_path)
            plt.close(fig)

            logging.info("Pr√©vision temporelle termin√©e.")
            return {
                "forecast": forecast[["ds", "yhat"]].tail(periods).to_dict(orient="records"),
                "forecast_plot_path": file_path,
            }
        except Exception as e:
            logging.error(f"Erreur lors de la pr√©vision temporelle : {e}")
            return {"error": str(e)}

    @staticmethod
    def split_data(data: pd.DataFrame, target: str, test_size: float = 0.2) -> tuple:
        """
        Divise les donn√©es en ensembles d'entra√Ænement et de test.

        Args:
            data (pd.DataFrame): Donn√©es au format DataFrame.
            target (str): Colonne cible.
            test_size (float): Taille de l'ensemble de test.

        Returns:
            tuple: (X_train, X_test, y_train, y_test)
        """
        try:
            X = data.drop(columns=[target])
            y = data[target]
            return train_test_split(X, y, test_size=test_size, random_state=42)
        except Exception as e:
            logging.error(f"Erreur lors de la division des donn√©es : {e}")
            return None, None, None, None

    @staticmethod
    def optimize_hyperparameters(model, param_grid: dict, X_train, y_train) -> dict:
        """
        Optimise les hyperparam√®tres d'un mod√®le avec RandomizedSearchCV.

        Args:
            model: Mod√®le √† optimiser.
            param_grid (dict): Grille des hyperparam√®tres.
            X_train: Donn√©es d'entra√Ænement.
            y_train: √âtiquettes d'entra√Ænement.

        Returns:
            dict: Meilleurs hyperparam√®tres et mod√®le optimis√©.
        """
        try:
            search = RandomizedSearchCV(model, param_grid, cv=3, n_iter=10, random_state=42)
            search.fit(X_train, y_train)
            return {
                "best_model": search.best_estimator_,
                "best_params": search.best_params_,
                "best_score": search.best_score_,
            }
        except Exception as e:
            logging.error(f"Erreur lors de l'optimisation des hyperparam√®tres : {e}")
            return {"error": str(e)}

    @staticmethod
    def _generate_boxplot(data, title, file_path):
        """G√©n√®re un boxplot et le sauvegarde."""
        plt.figure(figsize=(8, 5))
        plt.boxplot(data, vert=False, patch_artist=True, boxprops=dict(facecolor="lightblue"))
        plt.title(title)
        plt.savefig(file_path)
        plt.close()

    @staticmethod
    def _generate_scatter_plot(data, predictions, title, file_path):
        """G√©n√®re un graphique de dispersion et le sauvegarde."""
        plt.figure(figsize=(8, 5))
        plt.scatter(range(len(data)), data, c=predictions, cmap="coolwarm", s=50)
        plt.title(title)
        plt.xlabel("Index")
        plt.ylabel("Valeur")
        plt.savefig(file_path)
        plt.close()

class TimeSeriesProcessor:
    """
    Classe pour analyser, traiter et pr√©voir des s√©ries temporelles.
    """

    def __init__(self):
        self.visualization_dir = "time_series_visualizations"
        os.makedirs(self.visualization_dir, exist_ok=True)
        logging.basicConfig(level=logging.INFO)

    def handle_missing_values(self, data: pd.DataFrame, method: str = "linear") -> pd.DataFrame:
        """
        G√®re les valeurs manquantes dans une s√©rie temporelle.

        Args:
            data (pd.DataFrame): S√©rie temporelle avec colonnes "ds" (date) et "y" (valeur).
            method (str): M√©thode de remplissage, parmi ["linear", "mean", "median", "ffill", "bfill"].

        Returns:
            pd.DataFrame: S√©rie temporelle avec les valeurs manquantes remplac√©es.
        """
        try:
            if "y" not in data.columns or "ds" not in data.columns:
                raise ValueError("Les colonnes requises ('ds', 'y') ne sont pas pr√©sentes.")

            if method in ["linear", "mean", "median"]:
                imputer = SimpleImputer(strategy=method if method != "linear" else "mean")
                data["y"] = imputer.fit_transform(data[["y"]])
                if method == "linear":
                    data["y"] = data["y"].interpolate(method="linear")
            elif method in ["ffill", "bfill"]:
                data["y"] = data["y"].fillna(method=method)
            else:
                raise ValueError(f"M√©thode inconnue : {method}")

            logging.info("Valeurs manquantes trait√©es avec succ√®s.")
            return data
        except Exception as e:
            logging.error(f"Erreur lors du traitement des valeurs manquantes : {e}")
            return None

    def decompose_series(self, data: pd.DataFrame, model: str = "additive") -> dict:
        """
        D√©compose une s√©rie temporelle en composantes : tendance, saisonnalit√© et r√©sidu.

        Args:
            data (pd.DataFrame): S√©rie temporelle avec colonnes "ds" (date) et "y" (valeur).
            model (str): Type de d√©composition ("additive" ou "multiplicative").

        Returns:
            dict: Composantes d√©compos√©es de la s√©rie.
        """
        try:
            if "y" not in data.columns or "ds" not in data.columns:
                raise ValueError("Les colonnes requises ('ds', 'y') ne sont pas pr√©sentes.")

            data = data.set_index("ds")
            decomposition = seasonal_decompose(data["y"], model=model, period=12)

            # G√©n√©rer un graphique des composantes
            file_path = os.path.join(self.visualization_dir, "series_decomposition.png")
            decomposition.plot()
            plt.savefig(file_path)
            plt.close()

            logging.info("D√©composition de la s√©rie temporelle effectu√©e.")
            return {
                "trend": decomposition.trend,
                "seasonal": decomposition.seasonal,
                "residual": decomposition.resid,
                "decomposition_plot": file_path,
            }
        except Exception as e:
            logging.error(f"Erreur lors de la d√©composition de la s√©rie temporelle : {e}")
            return {"error": str(e)}

    def detect_outliers(self, data: pd.DataFrame, threshold: float = 3.0) -> pd.DataFrame:
        """
        D√©tecte les valeurs aberrantes dans une s√©rie temporelle bas√©e sur un seuil.

        Args:
            data (pd.DataFrame): S√©rie temporelle avec colonnes "ds" et "y".
            threshold (float): Seuil pour d√©tecter les outliers (z-score).

        Returns:
            pd.DataFrame: S√©rie temporelle marqu√©e avec une colonne "is_outlier".
        """
        try:
            if "y" not in data.columns or "ds" not in data.columns:
                raise ValueError("Les colonnes requises ('ds', 'y') ne sont pas pr√©sentes.")

            # Calcul du Z-score
            data["z_score"] = (data["y"] - data["y"].mean()) / data["y"].std()
            data["is_outlier"] = abs(data["z_score"]) > threshold

            # Visualisation des outliers
            file_path = os.path.join(self.visualization_dir, "outliers_detection.png")
            plt.figure(figsize=(10, 6))
            plt.plot(data["ds"], data["y"], label="S√©rie temporelle")
            plt.scatter(data.loc[data["is_outlier"], "ds"], data.loc[data["is_outlier"], "y"], color="red", label="Outliers")
            plt.legend()
            plt.title("D√©tection des valeurs aberrantes")
            plt.savefig(file_path)
            plt.close()

            logging.info("D√©tection des outliers effectu√©e avec succ√®s.")
            return data
        except Exception as e:
            logging.error(f"Erreur lors de la d√©tection des outliers : {e}")
            return None

    def forecast(self, data: pd.DataFrame, periods: int = 30) -> dict:
        """
        Effectue une pr√©vision sur la s√©rie temporelle.

        Args:
            data (pd.DataFrame): S√©rie temporelle avec colonnes "ds" (date) et "y" (valeur).
            periods (int): Nombre de p√©riodes √† pr√©voir.

        Returns:
            dict: R√©sultats des pr√©visions et graphiques.
        """
        try:
            if "y" not in data.columns or "ds" not in data.columns:
                raise ValueError("Les colonnes requises ('ds', 'y') ne sont pas pr√©sentes.")

            # Mod√®le Prophet
            model = Prophet()
            model.fit(data)

            # Pr√©vision
            future = model.make_future_dataframe(periods=periods)
            forecast = model.predict(future)

            # Graphique des pr√©visions
            forecast_plot_path = os.path.join(self.visualization_dir, "forecast_plot.png")
            fig = model.plot(forecast)
            plt.title("Pr√©visions des s√©ries temporelles")
            plt.savefig(forecast_plot_path)
            plt.close(fig)

            logging.info("Pr√©visions termin√©es avec succ√®s.")
            return {
                "forecast": forecast[["ds", "yhat", "yhat_lower", "yhat_upper"]].tail(periods),
                "forecast_plot_path": forecast_plot_path,
            }
        except Exception as e:
            logging.error(f"Erreur lors de la pr√©vision : {e}")
            return {"error": str(e)}

    def detect_trend_changes(self, data: pd.DataFrame, threshold: float = 0.05) -> pd.DataFrame:
        """
        D√©tecte les changements de tendance dans une s√©rie temporelle.

        Args:
            data (pd.DataFrame): S√©rie temporelle avec colonnes "ds" et "y".
            threshold (float): Seuil pour d√©tecter les changements (en pourcentage).

        Returns:
            pd.DataFrame: S√©rie temporelle avec une colonne "trend_change".
        """
        try:
            if "y" not in data.columns or "ds" not in data.columns:
                raise ValueError("Les colonnes requises ('ds', 'y') ne sont pas pr√©sentes.")

            # Calcul des variations relatives
            data["change"] = data["y"].pct_change().fillna(0)
            data["trend_change"] = abs(data["change"]) > threshold

            logging.info("D√©tection des changements de tendance effectu√©e.")
            return data
        except Exception as e:
            logging.error(f"Erreur lors de la d√©tection des changements de tendance : {e}")
            return None

class DataExplorer:
    """
    Classe pour effectuer une analyse exploratoire automatis√©e sur un jeu de donn√©es.
    """

    def __init__(self):
        self.output_dir = "data_exploration_reports"
        os.makedirs(self.output_dir, exist_ok=True)

    def detect_missing_values(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        D√©tecte et r√©sume les valeurs manquantes dans le DataFrame.

        Args:
            data (pd.DataFrame): Jeu de donn√©es.

        Returns:
            pd.DataFrame: R√©sum√© des valeurs manquantes.
        """
        try:
            missing_summary = data.isnull().sum()
            missing_percentage = (missing_summary / len(data)) * 100
            missing_report = pd.DataFrame({
                "Feature": missing_summary.index,
                "Missing Values": missing_summary.values,
                "Missing Percentage": missing_percentage.values
            }).sort_values(by="Missing Values", ascending=False)

            logging.info("R√©sum√© des valeurs manquantes g√©n√©r√©.")
            return missing_report
        except Exception as e:
            logging.error(f"Erreur lors de la d√©tection des valeurs manquantes : {e}")
            return None

    def visualize_distributions(self, data: pd.DataFrame, save: bool = True) -> str:
        """
        Visualise les distributions des variables num√©riques.

        Args:
            data (pd.DataFrame): Jeu de donn√©es.
            save (bool): Si True, sauvegarde le graphique.

        Returns:
            str: Chemin du fichier graphique.
        """
        try:
            numeric_columns = data.select_dtypes(include=np.number).columns
            if len(numeric_columns) == 0:
                return "Aucune colonne num√©rique √† visualiser."

            plt.figure(figsize=(12, 8))
            for i, column in enumerate(numeric_columns, 1):
                plt.subplot(3, 3, i)
                sns.histplot(data[column], kde=True, bins=30, color="blue", alpha=0.7)
                plt.title(f"Distribution - {column}")
            plt.tight_layout()

            file_path = os.path.join(self.output_dir, "distributions.png")
            if save:
                plt.savefig(file_path)
                plt.close()
                logging.info(f"Visualisation des distributions sauvegard√©e : {file_path}")
                return file_path
            else:
                plt.show()
        except Exception as e:
            logging.error(f"Erreur lors de la visualisation des distributions : {e}")
            return None

    def generate_correlation_heatmap(self, data: pd.DataFrame, save: bool = True) -> str:
        """
        G√©n√®re une carte de chaleur des corr√©lations.

        Args:
            data (pd.DataFrame): Jeu de donn√©es.
            save (bool): Si True, sauvegarde le graphique.

        Returns:
            str: Chemin du fichier graphique.
        """
        try:
            numeric_data = data.select_dtypes(include=np.number)
            if numeric_data.shape[1] < 2:
                return "Pas assez de colonnes num√©riques pour calculer les corr√©lations."

            correlation_matrix = numeric_data.corr()
            plt.figure(figsize=(10, 8))
            sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
            plt.title("Carte de chaleur des corr√©lations")

            file_path = os.path.join(self.output_dir, "correlation_heatmap.png")
            if save:
                plt.savefig(file_path)
                plt.close()
                logging.info(f"Carte de chaleur sauvegard√©e : {file_path}")
                return file_path
            else:
                plt.show()
        except Exception as e:
            logging.error(f"Erreur lors de la g√©n√©ration de la carte de chaleur : {e}")
            return None

    def perform_pca(self, data: pd.DataFrame, n_components: int = 2) -> pd.DataFrame:
        """
        Effectue une analyse en composantes principales (PCA).

        Args:
            data (pd.DataFrame): Jeu de donn√©es.
            n_components (int): Nombre de composantes principales.

        Returns:
            pd.DataFrame: R√©sultats de la PCA.
        """
        try:
            numeric_data = data.select_dtypes(include=np.number).dropna()
            pca = PCA(n_components=n_components)
            pca_result = pca.fit_transform(numeric_data)

            pca_df = pd.DataFrame(pca_result, columns=[f"PC{i+1}" for i in range(n_components)])
            pca_df["Explained Variance"] = pca.explained_variance_ratio_

            logging.info("PCA effectu√©e avec succ√®s.")
            return pca_df
        except Exception as e:
            logging.error(f"Erreur lors de l'analyse PCA : {e}")
            return None

    def generate_interactive_report(self, data: pd.DataFrame) -> str:
        """
        G√©n√®re un rapport interactif complet pour l'analyse des donn√©es.

        Args:
            data (pd.DataFrame): Jeu de donn√©es.

        Returns:
            str: Chemin vers le rapport interactif.
        """
        try:
            report = ProfileReport(data, title="Rapport Exploratoire", explorative=True)
            file_path = os.path.join(self.output_dir, "exploratory_report.html")
            report.to_file(file_path)
            logging.info(f"Rapport exploratoire g√©n√©r√© : {file_path}")
            return file_path
        except Exception as e:
            logging.error(f"Erreur lors de la g√©n√©ration du rapport interactif : {e}")
            return None

class AdaptiveDataAnalyzer:
    """
    Classe pour une analyse intelligente des donn√©es avec des fonctionnalit√©s adaptatives.
    """

    def __init__(self, output_dir="adaptive_analysis_outputs"):
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)

    def summarize_data(self, data: pd.DataFrame) -> dict:
        """
        G√©n√®re un r√©sum√© statistique intelligent des donn√©es.

        Args:
            data (pd.DataFrame): Jeu de donn√©es.

        Returns:
            dict: R√©sum√© contenant des statistiques descriptives.
        """
        try:
            numeric_summary = data.describe(include=[np.number]).T
            categorical_summary = data.describe(include=["object"]).T

            summary = {
                "numeric_summary": numeric_summary.to_dict(),
                "categorical_summary": categorical_summary.to_dict(),
                "missing_values": data.isnull().sum().to_dict(),
            }
            return summary
        except Exception as e:
            return {"error": f"Erreur lors du r√©sum√© des donn√©es : {e}"}

    def detect_anomalies(self, data: pd.DataFrame, contamination: float = 0.1) -> dict:
        """
        D√©tecte les anomalies dans les donn√©es num√©riques en utilisant Isolation Forest.

        Args:
            data (pd.DataFrame): Jeu de donn√©es.
            contamination (float): Proportion des anomalies.

        Returns:
            dict: R√©sultats de la d√©tection des anomalies.
        """
        try:
            numeric_data = data.select_dtypes(include=np.number).dropna()
            model = IsolationForest(contamination=contamination, random_state=42)
            predictions = model.fit_predict(numeric_data)
            anomalies = numeric_data[predictions == -1]

            return {
                "anomalies": anomalies.to_dict(),
                "anomaly_indices": anomalies.index.tolist(),
            }
        except Exception as e:
            return {"error": f"Erreur lors de la d√©tection des anomalies : {e}"}

    def perform_time_series_analysis(self, data: pd.Series, period: int = None) -> dict:
        """
        Analyse une s√©rie temporelle pour d√©tecter des tendances et des variations saisonni√®res.

        Args:
            data (pd.Series): S√©rie temporelle.
            period (int): P√©riode pour la d√©composition (par exemple, 12 pour des donn√©es mensuelles).

        Returns:
            dict: R√©sultats de la d√©composition de la s√©rie temporelle.
        """
        try:
            decomposition = seasonal_decompose(data, period=period, model="additive")
            decomposition_fig = self._plot_time_series_decomposition(decomposition, data.name)
            return {
                "trend": decomposition.trend.to_dict(),
                "seasonal": decomposition.seasonal.to_dict(),
                "residual": decomposition.resid.to_dict(),
                "decomposition_plot": decomposition_fig,
            }
        except Exception as e:
            return {"error": f"Erreur lors de l'analyse de la s√©rie temporelle : {e}"}

    def perform_pca(self, data: pd.DataFrame, n_components: int = 2) -> dict:
        """
        Effectue une analyse en composantes principales (PCA) sur les donn√©es.

        Args:
            data (pd.DataFrame): Jeu de donn√©es.
            n_components (int): Nombre de composantes principales.

        Returns:
            dict: R√©sultats de la PCA (composantes principales et variance expliqu√©e).
        """
        try:
            numeric_data = data.select_dtypes(include=np.number).dropna()
            pca = PCA(n_components=n_components)
            components = pca.fit_transform(numeric_data)

            explained_variance = pca.explained_variance_ratio_
            pca_df = pd.DataFrame(components, columns=[f"PC{i+1}" for i in range(n_components)])

            return {
                "components": pca_df.to_dict(),
                "explained_variance": explained_variance.tolist(),
            }
        except Exception as e:
            return {"error": f"Erreur lors de la PCA : {e}"}

    def generate_insights_report(self, data: pd.DataFrame) -> str:
        """
        G√©n√®re un rapport contenant les insights principaux des donn√©es.

        Args:
            data (pd.DataFrame): Jeu de donn√©es.

        Returns:
            str: Chemin du fichier rapport g√©n√©r√©.
        """
        try:
            insights = self.summarize_data(data)
            anomalies = self.detect_anomalies(data)
            pca_results = self.perform_pca(data)

            # G√©n√©rer le rapport
            report_path = os.path.join(self.output_dir, "data_insights_report.txt")
            with open(report_path, "w") as report_file:
                report_file.write("=== Insights Report ===\n\n")
                report_file.write("=== R√©sum√© des donn√©es ===\n")
                report_file.write(f"{pd.DataFrame(insights['numeric_summary']).to_string()}\n\n")
                report_file.write("=== Anomalies d√©tect√©es ===\n")
                report_file.write(f"{anomalies}\n\n")
                report_file.write("=== R√©sultats de la PCA ===\n")
                report_file.write(f"{pca_results}\n\n")

            return report_path
        except Exception as e:
            return f"Erreur lors de la g√©n√©ration du rapport : {e}"

    def _plot_time_series_decomposition(self, decomposition, series_name: str) -> str:
        """
        Cr√©e un graphique pour la d√©composition de la s√©rie temporelle.

        Args:
            decomposition: R√©sultats de la d√©composition (statsmodels).
            series_name (str): Nom de la s√©rie.

        Returns:
            str: Chemin du fichier du graphique g√©n√©r√©.
        """
        fig, axes = plt.subplots(4, 1, figsize=(12, 8), sharex=True)
        axes[0].plot(decomposition.observed, label="Observed")
        axes[1].plot(decomposition.trend, label="Trend")
        axes[2].plot(decomposition.seasonal, label="Seasonal")
        axes[3].plot(decomposition.resid, label="Residual")

        for ax, title in zip(axes, ["Observed", "Trend", "Seasonal", "Residual"]):
            ax.set_title(title)
            ax.legend()

        plt.tight_layout()
        file_path = os.path.join(self.output_dir, f"{series_name}_decomposition.png")
        plt.savefig(file_path)
        plt.close()
        return file_path

class ActionAnalyzeData(Action):
    def name(self):
        return "action_analyze_data"

    def run(self, dispatcher, tracker, domain):
        data = pd.DataFrame(eval(tracker.get_slot("data_frame")))
        analyzer = AdaptiveDataAnalyzer()

        insights_report = analyzer.generate_insights_report(data)
        dispatcher.utter_message(f"Rapport g√©n√©r√© : {insights_report}")
        return []

class UltimateDataPipelineManager(Action):
    def name(self) -> str:
        return "action_ultimate_data_pipeline_manager"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # √âtape 1 : R√©cup√©rer les donn√©es utilisateur
        raw_data = tracker.get_slot("raw_data")
        analysis_goal = tracker.get_slot("analysis_goal") or "exploration"

        if not raw_data:
            dispatcher.utter_message(text="Aucune donn√©e fournie. Peux-tu me donner tes donn√©es‚ÄØ?")
            return []

        try:
            # √âtape 2 : Convertir les donn√©es en DataFrame
            data = pd.DataFrame(ast.literal_eval(raw_data))

            # √âtape 3 : Ex√©cuter le pipeline en fonction de l'objectif
            if analysis_goal == "exploration":
                return self.perform_exploration(data, dispatcher)
            elif analysis_goal == "anomalie":
                return self.detect_anomalies(data, dispatcher)
            elif analysis_goal == "clustering":
                return self.perform_clustering(data, dispatcher)
            elif analysis_goal == "prediction":
                return self.perform_prediction(data, tracker, dispatcher)
            else:
                dispatcher.utter_message(text="Objectif non reconnu. Choisissez : exploration, anomalie, clustering ou prediction.")
                return []

        except Exception as e:
            dispatcher.utter_message(text=f"Une erreur est survenue : {str(e)}")
            return []

    def perform_exploration(self, data: pd.DataFrame, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Analyse exploratoire des donn√©es."""
        try:
            summary = data.describe().to_string()
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)

            # G√©n√©rer des visualisations
            pairplot_path = os.path.join(output_dir, "pairplot.png")
            sns.pairplot(data)
            plt.savefig(pairplot_path)
            plt.close()

            # Retourner le r√©sultat √† l'utilisateur
            dispatcher.utter_message(
                text=f"Voici un r√©sum√© des donn√©es :\n{summary}\nUn graphique des relations a √©t√© sauvegard√© sous '{pairplot_path}'."
            )
            return []
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de l'analyse exploratoire : {str(e)}")
            return []

    def detect_anomalies(self, data: pd.DataFrame, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """D√©tection des anomalies dans les donn√©es."""
        try:
            model = IsolationForest(contamination=0.1, random_state=42)
            predictions = model.fit_predict(data)
            anomalies = data[predictions == -1]

            # Visualisation des anomalies
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            anomaly_path = os.path.join(output_dir, "anomalies.png")

            plt.figure(figsize=(10, 6))
            sns.scatterplot(x=data.iloc[:, 0], y=data.iloc[:, 1], hue=(predictions == -1), palette="coolwarm")
            plt.title("D√©tection des anomalies")
            plt.savefig(anomaly_path)
            plt.close()

            dispatcher.utter_message(
                text=f"D√©tection des anomalies termin√©e. Un graphique a √©t√© sauvegard√© sous '{anomaly_path}'."
            )
            return []
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de la d√©tection des anomalies : {str(e)}")
            return []

    def perform_clustering(self, data: pd.DataFrame, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Clustering des donn√©es."""
        try:
            model = KMeans(n_clusters=3, random_state=42)
            labels = model.fit_predict(data)

            # Visualisation des clusters
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            cluster_path = os.path.join(output_dir, "clusters.png")

            plt.figure(figsize=(10, 6))
            sns.scatterplot(x=data.iloc[:, 0], y=data.iloc[:, 1], hue=labels, palette="tab10")
            plt.title("R√©sultat du clustering")
            plt.savefig(cluster_path)
            plt.close()

            dispatcher.utter_message(
                text=f"Clustering termin√©. Un graphique a √©t√© sauvegard√© sous '{cluster_path}'."
            )
            return []
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors du clustering : {str(e)}")
            return []

    def perform_prediction(self, data: pd.DataFrame, tracker: Tracker, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Pr√©dictions bas√©es sur un mod√®le."""
        target = tracker.get_slot("target_variable")
        model_type = tracker.get_slot("model_type") or "random_forest"

        if not target or target not in data.columns:
            dispatcher.utter_message(text="La variable cible est absente ou incorrecte.")
            return []

        try:
            # Pr√©parer les donn√©es
            X = data.drop(columns=[target])
            y = data[target]

            # Choisir et entra√Æner le mod√®le
            if model_type == "random_forest":
                model = RandomForestRegressor(random_state=42)
            elif model_type == "linear_regression":
                model = LinearRegression()
            else:
                dispatcher.utter_message(text="Type de mod√®le non reconnu.")
                return []

            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            model.fit(X_train, y_train)

            # √âvaluation
            predictions = model.predict(X_test)
            r2 = r2_score(y_test, predictions)

            dispatcher.utter_message(
                text=f"Pr√©diction termin√©e avec succ√®s. Coefficient de d√©termination (R¬≤) : {r2:.2f}"
            )
            return [SlotSet("model_predictions", predictions.tolist())]
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors des pr√©dictions : {str(e)}")
            return []

class ModularPipelineOrchestrator(Action):
    def name(self) -> str:
        return "action_modular_pipeline_orchestrator"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain) -> List[Dict[str, Any]]:
        # 1. R√©cup√©rer les donn√©es et le but
        raw_data = tracker.get_slot("raw_data")
        analysis_goal = tracker.get_slot("analysis_goal") or "auto_detect"

        if not raw_data:
            dispatcher.utter_message(text="Aucune donn√©e trouv√©e. Peux-tu les partager‚ÄØ?")
            return []

        try:
            # 2. Conversion des donn√©es
            data = pd.DataFrame(ast.literal_eval(raw_data))

            # 3. D√©tection automatique si n√©cessaire
            if analysis_goal == "auto_detect":
                analysis_goal = self.detect_analysis_goal(data)
                dispatcher.utter_message(
                    text=f"Objectif d√©tect√© automatiquement : {analysis_goal}."
                )

            # 4. Ex√©cuter l‚Äôobjectif du pipeline
            if analysis_goal == "exploration":
                return self.perform_exploration(data, dispatcher)
            elif analysis_goal == "anomalie":
                return self.detect_anomalies(data, dispatcher)
            elif analysis_goal == "clustering":
                return self.perform_clustering(data, dispatcher)
            elif analysis_goal == "prediction":
                return self.perform_prediction(data, tracker, dispatcher)
            elif analysis_goal == "rapport":
                return self.generate_pdf_report(data, dispatcher)
            else:
                dispatcher.utter_message(text="Objectif inconnu. Essayez : exploration, anomalie, clustering, prediction, rapport.")
                return []

        except Exception as e:
            dispatcher.utter_message(text=f"Une erreur s'est produite : {str(e)}")
            return []

    def detect_analysis_goal(self, data: pd.DataFrame) -> str:
        """D√©tecte automatiquement l‚Äôobjectif selon les donn√©es."""
        if {"ds", "y"}.issubset(data.columns):
            return "prediction"
        elif data.select_dtypes(include=["number"]).shape[1] > 0:
            return "exploration"
        elif data.isnull().sum().sum() > 0:
            return "anomalie"
        else:
            return "clustering"

    def perform_exploration(self, data: pd.DataFrame, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Analyse exploratoire des donn√©es."""
        try:
            summary = data.describe().to_string()
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)

            # Pairplot
            pairplot_path = os.path.join(output_dir, "pairplot.png")
            sns.pairplot(data)
            plt.savefig(pairplot_path)
            plt.close()

            dispatcher.utter_message(
                text=f"Analyse exploratoire termin√©e :\n{summary}\nUn graphique des relations a √©t√© g√©n√©r√© : {pairplot_path}"
            )
            return []
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de l'exploration des donn√©es : {str(e)}")
            return []

    def detect_anomalies(self, data: pd.DataFrame, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """D√©tection des anomalies dans les donn√©es."""
        try:
            model = IsolationForest(contamination=0.1, random_state=42)
            predictions = model.fit_predict(data)
            anomalies = data[predictions == -1]

            # Graphique anomalies
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            anomaly_path = os.path.join(output_dir, "anomalies.png")

            plt.figure(figsize=(10, 6))
            sns.scatterplot(x=data.iloc[:, 0], y=data.iloc[:, 1], hue=(predictions == -1), palette="coolwarm")
            plt.title("Anomalies d√©tect√©es")
            plt.savefig(anomaly_path)
            plt.close()

            dispatcher.utter_message(
                text=f"Anomalies d√©tect√©es. R√©sultat sauvegard√© sous '{anomaly_path}'."
            )
            return []
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de la d√©tection des anomalies : {str(e)}")
            return []

    def perform_clustering(self, data: pd.DataFrame, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Clustering et visualisation."""
        try:
            kmeans = KMeans(n_clusters=3, random_state=42)
            labels = kmeans.fit_predict(data)

            # Graphique clusters
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            cluster_path = os.path.join(output_dir, "clusters.png")

            plt.figure(figsize=(10, 6))
            sns.scatterplot(x=data.iloc[:, 0], y=data.iloc[:, 1], hue=labels, palette="tab10")
            plt.title("Clusters d√©tect√©s")
            plt.savefig(cluster_path)
            plt.close()

            dispatcher.utter_message(
                text=f"Clustering termin√©. R√©sultat sauvegard√© sous '{cluster_path}'."
            )
            return []
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors du clustering : {str(e)}")
            return []

    def perform_prediction(self, data: pd.DataFrame, tracker: Tracker, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Pr√©diction automatique bas√©e sur un mod√®le."""
        target_variable = tracker.get_slot("target_variable")
        model_type = tracker.get_slot("model_type") or "random_forest"

        if not target_variable or target_variable not in data.columns:
            dispatcher.utter_message(text="La variable cible est absente ou incorrecte.")
            return []

        try:
            X = data.drop(columns=[target_variable])
            y = data[target_variable]

            # Choix du mod√®le
            if model_type == "random_forest":
                model = RandomForestRegressor(random_state=42)
            elif model_type == "linear_regression":
                model = LinearRegression()
            else:
                dispatcher.utter_message(text="Mod√®le non reconnu.")
                return []

            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            model.fit(X_train, y_train)

            predictions = model.predict(X_test)
            r2 = r2_score(y_test, predictions)

            dispatcher.utter_message(
                text=f"Pr√©diction effectu√©e avec succ√®s. R¬≤ : {r2:.2f}"
            )
            return [SlotSet("model_predictions", predictions.tolist())]
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors des pr√©dictions : {str(e)}")
            return []

    def generate_pdf_report(self, data: pd.DataFrame, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """G√©n√©ration d‚Äôun rapport consolid√© en PDF."""
        try:
            output_dir = "reports"
            os.makedirs(output_dir, exist_ok=True)
            report_path = os.path.join(output_dir, "data_report.pdf")

            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", size=12)

            # R√©sum√© des donn√©es
            pdf.cell(200, 10, txt="Rapport des donn√©es", ln=True, align="C")
            summary = data.describe().to_string()
            pdf.multi_cell(0, 10, txt=summary)

            # Ajouter les graphiques
            for plot_file in os.listdir("visualizations"):
                pdf.add_page()
                pdf.image(os.path.join("visualizations", plot_file), x=10, y=30, w=180)

            # Sauvegarder le PDF
            pdf.output(report_path)

            dispatcher.utter_message(
                text=f"Rapport g√©n√©r√© avec succ√®s : {report_path}"
            )
            return []
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de la g√©n√©ration du rapport : {str(e)}")
            return []

class ActionSaveData(Action):
    def name(self) -> str:
        return "action_save_data"

    def run(self, dispatcher, tracker, domain):
        user_data = tracker.get_slot('user_data')
        dispatcher.utter_message(text=f"Vos donn√©es {user_data} ont √©t√© sauvegard√©es avec succ√®s!")
        # Simule la sauvegarde
        return [SlotSet("data_saved", True)]

class ActionSearchInfo(Action):
    def name(self) -> str:
        return "action_search_info"

    def run(self, dispatcher, tracker, domain):
        query = tracker.get_slot('search_query')
        response = requests.get(f"https://api.duckduckgo.com/?q={query}&format=json")
        data = response.json()
        dispatcher.utter_message(text=f"Voici ce que j'ai trouv√© : {data['AbstractText'] or 'Aucune information trouv√©e.'}")
        return []

class VisualizationUtils:
    """Classe utilitaire pour la cr√©ation et la sauvegarde des graphiques."""

    @staticmethod
    def create_output_dir(output_dir="outputs"):
        """Cr√©e un r√©pertoire pour les sorties."""
        os.makedirs(output_dir, exist_ok=True)
        return output_dir

    @staticmethod
    def save_plot(fig, filename, output_dir="outputs"):
        """Sauvegarde un graphique sous forme de fichier."""
        path = os.path.join(output_dir, filename)
        fig.savefig(path)
        plt.close(fig)
        return path

class BasePipeline:
    """
    Classe de base pour les pipelines de traitement de donn√©es.
    Fournit des m√©thodes utilitaires communes.
    """

    def __init__(self):
        self.output_dir = VisualizationUtils.create_output_dir("pipeline_outputs")

    def validate_data(self, data):
        """Valide les donn√©es pour s'assurer qu'elles sont exploitables."""
        if data is None or data.empty:
            raise ValueError("Les donn√©es fournies sont vides ou invalides.")
        return data

class DataExplorer(BasePipeline):
    """Pipeline d'exploration des donn√©es."""

    def analyze_statistics(self, data):
        """Calcule les statistiques descriptives."""
        try:
            data = self.validate_data(data)
            numeric_summary = data.describe(include="number")
            categorical_summary = data.describe(include="object")

            return {
                "numeric_summary": numeric_summary.to_dict(),
                "categorical_summary": categorical_summary.to_dict(),
            }
        except Exception as e:
            raise RuntimeError(f"Erreur dans l'analyse des statistiques : {e}")

    def visualize_distributions(self, data):
        """G√©n√®re un histogramme des distributions des colonnes num√©riques."""
        try:
            data = self.validate_data(data)
            numeric_columns = data.select_dtypes(include="number").columns

            if not numeric_columns.any():
                return "Aucune donn√©e num√©rique √† visualiser."

            fig, axes = plt.subplots(1, len(numeric_columns), figsize=(15, 5))
            for i, column in enumerate(numeric_columns):
                sns.histplot(data[column], kde=True, ax=axes[i])
                axes[i].set_title(f"Distribution - {column}")

            filename = VisualizationUtils.save_plot(fig, "distributions.png", self.output_dir)
            return {"distribution_plot": filename}
        except Exception as e:
            raise RuntimeError(f"Erreur dans la visualisation des distributions : {e}")

    def generate_correlation_heatmap(self, data):
        """G√©n√®re une carte de chaleur des corr√©lations."""
        try:
            data = self.validate_data(data)
            numeric_data = data.select_dtypes(include="number")

            if numeric_data.shape[1] < 2:
                return "Pas assez de donn√©es num√©riques pour g√©n√©rer la carte de chaleur."

            fig, ax = plt.subplots(figsize=(10, 8))
            sns.heatmap(numeric_data.corr(), annot=True, cmap="coolwarm", ax=ax)
            ax.set_title("Carte de Chaleur des Corr√©lations")

            filename = VisualizationUtils.save_plot(fig, "correlation_heatmap.png", self.output_dir)
            return {"correlation_heatmap": filename}
        except Exception as e:
            raise RuntimeError(f"Erreur dans la g√©n√©ration de la carte de chaleur : {e}")

class AdvancedDataAnalyzer(BasePipeline):
    """Pipeline d'analyse avanc√©e."""

    def detect_anomalies(self, data, contamination=0.1):
        """D√©tecte les anomalies √† l'aide d'Isolation Forest."""
        try:
            data = self.validate_data(data)
            model = IsolationForest(contamination=contamination, random_state=42)
            predictions = model.fit_predict(data)

            anomalies = data[predictions == -1]
            return {"anomalies": anomalies.to_dict(orient="records")}
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la d√©tection des anomalies : {e}")

    def perform_clustering(self, data, n_clusters=3):
        """Effectue un clustering sur les donn√©es."""
        try:
            data = self.validate_data(data)
            model = KMeans(n_clusters=n_clusters, random_state=42)
            labels = model.fit_predict(data)

            data["Cluster"] = labels
            return {"clusters": data.to_dict(orient="records")}
        except Exception as e:
            raise RuntimeError(f"Erreur lors du clustering : {e}")

class ModelTrainer(BasePipeline):
    """Pipeline d'entra√Ænement de mod√®les pr√©dictifs."""

    def train_model(self, data, target_column, model_type="random_forest"):
        """Entra√Æne un mod√®le pr√©dictif."""
        try:
            data = self.validate_data(data)

            if target_column not in data.columns:
                raise ValueError("La colonne cible est absente.")

            X = data.drop(columns=[target_column])
            y = data[target_column]
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

            if model_type == "random_forest":
                model = RandomForestRegressor(random_state=42)
            elif model_type == "linear_regression":
                model = LinearRegression()
            else:
                raise ValueError("Type de mod√®le non support√©.")

            model.fit(X_train, y_train)
            predictions = model.predict(X_test)
            r2 = r2_score(y_test, predictions)

            return {"model": model, "r2_score": r2, "predictions": predictions.tolist()}
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'entra√Ænement du mod√®le : {e}")

class TimeSeriesProcessor(BasePipeline):
    """Classe pour analyser, traiter et pr√©voir des s√©ries temporelles."""

    def decompose_series(self, data, model="additive"):
        """D√©compose une s√©rie temporelle."""
        try:
            data = self.validate_data(data)
            decomposition = seasonal_decompose(data, model=model)
            return {
                "trend": decomposition.trend,
                "seasonal": decomposition.seasonal,
                "residual": decomposition.resid,
            }
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la d√©composition de la s√©rie temporelle : {e}")

    def forecast(self, data, periods=7):
        """Effectue une pr√©vision √† l'aide de Prophet."""
        try:
            model = Prophet()
            model.fit(data)
            future = model.make_future_dataframe(periods=periods)
            forecast = model.predict(future)

            return forecast
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la pr√©vision : {e}")

class DataPreprocessor(BasePipeline):
    """Pipeline pour le pr√©traitement des donn√©es."""

    def handle_missing_values(self, data, strategy="mean"):
        """G√®re les valeurs manquantes dans les colonnes num√©riques."""
        try:
            data = self.validate_data(data)
            imputer = SimpleImputer(strategy=strategy)
            data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)
            return data
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la gestion des valeurs manquantes : {e}")

    def normalize_data(self, data):
        """Normalise les colonnes num√©riques."""
        try:
            data = self.validate_data(data)
            scaler = StandardScaler()
            numeric_columns = data.select_dtypes(include=["number"]).columns
            data[numeric_columns] = scaler.fit_transform(data[numeric_columns])
            return data
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la normalisation : {e}")

    def encode_categorical_data(self, data):
        """Encode les colonnes cat√©goriques en format num√©rique."""
        try:
            data = self.validate_data(data)
            categorical_columns = data.select_dtypes(include=["object"]).columns
            for column in categorical_columns:
                data[column] = LabelEncoder().fit_transform(data[column])
            return data
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'encodage des donn√©es cat√©goriques : {e}")

class DataExporter:
    """Classe pour exporter les donn√©es sous diff√©rents formats."""

    @staticmethod
    def export_to_csv(data, filename="data_export.csv", output_dir="exports"):
        """Exporte les donn√©es au format CSV."""
        try:
            os.makedirs(output_dir, exist_ok=True)
            path = os.path.join(output_dir, filename)
            data.to_csv(path, index=False)
            return path
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'exportation CSV : {e}")

    @staticmethod
    def export_to_json(data, filename="data_export.json", output_dir="exports"):
        """Exporte les donn√©es au format JSON."""
        try:
            os.makedirs(output_dir, exist_ok=True)
            path = os.path.join(output_dir, filename)
            data.to_json(path, orient="records")
            return path
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'exportation JSON : {e}")

class FeatureSelector(BasePipeline):
    """Pipeline pour la s√©lection des caract√©ristiques les plus pertinentes."""

    def select_best_features(self, data, target_column, k=5):
        """S√©lectionne les k meilleures caract√©ristiques en fonction de leur importance statistique."""
        try:
            data = self.validate_data(data)
            if target_column not in data.columns:
                raise ValueError("La colonne cible est absente.")

            X = data.drop(columns=[target_column])
            y = data[target_column]
            selector = SelectKBest(score_func=f_classif, k=k)
            selector.fit(X, y)

            selected_columns = X.columns[selector.get_support()]
            return selected_columns.tolist()
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la s√©lection des caract√©ristiques : {e}")

class BiasAnalyzer(BasePipeline):
    """Analyse les biais potentiels dans les pr√©dictions d'un mod√®le."""

    def detect_bias(self, predictions, ground_truth, group_column):
        """Analyse les biais en fonction d'une colonne cat√©gorique."""
        try:
            data = pd.DataFrame({"predictions": predictions, "ground_truth": ground_truth})
            confusion = pd.crosstab(data["predictions"], data["ground_truth"])
            bias_summary = confusion.div(confusion.sum(axis=1), axis=0).round(2)
            return {"confusion_matrix": confusion.to_dict(), "bias_summary": bias_summary.to_dict()}
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'analyse des biais : {e}")

class ActiveLearningManager(BasePipeline):
    """Pipeline pour l'apprentissage actif."""

    def select_uncertain_samples(self, model, data, n_samples=10):
        """Identifie les √©chantillons avec les pr√©dictions les plus incertaines."""
        try:
            data = self.validate_data(data)
            proba = model.predict_proba(data)
            uncertainty = 1 - proba.max(axis=1)  # Inverse de la confiance
            uncertain_indices = uncertainty.argsort()[-n_samples:]
            return data.iloc[uncertain_indices].to_dict(orient="records")
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la s√©lection des √©chantillons incertains : {e}")

class ModelEvaluator:
    """Classe pour √©valuer les performances des mod√®les."""

    @staticmethod
    def evaluate_model(y_true, y_pred, y_proba=None):
        """√âvalue un mod√®le sur plusieurs m√©triques."""
        try:
            metrics = {
                "accuracy": accuracy_score(y_true, y_pred),
                "f1_score": f1_score(y_true, y_pred, average="weighted"),
            }
            if y_proba is not None:
                metrics["roc_auc"] = roc_auc_score(y_true, y_proba, multi_class="ovr")
            return metrics
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'√©valuation du mod√®le : {e}")

class HyperparameterOptimizer:
    """Pipeline pour optimiser les hyperparam√®tres des mod√®les."""

    @staticmethod
    def optimize_model(model, param_grid, X_train, y_train, method="grid", n_iter=10):
        """Optimise les hyperparam√®tres avec Grid Search ou Randomized Search."""
        try:
            if method == "grid":
                search = GridSearchCV(model, param_grid, cv=3, scoring="accuracy")
            elif method == "random":
                search = RandomizedSearchCV(model, param_grid, n_iter=n_iter, cv=3, scoring="accuracy", random_state=42)
            else:
                raise ValueError("M√©thode non support√©e : choisissez 'grid' ou 'random'.")

            search.fit(X_train, y_train)
            return {"best_model": search.best_estimator_, "best_params": search.best_params_}
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'optimisation des hyperparam√®tres : {e}")

class RealTimePredictor:
    """Pipeline pour effectuer des pr√©dictions en temps r√©el."""

    @staticmethod
    def predict(model, data):
        """Effectue une pr√©diction avec un mod√®le donn√©."""
        try:
            data = pd.DataFrame(data)
            predictions = model.predict(data)
            return {"predictions": predictions.tolist()}
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la pr√©diction en temps r√©el : {e}")

class DashboardGenerator:
    """G√©n√®re des tableaux de bord interactifs."""

    def create_scatter_dashboard(self, data, x_col, y_col, color_col=None):
        """G√©n√®re un graphique de dispersion interactif."""
        try:
            fig = px.scatter(data, x=x_col, y=y_col, color=color_col, title="Tableau de Bord")
            fig.show()
            return fig
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la cr√©ation du tableau de bord : {e}")

class TimeSeriesForecaster:
    """Classe pour la pr√©vision des s√©ries temporelles."""

    def forecast_with_prophet(self, data, periods=30):
        """
        Pr√©vision avec Prophet.
        Args:
            data (pd.DataFrame): Donn√©es avec colonnes 'ds' (date) et 'y' (valeur).
            periods (int): Nombre de p√©riodes √† pr√©voir.
        Returns:
            dict: R√©sultats de la pr√©vision et graphique.
        """
        try:
            if not {"ds", "y"}.issubset(data.columns):
                raise ValueError("Les colonnes 'ds' et 'y' sont n√©cessaires.")
            model = Prophet()
            model.fit(data)
            future = model.make_future_dataframe(periods=periods)
            forecast = model.predict(future)

            # Sauvegarder le graphique
            plot_path = "time_series_forecast_prophet.png"
            model.plot(forecast).savefig(plot_path)

            return {"forecast": forecast, "plot_path": plot_path}
        except Exception as e:
            raise RuntimeError(f"Erreur dans la pr√©vision avec Prophet : {e}")

    def forecast_with_arima(self, data, order=(1, 1, 1)):
        """
        Pr√©vision avec ARIMA.
        Args:
            data (pd.Series): S√©rie temporelle.
            order (tuple): Param√®tres (p, d, q) pour ARIMA.
        Returns:
            dict: R√©sultats de la pr√©vision et graphique.
        """
        try:
            model = ARIMA(data, order=order)
            fitted_model = model.fit()
            forecast = fitted_model.forecast(steps=30)

            # Sauvegarder le graphique
            plot_path = "time_series_forecast_arima.png"
            plt.figure()
            plt.plot(data, label="Historique")
            plt.plot(range(len(data), len(data) + len(forecast)), forecast, label="Pr√©visions")
            plt.legend()
            plt.savefig(plot_path)
            plt.close()

            return {"forecast": forecast.tolist(), "plot_path": plot_path}
        except Exception as e:
            raise RuntimeError(f"Erreur dans la pr√©vision avec ARIMA : {e}")

class CustomPipelineManager:
    """G√®re des pipelines personnalis√©s pour le traitement des donn√©es."""

    def __init__(self, steps=None):
        """
        Initialise le pipeline.
        Args:
            steps (list): Liste des √©tapes du pipeline sous forme de fonctions.
        """
        self.steps = steps or []

    def add_step(self, step):
        """Ajoute une √©tape au pipeline."""
        self.steps.append(step)

    def execute_pipeline(self, data):
        """Ex√©cute les √©tapes du pipeline."""
        try:
            for step in self.steps:
                data = step(data)
            return data
        except Exception as e:
            raise RuntimeError(f"Erreur dans l'ex√©cution du pipeline : {e}")

class AutoMLManager:
    """Automatise la s√©lection du mod√®le et l'optimisation."""

    def __init__(self, models=None):
        self.models = models or {
            "Random Forest": RandomForestClassifier(),
            "Logistic Regression": LogisticRegression(),
            "Support Vector Machine": SVC(),
        }

    def find_best_model(self, X, y, scoring="accuracy"):
        """
        Trouve le meilleur mod√®le parmi une liste.
        Args:
            X (pd.DataFrame): Features.
            y (pd.Series): Cible.
            scoring (str): M√©trique de score.
        Returns:
            dict: Meilleur mod√®le et son score.
        """
        results = {}
        for name, model in self.models.items():
            score = cross_val_score(model, X, y, cv=3, scoring=scoring).mean()
            results[name] = score

        best_model_name = max(results, key=results.get)
        best_model = self.models[best_model_name]
        return {"best_model": best_model, "best_score": results[best_model_name]}


class DriftDetector:
    """D√©tecte les changements dans la distribution des donn√©es."""

    def detect_drift(self, reference_data, current_data):
        """
        Compare la distribution des donn√©es de r√©f√©rence et des donn√©es actuelles.
        Args:
            reference_data (pd.DataFrame): Donn√©es de r√©f√©rence.
            current_data (pd.DataFrame): Donn√©es actuelles.
        Returns:
            dict: R√©sum√© des r√©sultats du test.
        """
        try:
            drift_summary = {}
            for column in reference_data.columns:
                statistic, p_value = ks_2samp(reference_data[column], current_data[column])
                drift_summary[column] = {"statistic": statistic, "p_value": p_value}
            return drift_summary
        except Exception as e:
            raise RuntimeError(f"Erreur dans la d√©tection de drift : {e}")


class RealTimeMonitor:
    """Classe pour surveiller les performances en temps r√©el."""

    def monitor_performance(self, model, X, y, threshold=0.8):
        """
        V√©rifie si les performances du mod√®le respectent un seuil.
        Args:
            model: Mod√®le √† √©valuer.
            X (pd.DataFrame): Donn√©es d'entr√©e.
            y (pd.Series): Labels r√©els.
            threshold (float): Seuil de performance minimum.
        Returns:
            bool: Indique si le mod√®le passe le seuil.
        """
        try:
            score = model.score(X, y)
            return score >= threshold
        except Exception as e:
            raise RuntimeError(f"Erreur dans la surveillance des performances : {e}")

class ScenarioSimulator:
    """Simule diff√©rents sc√©narios pour tester les mod√®les."""

    def simulate_scenarios(self, model, data, scenarios):
        """
        Simule l'impact de diff√©rentes modifications des donn√©es.
        Args:
            model: Mod√®le √† √©valuer.
            data (pd.DataFrame): Donn√©es d'entr√©e.
            scenarios (list): Liste de sc√©narios (fonctions de transformation).
        Returns:
            dict: R√©sultats des simulations.
        """
        try:
            results = {}
            for scenario_name, scenario_function in scenarios.items():
                modified_data = scenario_function(data)
                predictions = model.predict(modified_data)
                results[scenario_name] = predictions
            return results
        except Exception as e:
            raise RuntimeError(f"Erreur dans la simulation des sc√©narios : {e}")

class DataBalancer:
    """√âquilibre les classes avec des techniques d'oversampling."""

    def balance_data(self, X, y):
        """
        Utilise SMOTE pour √©quilibrer les classes.
        Args:
            X (pd.DataFrame): Features.
            y (pd.Series): Cible.
        Returns:
            tuple: Donn√©es √©quilibr√©es (X_resampled, y_resampled).
        """
        try:
            smote = SMOTE(random_state=42)
            X_resampled, y_resampled = smote.fit_resample(X, y)
            return X_resampled, y_resampled
        except Exception as e:
            raise RuntimeError(f"Erreur dans l'√©quilibrage des donn√©es : {e}")

class DataVersioningManager:
    """G√®re les versions des jeux de donn√©es."""

    def __init__(self, storage_path="data_versions"):
        self.storage_path = storage_path
        os.makedirs(self.storage_path, exist_ok=True)

    def save_version(self, data: pd.DataFrame, version_name=None):
        """
        Sauvegarde une version des donn√©es.
        Args:
            data (pd.DataFrame): Jeu de donn√©es √† sauvegarder.
            version_name (str): Nom de la version (optionnel).
        Returns:
            str: Chemin du fichier sauvegard√©.
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            version_name = version_name or f"version_{timestamp}.csv"
            file_path = os.path.join(self.storage_path, version_name)
            data.to_csv(file_path, index=False)
            return file_path
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la sauvegarde de la version : {e}")

    def list_versions(self):
        """
        Liste toutes les versions des donn√©es sauvegard√©es.
        Returns:
            list: Liste des fichiers de version disponibles.
        """
        try:
            return [f for f in os.listdir(self.storage_path) if f.endswith(".csv")]
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la liste des versions : {e}")

class OutlierRemover:
    """D√©tecte et supprime les valeurs aberrantes des donn√©es."""

    def remove_outliers(self, data: pd.DataFrame, method="zscore", threshold=3.0):
        """
        Supprime les outliers d'un dataset.
        Args:
            data (pd.DataFrame): Jeu de donn√©es.
            method (str): M√©thode √† utiliser ('zscore' ou 'iqr').
            threshold (float): Seuil pour la d√©tection des outliers.
        Returns:
            pd.DataFrame: Jeu de donn√©es nettoy√©.
        """
        try:
            if method == "zscore":
                from scipy.stats import zscore
                z_scores = zscore(data.select_dtypes(include=[np.number]))
                mask = (abs(z_scores) < threshold).all(axis=1)
            elif method == "iqr":
                Q1 = data.quantile(0.25)
                Q3 = data.quantile(0.75)
                IQR = Q3 - Q1
                mask = ~((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)
            else:
                raise ValueError("M√©thode non reconnue. Choisissez 'zscore' ou 'iqr'.")
            return data[mask]
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la suppression des outliers : {e}")




class FeatureImportanceAnalyzer:
    """Analyse l'importance des caract√©ristiques pour un mod√®le."""

    def compute_feature_importance(self, model, feature_names):
        """
        Calcule l'importance des caract√©ristiques d'un mod√®le.
        Args:
            model: Mod√®le entra√Æn√© (ex. RandomForestClassifier).
            feature_names (list): Liste des noms des caract√©ristiques.
        Returns:
            pd.DataFrame: Importances des caract√©ristiques tri√©es.
        """
        try:
            importances = model.feature_importances_
            importance_df = pd.DataFrame({"Feature": feature_names, "Importance": importances})
            importance_df = importance_df.sort_values(by="Importance", ascending=False)

            # Sauvegarder le graphique
            plt.figure(figsize=(10, 6))
            sns.barplot(data=importance_df, x="Importance", y="Feature", palette="viridis")
            plt.title("Importance des caract√©ristiques")
            plt.tight_layout()
            plt.savefig(importances_plot_path)
            plt.close()

            return {"importance_df": importance_df, "plot_path": importances_plot_path}
        except Exception as e:
            raise RuntimeError(f"Erreur dans l'analyse d'importance des caract√©ristiques : {e}")


class DataAugmentationManager:
    """Augmente les donn√©es pour les ensembles d√©s√©quilibr√©s."""

    def augment_data(self, X, y, method="smote"):
        """
        Applique des techniques d'augmentation.
        Args:
            X (pd.DataFrame): Features.
            y (pd.Series): Labels.
            method (str): M√©thode d'augmentation ('smote').
        Returns:
            tuple: (X_augmented, y_augmented)
        """
        try:
            if method == "smote":
                smote = SMOTE(random_state=42)
                return smote.fit_resample(X, y)
            else:
                raise ValueError("M√©thode d'augmentation non support√©e.")
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'augmentation des donn√©es : {e}")

class BiasMitigator:
    """D√©tecte et att√©nue les biais dans les donn√©es."""

    def detect_bias(self, data, sensitive_feature, target):
        """
        D√©tecte les biais en comparant les distributions.
        Args:
            data (pd.DataFrame): Donn√©es.
            sensitive_feature (str): Colonne sensible (ex. sexe, ethnie).
            target (str): Colonne cible.
        Returns:
            dict: R√©sum√© des biais d√©tect√©s.
        """
        try:
            groups = data[sensitive_feature].unique()
            bias_summary = {}
            for group in groups:
                group_data = data[data[sensitive_feature] == group]
                bias_summary[group] = group_data[target].mean()
            return bias_summary
        except Exception as e:
            raise RuntimeError(f"Erreur dans la d√©tection de biais : {e}")

    def mitigate_bias(self, data, sensitive_feature, method="reweighing"):
        """
        Att√©nue les biais dans les donn√©es.
        Args:
            data (pd.DataFrame): Donn√©es.
            sensitive_feature (str): Colonne sensible.
            method (str): M√©thode d'att√©nuation ('reweighing').
        Returns:
            pd.DataFrame: Donn√©es corrig√©es.
        """
        try:
            if method == "reweighing":
                weights = data[sensitive_feature].value_counts(normalize=True)
                data["weights"] = data[sensitive_feature].map(weights)
                return data
            else:
                raise ValueError("M√©thode non reconnue.")
        except Exception as e:
            raise RuntimeError(f"Erreur dans l'att√©nuation des biais : {e}")

class IncrementalLearningManager:
    """G√®re l'apprentissage incr√©mental pour des mod√®les scalables."""

    def __init__(self):
        self.model = SGDClassifier()

    def train_incrementally(self, X_batch, y_batch):
        """
        Entra√Æne un mod√®le de mani√®re incr√©mentale.
        Args:
            X_batch (pd.DataFrame): Donn√©es du batch.
            y_batch (pd.Series): Labels du batch.
        """
        try:
            self.model.partial_fit(X_batch, y_batch, classes=np.unique(y_batch))
        except Exception as e:
            raise RuntimeError(f"Erreur dans l'apprentissage incr√©mental : {e}")

class AdaptiveHyperparameterTuner:
    """Optimise dynamiquement les hyperparam√®tres."""

    def tune_hyperparameters(self, model, param_grid, X_train, y_train):
        """
        Optimise les hyperparam√®tres avec GridSearchCV.
        Args:
            model: Mod√®le √† optimiser.
            param_grid (dict): Grille des hyperparam√®tres.
            X_train: Features d'entra√Ænement.
            y_train: Labels d'entra√Ænement.
        Returns:
            dict: Meilleur mod√®le et param√®tres.
        """
        try:
            grid_search = GridSearchCV(model, param_grid, cv=3)
            grid_search.fit(X_train, y_train)
            return {"best_model": grid_search.best_estimator_, "best_params": grid_search.best_params_}
        except Exception as e:
            raise RuntimeError(f"Erreur dans l'optimisation des hyperparam√®tres : {e}")


class ExplainableAIManager:
    """G√®re l'explicabilit√© des mod√®les IA."""

    def explain_with_shap(self, model, X_sample):
        """
        G√©n√®re des explications SHAP pour un mod√®le donn√©.
        Args:
            model: Mod√®le entra√Æn√©.
            X_sample: Donn√©es √† expliquer.
        Returns:
            shap_values: Valeurs SHAP.
        """
        try:
            explainer = shap.TreeExplainer(model)
            shap_values = explainer.shap_values(X_sample)

            # Graphique SHAP
            shap.summary_plot(shap_values, X_sample, show=False)
            plt.title("SHAP Summary Plot")
            plt.savefig("shap_summary.png")
            plt.close()

            return {"shap_values": shap_values, "summary_plot": "shap_summary.png"}
        except Exception as e:
            raise RuntimeError(f"Erreur avec SHAP : {e}")

    def explain_with_lime(self, model, X_sample, y_sample):
        """
        G√©n√®re des explications LIME pour un mod√®le donn√©.
        Args:
            model: Mod√®le entra√Æn√©.
            X_sample: Donn√©es √† expliquer.
            y_sample: Cible associ√©e.
        Returns:
            lime_explanation: Explications LIME.
        """
        try:
            explainer = lime.lime_tabular.LimeTabularExplainer(
                X_sample.values,
                feature_names=X_sample.columns,
                class_names=y_sample.unique(),
                verbose=True,
                mode="classification",
            )
            explanation = explainer.explain_instance(
                X_sample.iloc[0].values, model.predict_proba
            )
            explanation.save_to_file("lime_explanation.html")
            return {"lime_explanation": "lime_explanation.html"}
        except Exception as e:
            raise RuntimeError(f"Erreur avec LIME : {e}")




class DataPrivacyManager:
    """G√®re la confidentialit√© des donn√©es sensibles."""

    def anonymize_data(self, data: pd.DataFrame, sensitive_columns: list):
        """
        Anonymise les colonnes sensibles d'un jeu de donn√©es.
        Args:
            data (pd.DataFrame): Donn√©es originales.
            sensitive_columns (list): Colonnes √† anonymiser.
        Returns:
            pd.DataFrame: Donn√©es anonymis√©es.
        """
        try:
            fake = Faker()
            anonymized_data = data.copy()
            for column in sensitive_columns:
                anonymized_data[column] = anonymized_data[column].apply(lambda _: fake.name())
            return anonymized_data
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'anonymisation : {e}")

    def mask_data(self, data: pd.DataFrame, sensitive_columns: list, mask_char="*"):
        """
        Masque les colonnes sensibles en rempla√ßant les valeurs par des caract√®res masqu√©s.
        Args:
            data (pd.DataFrame): Donn√©es originales.
            sensitive_columns (list): Colonnes √† masquer.
            mask_char (str): Caract√®re de masquage.
        Returns:
            pd.DataFrame: Donn√©es masqu√©es.
        """
        try:
            masked_data = data.copy()
            for column in sensitive_columns:
                masked_data[column] = masked_data[column].apply(lambda x: mask_char * len(str(x)))
            return masked_data
        except Exception as e:
            raise RuntimeError(f"Erreur lors du masquage : {e}")


class FederatedLearningManager:
    """G√®re l'apprentissage f√©d√©r√© entre plusieurs clients."""

    def aggregate_models(self, models: list):
        """
        Agr√®ge les mod√®les en combinant leurs poids.
        Args:
            models (list): Liste de mod√®les entra√Æn√©s.
        Returns:
            model: Mod√®le agr√©g√©.
        """
        try:
            weights = [model.coef_ for model in models]
            average_weights = np.mean(weights, axis=0)

            # Utiliser le premier mod√®le comme base
            aggregated_model = models[0]
            aggregated_model.coef_ = average_weights
            return aggregated_model
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'agr√©gation des mod√®les : {e}")

    def simulate_federated_learning(self, data_clients: list, model):
        """
        Simule un apprentissage f√©d√©r√© entre plusieurs clients.
        Args:
            data_clients (list): Liste de tuples (X_client, y_client).
            model: Mod√®le √† entra√Æner.
        Returns:
            aggregated_model: Mod√®le f√©d√©r√©.
        """
        try:
            trained_models = []
            for X_client, y_client in data_clients:
                model.fit(X_client, y_client)
                trained_models.append(model)
            return self.aggregate_models(trained_models)
        except Exception as e:
            raise RuntimeError(f"Erreur dans l'apprentissage f√©d√©r√© : {e}")



class RealTimeDashboardManager:
    """G√©n√®re des tableaux de bord interactifs en temps r√©el."""

    def __init__(self, data: pd.DataFrame):
        self.data = data

    def start_dashboard(self):
        """
        D√©marre une application Dash pour visualiser les donn√©es.
        """
        app = dash.Dash(__name__)

        app.layout = html.Div([
            dcc.Dropdown(
                id="feature-dropdown",
                options=[{"label": col, "value": col} for col in self.data.columns],
                value=self.data.columns[0],
            ),
            dcc.Graph(id="real-time-graph"),
        ])

        @app.callback(
            Output("real-time-graph", "figure"),
            [Input("feature-dropdown", "value")]
        )
        def update_graph(selected_feature):
            fig = px.histogram(self.data, x=selected_feature, title=f"Distribution de {selected_feature}")
            return fig

        app.run_server(debug=True)




class NeuralNetworkBuilder:
    """Construit des r√©seaux de neurones personnalis√©s."""

    def build_model(self, input_dim, output_dim, layers=[64, 32], activation="relu", dropout_rate=0.2):
        """
        Construit un mod√®le de r√©seau de neurones.
        Args:
            input_dim (int): Dimension de l'entr√©e.
            output_dim (int): Dimension de la sortie.
            layers (list): Nombre de neurones par couche.
            activation (str): Fonction d'activation.
            dropout_rate (float): Taux de dropout.
        Returns:
            model: Mod√®le de r√©seau de neurones.
        """
        try:
            model = Sequential()
            model.add(Dense(layers[0], input_dim=input_dim, activation=activation))
            for units in layers[1:]:
                model.add(Dense(units, activation=activation))
                model.add(Dropout(dropout_rate))
            model.add(Dense(output_dim, activation="softmax"))
            model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])
            return model
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la construction du mod√®le : {e}")



class AutoMLPipelineManager:
    """G√®re les pipelines AutoML."""

    def run_automl(self, X_train, y_train, X_test, y_test, generations=5, population_size=20):
        """
        Ex√©cute AutoML pour optimiser un mod√®le.
        Args:
            X_train, y_train: Donn√©es d'entra√Ænement.
            X_test, y_test: Donn√©es de test.
            generations (int): Nombre de g√©n√©rations.
            population_size (int): Taille de la population.
        Returns:
            dict: Meilleur pipeline et score.
        """
        try:
            automl = TPOTClassifier(generations=generations, population_size=population_size, verbosity=2, random_state=42)
            automl.fit(X_train, y_train)
            score = automl.score(X_test, y_test)
            return {"best_pipeline": automl.fitted_pipeline_, "score": score}
        except Exception as e:
            raise RuntimeError(f"Erreur dans AutoML : {e}")


class QuantumMachineLearningManager:
    """G√®re les mod√®les de Machine Learning quantique."""

    def build_quantum_circuit(self, num_qubits):
        """
        Construit un circuit quantique simple.
        Args:
            num_qubits (int): Nombre de qubits.
        Returns:
            QuantumCircuit: Circuit quantique.
        """
        circuit = QuantumCircuit(num_qubits)
        for qubit in range(num_qubits):
            circuit.h(qubit)  # Applique une porte Hadamard
        return circuit

    def train_quantum_model(self, X, y, num_qubits=3):
        """
        Entra√Æne un mod√®le quantique pour une t√¢che de classification.
        Args:
            X (ndarray): Donn√©es d'entra√Ænement.
            y (ndarray): √âtiquettes.
            num_qubits (int): Nombre de qubits pour le circuit quantique.
        Returns:
            dict: R√©sultats de l'entra√Ænement.
        """
        try:
            circuit = RealAmplitudes(num_qubits, reps=2)
            quantum_kernel = QuantumKernel(feature_map=circuit, quantum_instance=Aer.get_backend('qasm_simulator'))
            quantum_model = VQC(quantum_kernel=quantum_kernel, optimizer=None, feature_map=circuit)

            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            quantum_model.fit(X_train, y_train)
            score = quantum_model.score(X_test, y_test)
            return {"model": quantum_model, "accuracy": score}
        except Exception as e:
            raise RuntimeError(f"Erreur dans le mod√®le quantique : {e}")


class ReinforcementLearningManager:
    """G√®re des agents d'apprentissage par renforcement."""

    def __init__(self, state_space, action_space, learning_rate=0.1, discount_factor=0.99, exploration_rate=1.0):
        self.state_space = state_space
        self.action_space = action_space
        self.q_table = np.zeros((state_space, action_space))
        self.learning_rate = learning_rate
        self.discount_factor = discount_factor
        self.exploration_rate = exploration_rate
        self.exploration_decay = 0.99

    def choose_action(self, state):
        """
        Choisit une action en fonction de l'exploration/exploitation.
        Args:
            state (int): √âtat actuel.
        Returns:
            int: Action choisie.
        """
        if random.uniform(0, 1) < self.exploration_rate:
            return random.randint(0, self.action_space - 1)
        return np.argmax(self.q_table[state, :])

    def update_q_table(self, state, action, reward, next_state):
        """
        Met √† jour la Q-table en fonction de la r√©compense re√ßue.
        """
        best_next_action = np.argmax(self.q_table[next_state, :])
        td_target = reward + self.discount_factor * self.q_table[next_state, best_next_action]
        td_error = td_target - self.q_table[state, action]
        self.q_table[state, action] += self.learning_rate * td_error

    def train(self, environment, episodes=1000):
        """
        Entra√Æne un agent dans l'environnement sp√©cifi√©.
        Args:
            environment: Environnement compatible OpenAI Gym.
            episodes (int): Nombre d'√©pisodes d'entra√Ænement.
        Returns:
            list: Historique des r√©compenses.
        """
        rewards = []
        for episode in range(episodes):
            state = environment.reset()
            total_reward = 0
            done = False
            while not done:
                action = self.choose_action(state)
                next_state, reward, done, _ = environment.step(action)
                self.update_q_table(state, action, reward, next_state)
                total_reward += reward
                state = next_state
            self.exploration_rate *= self.exploration_decay
            rewards.append(total_reward)
        return rewards



class SyntheticDataGenerator:
    """G√©n√®re des donn√©es artificielles avec des GANs."""

    def build_generator(self, input_dim, output_dim):
        """
        Construit le g√©n√©rateur d'un GAN.
        """
        model = Sequential([
            Dense(128, activation='relu', input_dim=input_dim),
            Dense(output_dim, activation='tanh'),
        ])
        return model

    def build_discriminator(self, input_dim):
        """
        Construit le discriminateur d'un GAN.
        """
        model = Sequential([
            Dense(128, activation='relu', input_dim=input_dim),
            Dense(1, activation='sigmoid'),
        ])
        return model

    def train_gan(self, real_data, epochs=10000, batch_size=32):
        """
        Entra√Æne un GAN pour g√©n√©rer des donn√©es.
        """
        input_dim = real_data.shape[1]
        generator = self.build_generator(input_dim=100, output_dim=input_dim)
        discriminator = self.build_discriminator(input_dim=input_dim)

        discriminator.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])
        discriminator.trainable = False

        gan = Sequential([generator, discriminator])
        gan.compile(optimizer="adam", loss="binary_crossentropy")

        for epoch in range(epochs):
            noise = np.random.normal(0, 1, (batch_size, 100))
            generated_data = generator.predict(noise)

            real_labels = np.ones((batch_size, 1))
            fake_labels = np.zeros((batch_size, 1))

            d_loss_real = discriminator.train_on_batch(real_data, real_labels)
            d_loss_fake = discriminator.train_on_batch(generated_data, fake_labels)

            noise = np.random.normal(0, 1, (batch_size, 100))
            gan_loss = gan.train_on_batch(noise, real_labels)

        return generator




class DistributedDataPipelineManager:
    """G√®re le traitement distribu√© de donn√©es avec Dask."""

    def load_large_data(self, file_path):
        """
        Charge un fichier de grande taille avec Dask.
        """
        return dd.read_csv(file_path)

    def distributed_processing(self, data):
        """
        Applique un traitement distribu√©.
        """
        data["new_column"] = data["column"].map(lambda x: x**2)
        return data.compute()

    def save_processed_data(self, data, file_path):
        """
        Sauvegarde les donn√©es trait√©es.
        """
        data.to_csv(file_path, single_file=True)


class DynamicKnowledgeGraphBuilder:
    """Construit un graphe de connaissance √† partir de donn√©es textuelles."""

    def build_graph(self, entities, relations):
        """
        Construit un graphe √† partir d'entit√©s et de relations.
        """
        graph = nx.Graph()
        for entity in entities:
            graph.add_node(entity)
        for (entity1, entity2, relation) in relations:
            graph.add_edge(entity1, entity2, label=relation)
        return graph

    def visualize_graph(self, graph):
        """
        Visualise le graphe de connaissance.
        """
        pos = nx.spring_layout(graph)
        labels = nx.get_edge_attributes(graph, "label")
        nx.draw(graph, pos, with_labels=True, node_color="lightblue", edge_color="gray")
        nx.draw_networkx_edge_labels(graph, pos, edge_labels=labels)
        plt.show()

class AutonomousResearchAgent:
    """Agent autonome de recherche scientifique."""

    def __init__(self):
        self.hypothesis_generator = pipeline("text-generation", model="gpt-3.5-turbo")
        self.results = {}

    def generate_hypothesis(self, topic, num_hypotheses=3):
        """
        G√©n√®re des hypoth√®ses √† tester bas√©es sur un sujet donn√©.
        Args:
            topic (str): Sujet de recherche.
            num_hypotheses (int): Nombre d'hypoth√®ses √† g√©n√©rer.
        Returns:
            list: Hypoth√®ses g√©n√©r√©es.
        """
        prompts = [f"G√©n√®re une hypoth√®se scientifique sur : {topic}" for _ in range(num_hypotheses)]
        hypotheses = [self.hypothesis_generator(prompt, max_length=50)[0]["generated_text"] for prompt in prompts]
        return hypotheses

    def test_hypotheses(self, hypotheses, data):
        """
        Teste les hypoth√®ses g√©n√©r√©es sur les donn√©es.
        Args:
            hypotheses (list): Liste d'hypoth√®ses.
            data (pd.DataFrame): Donn√©es √† utiliser pour le test.
        Returns:
            dict: R√©sultats des tests.
        """
        self.results = {hypothesis: self._simulate_test(hypothesis, data) for hypothesis in hypotheses}
        return self.results

    def _simulate_test(self, hypothesis, data):
        """
        Simule un test pour une hypoth√®se.
        """
        return {"p_value": np.random.uniform(0, 1), "support": np.random.choice([True, False])}

    def generate_report(self):
        """
        G√©n√®re un rapport bas√© sur les r√©sultats.
        """
        report = "=== R√©sultats de l'agent de recherche ===\n"
        for hypothesis, result in self.results.items():
            report += f"Hypoth√®se : {hypothesis}\n"
            report += f"- p-value : {result['p_value']:.3f}\n"
            report += f"- Support : {'Oui' if result['support'] else 'Non'}\n\n"
        return report



class GenerativeModelArtisan:
    """Cr√©e des ≈ìuvres d'art g√©n√©ratives avec des mod√®les IA."""

    def generate_image(self, prompt, api_url="https://api.openai.com/v1/images/generations", api_key="YOUR_API_KEY"):
        """
        G√©n√®re une image √† partir d'un prompt.
        Args:
            prompt (str): Description de l'image.
        Returns:
            Image: Image g√©n√©r√©e.
        """
        headers = {"Authorization": f"Bearer {api_key}"}
        data = {"prompt": prompt, "n": 1, "size": "1024x1024"}
        response = requests.post(api_url, headers=headers, json=data)
        image_url = response.json()["data"][0]["url"]
        image = Image.open(BytesIO(requests.get(image_url).content))
        return image

    def create_interactive_art(self, prompts, iterations=5):
        """
        Cr√©e une ≈ìuvre d'art interactive bas√©e sur des it√©rations.
        Args:
            prompts (list): Liste de prompts pour guider la cr√©ation.
        Returns:
            list: Liste d'images g√©n√©r√©es.
        """
        images = []
        for i in range(iterations):
            prompt = prompts[i % len(prompts)]
            images.append(self.generate_image(prompt))
        return images

class SelfImprovingAgent:
    """Agent qui apprend de ses erreurs et s'am√©liore en continu."""

    def __init__(self):
        self.performance_log = []
        self.current_strategy = None

    def evaluate_performance(self, metric):
        """
        √âvalue la performance actuelle selon un m√©trique donn√©.
        """
        performance = np.random.uniform(0, 1)  # Simulation
        self.performance_log.append(performance)
        return performance

    def improve_strategy(self):
        """
        Modifie la strat√©gie actuelle en fonction des performances pass√©es.
        """
        if len(self.performance_log) < 2:
            return "Pas assez de donn√©es pour am√©liorer la strat√©gie."

        delta = self.performance_log[-1] - self.performance_log[-2]
        if delta < 0:
            self.current_strategy = "Strat√©gie alternative"  # Exemple d'ajustement
        return f"Nouvelle strat√©gie appliqu√©e : {self.current_strategy}"

    def train_on_feedback(self, feedback):
        """
        S'entra√Æne sur les retours re√ßus.
        """
        return f"Agent entra√Æn√© sur : {feedback}"



class NeuroInspiredAI:
    """Intelligence artificielle inspir√©e par le cerveau humain."""

    def simulate_neural_activity(self, neurons=100, duration=1000):
        """
        Simule une activit√© neuronale.
        """
        eqs = """
        dv/dt = (ge + gi - v) / (10*ms) : volt
        dge/dt = -ge / (5*ms) : volt
        dgi/dt = -gi / (10*ms) : volt
        """
        G = NeuronGroup(neurons, eqs, threshold="v > -50*mV", reset="v = -60*mV", method="exact")
        S = Synapses(G, G, on_pre="ge += 1.62*mV")
        S.connect(p=0.1)
        run(duration)
        return "Simulation termin√©e."


class EcosystemSimulationManager:
    """Simule un √©cosyst√®me complexe avec interactions dynamiques."""

    def __init__(self, prey_population=50, predator_population=10, growth_rate=0.1, predation_rate=0.01):
        self.prey_population = prey_population
        self.predator_population = predator_population
        self.growth_rate = growth_rate
        self.predation_rate = predation_rate
        self.history = []

    def simulate_step(self):
        """
        Simule une √©tape de l'√©cosyst√®me.
        """
        prey_growth = self.prey_population * self.growth_rate
        predation_loss = self.predation_rate * self.prey_population * self.predator_population
        predator_gain = predation_loss * 0.1

        self.prey_population += prey_growth - predation_loss
        self.predator_population += predator_gain - 0.05 * self.predator_population

        self.history.append((self.prey_population, self.predator_population))

    def run_simulation(self, steps=100):
        """
        Simule plusieurs √©tapes.
        """
        for _ in range(steps):
            self.simulate_step()

        prey, predators = zip(*self.history)
        plt.plot(prey, label="Proies")
        plt.plot(predators, label="Pr√©dateurs")
        plt.legend()
        plt.title("Simulation √âcosyst√®me")
        plt.show()


class MetaIntelligenceOrchestrator:
    """Orchestrateur d'intelligence artificielle auto-√©volutif."""

    def __init__(self):
        self.agents = []
        self.global_metrics = {"efficiency": [], "accuracy": []}

    def add_agent(self, agent):
        """
        Ajoute un nouvel agent √† l'orchestrateur.
        Args:
            agent (object): Instance d'un agent IA.
        """
        self.agents.append(agent)

    def evaluate_agents(self):
        """
        √âvalue tous les agents en fonction de leurs m√©triques.
        """
        for agent in self.agents:
            metrics = agent.evaluate_performance()
            self.global_metrics["efficiency"].append(metrics.get("efficiency", 0))
            self.global_metrics["accuracy"].append(metrics.get("accuracy", 0))

    def optimize_collaboration(self):
        """
        Optimise la collaboration entre les agents pour maximiser les performances.
        """
        efficiency_avg = sum(self.global_metrics["efficiency"]) / len(self.global_metrics["efficiency"])
        accuracy_avg = sum(self.global_metrics["accuracy"]) / len(self.global_metrics["accuracy"])
        return {"efficiency_avg": efficiency_avg, "accuracy_avg": accuracy_avg}

    def execute_global_task(self, task):
        """
        R√©partit une t√¢che complexe entre les agents.
        Args:
            task (dict): D√©tails de la t√¢che.
        """
        results = []
        for agent in self.agents:
            results.append(agent.run_task(task))
        return results

class HoloSimulatedRealityManager:
    """Gestionnaire de simulations en r√©alit√© augment√©e et holographiques."""

    def __init__(self):
        self.simulated_worlds = []

    def create_simulated_world(self, name, parameters):
        """
        Cr√©e un monde simul√© avec des param√®tres sp√©cifiques.
        Args:
            name (str): Nom du monde.
            parameters (dict): Param√®tres du monde (gravit√©, m√©t√©o, population...).
        """
        world = {"name": name, "parameters": parameters, "entities": []}
        self.simulated_worlds.append(world)
        return world

    def add_entity(self, world_name, entity):
        """
        Ajoute une entit√© √† un monde simul√©.
        Args:
            world_name (str): Nom du monde cible.
            entity (dict): Entit√© avec ses caract√©ristiques.
        """
        world = next((w for w in self.simulated_worlds if w["name"] == world_name), None)
        if world:
            world["entities"].append(entity)

    def simulate_step(self, world_name, iterations=1):
        """
        Simule des √©tapes dans le temps pour un monde.
        Args:
            world_name (str): Nom du monde.
            iterations (int): Nombre d'√©tapes √† simuler.
        """
        world = next((w for w in self.simulated_worlds if w["name"] == world_name), None)
        if world:
            for _ in range(iterations):
                # Simule les interactions entre entit√©s (simplifi√© ici)
                for entity in world["entities"]:
                    entity["state"] = "active"
        return world


class QuantumComputingSimulator:
    """Simule des algorithmes quantiques pour des applications avanc√©es."""

    def __init__(self):
        self.circuit = QuantumCircuit(2)  # Circuit avec 2 qubits

    def apply_quantum_entanglement(self):
        """Applique un enchev√™trement quantique."""
        self.circuit.h(0)  # Applique une porte Hadamard
        self.circuit.cx(0, 1)  # Applique une porte CNOT pour l'entanglement

    def measure(self):
        """Ajoute des mesures au circuit."""
        self.circuit.measure_all()

    def simulate(self):
        """Simule le circuit quantique."""
        simulator = Aer.get_backend("qasm_simulator")
        job = execute(self.circuit, simulator, shots=1024)
        result = job.result()
        counts = result.get_counts(self.circuit)
        return counts


class CosmicDataAnalyzer:
    """Analyse des donn√©es cosmiques pour l'astronomie avanc√©e."""

    def __init__(self):
        self.data = None

    def load_cosmic_data(self, file_path):
        """
        Charge des donn√©es astronomiques depuis un fichier.
        Args:
            file_path (str): Chemin vers le fichier de donn√©es.
        """
        self.data = Table.read(file_path, format="ascii")
        return self.data

    def plot_stellar_distribution(self):
        """
        Trace la distribution des √©toiles dans le ciel.
        """
        if self.data:
            coords = SkyCoord(self.data["ra"], self.data["dec"], unit="deg")
            plt.scatter(coords.ra.deg, coords.dec.deg, alpha=0.5)
            plt.xlabel("Ascension Droite (RA)")
            plt.ylabel("D√©clinaison (Dec)")
            plt.title("Distribution des √©toiles")
            plt.show()

class AIDrivenPolicyOptimizer:
    """Optimise les politiques publiques √† l'aide de simulations IA."""

    def __init__(self, population_data):
        self.population_data = pd.DataFrame(population_data)

    def simulate_policy(self, policy, iterations=10):
        """
        Simule l'impact d'une politique donn√©e.
        Args:
            policy (dict): D√©tails de la politique.
            iterations (int): Nombre d'it√©rations.
        """
        results = []
        for _ in range(iterations):
            impact = self._evaluate_policy_impact(policy)
            results.append(impact)
        return results

    def _evaluate_policy_impact(self, policy):
        """
        √âvalue l'impact d'une politique.
        """
        # Exemple : Appliquer une taxe ou un subside
        self.population_data["income"] *= 1 - policy.get("tax_rate", 0)
        gini_index = 1 - (self.population_data["income"].var() / self.population_data["income"].mean())
        return {"gini_index": gini_index}

    def optimize_policy(self, objective="maximize_gini"):
        """
        Optimise une politique pour un objectif donn√©.
        """
        best_policy = {"tax_rate": 0.0}
        best_gini = 0
        for tax_rate in np.linspace(0, 0.5, 20):
            gini = self._evaluate_policy_impact({"tax_rate": tax_rate})["gini_index"]
            if gini > best_gini:
                best_gini = gini
                best_policy = {"tax_rate": tax_rate}
        return best_policy

class UniversalAIOrchestrator:
    """Orchestrateur universel supervisant des intelligences artificielles multi-domaines."""

    def __init__(self):
        self.domains = {}

    def register_ai(self, domain_name, ai_agent):
        """
        Enregistre une IA dans un domaine sp√©cifique.
        Args:
            domain_name (str): Nom du domaine (sant√©, climat, etc.).
            ai_agent (object): Instance de l'agent IA.
        """
        if domain_name not in self.domains:
            self.domains[domain_name] = []
        self.domains[domain_name].append(ai_agent)

    def execute_global_strategy(self, strategy):
        """
        Ex√©cute une strat√©gie globale en d√©l√©guant aux IA sp√©cifiques.
        Args:
            strategy (dict): D√©crit les t√¢ches par domaine.
        """
        results = {}
        for domain, tasks in strategy.items():
            if domain in self.domains:
                results[domain] = [agent.run_task(task) for agent, task in zip(self.domains[domain], tasks)]
        return results

    def generate_universal_report(self):
        """
        G√©n√®re un rapport consolid√© de toutes les IA enregistr√©es.
        """
        report = {}
        for domain, agents in self.domains.items():
            report[domain] = [agent.get_status() for agent in agents]
        return report

class ExoPlanetDiscoveryAI:
    """IA d√©di√©e √† l'exploration de plan√®tes habitables dans des donn√©es astronomiques."""

    def __init__(self):
        self.discovered_planets = []

    def analyze_star_system(self, data):
        """
        Analyse un syst√®me stellaire pour y trouver des exoplan√®tes.
        Args:
            data (DataFrame): Donn√©es du syst√®me stellaire.
        """
        habitable_zone = data[(data["distance"] > 0.8) & (data["distance"] < 2.5)]
        potential_planets = habitable_zone[habitable_zone["atmosphere"] == "oxygen-rich"]
        self.discovered_planets.extend(potential_planets["name"].tolist())

    def get_discoveries(self):
        """Retourne les plan√®tes d√©couvertes."""
        return self.discovered_planets

class AIForSocialHarmony:
    """IA visant √† r√©duire les in√©galit√©s sociales tout en am√©liorant la prosp√©rit√© g√©n√©rale."""

    def __init__(self, population_data):
        self.population_data = pd.DataFrame(population_data)

    def simulate_policy_impact(self, policy):
        """
        Simule l'impact d'une politique sociale ou √©conomique.
        Args:
            policy (dict): D√©tails de la politique.
        """
        self.population_data["income"] *= (1 - policy.get("tax_rate", 0.1))
        self.population_data["happiness"] += policy.get("subsidy", 0.05) * 100

    def optimize_policies(self):
        """
        Trouve la meilleure combinaison de taxes et subventions.
        """
        best_policy = {"tax_rate": 0.0, "subsidy": 0.0}
        best_happiness = 0
        for tax_rate in np.linspace(0, 0.5, 10):
            for subsidy in np.linspace(0, 0.2, 5):
                self.simulate_policy_impact({"tax_rate": tax_rate, "subsidy": subsidy})
                avg_happiness = self.population_data["happiness"].mean()
                if avg_happiness > best_happiness:
                    best_happiness = avg_happiness
                    best_policy = {"tax_rate": tax_rate, "subsidy": subsidy}
        return best_policy


class OmniFunctionalAI:
    """Une IA capable d'apprendre et de r√©soudre tout type de probl√®me."""

    def __init__(self):
        self.modules = {
            "image_processing": None,
            "natural_language": None,
            "time_series_forecasting": None,
            "music_generation": None,
        }

    def load_module(self, module_name, module):
        """
        Charge un module sp√©cialis√©.
        Args:
            module_name (str): Nom du module (image_processing, natural_language, etc.).
            module (object): Instance du module IA.
        """
        if module_name in self.modules:
            self.modules[module_name] = module
        else:
            raise ValueError("Module inconnu.")

    def execute_task(self, task_type, **kwargs):
        """
        Ex√©cute une t√¢che sp√©cifique avec le module appropri√©.
        Args:
            task_type (str): Type de t√¢che (image_processing, natural_language, etc.).
        """
        module = self.modules.get(task_type)
        if not module:
            raise ValueError(f"Module {task_type} non charg√©.")
        return module.run(**kwargs)

    def universal_report(self):
        """G√©n√®re un rapport des performances de chaque module."""
        report = {module: (mod.get_status() if mod else "Non charg√©") for module, mod in self.modules.items()}
        return report


#from qiskit import Aer, QuantumCircuit, transpile, execute


class QuantumDataAnalyzer:
    """Analyseur de donn√©es exploitant la m√©canique quantique."""

    def __init__(self):
        self.backend = Aer.get_backend('statevector_simulator')

    def prepare_circuit(self, data):
        """
        Pr√©pare un circuit quantique bas√© sur les donn√©es.
        Args:
            data (np.ndarray): Tableau de donn√©es.
        """
        circuit = QuantumCircuit(len(data))
        for i, value in enumerate(data):
            circuit.h(i)  # Applique une porte Hadamard pour chaque bit
            circuit.rz(value, i)  # Rotation bas√©e sur les donn√©es
        return circuit

    def analyze(self, data):
        """
        Effectue une analyse quantique des donn√©es.
        Args:
            data (np.ndarray): Tableau de donn√©es.
        """
        circuit = self.prepare_circuit(data)
        transpiled_circuit = transpile(circuit, self.backend)
        result = execute(transpiled_circuit, self.backend).result()
        state_vector = result.get_statevector()
        return {"state_vector": state_vector}


class IntergalacticNavigator:
    """IA d√©di√©e √† la navigation intergalactique."""

    def __init__(self):
        self.current_position = {"x": 0, "y": 0, "z": 0}
        self.known_destinations = []

    def add_destination(self, name, coordinates):
        """
        Ajoute une destination connue.
        Args:
            name (str): Nom de la destination.
            coordinates (dict): Coordonn√©es {x, y, z}.
        """
        self.known_destinations.append({"name": name, "coordinates": coordinates})

    def calculate_trajectory(self, destination_name):
        """
        Calcule la trajectoire optimale vers une destination.
        Args:
            destination_name (str): Nom de la destination.
        """
        destination = next((d for d in self.known_destinations if d["name"] == destination_name), None)
        if not destination:
            raise ValueError(f"Destination {destination_name} inconnue.")

        trajectory = {
            "start": self.current_position,
            "end": destination["coordinates"],
            "time_estimation": self.estimate_time(destination["coordinates"]),
        }
        return trajectory

    def estimate_time(self, coordinates):
        """
        Estime le temps de trajet.
        Args:
            coordinates (dict): Coordonn√©es {x, y, z}.
        """
        distance = sum((self.current_position[axis] - coordinates[axis]) ** 2 for axis in coordinates)
        return distance ** 0.5 / 299792  # Division par la vitesse de la lumi√®re (en km/s)


class AIForUniversalSustainability:
    """IA optimis√©e pour la durabilit√© √©cologique et sociale √† l'√©chelle mondiale."""

    def __init__(self):
        self.environmental_data = []

    def collect_data(self, data_source):
        """
        Collecte les donn√©es environnementales.
        Args:
            data_source (str): Chemin ou API pour les donn√©es.
        """
        data = pd.read_csv(data_source)  # Exemple simple
        self.environmental_data.append(data)

    def optimize_resource_allocation(self):
        """
        Propose des strat√©gies d'optimisation pour l'utilisation des ressources.
        """
        # Exemple d'optimisation : r√©duire les √©missions de CO2
        total_emissions = sum(data["CO2_emissions"] for data in self.environmental_data)
        strategies = {"solar_energy_investment": total_emissions * 0.5, "carbon_capture": total_emissions * 0.3}
        return strategies

    def predict_future_outcomes(self, years=50):
        """
        Pr√©voit les r√©sultats climatiques dans un futur donn√©.
        Args:
            years (int): Nombre d'ann√©es √† pr√©voir.
        """
        # Mod√®le de pr√©vision simplifi√©
        return {"temperature_increase": 1.5 * years / 100}


class LifeSimulatorAI:
    """Simule l'√©volution de la vie sur des millions d'ann√©es."""

    def __init__(self, initial_population=1000):
        self.population = initial_population
        self.environment_factors = {"resources": 1.0, "climate_stability": 1.0}

    def simulate_generation(self):
        """
        Simule une g√©n√©ration de vie en fonction des facteurs environnementaux.
        """
        survival_rate = self.environment_factors["resources"] * self.environment_factors["climate_stability"]
        self.population = int(self.population * survival_rate)
        return self.population

    def introduce_event(self, event_name, impact):
        """
        Introduit un √©v√©nement modifiant les conditions de vie.
        Args:
            event_name (str): Nom de l'√©v√©nement.
            impact (dict): Impact sur les facteurs environnementaux.
        """
        for key, value in impact.items():
            if key in self.environment_factors:
                self.environment_factors[key] *= value

    def simulate_millions_of_years(self, years):
        """
        Simule l'√©volution sur des millions d'ann√©es.
        Args:
            years (int): Nombre d'ann√©es √† simuler.
        """
        for _ in range(years):
            self.simulate_generation()
        return {"population": self.population, "environment": self.environment_factors}

class EmotionallyAwareAssistant:
    """IA capable de d√©tecter les √©motions et d'adapter ses r√©ponses."""

    def __init__(self):
        from transformers import pipeline
        self.emotion_analyzer = pipeline("sentiment-analysis")

    def detect_emotion(self, user_message: str) -> str:
        """
        D√©tecte l'√©motion dans un message utilisateur.
        Args:
            user_message (str): Message de l'utilisateur.
        Returns:
            str: Emotion d√©tect√©e.
        """
        emotions = self.emotion_analyzer(user_message)
        return emotions[0]["label"]

    def respond_with_empathy(self, user_message: str) -> str:
        """
        G√©n√®re une r√©ponse empathique bas√©e sur l'√©motion d√©tect√©e.
        Args:
            user_message (str): Message de l'utilisateur.
        Returns:
            str: R√©ponse empathique.
        """
        emotion = self.detect_emotion(user_message)
        responses = {
            "POSITIVE": "Je suis ravi d'entendre cela ! üòä Que puis-je faire pour rendre votre journ√©e encore meilleure ?",
            "NEGATIVE": "Je suis d√©sol√© que vous vous sentiez ainsi. üíî Parlez-moi, je suis l√† pour vous aider.",
            "NEUTRAL": "Je comprends. N'h√©sitez pas √† me dire en quoi je peux vous √™tre utile. üôÇ",
        }
        return responses.get(emotion, "Je suis l√† pour vous !")

import networkx as nx

class KnowledgeGraphAssistant:
    """Assistant utilisant un graphe de connaissances pour des r√©ponses intelligentes."""

    def __init__(self):
        self.graph = nx.DiGraph()

    def add_knowledge(self, subject: str, relationship: str, obj: str):
        """
        Ajoute une relation au graphe de connaissances.
        Args:
            subject (str): Sujet.
            relationship (str): Relation entre les n≈ìuds.
            obj (str): Objet.
        """
        self.graph.add_edge(subject, obj, relationship=relationship)

    def query_knowledge(self, subject: str) -> list:
        """
        Retourne toutes les relations d'un sujet.
        Args:
            subject (str): Sujet √† rechercher.
        Returns:
            list: Relations du sujet.
        """
        if subject in self.graph:
            return [
                f"{subject} --({d['relationship']})--> {nbr}"
                for nbr, d in self.graph[subject].items()
            ]
        return ["Aucune information trouv√©e."]

    def display_graph(self):
        """Affiche le graphe avec matplotlib."""
        import matplotlib.pyplot as plt
        plt.figure(figsize=(12, 8))
        pos = nx.spring_layout(self.graph)
        nx.draw(self.graph, pos, with_labels=True, node_color="skyblue", font_size=10)
        labels = nx.get_edge_attributes(self.graph, "relationship")
        nx.draw_networkx_edge_labels(self.graph, pos, edge_labels=labels)
        plt.show()

# Utilisation
# assistant = KnowledgeGraphAssistant()
# assistant.add_knowledge("ChatGPT", "is_a", "AI assistant")
# print(assistant.query_knowledge("ChatGPT"))
# assistant.display_graph()


class DynamicWorkflowOrchestrator:
    """Orchestrateur de workflows dynamiques."""

    def __init__(self):
        self.workflow_steps = []

    def add_step(self, step_name: str, action):
        """
        Ajoute une √©tape au workflow.
        Args:
            step_name (str): Nom de l'√©tape.
            action (callable): Fonction √† ex√©cuter pour cette √©tape.
        """
        self.workflow_steps.append({"name": step_name, "action": action})

    def execute_workflow(self, input_data):
        """
        Ex√©cute le workflow avec des donn√©es d'entr√©e.
        Args:
            input_data (dict): Donn√©es d'entr√©e initiales.
        Returns:
            dict: R√©sultats du workflow.
        """
        results = input_data
        for step in self.workflow_steps:
            results = step["action"](results)
        return results

# Exemple d'action
def clean_data(data):
    return {k: v.strip().lower() for k, v in data.items()}

def enrich_data(data):
    data["enriched"] = True
    return data

# Utilisation
# orchestrator = DynamicWorkflowOrchestrator()
# orchestrator.add_step("Nettoyage des donn√©es", clean_data)
# orchestrator.add_step("Enrichissement des donn√©es", enrich_data)
# result = orchestrator.execute_workflow({"Nom": " ChatGPT ", "Age": " OpenAI "})

class VirtualMentorAssistant:
    """Un mentor virtuel pour guider l'utilisateur dans ses apprentissages."""

    def __init__(self):
        self.skills = {}

    def add_skill(self, skill_name: str, learning_steps: list):
        """
        Ajoute une comp√©tence avec des √©tapes d'apprentissage.
        Args:
            skill_name (str): Nom de la comp√©tence.
            learning_steps (list): √âtapes pour ma√Ætriser la comp√©tence.
        """
        self.skills[skill_name] = {"steps": learning_steps, "progress": 0}

    def track_progress(self, skill_name: str):
        """
        Suit le progr√®s dans une comp√©tence.
        Args:
            skill_name (str): Comp√©tence √† suivre.
        Returns:
            str: √âtat actuel du progr√®s.
        """
        if skill_name not in self.skills:
            return "Comp√©tence non trouv√©e."
        skill = self.skills[skill_name]
        progress = skill["progress"]
        steps = skill["steps"]
        return f"Progression {progress}/{len(steps)} : {steps[progress] if progress < len(steps) else 'Termin√© !'}"

    def complete_step(self, skill_name: str):
        """
        Marque une √©tape comme compl√©t√©e.
        Args:
            skill_name (str): Comp√©tence concern√©e.
        """
        if skill_name in self.skills and self.skills[skill_name]["progress"] < len(self.skills[skill_name]["steps"]):
            self.skills[skill_name]["progress"] += 1

# Utilisation
# mentor = VirtualMentorAssistant()
# mentor.add_skill("Apprendre Python", ["Variables", "Boucles", "Classes", "Modules"])
# print(mentor.track_progress("Apprendre Python"))
# mentor.complete_step("Apprendre Python")
# print(mentor.track_progress("Apprendre Python"))

from PIL import Image

class MultimodalAssistant:
    """Assistant capable de traiter texte, images et audio."""

    def process_text(self, text: str) -> str:
        return f"Vous avez dit : {text}"

    def process_image(self, image_path: str) -> str:
        img = Image.open(image_path)
        return f"Image analys√©e. Dimensions : {img.size}, Format : {img.format}"

    def process_audio(self, audio_path: str) -> str:
        return f"Fichier audio {audio_path} analys√©."

# Utilisation
# assistant = MultimodalAssistant()
# print(assistant.process_text("Bonjour !"))
# print(assistant.process_image("image.png"))
# print(assistant.process_audio("audio.wav"))

class DreamGeneratorAssistant:
    """Assistant cr√©atif capable de g√©n√©rer des histoires, de l'art ou de la musique."""

    def generate_story(self, theme: str, length: int = 500) -> str:
        """
        G√©n√®re une histoire bas√©e sur un th√®me.
        Args:
            theme (str): Th√®me de l'histoire.
            length (int): Longueur approximative de l'histoire.
        Returns:
            str: Histoire g√©n√©r√©e.
        """
        return f"Voici une histoire sur le th√®me '{theme}':\n" + " ".join(["Il √©tait une fois..."] * length)

    def generate_music(self, mood: str, duration: int = 60) -> str:
        """
        G√©n√®re une piste musicale.
        Args:
            mood (str): Ambiance de la musique (joyeux, triste...).
            duration (int): Dur√©e en secondes.
        Returns:
            str: Description de la musique g√©n√©r√©e.
        """
        return f"G√©n√©ration d'une musique de {duration}s avec une ambiance '{mood}'. (Musique synth√©tis√©e √† venir‚ÄØ!)"

    def generate_art(self, prompt: str) -> str:
        """
        G√©n√®re une ≈ìuvre d'art bas√©e sur un prompt.
        Args:
            prompt (str): Description de l'art.
        Returns:
            str: Confirmation de la g√©n√©ration d'art.
        """
        return f"Une ≈ìuvre d'art bas√©e sur '{prompt}' est en cours de cr√©ation (illustration g√©n√©r√©e)."

# Utilisation
# dreamer = DreamGeneratorAssistant()
# print(dreamer.generate_story("aventure fantastique"))
# print(dreamer.generate_music("calme"))
# print(dreamer.generate_art("un coucher de soleil sur une plage"))

from transformers import MarianMTModel, MarianTokenizer

class UniversalTranslator:
    """Assistant multilingue avec traduction intelligente."""

    def __init__(self):
        self.models = {}
        self.tokenizers = {}

    def load_model(self, src_lang: str, tgt_lang: str):
        """Charge un mod√®le de traduction pour une paire de langues."""
        model_name = f"Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}"
        if model_name not in self.models:
            self.tokenizers[model_name] = MarianTokenizer.from_pretrained(model_name)
            self.models[model_name] = MarianMTModel.from_pretrained(model_name)

    def translate(self, text: str, src_lang: str, tgt_lang: str) -> str:
        """
        Traduit un texte d'une langue √† une autre.
        Args:
            text (str): Texte √† traduire.
            src_lang (str): Langue source.
            tgt_lang (str): Langue cible.
        Returns:
            str: Texte traduit.
        """
        self.load_model(src_lang, tgt_lang)
        model_name = f"Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}"
        tokenizer = self.tokenizers[model_name]
        model = self.models[model_name]
        encoded = tokenizer(text, return_tensors="pt", padding=True)
        translated = model.generate(**encoded)
        return tokenizer.decode(translated[0], skip_special_tokens=True)

# Utilisation
# translator = UniversalTranslator()
# print(translator.translate("Bonjour, comment allez-vous ?", "fr", "en"))

class HyperAssistantManager:
    """Un orchestrateur d'assistants pour g√©rer des t√¢ches multiples."""

    def __init__(self):
        self.assistants = {}

    def register_assistant(self, name: str, assistant):
        """
        Enregistre un assistant dans le syst√®me.
        Args:
            name (str): Nom de l'assistant.
            assistant: Instance de l'assistant.
        """
        self.assistants[name] = assistant

    def execute_task(self, assistant_name: str, task_name: str, *args, **kwargs):
        """
        Ex√©cute une t√¢che via un assistant enregistr√©.
        Args:
            assistant_name (str): Nom de l'assistant.
            task_name (str): Nom de la m√©thode √† appeler.
        Returns:
            R√©sultat de la m√©thode ex√©cut√©e.
        """
        if assistant_name in self.assistants:
            assistant = self.assistants[assistant_name]
            task = getattr(assistant, task_name, None)
            if callable(task):
                return task(*args, **kwargs)
        return f"L'assistant {assistant_name} ou la t√¢che {task_name} est introuvable."

# Utilisation
# manager = HyperAssistantManager()
# translator = UniversalTranslator()
# manager.register_assistant("translator", translator)
# print(manager.execute_task("translator", "translate", "Hola, ¬øc√≥mo est√°s?", "es", "en"))

class CrisisManagerAssistant:
    """Assistant pour g√©rer des situations de crise."""

    def handle_emergency(self, emergency_type: str):
        """
        G√®re une situation d'urgence.
        Args:
            emergency_type (str): Type d'urgence.
        Returns:
            str: Conseils ou actions recommand√©es.
        """
        responses = {
            "medical": "Appelez imm√©diatement le 112. Si la personne ne respire pas, commencez un massage cardiaque.",
            "technical": "Essayez de red√©marrer l'appareil. Si le probl√®me persiste, contactez le support technique.",
            "security": "Restez calme. Contactez les forces de l'ordre ou un service de s√©curit√©.",
        }
        return responses.get(emergency_type, "Type d'urgence inconnu. Fournissez plus d'informations.")

# Utilisation
# crisis_assistant = CrisisManagerAssistant()
# print(crisis_assistant.handle_emergency("medical"))

class UserContext:
    def __init__(self):
        self.memory = {}

    def update_context(self, user_id, key, value):
        if user_id not in self.memory:
            self.memory[user_id] = {}
        self.memory[user_id][key] = value

    def get_context(self, user_id):
        return self.memory.get(user_id, {})

class DatasetManager:
    """
    Classe pour g√©rer les ensembles de donn√©es, incluant la division en training, validation et test.
    """

    def __init__(self, test_size=0.2, val_size=0.1, random_state=42):
        self.test_size = test_size
        self.val_size = val_size
        self.random_state = random_state

    def split_data(self, data, target_column):
        """
        Divise les donn√©es en ensembles d'entra√Ænement, validation et test.

        Args:
            data (pd.DataFrame): Donn√©es √† diviser.
            target_column (str): Colonne cible.

        Returns:
            dict: Dictionnaire contenant les ensembles train, val et test.
        """
        X = data.drop(columns=[target_column])
        y = data[target_column]

        X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=self.test_size, random_state=self.random_state)
        val_size_adjusted = self.val_size / (1 - self.test_size)
        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=val_size_adjusted, random_state=self.random_state)

        return {
            "train": (X_train, y_train),
            "val": (X_val, y_val),
            "test": (X_test, y_test)
        }

class ModelManager:
    """
    Classe pour g√©rer les mod√®les machine learning, incluant l'entra√Ænement,
    l'√©valuation, et la persistance des mod√®les.
    """

    def __init__(self, model):
        self.model = model

    def train(self, X_train, y_train):
        """
        Entra√Æne le mod√®le.

        Args:
            X_train (pd.DataFrame): Features d'entra√Ænement.
            y_train (pd.Series): Cible d'entra√Ænement.

        Returns:
            self: Mod√®le entra√Æn√©.
        """
        self.model.fit(X_train, y_train)
        return self

    def evaluate(self, X_test, y_test, metric="accuracy"):
        """
        √âvalue le mod√®le sur des donn√©es de test.

        Args:
            X_test (pd.DataFrame): Features de test.
            y_test (pd.Series): Cible de test.
            metric (str): M√©trique d'√©valuation ('accuracy', 'mse', 'r2').

        Returns:
            float: Score de la m√©trique choisie.
        """
        predictions = self.model.predict(X_test)
        if metric == "accuracy":
            return accuracy_score(y_test, predictions)
        elif metric == "mse":
            return mean_squared_error(y_test, predictions)
        elif metric == "r2":
            return r2_score(y_test, predictions)
        else:
            raise ValueError(f"M√©trique inconnue : {metric}")

    def save_model(self, filepath):
        """
        Sauvegarde le mod√®le sur le disque.

        Args:
            filepath (str): Chemin de sauvegarde.
        """
        joblib.dump(self.model, filepath)

    def load_model(self, filepath):
        """
        Charge un mod√®le depuis le disque.

        Args:
            filepath (str): Chemin du mod√®le sauvegard√©.

        Returns:
            ModelManager: Instance de ModelManager avec le mod√®le charg√©.
        """
        self.model = joblib.load(filepath)
        return self

class AutoPipeline:
    """
    Classe pour automatiser les pipelines ML, de la pr√©paration des donn√©es √† l'√©valuation des mod√®les.
    """

    def __init__(self, model):
        self.preprocessor = DataPreprocessor()
        self.dataset_manager = DatasetManager()
        self.model_manager = ModelManager(model)

    def execute_pipeline(self, data, target_column, metric="accuracy"):
        """
        Ex√©cute le pipeline complet.

        Args:
            data (pd.DataFrame): Donn√©es brutes.
            target_column (str): Colonne cible.
            metric (str): M√©trique d'√©valuation.

        Returns:
            float: Score du mod√®le sur l'ensemble de test.
        """
        # Pr√©traitement des donn√©es
        preprocessed_data = self.preprocessor.preprocess(data)

        # Division des donn√©es
        datasets = self.dataset_manager.split_data(preprocessed_data, target_column)

        # Entra√Ænement
        self.model_manager.train(*datasets["train"])

        # √âvaluation
        return self.model_manager.evaluate(*datasets["test"], metric=metric)

class HyperparameterTuner:
    """
    Classe pour l'optimisation des hyperparam√®tres avec Optuna.
    """

    def __init__(self, model, X_train, y_train, metric="accuracy"):
        self.model = model
        self.X_train = X_train
        self.y_train = y_train
        self.metric = metric

    def tune(self, param_distributions, n_trials=50):
        """
        Optimise les hyperparam√®tres du mod√®le.

        Args:
            param_distributions (dict): Hyperparam√®tres √† tester.
            n_trials (int): Nombre d'it√©rations d'optimisation.

        Returns:
            dict: Meilleurs hyperparam√®tres.
        """
        def objective(trial):
            params = {key: trial.suggest_categorical(key, value) for key, value in param_distributions.items()}
            self.model.set_params(**params)
            score = cross_val_score(self.model, self.X_train, self.y_train, cv=5, scoring=self.metric).mean()
            return score

        study = optuna.create_study(direction="maximize")
        study.optimize(objective, n_trials=n_trials)
        return study.best_params

class AutoMLBot:
    """
    Classe pour effectuer une exploration AutoML avec H2O.
    """

    def __init__(self):
        h2o.init()

    def train(self, data, target, max_models=20, max_runtime_secs=300):
        """
        Entra√Æne plusieurs mod√®les pour trouver le meilleur.

        Args:
            data (pd.DataFrame): Donn√©es avec la colonne cible.
            target (str): Nom de la colonne cible.
            max_models (int): Nombre maximal de mod√®les √† tester.
            max_runtime_secs (int): Temps maximal d'entra√Ænement.

        Returns:
            h2o.automl.H2OAutoML: Objet AutoML avec les meilleurs mod√®les.
        """
        h2o_data = h2o.H2OFrame(data)
        train, test = h2o_data.split_frame(ratios=[.8])
        aml = H2OAutoML(max_models=max_models, max_runtime_secs=max_runtime_secs)
        aml.train(y=target, training_frame=train)
        return aml.leaderboard

    def predict(self, model, data):
        """
        Effectue une pr√©diction avec le meilleur mod√®le.

        Args:
            model (h2o.automl.H2OAutoML): Mod√®le H2O entra√Æn√©.
            data (pd.DataFrame): Donn√©es de test.

        Returns:
            h2o.H2OFrame: Pr√©dictions.
        """
        h2o_data = h2o.H2OFrame(data)
        return model.predict(h2o_data)

class ModelAPI:
    """
    Classe pour g√©rer l'entra√Ænement et l'exposition de mod√®les via une API REST.
    """

    def __init__(self, model):
        self.model = model
        self.app = Flask(__name__)

        @self.app.route("/train", methods=["POST"])
        def train():
            data = request.get_json()
            X = pd.DataFrame(data["X"])
            y = pd.Series(data["y"])
            self.model.fit(X, y)
            return jsonify({"message": "Mod√®le entra√Æn√© avec succ√®s."})

        @self.app.route("/predict", methods=["POST"])
        def predict():
            data = request.get_json()
            X = pd.DataFrame(data["X"])
            predictions = self.model.predict(X).tolist()
            return jsonify({"predictions": predictions})

        @self.app.route("/save", methods=["POST"])
        def save():
            filepath = request.json["filepath"]
            joblib.dump(self.model, filepath)
            return jsonify({"message": f"Mod√®le sauvegard√© sous {filepath}"})

    def run(self, port=5000):
        self.app.run(port=port)

class AutoAdaptivePipeline:
    """
    Pipeline dynamique qui ajuste automatiquement ses √©tapes en fonction des donn√©es.
    """

    def __init__(self):
        self.pipeline = None

    def build_pipeline(self, data, target):
        """
        Configure le pipeline automatiquement selon les types de colonnes.

        Args:
            data (pd.DataFrame): Donn√©es d'entr√©e.
            target (str): Colonne cible.

        Returns:
            Pipeline: Pipeline complet.
        """
        numeric_features = data.select_dtypes(include=['number']).columns.tolist()
        categorical_features = data.select_dtypes(exclude=['number']).columns.tolist()

        numeric_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='mean')),
            ('scaler', StandardScaler())
        ])

        categorical_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
            ('onehot', OneHotEncoder(handle_unknown='ignore'))
        ])

        preprocessor = ColumnTransformer(
            transformers=[
                ('num', numeric_transformer, numeric_features),
                ('cat', categorical_transformer, categorical_features)
            ]
        )

        self.pipeline = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('classifier', RandomForestClassifier())
        ])

    def train_and_evaluate(self, data, target):
        """
        Entra√Æne et √©value automatiquement le mod√®le sur des donn√©es.

        Args:
            data (pd.DataFrame): Donn√©es d'entr√©e.
            target (str): Nom de la colonne cible.

        Returns:
            dict: Scores d'√©valuation.
        """
        X = data.drop(columns=[target])
        y = data[target]
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        self.build_pipeline(X, target)
        self.pipeline.fit(X_train, y_train)

        accuracy = self.pipeline.score(X_test, y_test)
        return {"accuracy": accuracy}

    def predict(self, data):
        """
        Effectue des pr√©dictions sur de nouvelles donn√©es.

        Args:
            data (pd.DataFrame): Donn√©es √† pr√©dire.

        Returns:
            list: Pr√©dictions.
        """
        return self.pipeline.predict(data)



class DataAugmenter:
    """
    Classe pour augmenter les donn√©es automatiquement pour les images ou les textes.
    """

    def __init__(self):
        self.augmentation_pipeline = Compose([
            HorizontalFlip(p=0.5),
            Rotate(limit=15, p=0.7),
            RandomBrightnessContrast(p=0.3)
        ])

    def augment_image(self, image):
        """
        Augmente une image en appliquant des transformations.

        Args:
            image (np.array): Image √† augmenter.

        Returns:
            np.array: Image augment√©e.
        """
        return self.augmentation_pipeline(image=image)['image']

    def augment_text(self, text):
        """
        Augmente un texte en paraphrasant ou en g√©n√©rant des variations.

        Args:
            text (str): Texte d'entr√©e.

        Returns:
            list: Variations du texte.
        """
        from transformers import pipeline
        paraphraser = pipeline("text2text-generation", model="t5-small")
        augmented_texts = paraphraser(f"paraphrase: {text}", num_return_sequences=3)
        return [t['generated_text'] for t in augmented_texts]

class PreTrainedModelIntegrator:
    """
    Int√®gre des mod√®les pr√©-entra√Æn√©s pour le traitement avanc√©.
    """

    def __init__(self):
        self.text_model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased")
        self.tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
        self.image_model = fasterrcnn_resnet50_fpn(pretrained=True)

    def classify_text(self, text):
        """
        Classifie un texte en utilisant BERT.

        Args:
            text (str): Texte d'entr√©e.

        Returns:
            dict: R√©sultats de classification.
        """
        inputs = self.tokenizer(text, return_tensors="pt")
        outputs = self.text_model(**inputs)
        return outputs.logits.softmax(dim=-1).detach().numpy()

    def detect_objects(self, image_path):
        """
        D√©tecte des objets dans une image.

        Args:
            image_path (str): Chemin de l'image.

        Returns:
            dict: R√©sultats de d√©tection.
        """
        image = Image.open(image_path).convert("RGB")
        image_tensor = torchvision.transforms.ToTensor()(image)
        predictions = self.image_model([image_tensor])
        return predictions[0]

class MultiModalAnalyzer:
    """
    Analyse des donn√©es multimodales (texte, image, tableau).
    """

    def analyze(self, text_data, image_path, tabular_data):
        """
        Combine texte, image et tableau dans une seule analyse.

        Args:
            text_data (str): Texte √† analyser.
            image_path (str): Chemin de l'image.
            tabular_data (pd.DataFrame): Donn√©es tabulaires.

        Returns:
            dict: R√©sultats combin√©s.
        """
        pre_trained = PreTrainedModelIntegrator()

        text_result = pre_trained.classify_text(text_data)
        image_result = pre_trained.detect_objects(image_path)
        tabular_summary = tabular_data.describe().to_dict()

        return {
            "text_analysis": text_result,
            "image_analysis": image_result,
            "tabular_analysis": tabular_summary
        }


class InteractiveDashboard:
    """
    Cr√©e un tableau de bord interactif pour visualiser les r√©sultats.
    """

    def display(self, data, predictions, metrics):
        """
        Affiche les donn√©es et les r√©sultats de mani√®re interactive.

        Args:
            data (pd.DataFrame): Donn√©es utilis√©es.
            predictions (list): R√©sultats des pr√©dictions.
            metrics (dict): M√©triques d'√©valuation.
        """
        st.title("Analyse Interactive des Donn√©es")
        st.write("### Donn√©es d'entr√©e")
        st.dataframe(data)

        st.write("### Pr√©dictions")
        st.write(predictions)

        st.write("### M√©triques d'√©valuation")
        for metric, value in metrics.items():
            st.metric(metric, value)

from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC

class ParallelFusionLearning:
    """
    Apprentissage fusionnel parall√®le avec plusieurs mod√®les.
    """

    def __init__(self):
        self.models = [
            ("decision_tree", DecisionTreeClassifier()),
            ("svm", SVC(probability=True))
        ]
        self.stack_model = None

    def train(self, X, y):
        """
        Entra√Æne des mod√®les et construit un empilement.
        """
        meta_model = LogisticRegression()
        self.stack_model = StackingClassifier(estimators=self.models, final_estimator=meta_model)
        self.stack_model.fit(X, y)

    def predict(self, X):
        """
        Pr√©dit les r√©sultats en fusionnant les mod√®les.
        """
        return self.stack_model.predict(X)

    def explain_decision(self, X):
        """
        Explique la d√©cision √† l‚Äôaide de SHAP.
        """
        import shap
        explainer = shap.Explainer(self.stack_model, X)
        shap_values = explainer(X)
        return shap_values

class SmartModelManager:
    """
    Gestion dynamique des mod√®les selon leurs performances.
    """

    def __init__(self):
        self.models = {}
        self.best_model = None
        self.best_score = 0

    def add_model(self, name, model):
        """
        Ajoute un mod√®le √† la gestion.
        """
        self.models[name] = model

    def evaluate_models(self, X_train, X_test, y_train, y_test):
        """
        √âvalue tous les mod√®les et s√©lectionne le meilleur.
        """
        for name, model in self.models.items():
            model.fit(X_train, y_train)
            score = model.score(X_test, y_test)
            if score > self.best_score:
                self.best_score = score
                self.best_model = (name, model)
        return self.best_model

    def replace_underperforming_models(self, X_train, y_train):
        """
        Remplace les mod√®les sous-performants par des alternatives.
        """
        for name, model in self.models.items():
            score = model.score(X_train, y_train)
            if score < 0.7:  # Seuil de sous-performance
                self.models[name] = self._get_alternative_model(name)

    def _get_alternative_model(self, model_name):
        """
        Renvoie un mod√®le alternatif bas√© sur son nom.
        """
        if "tree" in model_name:
            return RandomForestClassifier()
        elif "svm" in model_name:
            return LogisticRegression()
        else:
            return GradientBoostingClassifier()

import numpy as np
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt

class SpatialAnalyzer3D:
    """
    Classe pour analyser et visualiser des donn√©es 3D.
    """

    def analyze_clusters(self, data, n_clusters=3):
        """
        Effectue un clustering 3D et visualise les r√©sultats.
        """
        from sklearn.cluster import KMeans
        kmeans = KMeans(n_clusters=n_clusters)
        labels = kmeans.fit_predict(data)

        # Visualisation
        fig = plt.figure()
        ax = fig.add_subplot(111, projection='3d')
        ax.scatter(data[:, 0], data[:, 1], data[:, 2], c=labels, cmap='viridis')
        plt.show()

        return {"clusters": labels, "centroids": kmeans.cluster_centers_}

    def simulate_trajectory(self, start, end, steps):
        """
        Simule un trajet 3D entre deux points.
        """
        x = np.linspace(start[0], end[0], steps)
        y = np.linspace(start[1], end[1], steps)
        z = np.linspace(start[2], end[2], steps)

        fig = plt.figure()
        ax = fig.add_subplot(111, projection='3d')
        ax.plot(x, y, z, label="Trajectoire simul√©e")
        ax.legend()
        plt.show()

        return np.vstack([x, y, z]).T

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LeakyReLU
import numpy as np

class SyntheticDataGenerator:
    """
    G√©n√®re des donn√©es synth√©tiques r√©alistes avec des GANs.
    """

    def __init__(self):
        self.generator = self._build_generator()
        self.discriminator = self._build_discriminator()
        self.gan = self._build_gan()

    def _build_generator(self):
        """
        Construit le g√©n√©rateur.
        """
        model = Sequential([
            Dense(128, input_dim=100),
            LeakyReLU(alpha=0.2),
            Dense(256),
            LeakyReLU(alpha=0.2),
            Dense(2, activation='tanh')  # G√©n√®re 2D (ou modifier pour d'autres dimensions)
        ])
        return model

    def _build_discriminator(self):
        """
        Construit le discriminateur.
        """
        model = Sequential([
            Dense(256, input_dim=2),
            LeakyReLU(alpha=0.2),
            Dense(1, activation='sigmoid')
        ])
        model.compile(optimizer="adam", loss="binary_crossentropy")
        return model

    def _build_gan(self):
        """
        Combine g√©n√©rateur et discriminateur.
        """
        self.discriminator.trainable = False
        model = Sequential([self.generator, self.discriminator])
        model.compile(optimizer="adam", loss="binary_crossentropy")
        return model

    def train(self, real_data, epochs=1000, batch_size=32):
        """
        Entra√Æne le GAN pour g√©n√©rer des donn√©es synth√©tiques.
        """
        for epoch in range(epochs):
            # S√©lection des vraies donn√©es
            idx = np.random.randint(0, real_data.shape[0], batch_size)
            real_samples = real_data[idx]

            # G√©n√©ration des fausses donn√©es
            noise = np.random.normal(0, 1, (batch_size, 100))
            fake_samples = self.generator.predict(noise)

            # Entra√Æne le discriminateur
            d_loss_real = self.discriminator.train_on_batch(real_samples, np.ones((batch_size, 1)))
            d_loss_fake = self.discriminator.train_on_batch(fake_samples, np.zeros((batch_size, 1)))

            # Entra√Æne le g√©n√©rateur
            noise = np.random.normal(0, 1, (batch_size, 100))
            g_loss = self.gan.train_on_batch(noise, np.ones((batch_size, 1)))

            if epoch % 100 == 0:
                print(f"Epoch {epoch}: D Loss = {d_loss_real + d_loss_fake}, G Loss = {g_loss}")

    def generate(self, n_samples=100):
        """
        G√©n√®re de nouvelles donn√©es.
        """
        noise = np.random.normal(0, 1, (n_samples, 100))
        return self.generator.predict(noise)

class MultiAgentSystem:
    """
    Syst√®me multi-agent pour ex√©cuter des t√¢ches complexes.
    """

    def __init__(self):
        self.agents = {}

    def register_agent(self, name, function):
        """
        Ajoute un agent avec une t√¢che sp√©cifique.
        """
        self.agents[name] = function

    def execute(self, task_name, *args, **kwargs):
        """
        Ex√©cute une t√¢che par un agent sp√©cifique.
        """
        if task_name in self.agents:
            return self.agents[task_name](*args, **kwargs)
        else:
            raise ValueError(f"Agent '{task_name}' non trouv√©.")

    def collaborate(self, tasks, *args, **kwargs):
        """
        Coordonne plusieurs agents pour collaborer.
        """
        results = {}
        for task_name in tasks:
            if task_name in self.agents:
                results[task_name] = self.agents[task_name](*args, **kwargs)
        return results

#from autosklearn.classification import AutoSklearnClassifier

class AutoMLPipeline:
    """
    Pipeline AutoML pour automatiser l'apprentissage et l'√©valuation.
    """

    def __init__(self, time_limit=360):
        self.model = AutoSklearnClassifier(time_left_for_this_task=time_limit)

    def fit(self, X_train, y_train):
        """
        Entra√Æne automatiquement plusieurs mod√®les.
        """
        self.model.fit(X_train, y_train)

    def predict(self, X_test):
        """
        Pr√©dit avec le meilleur mod√®le trouv√©.
        """
        return self.model.predict(X_test)

    def leaderboard(self):
        """
        Retourne les performances des mod√®les explor√©s.
        """
        return self.model.sprint_statistics()

from transformers import AutoModelForCausalLM, AutoTokenizer

class GenerativeConversationalAgent:
    """
    Agent bas√© sur GPT pour des r√©ponses conversationnelles intelligentes.
    """

    def __init__(self, model_name="gpt2"):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForCausalLM.from_pretrained(model_name)

    def generate_response(self, prompt, max_length=50):
        """
        G√©n√®re une r√©ponse bas√©e sur un prompt donn√©.
        """
        inputs = self.tokenizer(prompt, return_tensors="pt")
        outputs = self.model.generate(inputs.input_ids, max_length=max_length, num_return_sequences=1)
        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)

from sklearn.metrics import confusion_matrix

class BiasFairnessAnalyzer:
    """
    Analyse les biais et garantit l'√©quit√© dans les pr√©dictions.
    """

    def __init__(self, sensitive_feature):
        self.sensitive_feature = sensitive_feature

    def evaluate_fairness(self, data, labels, predictions):
        """
        √âvalue l'√©quit√© du mod√®le selon une caract√©ristique sensible.
        """
        groups = data[self.sensitive_feature].unique()
        fairness_report = {}
        for group in groups:
            group_indices = data[self.sensitive_feature] == group
            cm = confusion_matrix(labels[group_indices], predictions[group_indices])
            accuracy = cm.diagonal().sum() / cm.sum()
            fairness_report[group] = accuracy
        return fairness_report

from surprise import SVD, Dataset, Reader
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

class HybridRecommender:
    """
    Syst√®me de recommandation hybride.
    """

    def __init__(self):
        self.collaborative_model = SVD()
        self.content_similarity = None

    def fit(self, ratings, content_data):
        """
        Entra√Æne le mod√®le collaboratif et calcule les similarit√©s de contenu.
        """
        reader = Reader(rating_scale=(1, 5))
        data = Dataset.load_from_df(ratings[['userId', 'itemId', 'rating']], reader)
        self.collaborative_model.fit(data.build_full_trainset())

        vectorizer = TfidfVectorizer()
        self.content_similarity = cosine_similarity(vectorizer.fit_transform(content_data))

    def recommend(self, user_id, item_id):
        """
        Recommande un m√©lange de contenu similaire et de suggestions collaboratives.
        """
        collaborative_score = self.collaborative_model.predict(user_id, item_id).est
        content_score = self.content_similarity[item_id].mean()
        return (collaborative_score + content_score) / 2

import shap
import plotly.express as px

class InteractiveExplainability:
    """
    Classe pour des visualisations interactives avec SHAP.
    """

    def __init__(self, model, data):
        self.explainer = shap.Explainer(model, data)
        self.data = data

    def plot_summary(self):
        """
        Affiche un r√©sum√© interactif des explications.
        """
        shap_values = self.explainer(self.data)
        shap.summary_plot(shap_values, self.data)

    def interactive_scatter(self):
        """
        Cr√©e un graphique interactif des impacts des caract√©ristiques.
        """
        shap_values = self.explainer(self.data)
        shap_df = pd.DataFrame(shap_values.values, columns=self.data.columns)
        shap_df["Impact"] = shap_values.values.mean(axis=1)

        fig = px.scatter(shap_df, x="Impact", y=self.data.columns[0], color=self.data.columns[1])
        fig.show()

class MetaLearningAgent:
    """
    Agent de m√©ta-apprentissage qui ajuste ses algorithmes selon la t√¢che.
    """

    def __init__(self, base_model):
        self.base_model = base_model
        self.meta_weights = {}

    def learn(self, task_data, task_labels):
        """
        Apprend des m√©ta-poids pour ajuster le mod√®le de base.
        """
        self.meta_weights = self._compute_meta_weights(task_data, task_labels)

    def predict(self, data):
        """
        Pr√©dit en utilisant les m√©ta-poids.
        """
        adjusted_model = self._adjust_model(self.base_model, self.meta_weights)
        return adjusted_model.predict(data)

    def _compute_meta_weights(self, task_data, task_labels):
        # Simule le calcul des m√©ta-poids
        return {feature: weight for feature, weight in enumerate(range(len(task_data.columns)))}

    def _adjust_model(self, model, weights):
        # Ajuste dynamiquement le mod√®le
        model.set_params(**weights)
        return model

class ActiveFeedbackLoop:
    """
    Pipeline pour inclure le retour utilisateur dans le mod√®le.
    """

    def __init__(self, model):
        self.model = model
        self.feedback_data = []

    def get_feedback(self, user_input, predicted_output):
        """
        Demande √† l'utilisateur si la pr√©diction est correcte.
        """
        is_correct = input(f"La pr√©diction '{predicted_output}' est-elle correcte (oui/non) ? ").lower()
        self.feedback_data.append((user_input, predicted_output, is_correct == "oui"))

    def update_model(self):
        """
        Met √† jour le mod√®le en fonction du retour.
        """
        corrected_data = [data for data in self.feedback_data if data[2]]
        if corrected_data:
            X, y = zip(*[(d[0], d[1]) for d in corrected_data])
            self.model.fit(X, y)

import gym
import numpy as np

class ReinforcementLearningAgent:
    """
    Agent d'apprentissage par renforcement pour r√©soudre des t√¢ches complexes.
    """

    def __init__(self, env_name="CartPole-v1"):
        self.env = gym.make(env_name)
        self.q_table = np.zeros((self.env.observation_space.n, self.env.action_space.n))
        self.alpha = 0.1  # Taux d'apprentissage
        self.gamma = 0.99  # Facteur d'actualisation
        self.epsilon = 1.0  # Exploration initiale

    def train(self, episodes=1000):
        """
        Entra√Æne l'agent avec Q-Learning.
        """
        for episode in range(episodes):
            state = self.env.reset()
            done = False

            while not done:
                if np.random.uniform(0, 1) < self.epsilon:
                    action = self.env.action_space.sample()  # Exploration
                else:
                    action = np.argmax(self.q_table[state])  # Exploitation

                next_state, reward, done, _ = self.env.step(action)
                self.q_table[state, action] = self.q_table[state, action] + \
                    self.alpha * (reward + self.gamma * np.max(self.q_table[next_state]) - self.q_table[state, action])
                state = next_state

            self.epsilon = max(0.01, self.epsilon * 0.995)  # R√©duction de l'exploration

    def choose_action(self, state):
        """
        Choisit une action bas√©e sur la Q-Table.
        """
        return np.argmax(self.q_table[state])

class ContextualDialogManager:
    """
    G√®re le contexte des conversations pour un dialogue multi-turn.
    """

    def __init__(self):
        self.context = {}

    def update_context(self, user_message, bot_response):
        """
        Met √† jour le contexte avec les messages utilisateur et bot.
        """
        self.context["last_user_message"] = user_message
        self.context["last_bot_response"] = bot_response

    def generate_response(self, user_message):
        """
        G√©n√®re une r√©ponse bas√©e sur le contexte.
        """
        if "last_user_message" in self.context:
            return f"En r√©ponse √† votre pr√©c√©dente question : {self.context['last_user_message']}, voici ma r√©ponse : ..."
        else:
            return "Bonjour, comment puis-je vous aider ?"

from concurrent.futures import ThreadPoolExecutor

class MultiTaskPipeline:
    """
    Ex√©cute plusieurs t√¢ches simultan√©ment pour maximiser l'efficacit√©.
    """

    def __init__(self):
        self.tasks = []

    def add_task(self, function, *args):
        """
        Ajoute une t√¢che √† la pipeline.
        """
        self.tasks.append((function, args))

    def execute(self):
        """
        Ex√©cute toutes les t√¢ches en parall√®le.
        """
        results = []
        with ThreadPoolExecutor() as executor:
            futures = [executor.submit(task[0], *task[1]) for task in self.tasks]
            for future in futures:
                results.append(future.result())
        return results

from flask import Flask, request, jsonify

class RealTimeDeployment:
    """
    D√©ploie un mod√®le en temps r√©el via une API REST.
    """

    def __init__(self, model):
        self.model = model
        self.app = Flask(__name__)

        @self.app.route("/predict", methods=["POST"])
        def predict():
            data = request.json
            prediction = self.model.predict([data['features']])
            return jsonify({"prediction": prediction.tolist()})

    def run(self, host="0.0.0.0", port=5000):
        self.app.run(host=host, port=port)

import shap

class ExplainableAIAgent:
    """
    Explique les d√©cisions des mod√®les avec SHAP.
    """

    def __init__(self, model, data):
        self.explainer = shap.Explainer(model, data)

    def explain(self, instance):
        """
        G√©n√®re une explication pour une instance donn√©e.
        """
        shap_values = self.explainer(instance)
        shap.plots.waterfall(shap_values[0])

import spacy
from sklearn.feature_extraction.text import TfidfVectorizer

class SemanticTextAnalyzer:
    """
    Analyse avanc√©e de texte avec embeddings et mod√®les NLP.
    """

    def __init__(self, model_name="en_core_web_sm"):
        self.nlp = spacy.load(model_name)

    def extract_keywords(self, text, top_n=5):
        """
        Extrait les mots-cl√©s importants d'un texte.
        """
        doc = self.nlp(text)
        tfidf = TfidfVectorizer()
        tfidf_matrix = tfidf.fit_transform([token.text for token in doc if not token.is_stop and not token.is_punct])
        keywords = tfidf.get_feature_names_out()
        return keywords[:top_n]

    def summarize(self, text):
        """
        G√©n√®re un r√©sum√© bas√© sur des phrases cl√©s.
        """
        doc = self.nlp(text)
        sentences = [sent.text for sent in doc.sents]
        return sentences[:2]  # Les deux premi√®res phrases comme r√©sum√©

import ray
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

@ray.remote
class DistributedTrainingManager:
    """
    G√®re l'entra√Ænement distribu√© des mod√®les en parall√®le.
    """

    def __init__(self, model_class, params):
        self.model = model_class(**params)

    def train(self, X_train, y_train):
        self.model.fit(X_train, y_train)
        return self.model

    def evaluate(self, X_test, y_test):
        return self.model.score(X_test, y_test)

#import autosklearn.classification

class AutoMLModelSearcher:
    """
    Automatisation de la recherche de mod√®les avec Auto-sklearn.
    """

    def __init__(self, time_limit=360):
        self.model = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=time_limit)

    def train(self, X_train, y_train):
        """
        Entra√Æne le mod√®le AutoML.
        """
        self.model.fit(X_train, y_train)
        return self.model

    def evaluate(self, X_test, y_test):
        """
        √âvalue le mod√®le sur un ensemble de test.
        """
        return self.model.score(X_test, y_test)

import torch
from diffusers import StableDiffusionPipeline

class ImageGenerator:
    """
    G√©n√®re des images bas√©es sur du texte avec un mod√®le de diffusion.
    """

    def __init__(self, model_name="runwayml/stable-diffusion-v1-5"):
        self.pipeline = StableDiffusionPipeline.from_pretrained(model_name, torch_dtype=torch.float16)
        self.pipeline.to("cuda")

    def generate_image(self, prompt, output_path="generated_image.png"):
        """
        G√©n√®re une image √† partir d'une description textuelle.
        """
        image = self.pipeline(prompt).images[0]
        image.save(output_path)
        return output_path

from transformers import pipeline

class TaskPlannerGPT:
    """
    Planifie automatiquement des t√¢ches avec un mod√®le GPT.
    """

    def __init__(self, model_name="gpt-3.5-turbo"):
        self.generator = pipeline("text-generation", model=model_name)

    def plan_tasks(self, goal, context=""):
        """
        Planifie des t√¢ches bas√©es sur un objectif donn√©.
        """
        prompt = f"Planifie les √©tapes pour atteindre l'objectif suivant : {goal}. Contexte : {context}"
        result = self.generator(prompt, max_length=200, num_return_sequences=1)
        return result[0]["generated_text"]

import networkx as nx

class KnowledgeGraphRecommender:
    """
    G√©n√®re des recommandations bas√©es sur un graphe de connaissances.
    """

    def __init__(self):
        self.graph = nx.Graph()

    def add_relationship(self, entity1, entity2, weight=1):
        """
        Ajoute une relation entre deux entit√©s.
        """
        self.graph.add_edge(entity1, entity2, weight=weight)

    def recommend(self, entity, top_n=5):
        """
        Recommande les entit√©s les plus li√©es √† l'entit√© donn√©e.
        """
        neighbors = sorted(self.graph[entity], key=lambda x: self.graph[entity][x]["weight"], reverse=True)
        return neighbors[:top_n]

class DynamicLearningBot:
    """
    Chatbot qui apprend dynamiquement des interactions utilisateur.
    """

    def __init__(self):
        self.knowledge_base = {}

    def learn(self, user_input, bot_response):
        """
        Apprend une nouvelle paire question-r√©ponse.
        """
        self.knowledge_base[user_input] = bot_response

    def respond(self, user_input):
        """
        R√©pond √† une question, ou apprend si inconnu.
        """
        if user_input in self.knowledge_base:
            return self.knowledge_base[user_input]
        else:
            return "Je ne sais pas encore r√©pondre √† cela. Veux-tu m'apprendre ?"

from feature_engine.creation import MathFeatures

class AutomaticFeatureEngineer:
    """
    Cr√©e des caract√©ristiques avanc√©es automatiquement.
    """

    def __init__(self):
        self.pipeline = MathFeatures(variables=None, math_operations=["sum", "prod", "mean", "std", "max", "min"])

    def fit_transform(self, data):
        """
        Applique les transformations math√©matiques sur les donn√©es.
        """
        return self.pipeline.fit_transform(data)

from pandas_profiling import ProfileReport

class DataStoryteller:
    """
    G√©n√®re des rapports narratifs interactifs bas√©s sur les donn√©es.
    """

    def __init__(self):
        self.output_dir = "reports"
        os.makedirs(self.output_dir, exist_ok=True)

    def generate_story(self, data: pd.DataFrame, report_name="data_story"):
        """
        Cr√©e un rapport interactif complet.
        """
        try:
            report = ProfileReport(data, title="Data Story", explorative=True)
            file_path = os.path.join(self.output_dir, f"{report_name}.html")
            report.to_file(file_path)
            return file_path
        except Exception as e:
            return f"Erreur lors de la cr√©ation du rapport : {e}"

from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer

class DeepRecommender:
    """
    Syst√®me de recommandation avanc√© utilisant des embeddings de texte.
    """

    def __init__(self, model_name="all-MiniLM-L6-v2"):
        self.model = SentenceTransformer(model_name)

    def generate_embeddings(self, items):
        """
        G√©n√®re des embeddings pour une liste d'items (e.g., textes ou titres).
        """
        return self.model.encode(items)

    def recommend(self, query, items, top_n=5):
        """
        Recommande des items similaires √† une requ√™te donn√©e.
        """
        query_embedding = self.generate_embeddings([query])
        item_embeddings = self.generate_embeddings(items)
        similarities = cosine_similarity(query_embedding, item_embeddings)[0]
        recommendations = sorted(zip(items, similarities), key=lambda x: x[1], reverse=True)[:top_n]
        return recommendations

from PIL import Image
from transformers import pipeline

class VisionAssistant:
    """
    Assistant capable de comprendre et d√©crire des images.
    """

    def __init__(self, model_name="google/vit-base-patch16-224"):
        self.vision_model = pipeline("image-classification", model=model_name)

    def analyze_image(self, image_path):
        """
        Analyse et d√©crit une image.
        """
        image = Image.open(image_path)
        results = self.vision_model(image)
        return results

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense

class MultiTaskForecaster:
    """
    Mod√®le de pr√©vision multit√¢ches (classification et r√©gression).
    """

    def __init__(self, input_shape):
        inputs = Input(shape=(input_shape,))
        common = Dense(128, activation="relu")(inputs)

        # T√¢che 1 : Classification
        classification_output = Dense(1, activation="sigmoid", name="classification")(common)

        # T√¢che 2 : R√©gression
        regression_output = Dense(1, name="regression")(common)

        self.model = Model(inputs=inputs, outputs=[classification_output, regression_output])

    def compile(self):
        self.model.compile(optimizer="adam",
                           loss={"classification": "binary_crossentropy", "regression": "mse"},
                           metrics={"classification": "accuracy", "regression": "mae"})

class ConversationalMemoryManager:
    """
    G√®re la m√©moire √† long terme des conversations du bot.
    """

    def __init__(self):
        self.memory = []

    def add_interaction(self, user_message, bot_response):
        """
        Ajoute une interaction dans la m√©moire.
        """
        self.memory.append({"user": user_message, "bot": bot_response})

    def retrieve_context(self, keyword, max_results=5):
        """
        Recherche des interactions pass√©es li√©es √† un mot-cl√©.
        """
        return [item for item in self.memory if keyword.lower() in item["user"].lower()][:max_results]

from haystack.document_stores import InMemoryDocumentStore
from haystack.nodes import FARMReader, DensePassageRetriever
from haystack.pipelines import ExtractiveQAPipeline

class DocumentQA:
    """
    R√©pond aux questions en recherchant dans des documents.
    """

    def __init__(self):
        self.document_store = InMemoryDocumentStore()
        self.retriever = DensePassageRetriever(self.document_store)
        self.reader = FARMReader("deepset/roberta-base-squad2")
        self.pipeline = ExtractiveQAPipeline(reader=self.reader, retriever=self.retriever)

    def add_documents(self, docs):
        """
        Ajoute des documents √† la base.
        """
        self.document_store.write_documents(docs)

    def answer_question(self, question):
        """
        R√©pond √† une question en cherchant dans les documents.
        """
        return self.pipeline.run(query=question, params={"Retriever": {"top_k": 5}})

from gtts import gTTS

class SpeechGenerator:
    """
    G√©n√®re de l'audio √† partir de texte.
    """

    def __init__(self, lang="fr"):
        self.lang = lang

    def text_to_speech(self, text, output_path="output.mp3"):
        """
        Convertit un texte en fichier audio.
        """
        tts = gTTS(text=text, lang=self.lang)
        tts.save(output_path)
        return output_path

from pyspark.sql import SparkSession

class RealTimeDataProcessor:
    """
    Analyse des donn√©es en temps r√©el avec Spark Streaming.
    """

    def __init__(self):
        self.spark = SparkSession.builder.appName("RealTimeProcessor").getOrCreate()

    def process_stream(self, stream_source):
        """
        Lit et traite un flux en continu.
        """
        df = self.spark.readStream.format("socket").option("host", "localhost").option("port", 9999).load()
        query = df.writeStream.outputMode("append").format("console").start()
        query.awaitTermination()

#from modAL.models import ActiveLearner
from sklearn.ensemble import RandomForestClassifier

class ActiveLearningManager:
    """
    Impl√©mente un gestionnaire d'apprentissage actif.
    """

    def __init__(self, X_pool, y_pool):
        self.learner = ActiveLearner(estimator=RandomForestClassifier(), X_training=X_pool, y_training=y_pool)

    def query_next(self):
        """
        S√©lectionne l'√©chantillon le plus incertain pour l'annotation.
        """
        query_idx, _ = self.learner.query(X_pool)
        return query_idx

import plotly.express as px

class Interactive3DVisualizer:
    """
    G√©n√®re des visualisations interactives en 3D.
    """

    def plot_3d(self, data, x_col, y_col, z_col, color_col):
        """
        G√©n√®re un graphique 3D interactif.
        """
        fig = px.scatter_3d(data, x=x_col, y=y_col, z=z_col, color=color_col)
        fig.show()

class ActionEncryptFile(Action):
    def name(self) -> str:
        return "action_encrypt_file"

    async def run(self, dispatcher, tracker, domain) -> list[EventType]:
        dispatcher.utter_message(text="Encrypting the file...")
        # Logique d'encryption ici
        return []




class SomeAction(Action):
    def name(self) -> str:
        return "some_action"

    def run(
            self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        Orchestrateur universel pour ex√©cuter dynamiquement toutes les actions existantes.
        """

        # Extraire l'action cible et les param√®tres
        target_action = tracker.get_slot("target_action")  # Nom de l'action cible
        action_params = tracker.get_slot("action_params")  # Param√®tres sous forme JSON

        if not target_action:
            dispatcher.utter_message(text="Erreur : aucune action cible sp√©cifi√©e.")
            return []

        try:
            # Charger dynamiquement l'action cible
            action_instance = self.load_action(target_action)

            if not action_instance:
                dispatcher.utter_message(
                    text=f"Action '{target_action}' introuvable. Assurez-vous qu'elle est bien enregistr√©e."
                )
                return []

            # D√©coder les param√®tres
            params = self.decode_params(action_params)

            # Ex√©cuter l'action
            result = action_instance.run(dispatcher, tracker, domain, **params)

            # Informer l'utilisateur
            dispatcher.utter_message(text=f"R√©sultat de l'action '{target_action}' : {result}")
            return result
        except Exception as e:
            logging.exception(f"Erreur lors de l'ex√©cution de '{target_action}': {e}")
            dispatcher.utter_message(
                text=f"Erreur lors de l'ex√©cution de l'action '{target_action}': {str(e)}"
            )
            return []

    def load_action(self, action_name: str) -> Any:
        """
        Charge dynamiquement une action bas√©e sur son nom.
        """
        try:
            # Identifier le module Python de l'action
            module_name = action_name.replace("action_", "")
            module_path = f"actions.{module_name}"

            # Importer dynamiquement le module
            module = importlib.import_module(module_path)

            # Instancier la classe correspondante
            action_class_name = module_name.capitalize()
            action_class = getattr(module, action_class_name, None)

            if action_class:
                return action_class()

            logging.error(f"Classe '{action_class_name}' non trouv√©e dans le module '{module_path}'.")
            return None
        except ModuleNotFoundError:
            logging.error(f"Module '{action_name}' introuvable.")
            return None

    def decode_params(self, params: str) -> Dict[str, Any]:
        """
        D√©codage des param√®tres JSON pour les convertir en dictionnaire.
        """
        try:
            return json.loads(params) if params else {}
        except json.JSONDecodeError:
            logging.error(f"Impossible de d√©coder les param√®tres JSON : {params}")
            return {}

