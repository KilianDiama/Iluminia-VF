import os
import logging
from typing import Union, Any, Dict, List, Tuple, Callable
import torch
from fastapi import FastAPI, Depends, HTTPException, status, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm
from qiskit import QuantumCircuit
from astropy.table import Table
from rasa_sdk.events import EventType
from astropy.coordinates import SkyCoord
from motor.motor_asyncio import AsyncIOMotorClient
from sklearn.pipeline import Pipeline
import dash
import streamlit as st
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from flask import Flask, request, jsonify, send_file, abort
import random
import motor.motor_asyncio
import albumentations

from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from dash import dcc, html
from albumentations import Compose, HorizontalFlip, RandomBrightnessContrast, Rotate
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from PIL import Image
from torchvision.models.detection import fasterrcnn_resnet50_fpn
#from brian2 import NeuronGroup, Synapses, run
from dash.dependencies import Input, Output
from PIL import Image
from io import BytesIO
import requests
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
import pandas as pd
import plotly.express as px
import networkx as nx
from cryptography.fernet import Fernet
from tpot import TPOTClassifier
from faker import Faker
import asyncio
from sentence_transformers import SentenceTransformer
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
import boto3
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import aiofiles
from rasa_sdk import Action
from rasa_sdk.executor import CollectingDispatcher
from rasa_sdk.events import SlotSet
from dask import dataframe as dd
#from qiskit import Aer, QuantumCircuit, transpile
from qiskit.circuit.library import RealAmplitudes
from qiskit_machine_learning.algorithms import VQC
#from qiskit_machine_learning.kernels import QuantumKernel
from sklearn.model_selection import train_test_split
from scipy.stats import ks_2samp
from cachetools import TTLCache
import joblib
import pandas as pd
import matplotlib.pyplot as plt
from io import BytesIO
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
import datetime
from collections import Counter
import spacy
from langdetect import detect
from joblib import Parallel, delayed
import time
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import GridSearchCV
import yaml
from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN
import hdbscan
from umap import UMAP
from typing import Optional
import plotly.graph_objects as go
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.backends import default_backend
from dotenv import load_dotenv
import base64
import numpy as np
from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes
from collections import defaultdict
from pydantic import BaseModel
from rasa_sdk import Tracker
from rasa_sdk.types import DomainDict
from sklearn.linear_model import LinearRegression
from imblearn.over_sampling import SMOTE
import shap
from datetime import datetime
from typing import Text
from sklearn.ensemble import RandomForestClassifier
from rasa.engine.graph import GraphComponent
from rasa.shared.nlu.training_data.training_data import TrainingData
from rasa.shared.nlu.constants import INTENT
#from rasa.nlu.model import Metadata
import tensorflow as tf
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
import pandas as pd
import argparse


import os
from Crypto.Cipher import AES
import sys

if len(sys.argv) < 2:
    print("Erreur : Aucun fichier spécifié.")
    sys.exit(1)

chemin_fichier = sys.argv[1]  # Récupère le premier argument passé en ligne de commande
df = pd.read_csv(chemin_fichier)

# 🔍 Récupérer la clé depuis les variables d'environnement
key = os.getenv("SECRET_KEY")

# ⚠️ Vérifier si la clé est bien récupérée
if key is None:
    raise ValueError("🚨 ERREUR : SECRET_KEY n'est pas définie. Vérifiez vos variables d'environnement.")

print("🔑 Clé récupérée :", key)

# 🔧 Corriger la longueur de la clé (AES accepte uniquement 16, 24 ou 32 bytes)
key = key.ljust(16, "0")[:16].encode("utf-8")  # Complète avec des '0' si nécessaire

# ✅ Initialiser AES
cipher = AES.new(key, AES.MODE_ECB)
print("✅ AES initialisé avec succès !")

iv = os.urandom(16)  # Générer un IV aléatoire si besoin

try:
    chemin_fichier = "data.csv"
    df = pd.read_csv(chemin_fichier)
    if df.empty:
        raise ValueError("Le fichier CSV est vide.")
except pd.errors.EmptyDataError:
    print("Erreur : Le fichier CSV est vide ou corrompu.")
    
chemin_fichier = "C:/Users/diama/projet_RASA/actions/ILLUMINIA/mon_fichier.csv"
if not os.path.exists(chemin_fichier):
    raise FileNotFoundError(f"Le fichier {chemin_fichier} n'existe pas.")


parser = argparse.ArgumentParser()
parser.add_argument("--chemin_fichier", type=str, required=True)
args = parser.parse_args()

print(f"Chargement du fichier : {args.chemin_fichier}")
X_test = pd.read_csv('/kaggle/input/mon_fichier.csv')



chemin_fichier = "/kaggle/input/mon_fichier.csv"
mot_de_passe = "MonSuperMotDePasse123"

# Définir les données d'exemple
data = {
    "feature1": [5.6, 4.7, 6.1],
    "feature2": [3.2, 2.8, 3.0]
}

import argparse
import os
import pandas as pd

def main(chemin_fichier, fichier_analyse):
    if not os.path.exists(chemin_fichier):
        raise FileNotFoundError(f"Le fichier {chemin_fichier} n'existe pas.")

    if not os.path.exists(fichier_analyse):
        raise FileNotFoundError(f"Le fichier {fichier_analyse} n'existe pas.")

    # Charger et traiter les fichiers CSV
    print(f"✅ Fichier principal chargé : {chemin_fichier}")
    print(f"✅ Fichier à analyser chargé : {fichier_analyse}")
    chemin_fichier = "data.csv"
    df = pd.read_csv(chemin_fichier)
    df_analyse = pd.read_csv(fichier_analyse)

    print("📊 Données du fichier principal :")
    print(df.head())

    print("📊 Données à analyser :")
    print(df_analyse.head())

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Programme ILLUMINIA pour analyse de données.")
    parser.add_argument("--chemin_fichier", required=True, help="Chemin du fichier principal.")
    parser.add_argument("--fichier_analyse", default="C:/Users/diama/projet_RASA/actions/ILLUMINIA/fichier_a_analyser.csv", help="Chemin du fichier à analyser")

    
    args = parser.parse_args()
    main(args.chemin_fichier, args.fichier_analyse)


# Créer un DataFrame
df = pd.DataFrame(data)

# Enregistrer sous forme de CSV
file_path = "C:/Users/diama/projet_RASA/actions/ILLUMINIA/chemin_vers_ton_fichier_test.csv"
df.to_csv(file_path, index=False)

print(f"✅ Fichier CSV créé avec succès : {file_path}")


# Définition correcte du pipeline
pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

# Données fictives pour l'exemple
X_train = pd.DataFrame({
    'feature1': [1.0, 2.0, None],
    'feature2': [4.0, None, 6.0]
})

# Utilisation du pipeline
X_train_prepared = pipeline.fit_transform(X_train)
print(X_train_prepared)

# Charger les données de test depuis un fichier
X_test = pd.read_csv('chemin_vers_ton_fichier_test.csv')

# Assure-toi que les colonnes correspondent au pipeline
X_test = X_test[['feature1', 'feature2']]  # Ajuste en fonction de tes colonnes

X_test = X_test.rename(columns={
    "feature1": "sepal length (cm)",
    "feature2": "sepal width (cm)"
})

load_dotenv()
import tkinter as tk
from tkinter import filedialog, messagebox
import pandas as pd

def charger_fichier():
    fichier = filedialog.askopenfilename(filetypes=[("Fichiers CSV", "*.csv")])
    if fichier:
        label_fichier.config(text=f"Fichier sélectionné : {fichier}")
        global chemin_fichier
        chemin_fichier = fichier

def analyser_fichier():
    if not chemin_fichier:
        messagebox.showerror("Erreur", "Veuillez sélectionner un fichier CSV.")
        return
    chemin_fichier = "data.csv"
    df = pd.read_csv(chemin_fichier)
    messagebox.showinfo("Analyse réussie", f"Le fichier contient {df.shape[0]} lignes et {df.shape[1]} colonnes.")

# Création de la fenêtre
root = tk.Tk()
root.title("ILLUMINIA - Analyse de données")

# Bouton pour charger un fichier
btn_charger = tk.Button(root, text="Choisir un fichier CSV", command=charger_fichier)
btn_charger.pack(pady=10)

# Label pour afficher le fichier sélectionné
label_fichier = tk.Label(root, text="Aucun fichier sélectionné", fg="blue")
label_fichier.pack(pady=5)

# Bouton pour analyser
btn_analyser = tk.Button(root, text="Analyser", command=analyser_fichier)
btn_analyser.pack(pady=10)

# Démarrer la fenêtre
root.mainloop()

# Configuration des constantes
ENCRYPTION_KEY = os.getenv("ENCRYPTION_KEY")
MASTER_PASSWORD = os.getenv("MASTER_PASSWORD")

if not ENCRYPTION_KEY or not MASTER_PASSWORD:
    raise ValueError("Les clés ou mots de passe sont manquants dans les variables d'environnement.")

# Configuration du logger
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialisation de FastAPI
app = FastAPI()

# Middleware pour vérifier l'autorisation
@app.middleware("http")
async def check_authorization(request: Request, call_next):
    secret_key = request.headers.get("Authorization")
    logger.info(f"Authorization header received: {secret_key}")
    if not secret_key or secret_key != f"Bearer {MASTER_PASSWORD}":
        logger.warning("Unauthorized access attempt detected.")
        raise HTTPException(status_code=401, detail="Unauthorized")
    response = await call_next(request)
    return response

# Modèles pour FastAPI (utilisés dans les endpoints)
class WebhookPayload(BaseModel):
    signature: str
    payload: str

# Routes de l'application
@app.get("/test_env")
async def test_env():
    """
    Route pour tester les variables d'environnement chargées.
    """
    return {
        "ENCRYPTION_KEY": ENCRYPTION_KEY,
        "MASTER_PASSWORD": MASTER_PASSWORD,
    }

@app.post("/verify_webhook")
async def verify_webhook(payload: WebhookPayload):
    """
    Vérifie la signature d'un webhook.
    """
    is_valid = verify_webhook_signature(payload.signature, payload.payload, MASTER_PASSWORD)
    if is_valid:
        return {"status": "valid"}
    else:
        raise HTTPException(status_code=400, detail="Invalid signature")

# Fonction pour générer un salt sécurisé
def generate_salt() -> bytes:
    return os.urandom(16)

# Fonction pour dériver une clé à partir d'un mot de passe maître
def derive_key(master_password: str, salt: bytes) -> bytes:
    kdf = PBKDF2HMAC(
        algorithm=hashes.SHA256(),
        length=32,
        salt=salt,
        iterations=100000,
        backend=default_backend()
    )
    return kdf.derive(master_password.encode())

# Fonction pour crypter une clé
def encrypt_encryption_key(encryption_key: bytes, master_password: str) -> bytes:
    try:
        salt = generate_salt()
        master_key = derive_key(master_password, salt)
        cipher = Cipher(algorithms.AES(master_key), modes.GCM(os.urandom(12)), backend=default_backend())
        encryptor = cipher.encryptor()
        encrypted_key = encryptor.update(encryption_key) + encryptor.finalize()

        return salt + cipher.algorithm.iv + encryptor.tag + encrypted_key
    except Exception as e:
        logger.error(f"Erreur lors du chiffrement : {e}")
        raise

# Fonction pour déchiffrer une clé
def decrypt_encryption_key(encrypted_data: bytes, master_password: str) -> bytes:
    try:
        salt = encrypted_data[:16]
        iv = encrypted_data[16:28]
        tag = encrypted_data[28:44]
        encrypted_key = encrypted_data[44:]

        master_key = derive_key(master_password, salt)
        cipher = Cipher(algorithms.AES(master_key), modes.GCM(iv, tag), backend=default_backend())
        decryptor = cipher.decryptor()
        return decryptor.update(encrypted_key) + decryptor.finalize()
    except Exception as e:
        logger.error("Erreur lors du déchiffrement de la clé : %s", e)
        raise

# Fonction pour vérifier la signature d'un webhook
def verify_webhook_signature(signature: str, payload: str, secret_key: str) -> bool:
    """
    Vérifie la signature HMAC d'un webhook pour s'assurer qu'il vient de la source autorisée.
    """
    expected_signature = hmac.new(secret_key.encode(), payload.encode(), hashlib.sha256).hexdigest()
    return hmac.compare_digest(signature, expected_signature)

# Exemple d'utilisation en ligne de commande
if __name__ == "__main__":
    try:
        # Demander un mot de passe maître à l'utilisateur
        master_password = input("Entrez votre mot de passe maître pour sécuriser la clé : ").strip()
        if len(master_password) < 8:
            raise ValueError("Le mot de passe maître doit contenir au moins 8 caractères.")

        # Génération d'une clé de chiffrement aléatoire
        encryption_key = os.urandom(32)

        # Chiffrement de la clé
        encrypted_key = encrypt_encryption_key(encryption_key, master_password)
        logger.info(f"Clé chiffrée (base64) : {encrypted_key}")

        # Sauvegarde dans un fichier
        with open("encrypted_key.txt", "wb") as file:
            file.write(encrypted_key)

        # Lecture depuis le fichier
        with open("encrypted_key.txt", "rb") as file:
            stored_encrypted_key = file.read()

        # Déchiffrement de la clé
        decrypted_key = decrypt_encryption_key(stored_encrypted_key, master_password)
        assert encryption_key == decrypted_key, "La clé déchiffrée ne correspond pas à l'originale."
        logger.info("Chiffrement et déchiffrement réussis.")
    except Exception as e:
        logger.error(f"Une erreur critique s'est produite : {e}")
        
class ActionGenerateVisualization(Action):
    def name(self) -> str:
        return "action_generate_visualization"

    def run(self, dispatcher: CollectingDispatcher,
            tracker: Tracker,
            domain: DomainDict) -> list:
        """
        Génère un graphique basé sur les données utilisateur ou des valeurs par défaut.
        Offre plusieurs types de graphiques selon la demande utilisateur.
        """
        user_message = tracker.latest_message.get('text', "").lower()
        logger.info(f"Message utilisateur reçu : {user_message}")

        try:
            # Extraction des données utilisateur
            if "données" in user_message:
                data = [int(num) for num in user_message.split() if num.isdigit()]
                logger.info(f"Données utilisateur extraites : {data}")
            else:
                data = [10, 20, 30, 40]  # Valeurs par défaut
                logger.info("Aucune donnée utilisateur détectée, valeurs par défaut utilisées.")

            if not data:
                dispatcher.utter_message(text="Je n'ai pas trouvé de données valides pour générer un graphique.")
                return []

            # Choix du type de graphique
            chart_type = "bar"
            if "ligne" in user_message:
                chart_type = "line"
            elif "camembert" in user_message:
                chart_type = "pie"

            # Génération du graphique
            plt.figure(figsize=(6, 4))
            if chart_type == "bar":
                plt.bar(range(len(data)), data, color='blue')
                plt.xlabel("Index")
                plt.ylabel("Valeurs")
            elif chart_type == "line":
                plt.plot(range(len(data)), data, marker='o', color='green')
                plt.xlabel("Index")
                plt.ylabel("Valeurs")
            elif chart_type == "pie":
                plt.pie(data, labels=[f"Part {i+1}" for i in range(len(data))], autopct='%1.1f%%')
            plt.title("Visualisation des données utilisateur")

            # Sauvegarde du graphique en Base64
            buffer = BytesIO()
            plt.savefig(buffer, format="png")
            buffer.seek(0)
            image_base64 = base64.b64encode(buffer.read()).decode('utf-8')
            buffer.close()
            plt.close()
            logger.info("Graphique généré et encodé avec succès.")

            # Envoi du graphique encodé au format Base64
            dispatcher.utter_message(
                text=f"Voici votre graphique ({chart_type}) :",
                image=f"data:image/png;base64,{image_base64}"
            )
        except Exception as e:
            logger.error(f"Erreur lors de la génération du graphique : {e}")
            dispatcher.utter_message(text="Une erreur est survenue lors de la génération du graphique.")

        return []
class FileManager:
    """
    Gère l'importation, l'exportation et l'organisation des fichiers.
    """

    def __init__(self, base_dir: str = "files"):
        """
        Initialise le gestionnaire de fichiers.

        Args:
            base_dir (str): Répertoire de base pour sauvegarder les fichiers.
        """
        self.base_dir = base_dir
        os.makedirs(self.base_dir, exist_ok=True)

    def save_csv(self, data: Union[pd.DataFrame, List[Dict]], file_name: str) -> str:
        """
        Sauvegarde des données au format CSV.

        Args:
            data (Union[pd.DataFrame, List[Dict]]): Données à sauvegarder.
            file_name (str): Nom du fichier CSV.

        Returns:
            str: Chemin du fichier sauvegardé.
        """
        if isinstance(data, list):
            data = pd.DataFrame(data)
        if not isinstance(data, pd.DataFrame):
            raise ValueError("Les données doivent être un DataFrame ou une liste de dictionnaires.")

        file_path = os.path.join(self.base_dir, file_name)
        data.to_csv(file_path, index=False)
        return file_path

    def save_json(self, data: Dict, file_name: str) -> str:
        """
        Sauvegarde des données au format JSON.

        Args:
            data (Dict): Données à sauvegarder.
            file_name (str): Nom du fichier JSON.

        Returns:
            str: Chemin du fichier sauvegardé.
        """
        file_path = os.path.join(self.base_dir, file_name)
        with open(file_path, "w") as f:
            json.dump(data, f, indent=4)
        return file_path

    def load_csv(self, file_name: str) -> pd.DataFrame:
        """
        Charge des données à partir d'un fichier CSV.

        Args:
            file_name (str): Nom du fichier CSV.

        Returns:
            pd.DataFrame: Données chargées.
        """
        file_path = os.path.join(self.base_dir, file_name)
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Fichier introuvable : {file_path}")
        return pd.read_csv(file_path)

    def load_json(self, file_name: str) -> Dict:
        """
        Charge des données à partir d'un fichier JSON.

        Args:
            file_name (str): Nom du fichier JSON.

        Returns:
            Dict: Données chargées.
        """
        file_path = os.path.join(self.base_dir, file_name)
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Fichier introuvable : {file_path}")
        with open(file_path, "r") as f:
            return json.load(f)

class SecureFileManager:
    def __init__(self, master_password: str):
        self.master_password = master_password.encode()

    def _generate_salt(self) -> bytes:
        return os.urandom(16)

    def _derive_key(self, salt: bytes) -> bytes:
        kdf = PBKDF2HMAC(
            algorithm=hashes.SHA256(),
            length=32,
            salt=salt,
            iterations=100000,
            backend=default_backend(),
        )
        return kdf.derive(self.master_password)

    def encrypt_data(self, data: bytes) -> str:
        salt = self._generate_salt()
        key = self._derive_key(salt)
        iv = os.urandom(12)
        cipher = Cipher(algorithms.AES(key), modes.GCM(iv), backend=default_backend())
        encryptor = cipher.encryptor()
        encrypted_data = encryptor.update(data) + encryptor.finalize()
        return base64.b64encode(salt + iv + encryptor.tag + encrypted_data).decode("utf-8")

    def decrypt_data(self, encrypted_data: str) -> bytes:
        decoded_data = base64.b64decode(encrypted_data)
        salt = decoded_data[:16]
        iv = decoded_data[16:28]
        tag = decoded_data[28:44]
        ciphertext = decoded_data[44:]
        key = self._derive_key(salt)
        cipher = Cipher(algorithms.AES(key), modes.GCM(iv, tag), backend=default_backend())
        decryptor = cipher.decryptor()
        return decryptor.update(ciphertext) + decryptor.finalize()

async def global_exception_handler(request, exc):
    return JSONResponse(
        status_code=500,
        content={"message": "Une erreur interne est survenue. Veuillez réessayer plus tard."}
    )
if __name__ == "__main__":
    # Exemple d'utilisation
    original_data = "Exemple de texte à chiffrer".encode("utf-8")
    master_password = "supersecur3password"
    manager = SecureFileManager(master_password)

    # Chiffrement
    encrypted = manager.encrypt_data(original_data)
    print(f"Encrypted Data: {encrypted}")

    # Déchiffrement
    decrypted = manager.decrypt_data(encrypted)
    print(f"Decrypted Data: {decrypted.decode('utf-8')}")

nlp = spacy.load("en_core_web_sm")

try:

    response = "Voici votre message : {placeholder}"
except KeyError as e:
    logger.error(f"Variable manquante dans la réponse : {e}")
    text = "Une erreur est survenue dans la génération de la réponse."

# Fonction pour lire un fichier texte
def lire_fichier(fichier: str) -> Optional[str]:
    """Lire un fichier texte et retourner son contenu."""
    try:
        with open(fichier, 'r', encoding='utf-8') as f:
            contenu = f.read()
        return contenu
    except FileNotFoundError:
        print(f"Le fichier {fichier} n'a pas été trouvé.")
    except Exception as e:
        print(f"Erreur lors de la lecture du fichier : {e}")
    return None


# Fonction pour lire un fichier JSON
def lire_fichier_json(fichier: str) -> Optional[Dict[str, Any]]:
    """Lire un fichier JSON et retourner les données sous forme de dictionnaire."""
    try:
        with open(fichier, 'r', encoding='utf-8') as f:
            données = json.load(f)
        return données
    except FileNotFoundError:
        print(f"Le fichier {fichier} n'a pas été trouvé.")
    except json.JSONDecodeError:
        print(f"Erreur de décodage JSON dans le fichier {fichier}.")
    except Exception as e:
        print(f"Erreur lors de la lecture du fichier : {e}")
    return None


# Fonction pour lire un fichier CSV
def lire_fichier_csv(fichier: str) -> Optional[pd.DataFrame]:
    """Lire un fichier CSV et le charger dans un DataFrame pandas."""
    try:
        données_csv = pd.read_csv(fichier)
        return données_csv
    except FileNotFoundError:
        print(f"Le fichier {fichier} n'a pas été trouvé.")
    except pd.errors.EmptyDataError:
        print(f"Le fichier {fichier} est vide.")
    except Exception as e:
        print(f"Erreur lors de la lecture du fichier : {e}")
    return None


# Fonction d'analyse de texte avec spaCy
def analyse_texte(texte: str):
    """Analyser un texte avec spaCy pour extraire des entités et faire du POS tagging."""
    doc = nlp(texte)

    # Extraire les entités nommées
    entités = [(ent.text, ent.label_) for ent in doc.ents]

    # Afficher les résultats de l'analyse de texte
    print("Entités nommées :")
    for ent in entités:
        print(f"Texte: {ent[0]}, Type: {ent[1]}")

    print("\nAnalyse des tokens (part-of-speech tagging) :")
    for token in doc:
        print(f"{token.text}: {token.pos_}")


# Exemple d'analyse avec un fichier
def traiter_fichier(fichier: str):
    """Traiter un fichier en fonction de son type (texte, CSV, JSON)."""
    if fichier.endswith(".txt"):
        contenu = lire_fichier(fichier)
        if contenu:
            print(f"Analyse du fichier texte {fichier}:\n")
            analyse_texte(contenu)

    elif fichier.endswith(".json"):
        données_json = lire_fichier_json(fichier)
        if données_json:
            print(f"Analyse du fichier JSON {fichier}:")
            print(données_json)

    elif fichier.endswith(".csv"):
        données_csv = lire_fichier_csv(fichier)
        if données_csv is not None:
            print(f"Analyse du fichier CSV {fichier}:")
            print(données_csv.head())  # Affiche les premières lignes du CSV

    else:
        print(f"Format de fichier non pris en charge : {fichier}")


# Fonction principale pour exécuter le script
def main():
    fichier = input("Entrez le chemin du fichier à analyser : ")

    if os.path.exists(fichier):
        traiter_fichier(fichier)
    else:
        print(f"Le fichier {fichier} n'existe pas.")


# Lancer l'exécution du programme
if __name__ == "__main__":
    main()



class CustomIntentClassifier(GraphComponent):
    def __init__(self, config=None):
        self.config = config or {}

    def train(self, training_data: TrainingData):
        sentences = [example.text for example in training_data.training_examples]
        intents = [example.get(INTENT) for example in training_data.training_examples]

        # Préparation des données (simplifiée)
        self.vectorizer = tf.keras.layers.TextVectorization(max_tokens=10000, output_sequence_length=100)
        self.vectorizer.adapt(sentences)

        X = self.vectorizer(sentences)
        y = tf.keras.utils.to_categorical([training_data.intents.index(intent) for intent in intents])

        # Modèle TensorFlow
        self.model = tf.keras.Sequential([
            tf.keras.layers.Embedding(input_dim=10000, output_dim=64),
            tf.keras.layers.GlobalAveragePooling1D(),
            tf.keras.layers.Dense(64, activation="relu"),
            tf.keras.layers.Dense(len(training_data.intents), activation="softmax")
        ])
        self.model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])
        self.model.fit(X, y, epochs=5, batch_size=32)

    def process(self, message, **kwargs):
        sentence = tf.constant([message.text])
        X = self.vectorizer(sentence)
        probabilities = self.model.predict(X)
        intent_index = np.argmax(probabilities)
        intent_name = self.config["intents"][intent_index]

        # Mise à jour du message avec l'intention détectée
        message.set(INTENT, {"name": intent_name, "confidence": float(probabilities[0][intent_index])})

    @classmethod
    def create(cls, config, model_storage, resource, execution_context):
        return cls(config)


class APIIntegrationManager:
    """
    Gère les intégrations avec des APIs tierces, avec support pour le cache et les limites de taux.
    """

    def __init__(self, cache_ttl: int = 3600, rate_limit: int = 60):
        """
        Initialise le gestionnaire API.

        Args:
            cache_ttl (int): Temps de vie des entrées en cache en secondes.
            rate_limit (int): Limite des appels API par minute.
        """
        self.api_keys = {}
        self.api_endpoints = {}
        self.response_cache = TTLCache(maxsize=1000, ttl=cache_ttl)
        self.rate_limit = rate_limit
        self.last_call_time = {}
        logger.info("APIIntegrationManager initialized with caching and rate limiting.")

    def add_api(self, api_name: str, base_url: str, api_key: Optional[str] = None):
        """
        Ajoute une nouvelle API à gérer.

        Args:
            api_name (str): Nom de l'API.
            base_url (str): URL de base de l'API.
            api_key (Optional[str]): Clé API si nécessaire.
        """
        self.api_endpoints[api_name] = base_url
        if api_key:
            self.api_keys[api_name] = api_key
        logger.info(f"API '{api_name}' added with base URL: {base_url}.")

    def rate_limiter(self, api_name: str):
        """
        Applique une limite de taux sur les appels API.

        Args:
            api_name (str): Nom de l'API.
        """
        if api_name in self.last_call_time:
            elapsed_time = time.time() - self.last_call_time[api_name]
            wait_time = max(0, (60 / self.rate_limit) - elapsed_time)
            if wait_time > 0:
                logger.info(f"Rate limit reached for API '{api_name}'. Waiting {wait_time:.2f} seconds...")
                time.sleep(wait_time)
        self.last_call_time[api_name] = time.time()

    def make_request(self, api_name: str, endpoint: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Effectue un appel API avec gestion des erreurs et mise en cache.

        Args:
            api_name (str): Nom de l'API.
            endpoint (str): Endpoint spécifique.
            params (Optional[Dict[str, Any]]): Paramètres de requête.

        Returns:
            Dict[str, Any]: Réponse JSON de l'API.
        """
        try:
            if api_name not in self.api_endpoints:
                raise ValueError(f"API '{api_name}' is not configured.")

            base_url = self.api_endpoints[api_name]
            url = f"{base_url}/{endpoint}"
            params = params or {}

            # Ajouter la clé API si nécessaire
            if api_name in self.api_keys:
                params["api_key"] = self.api_keys[api_name]

            # Gestion du cache
            cache_key = f"{api_name}:{endpoint}:{str(params)}"
            if cache_key in self.response_cache:
                logger.info(f"Cache hit for API '{api_name}' and endpoint '{endpoint}'.")
                return self.response_cache[cache_key]

            # Appliquer la limite de taux
            self.rate_limiter(api_name)

            # Effectuer la requête
            logger.info(f"Making request to API '{api_name}' at endpoint '{endpoint}'...")
            response = requests.get(url, params=params)
            response.raise_for_status()
            data = response.json()

            # Ajouter au cache
            self.response_cache[cache_key] = data
            logger.info(f"Request successful for API '{api_name}' at endpoint '{endpoint}'.")
            return data
        except requests.exceptions.RequestException as e:
            logger.error(f"Error during API request to '{api_name}': {e}")
            return {"error": "API request failed."}
        except Exception as e:
            logger.error(f"Unexpected error during API request to '{api_name}': {e}")
            return {"error": "An unexpected error occurred."}

    def get_cached_response(self, api_name: str, endpoint: str, params: Optional[Dict[str, Any]] = None) -> Optional[Dict[str, Any]]:
        """
        Récupère une réponse mise en cache si disponible.

        Args:
            api_name (str): Nom de l'API.
            endpoint (str): Endpoint spécifique.
            params (Optional[Dict[str, Any]]): Paramètres de requête.

        Returns:
            Optional[Dict[str, Any]]: Réponse mise en cache ou None si non trouvée.
        """
        cache_key = f"{api_name}:{endpoint}:{str(params)}"
        return self.response_cache.get(cache_key)

    def remove_cached_response(self, api_name: str, endpoint: str, params: Optional[Dict[str, Any]] = None):
        """
        Supprime une réponse mise en cache.

        Args:
            api_name (str): Nom de l'API.
            endpoint (str): Endpoint spécifique.
            params (Optional[Dict[str, Any]]): Paramètres de requête.
        """
        cache_key = f"{api_name}:{endpoint}:{str(params)}"
        if cache_key in self.response_cache:
            del self.response_cache[cache_key]
            logger.info(f"Cache entry removed for API '{api_name}' and endpoint '{endpoint}'.")

    def clear_cache(self):
        """
        Efface tout le cache.
        """
        self.response_cache.clear()
        logger.info("All API cache cleared.")

class VisualizationService:
    """
    Service pour créer et exporter des visualisations interactives et statiques.
    """

    def __init__(self, output_dir: str = "visualizations"):
        """
        Initialise le service de visualisation.

        Args:
            output_dir (str): Répertoire pour sauvegarder les graphiques exportés.
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        logger.info(f"VisualizationService initialized. Output directory: {output_dir}")

    def create_bar_chart(self, data: Dict[str, int], title: str = "Bar Chart") -> go.Figure:
        """
        Crée un graphique en barres.

        Args:
            data (Dict[str, int]): Données au format {catégorie: valeur}.
            title (str): Titre du graphique.

        Returns:
            go.Figure: Graphique interactif Plotly.
        """
        try:
            logger.info("Creating bar chart...")
            fig = go.Figure(data=[go.Bar(x=list(data.keys()), y=list(data.values()))])
            fig.update_layout(title=title, xaxis_title="Categories", yaxis_title="Values")
            logger.info("Bar chart created successfully.")
            return fig
        except Exception as e:
            logger.error(f"Error creating bar chart: {e}")
            return go.Figure()

    def create_pie_chart(self, data: Dict[str, int], title: str = "Pie Chart") -> go.Figure:
        """
        Crée un graphique en camembert.

        Args:
            data (Dict[str, int]): Données au format {catégorie: valeur}.
            title (str): Titre du graphique.

        Returns:
            go.Figure: Graphique interactif Plotly.
        """
        try:
            logger.info("Creating pie chart...")
            fig = go.Figure(data=[go.Pie(labels=list(data.keys()), values=list(data.values()))])
            fig.update_layout(title=title)
            logger.info("Pie chart created successfully.")
            return fig
        except Exception as e:
            logger.error(f"Error creating pie chart: {e}")
            return go.Figure()

    def create_scatter_plot(self, x: List[float], y: List[float], title: str = "Scatter Plot") -> go.Figure:
        """
        Crée un graphique en nuage de points.

        Args:
            x (List[float]): Coordonnées X.
            y (List[float]): Coordonnées Y.
            title (str): Titre du graphique.

        Returns:
            go.Figure: Graphique interactif Plotly.
        """
        try:
            logger.info("Creating scatter plot...")
            fig = go.Figure(data=[go.Scatter(x=x, y=y, mode='markers')])
            fig.update_layout(title=title, xaxis_title="X Axis", yaxis_title="Y Axis")
            logger.info("Scatter plot created successfully.")
            return fig
        except Exception as e:
            logger.error(f"Error creating scatter plot: {e}")
            return go.Figure()

    def export_chart(self, fig: go.Figure, file_name: str = "chart.html", export_as_image: bool = False):
        """
        Exporte un graphique interactif au format HTML et optionnellement comme image.

        Args:
            fig (go.Figure): Graphique Plotly.
            file_name (str): Nom du fichier exporté.
            export_as_image (bool): Exporter aussi en tant qu'image (PNG).
        """
        try:
            output_path = os.path.join(self.output_dir, file_name)
            fig.write_html(output_path)
            logger.info(f"Chart exported to {output_path}.")

            if export_as_image:
                image_path = output_path.replace(".html", ".png")
                fig.write_image(image_path)
                logger.info(f"Chart exported as image to {image_path}.")
        except Exception as e:
            logger.error(f"Error exporting chart: {e}")

    def create_and_export_bar_chart(self, data: Dict[str, int], title: str, file_name: str):
        """
        Pipeline pour créer et exporter un graphique en barres.

        Args:
            data (Dict[str, int]): Données au format {catégorie: valeur}.
            title (str): Titre du graphique.
            file_name (str): Nom du fichier exporté.
        """
        fig = self.create_bar_chart(data, title)
        self.export_chart(fig, file_name)

    def visualize_dataframe(self, df: pd.DataFrame, x_column: str, y_column: str, chart_type: str = "scatter", title: str = "Chart"):
        """
        Crée un graphique à partir d'un DataFrame.

        Args:
            df (pd.DataFrame): DataFrame contenant les données.
            x_column (str): Colonne pour l'axe X.
            y_column (str): Colonne pour l'axe Y.
            chart_type (str): Type de graphique ("scatter", "bar").
            title (str): Titre du graphique.

        Returns:
            go.Figure: Graphique interactif.
        """
        try:
            logger.info(f"Creating {chart_type} chart from DataFrame...")
            if chart_type == "scatter":
                return self.create_scatter_plot(df[x_column].tolist(), df[y_column].tolist(), title)
            elif chart_type == "bar":
                data = df.groupby(x_column)[y_column].sum().to_dict()
                return self.create_bar_chart(data, title)
            else:
                logger.error(f"Unsupported chart type: {chart_type}")
                return go.Figure()
        except Exception as e:
            logger.error(f"Error visualizing DataFrame: {e}")
            return go.Figure()

class UserConsentManager:
    """
    Gère les consentements des utilisateurs pour des actions spécifiques.
    """

    def __init__(self, db_manager):
        """
        Initialise le gestionnaire de consentement.

        Args:
            db_manager: Gestionnaire de base de données pour stocker les consentements.
        """
        self.db_manager = db_manager
        logger.info("UserConsentManager initialized with database integration.")

    async def record_consent(self, user_id: str, consent_type: str, consent_value: bool):
        """
        Enregistre ou met à jour un consentement pour un utilisateur.

        Args:
            user_id (str): ID utilisateur.
            consent_type (str): Type de consentement (e.g., "data_collection").
            consent_value (bool): Valeur du consentement (True ou False).
        """
        try:
            consent_record = {
                "user_id": user_id,
                "consent_type": consent_type,
                "consent_value": consent_value,
                "timestamp": datetime.datetime.utcnow()
            }
            await self.db_manager.save_consent(consent_record)
            logger.info(f"Consent recorded for user '{user_id}' and type '{consent_type}': {consent_value}")
        except Exception as e:
            logger.error(f"Error recording consent for user '{user_id}': {e}")

    async def validate_consent(self, user_id: str, consent_type: str) -> bool:
        """
        Valide si un utilisateur a donné son consentement pour une action spécifique.

        Args:
            user_id (str): ID utilisateur.
            consent_type (str): Type de consentement requis.

        Returns:
            bool: True si le consentement est valide, sinon False.
        """
        try:
            consent = await self.db_manager.get_consent(user_id, consent_type)
            if consent and consent.get("consent_value"):
                logger.info(f"Valid consent found for user '{user_id}' and type '{consent_type}'.")
                return True
            logger.warning(f"No valid consent found for user '{user_id}' and type '{consent_type}'.")
            return False
        except Exception as e:
            logger.error(f"Error validating consent for user '{user_id}': {e}")
            return False

    async def revoke_consent(self, user_id: str, consent_type: Optional[str] = None):
        """
        Révoque un ou tous les consentements d'un utilisateur.

        Args:
            user_id (str): ID utilisateur.
            consent_type (Optional[str]): Type spécifique de consentement à révoquer. Si None, révoque tous les consentements.
        """
        try:
            if consent_type:
                await self.db_manager.delete_consent(user_id, consent_type)
                logger.info(f"Consent revoked for user '{user_id}' and type '{consent_type}'.")
            else:
                await self.db_manager.delete_all_consents(user_id)
                logger.info(f"All consents revoked for user '{user_id}'.")
        except Exception as e:
            logger.error(f"Error revoking consent for user '{user_id}': {e}")

    async def list_user_consents(self, user_id: str) -> Dict[str, Any]:
        """
        Récupère tous les consentements d'un utilisateur.

        Args:
            user_id (str): ID utilisateur.

        Returns:
            Dict[str, Any]: Consentements de l'utilisateur.
        """
        try:
            consents = await self.db_manager.get_all_consents(user_id)
            logger.info(f"Listed consents for user '{user_id}': {consents}")
            return consents
        except Exception as e:
            logger.error(f"Error listing consents for user '{user_id}': {e}")
            return {}

    async def is_consent_required(self, user_id: str, consent_type: str) -> bool:
        """
        Vérifie si un consentement est requis pour un utilisateur.

        Args:
            user_id (str): ID utilisateur.
            consent_type (str): Type de consentement.

        Returns:
            bool: True si le consentement est requis, sinon False.
        """
        try:
            required_consents = ["data_collection", "notifications"]  # Exemple de types requis
            if consent_type in required_consents:
                logger.info(f"Consent required for user '{user_id}' and type '{consent_type}'.")
                return True
            logger.info(f"Consent not required for user '{user_id}' and type '{consent_type}'.")
            return False
        except Exception as e:
            logger.error(f"Error checking if consent is required for user '{user_id}': {e}")
            return False

class InteractionLogger:
    """
    Gère l'enregistrement et la récupération des interactions utilisateur.
    """

    def __init__(self, storage_type: str = "json", storage_path: str = "interactions", db_manager=None):
        """
        Initialise le logger d'interactions.

        Args:
            storage_type (str): Type de stockage ('json', 'database').
            storage_path (str): Chemin pour les fichiers JSON.
            db_manager: Gestionnaire de base de données (si 'database' est utilisé).
        """
        self.storage_type = storage_type
        self.storage_path = storage_path
        self.db_manager = db_manager

        if storage_type == "json":
            os.makedirs(storage_path, exist_ok=True)
            logger.info(f"InteractionLogger initialized for JSON storage at '{storage_path}'.")
        elif storage_type == "database":
            if not db_manager:
                raise ValueError("A database manager must be provided for 'database' storage.")
            logger.info("InteractionLogger initialized for database storage.")

    def _get_json_file_path(self, user_id: str) -> str:
        """
        Génère le chemin du fichier JSON pour un utilisateur.

        Args:
            user_id (str): ID utilisateur.

        Returns:
            str: Chemin complet du fichier JSON.
        """
        return os.path.join(self.storage_path, f"{user_id}_interactions.json")

    def save_interaction(self, user_id: str, message: str, response: str, metadata: Optional[Dict[str, Any]] = None):
        """
        Enregistre une interaction utilisateur.

        Args:
            user_id (str): ID utilisateur.
            message (str): Message utilisateur.
            response (str): Réponse générée.
            metadata (Optional[Dict[str, Any]]): Métadonnées supplémentaires.
        """
        try:
            interaction = {
                "user_id": user_id,
                "message": message,
                "response": response,
                "metadata": metadata or {},
                "timestamp": datetime.datetime.utcnow().isoformat()
            }

            if self.storage_type == "json":
                file_path = self._get_json_file_path(user_id)
                if os.path.exists(file_path):
                    with open(file_path, "r") as file:
                        interactions = json.load(file)
                else:
                    interactions = []
                interactions.append(interaction)
                with open(file_path, "w") as file:
                    json.dump(interactions, file, indent=4)
                logger.info(f"Interaction saved to JSON for user '{user_id}'.")
            elif self.storage_type == "database":
                self.db_manager.save_interaction(interaction)
                logger.info(f"Interaction saved to database for user '{user_id}'.")
        except Exception as e:
            logger.error(f"Error saving interaction for user '{user_id}': {e}")

    def get_interactions(self, user_id: str) -> List[Dict[str, Any]]:
        """
        Récupère les interactions d'un utilisateur.

        Args:
            user_id (str): ID utilisateur.

        Returns:
            List[Dict[str, Any]]: Liste des interactions.
        """
        try:
            if self.storage_type == "json":
                file_path = self._get_json_file_path(user_id)
                if os.path.exists(file_path):
                    with open(file_path, "r") as file:
                        interactions = json.load(file)
                    logger.info(f"Interactions retrieved from JSON for user '{user_id}'.")
                    return interactions
                else:
                    logger.warning(f"No interactions found for user '{user_id}' in JSON.")
                    return []
            elif self.storage_type == "database":
                interactions = self.db_manager.get_interactions(user_id)
                logger.info(f"Interactions retrieved from database for user '{user_id}'.")
                return interactions
        except Exception as e:
            logger.error(f"Error retrieving interactions for user '{user_id}': {e}")
            return []

    def search_interactions(self, user_id: str, keyword: str) -> List[Dict[str, Any]]:
        """
        Recherche des interactions contenant un mot-clé.

        Args:
            user_id (str): ID utilisateur.
            keyword (str): Mot-clé à rechercher.

        Returns:
            List[Dict[str, Any]]: Liste des interactions correspondantes.
        """
        try:
            interactions = self.get_interactions(user_id)
            results = [i for i in interactions if keyword.lower() in i["message"].lower() or keyword.lower() in i["response"].lower()]
            logger.info(f"Found {len(results)} interactions for user '{user_id}' containing keyword '{keyword}'.")
            return results
        except Exception as e:
            logger.error(f"Error searching interactions for user '{user_id}': {e}")
            return []

    def delete_interactions(self, user_id: str):
        """
        Supprime toutes les interactions d'un utilisateur.

        Args:
            user_id (str): ID utilisateur.
        """
        try:
            if self.storage_type == "json":
                file_path = self._get_json_file_path(user_id)
                if os.path.exists(file_path):
                    os.remove(file_path)
                    logger.info(f"All interactions deleted for user '{user_id}' in JSON.")
                else:
                    logger.warning(f"No interactions to delete for user '{user_id}' in JSON.")
            elif self.storage_type == "database":
                self.db_manager.delete_interactions(user_id)
                logger.info(f"All interactions deleted for user '{user_id}' in database.")
        except Exception as e:
            logger.error(f"Error deleting interactions for user '{user_id}': {e}")

class UserPreferenceManager:
    """
    Gère les préférences utilisateur pour la personnalisation des services.
    """

    def __init__(self, db_manager):
        """
        Initialise le gestionnaire de préférences utilisateur.

        Args:
            db_manager: Gestionnaire de base de données pour stocker les préférences.
        """
        self.db_manager = db_manager
        logger.info("UserPreferenceManager initialized with database integration.")

    async def set_preference(self, user_id: str, key: str, value: Any):
        """
        Définit ou met à jour une préférence utilisateur.

        Args:
            user_id (str): ID utilisateur.
            key (str): Clé de la préférence.
            value (Any): Valeur associée à la préférence.
        """
        try:
            preference = {"user_id": user_id, "key": key, "value": value}
            await self.db_manager.save_preference(preference)
            logger.info(f"Preference set for user '{user_id}' with key '{key}' and value '{value}'.")
        except Exception as e:
            logger.error(f"Error setting preference for user '{user_id}': {e}")

    async def get_preference(self, user_id: str, key: str) -> Optional[Any]:
        """
        Récupère une préférence utilisateur.

        Args:
            user_id (str): ID utilisateur.
            key (str): Clé de la préférence.

        Returns:
            Optional[Any]: Valeur associée à la préférence ou None si non trouvée.
        """
        try:
            preference = await self.db_manager.get_preference(user_id, key)
            if preference:
                logger.info(f"Preference retrieved for user '{user_id}' with key '{key}': {preference['value']}")
                return preference["value"]
            logger.warning(f"No preference found for user '{user_id}' with key '{key}'.")
            return None
        except Exception as e:
            logger.error(f"Error retrieving preference for user '{user_id}': {e}")
            return None

    async def list_preferences(self, user_id: str) -> Dict[str, Any]:
        """
        Récupère toutes les préférences d'un utilisateur.

        Args:
            user_id (str): ID utilisateur.

        Returns:
            Dict[str, Any]: Dictionnaire des préférences utilisateur.
        """
        try:
            preferences = await self.db_manager.get_all_preferences(user_id)
            preferences_dict = {pref["key"]: pref["value"] for pref in preferences}
            logger.info(f"All preferences listed for user '{user_id}': {preferences_dict}")
            return preferences_dict
        except Exception as e:
            logger.error(f"Error listing preferences for user '{user_id}': {e}")
            return {}

    async def delete_preference(self, user_id: str, key: Optional[str] = None):
        """
        Supprime une ou toutes les préférences d'un utilisateur.

        Args:
            user_id (str): ID utilisateur.
            key (Optional[str]): Clé spécifique de la préférence à supprimer. Si None, toutes les préférences seront supprimées.
        """
        try:
            if key:
                await self.db_manager.delete_preference(user_id, key)
                logger.info(f"Preference with key '{key}' deleted for user '{user_id}'.")
            else:
                await self.db_manager.delete_all_preferences(user_id)
                logger.info(f"All preferences deleted for user '{user_id}'.")
        except Exception as e:
            logger.error(f"Error deleting preferences for user '{user_id}': {e}")

    async def has_preference(self, user_id: str, key: str) -> bool:
        """
        Vérifie si un utilisateur a défini une préférence spécifique.

        Args:
            user_id (str): ID utilisateur.
            key (str): Clé de la préférence.

        Returns:
            bool: True si la préférence existe, sinon False.
        """
        try:
            preference = await self.db_manager.get_preference(user_id, key)
            exists = preference is not None
            logger.info(f"Preference existence check for user '{user_id}' and key '{key}': {exists}")
            return exists
        except Exception as e:
            logger.error(f"Error checking preference existence for user '{user_id}': {e}")
            return False



class ActionProvideFeedback(Action):
    """
    Gère les feedbacks utilisateurs, analyse leur sentiment via des règles, et met à jour les slots.
    """

    def name(self) -> str:
        """
        Retourne le nom de l'action pour Rasa.
        """
        return "action_provide_feedback"

    async def run(self, dispatcher: CollectingDispatcher,
                  tracker: Tracker,
                  domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Traite le feedback utilisateur, analyse son sentiment, et met à jour les slots.

        Args:
            dispatcher: Pour envoyer des messages à l'utilisateur.
            tracker: Contient l'état actuel du dialogue.
            domain: Le domaine de l'application.

        Returns:
            Une liste d'événements pour mettre à jour les slots.
        """
        try:
            # Récupérer le message utilisateur et les slots
            user_message = tracker.latest_message.get('text', "").strip()
            feedback_slot = tracker.get_slot("user_feedback")

            if not user_message:
                dispatcher.utter_message(text="Je n'ai pas reçu de feedback. Pouvez-vous réessayer ?")
                logger.warning("Message utilisateur vide.")
                return []

            # Analyser le sentiment du feedback
            sentiment = self.analyze_sentiment(user_message)

            # Réponse dynamique selon le sentiment
            if not feedback_slot:
                feedback_slot = user_message
                dispatcher.utter_message(text=f"Merci pour votre retour : '{feedback_slot}'")
            else:
                dispatcher.utter_message(text=f"Votre feedback précédent était : '{feedback_slot}'")

            # Messages basés sur le sentiment détecté
            sentiment_response = {
                "positif": "Merci pour vos encouragements ! Nous sommes ravis de vous satisfaire. 😊",
                "négatif": "Je suis désolé pour cela. Pouvez-vous m'expliquer davantage pour que je puisse aider ?",
                "neutre": "Merci pour votre retour. Nous allons continuer à nous améliorer !"
            }
            dispatcher.utter_message(text=sentiment_response.get(sentiment, "Merci pour votre retour."))

            # Mettre à jour les slots
            return [
                SlotSet("user_feedback", feedback_slot),
                SlotSet("feedback_sentiment", sentiment)
            ]

        except Exception as e:
            # Gestion des erreurs
            logger.error(f"Erreur lors du traitement du feedback : {e}")
            dispatcher.utter_message(text="Une erreur est survenue lors de l'analyse du feedback. Veuillez réessayer.")
            return []

    def analyze_sentiment(self, feedback: str) -> str:
        """
        Analyse le sentiment du feedback en utilisant une approche basée sur des mots-clés pondérés.

        Args:
            feedback: Texte du feedback utilisateur.

        Returns:
            str: Sentiment détecté ('positif', 'négatif', ou 'neutre').
        """
        try:
            # Définir des mots-clés et leurs pondérations
            keywords = {
                "positif": {"super": 2, "bien": 1, "merci": 1, "excellent": 3, "parfait": 3, "génial": 2},
                "négatif": {"mauvais": 2, "problème": 3, "nul": 3, "terrible": 2, "horrible": 3, "pas bien": 2}
            }

            # Initialiser les scores
            positive_score = sum(weight for word, weight in keywords["positif"].items() if word in feedback.lower())
            negative_score = sum(weight for word, weight in keywords["négatif"].items() if word in feedback.lower())

            # Identifier le sentiment
            if positive_score > negative_score:
                return "positif"
            elif negative_score > positive_score:
                return "négatif"
            else:
                return "neutre"

        except Exception as e:
            logger.error(f"Erreur lors de l'analyse du sentiment : {e}")
            return "neutre"

class NotificationService:
    """
    Service de gestion et d'envoi de notifications multi-canaux (email, SMS, push, etc.).
    """

    def __init__(self, email_config: Dict[str, Any] = None, sms_config: Dict[str, Any] = None):
        """
        Initialise le service de notification avec des configurations d'email et de SMS.

        Args:
            email_config (Dict[str, Any]): Configuration pour l'email (smtp, username, password).
            sms_config (Dict[str, Any]): Configuration pour SMS (Twilio SID, token, etc.).
        """
        self.email_config = email_config or {}
        self.sms_config = sms_config or {}
        logger.info("NotificationService initialized.")

    def send_email(self, to: str, subject: str, body: str):
        """
        Envoie un email via SMTP.

        Args:
            to (str): Destinataire de l'email.
            subject (str): Sujet de l'email.
            body (str): Corps de l'email.
        """
        try:
            msg = MIMEMultipart()
            msg["From"] = self.email_config.get("sender_email")
            msg["To"] = to
            msg["Subject"] = subject
            msg.attach(MIMEText(body, "plain"))

            with smtplib.SMTP_SSL(self.email_config.get("smtp_server"), self.email_config.get("smtp_port")) as server:
                server.login(self.email_config.get("username"), self.email_config.get("password"))
                server.sendmail(self.email_config.get("sender_email"), to, msg.as_string())
            logger.info(f"Email sent to {to}.")
        except Exception as e:
            logger.error(f"Error sending email to {to}: {e}")

    def send_sms(self, to: str, message: str):
        """
        Envoie un SMS via Twilio.

        Args:
            to (str): Numéro de téléphone du destinataire.
            message (str): Corps du message.
        """
        try:
            client = Client(self.sms_config.get("sid"), self.sms_config.get("auth_token"))
            message = client.messages.create(
                body=message,
                from_=self.sms_config.get("from_number"),
                to=to
            )
            logger.info(f"SMS sent to {to}. SID: {message.sid}")
        except Exception as e:
            logger.error(f"Error sending SMS to {to}: {e}")

    def send_push_notification(self, user_id: str, message: str):
        """
        Envoie une notification push (exemple via un service externe).

        Args:
            user_id (str): ID utilisateur.
            message (str): Corps du message.
        """
        # Placeholder for push notification API
        try:
            # Example API call (depends on actual push service)
            # response = push_service.send_notification(user_id, message)
            logger.info(f"Push notification sent to user '{user_id}'.")
        except Exception as e:
            logger.error(f"Error sending push notification to user '{user_id}': {e}")

    def send_notification(self, user_id: str, channel: str, message: str):
        """
        Envoie une notification via le canal spécifié.

        Args:
            user_id (str): ID utilisateur.
            channel (str): Canal de notification ('email', 'sms', 'push').
            message (str): Corps du message.
        """
        try:
            if channel == "email":
                # Email should be stored as user preference or fetched from user data
                to_email = "user@example.com"  # This should be dynamically fetched
                self.send_email(to_email, "Notification", message)
            elif channel == "sms":
                # SMS should be stored as user preference or fetched from user data
                to_phone = "+1234567890"  # This should be dynamically fetched
                self.send_sms(to_phone, message)
            elif channel == "push":
                self.send_push_notification(user_id, message)
            else:
                logger.warning(f"Unsupported notification channel: {channel}")
        except Exception as e:
            logger.error(f"Error sending notification to user '{user_id}' on channel '{channel}': {e}")

    def send_bulk_notifications(self, users: List[Dict[str, Any]], channel: str, message: str):
        """
        Envoie une notification en masse à plusieurs utilisateurs.

        Args:
            users (List[Dict[str, Any]]): Liste d'utilisateurs avec leur ID et préférences de notification.
            channel (str): Canal de notification ('email', 'sms', 'push').
            message (str): Corps du message.
        """
        try:
            for user in users:
                user_id = user["user_id"]
                self.send_notification(user_id, channel, message)
            logger.info(f"Bulk notifications sent on channel '{channel}'.")
        except Exception as e:
            logger.error(f"Error sending bulk notifications: {e}")

class DataValidationService:
    """
    Service pour valider les données entrantes avant traitement.
    """

    def __init__(self):
        """
        Initialise le service de validation des données.
        """
        logger.info("DataValidationService initialized.")

    def validate_type(self, data: Any, expected_type: type) -> bool:
        """
        Valide le type de données.

        Args:
            data (Any): Donnée à valider.
            expected_type (type): Type attendu.

        Returns:
            bool: True si le type correspond, sinon False.
        """
        if not isinstance(data, expected_type):
            logger.error(f"Data type validation failed. Expected {expected_type}, got {type(data)}.")
            return False
        return True

    def validate_required_fields(self, data: Dict[str, Any], required_fields: List[str]) -> bool:
        """
        Valide que les champs requis sont présents dans les données.

        Args:
            data (Dict[str, Any]): Données à valider.
            required_fields (List[str]): Liste des champs requis.

        Returns:
            bool: True si tous les champs requis sont présents, sinon False.
        """
        missing_fields = [field for field in required_fields if field not in data]
        if missing_fields:
            logger.error(f"Missing required fields: {', '.join(missing_fields)}.")
            return False
        return True

    def validate_format(self, data: str, pattern: str) -> bool:
        """
        Valide un format de données (par exemple, email, téléphone) avec une expression régulière.

        Args:
            data (str): Donnée à valider.
            pattern (str): Expression régulière pour valider le format.

        Returns:
            bool: True si le format est valide, sinon False.
        """
        import re
        if not re.match(pattern, data):
            logger.error(f"Data format validation failed for value: {data}. Expected pattern: {pattern}.")
            return False
        return True

    def validate_data(self, data: Dict[str, Any], validation_rules: Dict[str, Any]) -> bool:
        """
        Valide des données selon un ensemble de règles de validation.

        Args:
            data (Dict[str, Any]): Données à valider.
            validation_rules (Dict[str, Any]): Règles de validation sous forme de dictionnaire.

        Returns:
            bool: True si les données respectent les règles, sinon False.
        """
        for field, rules in validation_rules.items():
            value = data.get(field)
            for rule, rule_value in rules.items():
                if rule == "required" and rule_value:
                    if value is None or value == "":
                        logger.error(f"Field '{field}' is required but missing or empty.")
                        return False
                if rule == "type" and not self.validate_type(value, rule_value):
                    logger.error(f"Field '{field}' has invalid type. Expected {rule_value}.")
                    return False
                if rule == "format" and not self.validate_format(value, rule_value):
                    logger.error(f"Field '{field}' has invalid format. Expected pattern: {rule_value}.")
                    return False
        logger.info("Data validation passed successfully.")
        return True

    def validate_nested_data(self, data: Dict[str, Any], validation_rules: Dict[str, Any]) -> bool:
        """
        Valide des données imbriquées dans des structures complexes (par exemple, objets JSON imbriqués).

        Args:
            data (Dict[str, Any]): Données à valider.
            validation_rules (Dict[str, Any]): Règles de validation pour les données imbriquées.

        Returns:
            bool: True si les données imbriquées respectent les règles, sinon False.
        """
        for field, sub_rules in validation_rules.items():
            value = data.get(field)
            if isinstance(value, dict):  # Si la valeur est un dictionnaire imbriqué
                if not self.validate_nested_data(value, sub_rules):  # Appel récursif pour validation imbriquée
                    logger.error(f"Nested data validation failed for field '{field}'.")
                    return False
            else:
                if not self.validate_data({field: value}, {field: sub_rules}):
                    logger.error(f"Data validation failed for field '{field}'.")
                    return False
        logger.info("Nested data validation passed successfully.")
        return True


class ReportGenerator:
    """
    Gère la génération de rapports personnalisés à partir des données.
    """

    def __init__(self, output_dir: str = "reports"):
        """
        Initialise le générateur de rapports.

        Args:
            output_dir (str): Répertoire pour sauvegarder les rapports générés.
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        logger.info(f"ReportGenerator initialized. Output directory: {output_dir}")

    def generate_pdf_report(self, data: pd.DataFrame, title: str = "Data Report") -> str:
        """
        Génére un rapport PDF à partir des données.

        Args:
            data (pd.DataFrame): Données à inclure dans le rapport.
            title (str): Titre du rapport.

        Returns:
            str: Chemin du fichier PDF généré.
        """
        try:
            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", size=12)

            # Titre
            pdf.cell(200, 10, txt=title, ln=True, align="C")

            # Contenu
            for index, row in data.iterrows():
                row_str = ", ".join([str(cell) for cell in row])
                pdf.cell(200, 10, txt=row_str, ln=True)

            # Sauvegarde du rapport
            file_path = os.path.join(self.output_dir, f"{title.replace(' ', '_')}.pdf")
            pdf.output(file_path)
            logger.info(f"PDF report generated at {file_path}.")
            return file_path
        except Exception as e:
            logger.error(f"Error generating PDF report: {e}")
            return ""

    def generate_excel_report(self, data: pd.DataFrame, title: str = "Data Report") -> str:
        """
        Génére un rapport Excel à partir des données.

        Args:
            data (pd.DataFrame): Données à inclure dans le rapport.
            title (str): Titre du rapport.

        Returns:
            str: Chemin du fichier Excel généré.
        """
        try:
            file_path = os.path.join(self.output_dir, f"{title.replace(' ', '_')}.xlsx")
            data.to_excel(file_path, index=False)
            logger.info(f"Excel report generated at {file_path}.")
            return file_path
        except Exception as e:
            logger.error(f"Error generating Excel report: {e}")
            return ""

    def generate_html_report(self, data: pd.DataFrame, title: str = "Data Report") -> str:
        """
        Génére un rapport HTML interactif à partir des données.

        Args:
            data (pd.DataFrame): Données à inclure dans le rapport.
            title (str): Titre du rapport.

        Returns:
            str: Chemin du fichier HTML généré.
        """
        try:
            file_path = os.path.join(self.output_dir, f"{title.replace(' ', '_')}.html")
            data.to_html(file_path, index=False)
            logger.info(f"HTML report generated at {file_path}.")
            return file_path
        except Exception as e:
            logger.error(f"Error generating HTML report: {e}")
            return ""

    def generate_data_visualization(self, data: pd.DataFrame, chart_type: str = "bar",
                                    title: str = "Data Visualization") -> str:
        """
        Génère une visualisation des données sous forme de graphique.

        Args:
            data (pd.DataFrame): Données à visualiser.
            chart_type (str): Type de graphique à générer ('bar', 'line', 'scatter', etc.).
            title (str): Titre du graphique.

        Returns:
            str: Chemin du fichier image généré.
        """
        try:
            plt.figure(figsize=(10, 6))
            if chart_type == "bar":
                data.plot(kind="bar")
            elif chart_type == "line":
                data.plot(kind="line")
            elif chart_type == "scatter":
                sns.scatterplot(x=data.columns[0], y=data.columns[1], data=data)
            else:
                logger.warning(f"Unsupported chart type: {chart_type}")

            # Sauvegarde du graphique
            chart_file_path = os.path.join(self.output_dir, f"{title.replace(' ', '_')}.png")
            plt.title(title)
            plt.savefig(chart_file_path)
            plt.close()
            logger.info(f"Data visualization saved as image at {chart_file_path}.")
            return chart_file_path
        except Exception as e:
            logger.error(f"Error generating data visualization: {e}")
            return ""

    def generate_and_export_report(self, data: pd.DataFrame, report_type: str = "pdf", title: str = "Data Report"):
        """
        Génère et exporte le rapport dans le format spécifié.

        Args:
            data (pd.DataFrame): Données à inclure dans le rapport.
            report_type (str): Type de rapport ('pdf', 'excel', 'html').
            title (str): Titre du rapport.
        """
        try:
            if report_type == "pdf":
                self.generate_pdf_report(data, title)
            elif report_type == "excel":
                self.generate_excel_report(data, title)
            elif report_type == "html":
                self.generate_html_report(data, title)
            else:
                logger.warning(f"Unsupported report type: {report_type}")
        except Exception as e:
            logger.error(f"Error generating and exporting report: {e}")

class AuditTrailManager:
    """
    Gère les journaux d'audit pour suivre les actions utilisateurs et événements système.
    """

    def __init__(self, storage_type: str = "json", storage_path: str = "audit_trails", db_manager=None):
        """
        Initialise le gestionnaire des journaux d’audit.

        Args:
            storage_type (str): Type de stockage ('json' ou 'database').
            storage_path (str): Répertoire pour les fichiers JSON (si stockage en fichier).
            db_manager: Gestionnaire de base de données (si stockage en base).
        """
        self.storage_type = storage_type
        self.storage_path = storage_path
        self.db_manager = db_manager
        os.makedirs(storage_path, exist_ok=True)  # Pour stockage local dans des fichiers
        logger.info("AuditTrailManager initialized.")

    def _get_json_file_path(self) -> str:
        """
        Génère le chemin du fichier JSON où les logs seront stockés.

        Returns:
            str: Chemin du fichier de log.
        """
        return os.path.join(self.storage_path, f"audit_trail_{datetime.datetime.utcnow().strftime('%Y%m%d')}.json")

    def log_event(self, user_id: str, action: str, event_data: Optional[Dict[str, Any]] = None):
        """
        Enregistre un événement dans le journal d’audit.

        Args:
            user_id (str): ID utilisateur.
            action (str): Action effectuée par l’utilisateur.
            event_data (Optional[Dict[str, Any]]): Données supplémentaires sur l'événement.
        """
        event = {
            "user_id": user_id,
            "action": action,
            "event_data": event_data or {},
            "timestamp": datetime.datetime.utcnow().isoformat()
        }

        if self.storage_type == "json":
            file_path = self._get_json_file_path()
            try:
                if os.path.exists(file_path):
                    with open(file_path, "r") as file:
                        logs = json.load(file)
                else:
                    logs = []
                logs.append(event)
                with open(file_path, "w") as file:
                    json.dump(logs, file, indent=4)
                logger.info(f"Event logged to JSON: {event}")
            except Exception as e:
                logger.error(f"Error logging event to JSON: {e}")

        elif self.storage_type == "database" and self.db_manager:
            try:
                self.db_manager.save_event(event)
                logger.info(f"Event logged to database: {event}")
            except Exception as e:
                logger.error(f"Error logging event to database: {e}")

    def search_events(self, user_id: Optional[str] = None, action: Optional[str] = None,
                      start_date: Optional[str] = None, end_date: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        Recherche des événements selon différents critères (utilisateur, action, date).

        Args:
            user_id (Optional[str]): ID utilisateur (filtrage par utilisateur).
            action (Optional[str]): Type d'action (filtrage par action).
            start_date (Optional[str]): Date de début du filtrage.
            end_date (Optional[str]): Date de fin du filtrage.

        Returns:
            List[Dict[str, Any]]: Liste des événements correspondant aux critères.
        """
        try:
            if self.storage_type == "json":
                file_path = self._get_json_file_path()
                if os.path.exists(file_path):
                    with open(file_path, "r") as file:
                        logs = json.load(file)
                    filtered_logs = [log for log in logs if self._matches_criteria(log, user_id, action, start_date, end_date)]
                    logger.info(f"Found {len(filtered_logs)} events matching criteria.")
                    return filtered_logs
                logger.warning("No log file found.")
                return []

            elif self.storage_type == "database" and self.db_manager:
                events = self.db_manager.get_events(user_id, action, start_date, end_date)
                logger.info(f"Found {len(events)} events in the database matching criteria.")
                return events

        except Exception as e:
            logger.error(f"Error searching events: {e}")
            return []

    def _matches_criteria(self, event: Dict[str, Any], user_id: Optional[str], action: Optional[str],
                          start_date: Optional[str], end_date: Optional[str]) -> bool:
        """
        Vérifie si un événement correspond aux critères de recherche.

        Args:
            event (Dict[str, Any]): L'événement à vérifier.
            user_id (Optional[str]): ID utilisateur.
            action (Optional[str]): Type d'action.
            start_date (Optional[str]): Date de début.
            end_date (Optional[str]): Date de fin.

        Returns:
            bool: True si l'événement correspond aux critères, sinon False.
        """
        if user_id and event["user_id"] != user_id:
            return False
        if action and event["action"] != action:
            return False
        if start_date and event["timestamp"] < start_date:
            return False
        if end_date and event["timestamp"] > end_date:
            return False
        return True

    def export_events(self, user_id: Optional[str] = None, start_date: Optional[str] = None,
                      end_date: Optional[str] = None, file_format: str = "json") -> str:
        """
        Exporte les événements dans un format spécifié (JSON, CSV).

        Args:
            user_id (Optional[str]): ID utilisateur.
            start_date (Optional[str]): Date de début pour filtrer.
            end_date (Optional[str]): Date de fin pour filtrer.
            file_format (str): Format d'exportation ('json' ou 'csv').

        Returns:
            str: Chemin du fichier exporté.
        """
        events = self.search_events(user_id, None, start_date, end_date)
        if file_format == "json":
            file_path = os.path.join(self.storage_path, f"audit_trail_{datetime.datetime.utcnow().strftime('%Y%m%d')}.json")
            try:
                with open(file_path, "w") as file:
                    json.dump(events, file, indent=4)
                logger.info(f"Events exported to JSON at {file_path}.")
                return file_path
            except Exception as e:
                logger.error(f"Error exporting events to JSON: {e}")
                return ""

        elif file_format == "csv":
            file_path = os.path.join(self.storage_path, f"audit_trail_{datetime.datetime.utcnow().strftime('%Y%m%d')}.csv")
            try:
                import csv
                with open(file_path, mode="w", newline="") as file:
                    writer = csv.DictWriter(file, fieldnames=["user_id", "action", "event_data", "timestamp"])
                    writer.writeheader()
                    writer.writerows(events)
                logger.info(f"Events exported to CSV at {file_path}.")
                return file_path
            except Exception as e:
                logger.error(f"Error exporting events to CSV: {e}")
                return ""

        logger.error(f"Unsupported export format: {file_format}")
        return ""

class UserRequest(BaseModel):
    message: str
    tone: str = "friendly"

@app.post("/respond")
async def respond(request: UserRequest):
    """
    Génère une réponse textuelle personnalisée.
    """
    try:
        # Étape 1 : Génération brute
        raw_response = nlp_processor.generate_response(request.message)

        # Étape 2 : Validation éthique
        refined_response = ethics_validator.validate_and_refine(raw_response)

        # Étape 3 : Personnalisation du ton
        personalized_response = nlp_processor.adjust_tone(refined_response, request.tone)

        return {"response": personalized_response}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lors de la réponse : {str(e)}")

@app.post("/speak")
async def speak(request: UserRequest):
    """
    Génère un fichier audio à partir d'une réponse textuelle.
    """
    try:
        # Génération de la réponse
        response = await respond(request)
        text_response = response["response"]

        # Conversion en audio
        audio_path = speech_synthesizer.text_to_speech(text_response)

        return {"message": "Audio généré avec succès", "audio_file": audio_path}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lors de la génération audio : {str(e)}")

class TaskQueueManager:
    """
    Gère les tâches dans une file d'attente et les exécute de manière asynchrone.
    """

    def __init__(self, max_concurrent_tasks: int = 5):
        """
        Initialise le gestionnaire de la file d'attente de tâches.

        Args:
            max_concurrent_tasks (int): Nombre maximal de tâches pouvant être exécutées en parallèle.
        """
        self.queue = deque()
        self.running_tasks = set()
        self.max_concurrent_tasks = max_concurrent_tasks
        logger.info("TaskQueueManager initialized.")

    async def _execute_task(self, task_id: str, task: Callable[[], Any], metadata: Optional[Dict[str, Any]] = None):
        """
        Exécute une tâche dans la file d'attente.

        Args:
            task_id (str): ID unique de la tâche.
            task (Callable[[], Any]): Fonction représentant la tâche à exécuter.
            metadata (Optional[Dict[str, Any]]): Métadonnées associées à la tâche.
        """
        try:
            logger.info(f"Starting task {task_id}.")
            result = await task()
            logger.info(f"Task {task_id} completed successfully. Result: {result}")
        except Exception as e:
            logger.error(f"Error executing task {task_id}: {e}")
            # Optionnel: Gestion des erreurs comme relancer la tâche
            metadata["status"] = "failed"
        finally:
            self.running_tasks.remove(task_id)
            await self._process_queue()

    async def _process_queue(self):
        """
        Traite les tâches dans la file d'attente tant que la limite de tâches concurrentes n'est pas atteinte.
        """
        while self.queue and len(self.running_tasks) < self.max_concurrent_tasks:
            task_id, task, metadata = self.queue.popleft()
            self.running_tasks.add(task_id)
            asyncio.create_task(self._execute_task(task_id, task, metadata))

    def add_task(self, task: Callable[[], Any], metadata: Optional[Dict[str, Any]] = None):
        """
        Ajoute une tâche à la file d'attente.

        Args:
            task (Callable[[], Any]): Fonction représentant la tâche à ajouter.
            metadata (Optional[Dict[str, Any]]): Métadonnées associées à la tâche.
        """
        task_id = str(uuid.uuid4())
        metadata = metadata or {}
        metadata["status"] = "queued"
        self.queue.append((task_id, task, metadata))
        logger.info(f"Task {task_id} added to the queue.")
        asyncio.create_task(self._process_queue())

    async def run_all_tasks(self):
        """
        Exécute toutes les tâches en attente dans la file d'attente jusqu'à ce qu'elles soient terminées.
        """
        while self.queue or self.running_tasks:
            await asyncio.sleep(1)

    def get_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:
        """
        Récupère le statut d'une tâche en cours.

        Args:
            task_id (str): ID de la tâche.

        Returns:
            Optional[Dict[str, Any]]: Métadonnées associées à la tâche, y compris son statut.
        """
        for task_id_in_queue, task, metadata in self.queue:
            if task_id_in_queue == task_id:
                return metadata
        if task_id in self.running_tasks:
            return {"status": "running"}
        return None

    def cancel_task(self, task_id: str):
        """
        Annule une tâche en cours (si possible).

        Args:
            task_id (str): ID de la tâche à annuler.
        """
        for task_id_in_queue, task, metadata in list(self.queue):
            if task_id_in_queue == task_id:
                self.queue.remove((task_id_in_queue, task, metadata))
                logger.info(f"Task {task_id} canceled.")
                break
        if task_id in self.running_tasks:
            # Ici, vous pouvez ajouter une logique pour annuler la tâche si nécessaire
            logger.info(f"Task {task_id} is currently running and cannot be canceled.")

    def list_tasks(self) -> List[Dict[str, Any]]:
        """
        Liste toutes les tâches en attente ou en cours d'exécution.

        Returns:
            List[Dict[str, Any]]: Liste des tâches avec leur statut.
        """
        task_list = []
        for task_id_in_queue, task, metadata in self.queue:
            task_list.append(metadata)
        for task_id_in_running in self.running_tasks:
            task_list.append({"status": "running", "task_id": task_id_in_running})
        return task_list

class DataEncryptionManager:
    """
    Gère le chiffrement et le déchiffrement des données sensibles avec support de plusieurs algorithmes.
    """

    def __init__(self, encryption_key: str = None):
        """
        Initialise le gestionnaire de chiffrement avec une clé spécifiée.

        Args:
            encryption_key (str): Clé utilisée pour le chiffrement, si non fournie, une clé par défaut sera utilisée.
        """
        self.encryption_key = self._derive_key(encryption_key or os.getenv("ENCRYPTION_KEY", "default_secure_key"))
        logger.info("DataEncryptionManager initialized with AES encryption.")

    def _derive_key(self, passphrase: str) -> bytes:
        """
        Dérive une clé de chiffrement à partir d'une passphrase via PBKDF2.

        Args:
            passphrase (str): Passphrase pour générer la clé.

        Returns:
            bytes: Clé dérivée.
        """
        salt = b"data_encryption_salt"
        kdf = PBKDF2HMAC(
            algorithm=hashes.SHA256(),
            length=32,
            salt=salt,
            iterations=100000,
            backend=default_backend()
        )
        return base64.urlsafe_b64encode(kdf.derive(passphrase.encode()))

    def encrypt_data(self, data: str) -> str:
        """
        Chiffre les données en utilisant AES (CFB mode).

        Args:
            data (str): Données à chiffrer.

        Returns:
            str: Données chiffrées au format base64.
        """
        try:
            iv = os.urandom(16)
            cipher = Cipher(algorithms.AES(self.encryption_key), modes.CFB(iv), backend=default_backend())
            encryptor = cipher.encryptor()
            encrypted_data = encryptor.update(data.encode()) + encryptor.finalize()
            encrypted_base64 = base64.b64encode(iv + encrypted_data).decode('utf-8')
            logger.info("Data encrypted successfully.")
            return encrypted_base64
        except Exception as e:
            logger.error(f"Error encrypting data: {e}")
            raise

    def decrypt_data(self, encrypted_data_base64: str) -> str:
        """
        Déchiffre les données chiffrées en utilisant AES.

        Args:
            encrypted_data_base64 (str): Données chiffrées au format base64.

        Returns:
            str: Données déchiffrées.
        """
        try:
            encrypted_data = base64.b64decode(encrypted_data_base64)
            iv = encrypted_data[:16]
            encrypted_data = encrypted_data[16:]

            cipher = Cipher(algorithms.AES(self.encryption_key), modes.CFB(iv), backend=default_backend())
            decryptor = cipher.decryptor()
            decrypted_data = decryptor.update(encrypted_data) + decryptor.finalize()
            logger.info("Data decrypted successfully.")
            return decrypted_data.decode('utf-8')
        except Exception as e:
            logger.error(f"Error decrypting data: {e}")
            raise

    def generate_rsa_key_pair(self) -> Dict[str, Any]:
        """
        Génère une paire de clés RSA (publique et privée).

        Returns:
            Dict[str, Any]: Clé publique et clé privée au format PEM.
        """
        try:
            private_key = rsa.generate_private_key(
                public_exponent=65537,
                key_size=2048,
                backend=default_backend()
            )
            private_pem = private_key.private_bytes(
                encoding=serialization.Encoding.PEM,
                format=serialization.PrivateFormat.TraditionalOpenSSL,
                encryption_algorithm=serialization.NoEncryption()
            )
            public_key = private_key.public_key()
            public_pem = public_key.public_bytes(
                encoding=serialization.Encoding.PEM,
                format=serialization.PublicFormat.SubjectPublicKeyInfo
            )
            logger.info("RSA key pair generated successfully.")
            return {"private_key": private_pem.decode('utf-8'), "public_key": public_pem.decode('utf-8')}
        except Exception as e:
            logger.error(f"Error generating RSA key pair: {e}")
            raise

    def encrypt_rsa(self, public_key_pem: str, data: str) -> str:
        """
        Chiffre les données avec une clé publique RSA.

        Args:
            public_key_pem (str): Clé publique en format PEM.
            data (str): Données à chiffrer.

        Returns:
            str: Données chiffrées au format base64.
        """
        try:
            public_key = serialization.load_pem_public_key(public_key_pem.encode(), backend=default_backend())
            encrypted_data = public_key.encrypt(
                data.encode(),
                padding.PKCS1v15()
            )
            encrypted_base64 = base64.b64encode(encrypted_data).decode('utf-8')
            logger.info("Data encrypted with RSA successfully.")
            return encrypted_base64
        except Exception as e:
            logger.error(f"Error encrypting data with RSA: {e}")
            raise

    def decrypt_rsa(self, private_key_pem: str, encrypted_data_base64: str) -> str:
        """
        Déchiffre les données avec une clé privée RSA.

        Args:
            private_key_pem (str): Clé privée en format PEM.
            encrypted_data_base64 (str): Données chiffrées en base64.

        Returns:
            str: Données déchiffrées.
        """
        try:
            private_key = serialization.load_pem_private_key(private_key_pem.encode(), password=None, backend=default_backend())
            encrypted_data = base64.b64decode(encrypted_data_base64)
            decrypted_data = private_key.decrypt(
                encrypted_data,
                padding.PKCS1v15()
            )
            logger.info("Data decrypted with RSA successfully.")
            return decrypted_data.decode('utf-8')
        except Exception as e:
            logger.error(f"Error decrypting data with RSA: {e}")
            raise


class SessionManager:
    """
    Gère la création, la validation et l'expiration des sessions utilisateurs.
    """

    def __init__(self, secret_key: str, session_timeout: int = 3600):
        """
        Initialise le gestionnaire de sessions.

        Args:
            secret_key (str): Clé secrète pour signer les jetons JWT.
            session_timeout (int): Délai d'expiration de la session en secondes (par défaut 1 heure).
        """
        self.secret_key = secret_key
        self.session_timeout = session_timeout
        self.sessions = {}  # Dictionnaire pour stocker les sessions actives (en mémoire)
        logger.info("SessionManager initialized.")

    def create_session(self, user_id: str) -> str:
        """
        Crée une nouvelle session pour un utilisateur.

        Args:
            user_id (str): ID de l'utilisateur pour lequel la session est créée.

        Returns:
            str: Jeton JWT pour la session.
        """
        session_id = str(uuid.uuid4())
        expiration_time = datetime.utcnow() + timedelta(seconds=self.session_timeout)
        session_data = {
            "user_id": user_id,
            "session_id": session_id,
            "exp": expiration_time,
            "iat": datetime.utcnow()
        }

        # Créer un jeton JWT signé
        token = jwt.encode(session_data, self.secret_key, algorithm="HS256")
        self.sessions[session_id] = session_data
        logger.info(f"Session created for user '{user_id}' with session ID '{session_id}'.")
        return token

    def validate_session(self, token: str) -> Optional[Dict[str, Any]]:
        """
        Valide une session en vérifiant son jeton JWT.

        Args:
            token (str): Le jeton JWT de la session.

        Returns:
            Optional[Dict[str, Any]]: Les données de la session si valide, sinon None.
        """
        try:
            # Décoder et valider le jeton JWT
            session_data = jwt.decode(token, self.secret_key, algorithms=["HS256"])
            session_id = session_data.get("session_id")

            if session_id in self.sessions:
                stored_session = self.sessions[session_id]
                if stored_session["exp"] >= datetime.utcnow():
                    logger.info(
                        f"Session validated for user '{stored_session['user_id']}' with session ID '{session_id}'.")
                    return stored_session
                else:
                    logger.warning(f"Session expired for session ID '{session_id}'.")
                    self.expire_session(session_id)
                    return None
            else:
                logger.warning(f"Session not found for session ID '{session_id}'.")
                return None

        except jwt.ExpiredSignatureError:
            logger.warning("Session token has expired.")
            return None
        except jwt.InvalidTokenError:
            logger.warning("Invalid session token.")
            return None

    def expire_session(self, session_id: str):
        """
        Expire une session spécifiée.

        Args:
            session_id (str): ID de la session à expirer.
        """
        if session_id in self.sessions:
            del self.sessions[session_id]
            logger.info(f"Session with session ID '{session_id}' expired and removed.")

    def renew_session(self, token: str) -> Optional[str]:
        """
        Renouvelle une session en créant un nouveau jeton avec une nouvelle date d'expiration.

        Args:
            token (str): Le jeton JWT de la session.

        Returns:
            Optional[str]: Nouveau jeton JWT avec la session renouvelée, ou None si la session est invalide ou expirée.
        """
        session_data = self.validate_session(token)
        if session_data:
            user_id = session_data["user_id"]
            logger.info(f"Session renewed for user '{user_id}'.")
            return self.create_session(user_id)
        return None

    def list_active_sessions(self) -> Dict[str, Any]:
        """
        Liste toutes les sessions actives.

        Returns:
            Dict[str, Any]: Dictionnaire avec les données de toutes les sessions actives.
        """
        active_sessions = {session_id: data for session_id, data in self.sessions.items() if
                           data["exp"] >= datetime.utcnow()}
        logger.info(f"Active sessions: {len(active_sessions)} found.")
        return active_sessions

class UserActivityTracker:
    """
    Suivi des activités des utilisateurs dans l'application.
    """

    def __init__(self, storage_type: str = "json", storage_path: str = "user_activities"):
        """
        Initialise le gestionnaire du suivi des activités des utilisateurs.

        Args:
            storage_type (str): Type de stockage ('json' ou 'database').
            storage_path (str): Répertoire pour les fichiers JSON (si stockage en fichier).
        """
        self.storage_type = storage_type
        self.storage_path = storage_path
        os.makedirs(storage_path, exist_ok=True)
        logger.info("UserActivityTracker initialized.")

    def _get_json_file_path(self) -> str:
        """
        Génère le chemin du fichier JSON où les logs d'activités seront stockés.

        Returns:
            str: Chemin du fichier de log.
        """
        return os.path.join(self.storage_path, f"user_activity_{datetime.utcnow().strftime('%Y%m%d')}.json")

    def record_activity(self, user_id: str, action: str, details: Optional[Dict[str, Any]] = None):
        """
        Enregistre une activité utilisateur dans le système.

        Args:
            user_id (str): ID utilisateur.
            action (str): Action réalisée par l'utilisateur (par exemple, "view_page", "click_button").
            details (Optional[Dict[str, Any]]): Données supplémentaires sur l'action effectuée.
        """
        activity = {
            "user_id": user_id,
            "action": action,
            "details": details or {},
            "timestamp": datetime.utcnow().isoformat()
        }

        if self.storage_type == "json":
            file_path = self._get_json_file_path()
            try:
                if os.path.exists(file_path):
                    with open(file_path, "r") as file:
                        activities = json.load(file)
                else:
                    activities = []
                activities.append(activity)
                with open(file_path, "w") as file:
                    json.dump(activities, file, indent=4)
                logger.info(f"Activity recorded for user '{user_id}' with action '{action}'.")
            except Exception as e:
                logger.error(f"Error recording activity to JSON for user '{user_id}': {e}")

        elif self.storage_type == "database":
            # Placeholder for database integration (could be MongoDB, SQL, etc.)
            # self.db_manager.save_activity(activity)
            logger.info(f"Activity recorded to database for user '{user_id}' with action '{action}'.")
        else:
            logger.warning("Unsupported storage type for activities.")

    def get_activities(self, user_id: str, start_date: Optional[str] = None, end_date: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        Récupère les activités d'un utilisateur selon un critère de date.

        Args:
            user_id (str): ID utilisateur.
            start_date (Optional[str]): Date de début du filtrage (au format 'YYYY-MM-DD').
            end_date (Optional[str]): Date de fin du filtrage (au format 'YYYY-MM-DD').

        Returns:
            List[Dict[str, Any]]: Liste des activités de l'utilisateur.
        """
        try:
            if self.storage_type == "json":
                file_path = self._get_json_file_path()
                if os.path.exists(file_path):
                    with open(file_path, "r") as file:
                        activities = json.load(file)
                    filtered_activities = [
                        activity for activity in activities if activity["user_id"] == user_id
                        and (not start_date or activity["timestamp"] >= start_date)
                        and (not end_date or activity["timestamp"] <= end_date)
                    ]
                    logger.info(f"Found {len(filtered_activities)} activities for user '{user_id}'.")
                    return filtered_activities
                logger.warning(f"No activity log found for user '{user_id}'.")
                return []

            elif self.storage_type == "database":
                # Placeholder for database retrieval logic
                # activities = self.db_manager.get_activities(user_id, start_date, end_date)
                logger.info(f"Activities retrieved from database for user '{user_id}'.")
                return []
        except Exception as e:
            logger.error(f"Error retrieving activities for user '{user_id}': {e}")
            return []

    def export_activities(self, user_id: str, start_date: Optional[str] = None, end_date: Optional[str] = None, file_format: str = "json") -> str:
        """
        Exporte les activités d'un utilisateur dans un format spécifié.

        Args:
            user_id (str): ID utilisateur.
            start_date (Optional[str]): Date de début pour filtrer les activités.
            end_date (Optional[str]): Date de fin pour filtrer les activités.
            file_format (str): Format d'exportation ('json' ou 'csv').

        Returns:
            str: Chemin du fichier exporté.
        """
        activities = self.get_activities(user_id, start_date, end_date)
        if file_format == "json":
            file_path = os.path.join(self.storage_path, f"user_activity_{datetime.utcnow().strftime('%Y%m%d')}.json")
            try:
                with open(file_path, "w") as file:
                    json.dump(activities, file, indent=4)
                logger.info(f"Activities exported to JSON at {file_path}.")
                return file_path
            except Exception as e:
                logger.error(f"Error exporting activities to JSON: {e}")
                return ""

        elif file_format == "csv":
            file_path = os.path.join(self.storage_path, f"user_activity_{datetime.utcnow().strftime('%Y%m%d')}.csv")
            try:
                import csv
                with open(file_path, mode="w", newline="") as file:
                    writer = csv.DictWriter(file, fieldnames=["user_id", "action", "details", "timestamp"])
                    writer.writeheader()
                    writer.writerows(activities)
                logger.info(f"Activities exported to CSV at {file_path}.")
                return file_path
            except Exception as e:
                logger.error(f"Error exporting activities to CSV: {e}")
                return ""

        logger.error(f"Unsupported export format: {file_format}")
        return ""


class AccessControlManager:
    """
    Gère les rôles et permissions des utilisateurs pour assurer un contrôle d'accès sécurisé.
    """

    def __init__(self):
        """
        Initialise le gestionnaire de contrôle d'accès.
        Les rôles et permissions sont définis par défaut, mais peuvent être personnalisés.
        """
        # Exemple de rôles et permissions par défaut
        self.roles = {
            "admin": ["create", "read", "update", "delete"],
            "user": ["read"],
        }
        self.users = {}  # {user_id: role}
        logger.info("AccessControlManager initialized with default roles and permissions.")

    def assign_role(self, user_id: str, role: str):
        """
        Assigne un rôle à un utilisateur.

        Args:
            user_id (str): ID de l'utilisateur.
            role (str): Rôle à assigner (par exemple, 'admin', 'user').
        """
        if role not in self.roles:
            logger.error(f"Attempt to assign invalid role '{role}' to user '{user_id}'.")
            raise ValueError(f"Role '{role}' does not exist.")
        self.users[user_id] = role
        logger.info(f"Role '{role}' assigned to user '{user_id}'.")

    def check_permission(self, user_id: str, action: str) -> bool:
        """
        Vérifie si un utilisateur a la permission d'effectuer une action.

        Args:
            user_id (str): ID de l'utilisateur.
            action (str): Action à vérifier (par exemple, 'read', 'delete').

        Returns:
            bool: True si l'utilisateur a la permission d'effectuer l'action, sinon False.
        """
        role = self.users.get(user_id)
        if not role:
            logger.warning(f"User '{user_id}' has no assigned role.")
            return False

        if action in self.roles.get(role, []):
            logger.info(f"User '{user_id}' is allowed to perform action '{action}'.")
            return True

        logger.warning(f"User '{user_id}' is not allowed to perform action '{action}'.")
        return False

    def get_user_permissions(self, user_id: str) -> List[str]:
        """
        Récupère les permissions d'un utilisateur.

        Args:
            user_id (str): ID de l'utilisateur.

        Returns:
            List[str]: Liste des actions que l'utilisateur est autorisé à effectuer.
        """
        role = self.users.get(user_id)
        if not role:
            logger.warning(f"User '{user_id}' has no assigned role.")
            return []

        permissions = self.roles.get(role, [])
        logger.info(f"User '{user_id}' has the following permissions: {permissions}.")
        return permissions

    def update_role_permissions(self, role: str, permissions: List[str]):
        """
        Met à jour les permissions associées à un rôle.

        Args:
            role (str): Le rôle à mettre à jour.
            permissions (List[str]): Liste des nouvelles permissions pour le rôle.
        """
        if role not in self.roles:
            logger.error(f"Attempt to update invalid role '{role}'.")
            raise ValueError(f"Role '{role}' does not exist.")

        self.roles[role] = permissions
        logger.info(f"Permissions for role '{role}' updated to {permissions}.")

    def revoke_permission(self, user_id: str, permission: str):
        """
        Révoque une permission spécifique pour un utilisateur.

        Args:
            user_id (str): ID de l'utilisateur.
            permission (str): Permission à révoquer.
        """
        role = self.users.get(user_id)
        if not role:
            logger.warning(f"User '{user_id}' has no assigned role.")
            return

        if permission in self.roles.get(role, []):
            self.roles[role].remove(permission)
            logger.info(f"Permission '{permission}' revoked from user '{user_id}'.")
        else:
            logger.warning(f"User '{user_id}' does not have permission '{permission}'.")

    def audit_permissions(self, user_id: str) -> Dict[str, Any]:
        """
        Effectue un audit des permissions d'un utilisateur.

        Args:
            user_id (str): ID de l'utilisateur.

        Returns:
            Dict[str, Any]: Détails des permissions de l'utilisateur et de son rôle.
        """
        role = self.users.get(user_id)
        if not role:
            logger.warning(f"User '{user_id}' has no assigned role.")
            return {}

        permissions = self.roles.get(role, [])
        logger.info(f"Audit for user '{user_id}': Role '{role}', Permissions {permissions}.")
        return {"user_id": user_id, "role": role, "permissions": permissions}

class NotificationQueueManager:
    """
    Gère la file d'attente des notifications à envoyer, avec gestion des priorités et des échecs.
    """

    def __init__(self, max_concurrent_notifications: int = 5):
        """
        Initialise le gestionnaire de la file d'attente des notifications.

        Args:
            max_concurrent_notifications (int): Nombre maximal de notifications pouvant être envoyées simultanément.
        """
        self.queue = deque()
        self.running_notifications = set()
        self.max_concurrent_notifications = max_concurrent_notifications
        logger.info("NotificationQueueManager initialized.")

    async def _send_notification(self, notification_id: str, send_function: Callable[[], Any], metadata: Dict[str, Any]):
        """
        Envoie une notification en exécutant la fonction d'envoi associée.

        Args:
            notification_id (str): ID unique de la notification.
            send_function (Callable[[], Any]): Fonction pour envoyer la notification.
            metadata (Dict[str, Any]): Métadonnées associées à la notification.
        """
        try:
            logger.info(f"Sending notification {notification_id}.")
            result = await send_function()
            logger.info(f"Notification {notification_id} sent successfully. Result: {result}")
        except Exception as e:
            logger.error(f"Error sending notification {notification_id}: {e}")
            metadata["status"] = "failed"
        finally:
            self.running_notifications.remove(notification_id)
            await self._process_queue()

    async def _process_queue(self):
        """
        Traite les notifications dans la file d'attente tant que le nombre de notifications en cours d'envoi est inférieur à la limite.
        """
        while self.queue and len(self.running_notifications) < self.max_concurrent_notifications:
            notification_id, send_function, metadata = self.queue.popleft()
            self.running_notifications.add(notification_id)
            asyncio.create_task(self._send_notification(notification_id, send_function, metadata))

    def add_notification(self, send_function: Callable[[], Any], metadata: Dict[str, Any] = None):
        """
        Ajoute une notification à la file d'attente.

        Args:
            send_function (Callable[[], Any]): Fonction pour envoyer la notification.
            metadata (Dict[str, Any]): Métadonnées associées à la notification.
        """
        notification_id = str(time.time())
        metadata = metadata or {}
        metadata["status"] = "queued"
        self.queue.append((notification_id, send_function, metadata))
        logger.info(f"Notification {notification_id} added to the queue.")
        asyncio.create_task(self._process_queue())

    async def run_all_notifications(self):
        """
        Exécute toutes les notifications en attente dans la file d'attente jusqu'à ce qu'elles soient terminées.
        """
        while self.queue or self.running_notifications:
            await asyncio.sleep(1)

    def get_notification_status(self, notification_id: str) -> Dict[str, Any]:
        """
        Récupère l'état actuel d'une notification.

        Args:
            notification_id (str): ID de la notification.

        Returns:
            Dict[str, Any]: Métadonnées associées à la notification, y compris son statut.
        """
        for notification_id_in_queue, send_function, metadata in self.queue:
            if notification_id_in_queue == notification_id:
                return metadata
        if notification_id in self.running_notifications:
            return {"status": "running"}
        return {"status": "not found"}

    def cancel_notification(self, notification_id: str):
        """
        Annule une notification en cours ou en attente.

        Args:
            notification_id (str): ID de la notification à annuler.
        """
        for notification_id_in_queue, send_function, metadata in list(self.queue):
            if notification_id_in_queue == notification_id:
                self.queue.remove((notification_id_in_queue, send_function, metadata))
                logger.info(f"Notification {notification_id} canceled.")
                break
        if notification_id in self.running_notifications:
            # Ici, vous pouvez ajouter une logique pour annuler la notification si nécessaire
            logger.info(f"Notification {notification_id} is currently running and cannot be canceled.")

    def list_notifications(self) -> Dict[str, Any]:
        """
        Liste toutes les notifications en attente ou en cours d'envoi.

        Returns:
            Dict[str, Any]: Détails des notifications avec leur statut.
        """
        notification_list = []
        for notification_id_in_queue, send_function, metadata in self.queue:
            notification_list.append(metadata)
        for notification_id_in_running in self.running_notifications:
            notification_list.append({"status": "running", "notification_id": notification_id_in_running})
        logger.info(f"Notifications in queue or running: {len(notification_list)} found.")
        return notification_list

class ErrorHandlingManager:
    """
    Gère les erreurs de l'application, capture les exceptions et les notifie en cas de besoin.
    """

    def __init__(self, email_config: Dict[str, str] = None):
        """
        Initialise le gestionnaire des erreurs.

        Args:
            email_config (Dict[str, str]): Configuration pour l'envoi des emails (host, port, sender_email, etc.).
        """
        self.email_config = email_config or {}
        logger.info("ErrorHandlingManager initialized.")

    def log_error(self, error: Exception, context: Optional[Dict[str, Any]] = None):
        """
        Enregistre une erreur dans les logs et notifie si nécessaire.

        Args:
            error (Exception): L'exception à enregistrer.
            context (Optional[Dict[str, Any]]): Métadonnées contextuelles, telles que l'utilisateur ou l'action effectuée.
        """
        error_message = str(error)
        stack_trace = traceback.format_exc()
        log_message = f"Error: {error_message}\nStack trace: {stack_trace}"
        if context:
            log_message += f"\nContext: {context}"

        logger.error(log_message)
        self.send_email_notification(log_message)

    def send_email_notification(self, message: str):
        """
        Envoie un email pour notifier une erreur critique.

        Args:
            message (str): Le message d'erreur à envoyer.
        """
        if not self.email_config:
            logger.warning("No email configuration found. Skipping email notification.")
            return

        try:
            msg = MIMEMultipart()
            msg['From'] = self.email_config.get("sender_email")
            msg['To'] = self.email_config.get("recipient_email")
            msg['Subject'] = "Critical Error Notification"
            msg.attach(MIMEText(message, 'plain'))

            with smtplib.SMTP_SSL(self.email_config.get("host"), self.email_config.get("port")) as server:
                server.login(self.email_config.get("username"), self.email_config.get("password"))
                server.sendmail(msg['From'], msg['To'], msg.as_string())

            logger.info("Error notification sent via email.")
        except Exception as e:
            logger.error(f"Failed to send error email: {e}")

    def handle_exception(self, error: Exception, context: Optional[Dict[str, Any]] = None):
        """
        Gère une exception en l'enregistrant et en la notifiant si nécessaire.

        Args:
            error (Exception): L'exception à gérer.
            context (Optional[Dict[str, Any]]): Métadonnées contextuelles pour enrichir le log d'erreur.
        """
        self.log_error(error, context)
        self.send_email_notification(f"A critical error occurred: {error}")

    def retry_failed_task(self, task_function: Callable[[], Any], retries: int = 3, delay: int = 5) -> Any:
        """
        Réessaie une tâche échouée après un délai donné.

        Args:
            task_function (Callable[[], Any]): Fonction de la tâche à réessayer.
            retries (int): Nombre de tentatives avant d'abandonner.
            delay (int): Délai en secondes entre les tentatives.

        Returns:
            Any: Le résultat de la tâche réussie, ou l'exception si elle échoue après le nombre de tentatives.
        """
        attempt = 0
        while attempt < retries:
            try:
                return task_function()
            except Exception as e:
                attempt += 1
                logger.error(f"Task failed on attempt {attempt}/{retries}: {e}")
                if attempt < retries:
                    logger.info(f"Retrying in {delay} seconds...")
                    time.sleep(delay)
                else:
                    logger.error("Maximum retries reached. Task failed permanently.")
                    raise e

    def retry_failed_task_with_backoff(self, task_function: Callable[[], Any], retries: int = 3, initial_delay: int = 2) -> Any:
        """
        Réessaie une tâche échouée avec un délai d'attente exponentiel entre les tentatives.

        Args:
            task_function (Callable[[], Any]): Fonction de la tâche à réessayer.
            retries (int): Nombre de tentatives avant d'abandonner.
            initial_delay (int): Délai initial en secondes avant la première tentative.

        Returns:
            Any: Le résultat de la tâche réussie, ou l'exception si elle échoue après le nombre de tentatives.
        """
        attempt = 0
        delay = initial_delay
        while attempt < retries:
            try:
                return task_function()
            except Exception as e:
                attempt += 1
                logger.error(f"Task failed on attempt {attempt}/{retries}: {e}")
                if attempt < retries:
                    logger.info(f"Retrying in {delay} seconds...")
                    time.sleep(delay)
                    delay *= 2  # Exponential backoff
                else:
                    logger.error("Maximum retries reached. Task failed permanently.")
                    raise e


class AnalyticsManager:
    """
    Gère l'analyse des données des utilisateurs, la génération de rapports et la visualisation des données de performance.
    """

    def __init__(self):
        """
        Initialise le gestionnaire des analyses.
        """
        logger.info("AnalyticsManager initialized.")

    def collect_data(self, user_id: str, action: str, metadata: Dict[str, Any]):
        """
        Collecte les données d'interaction de l'utilisateur pour analyse.

        Args:
            user_id (str): L'ID de l'utilisateur.
            action (str): L'action effectuée par l'utilisateur (ex. "click", "view", etc.).
            metadata (Dict[str, Any]): Données contextuelles supplémentaires sur l'action.
        """
        # Pour simplifier, on suppose que les données sont collectées dans une structure Pandas DataFrame
        data = {
            "user_id": user_id,
            "action": action,
            "metadata": metadata,
            "timestamp": datetime.utcnow()
        }
        logger.info(f"Data collected for user '{user_id}' performing action '{action}'.")

        return pd.DataFrame([data])

    def generate_statistics(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        Génère des statistiques sur les interactions des utilisateurs.

        Args:
            data (pd.DataFrame): Données d'interactions des utilisateurs à analyser.

        Returns:
            Dict[str, Any]: Statistiques agrégées comme la moyenne, médiane, etc.
        """
        try:
            stats = {
                "total_interactions": len(data),
                "unique_users": data["user_id"].nunique(),
                "actions_count": data["action"].value_counts().to_dict(),
                "average_interaction_time": data["metadata"].apply(lambda x: x.get('interaction_time', 0)).mean(),
            }
            logger.info(f"Generated statistics: {stats}")
            return stats
        except Exception as e:
            logger.error(f"Error generating statistics: {e}")
            return {}

    def generate_report(self, data: pd.DataFrame) -> None:
        """
        Génère un rapport sur les interactions des utilisateurs.

        Args:
            data (pd.DataFrame): Données d'interactions des utilisateurs à analyser.
        """
        try:
            stats = self.generate_statistics(data)
            logger.info("Generating report...")
            report_data = {
                "total_interactions": stats["total_interactions"],
                "unique_users": stats["unique_users"],
                "actions_count": stats["actions_count"],
                "average_interaction_time": stats["average_interaction_time"]
            }

            report_df = pd.DataFrame([report_data])
            report_df.to_csv("user_interaction_report.csv", index=False)
            logger.info("Report generated and saved to 'user_interaction_report.csv'.")
        except Exception as e:
            logger.error(f"Error generating report: {e}")

    def visualize_data(self, data: pd.DataFrame) -> None:
        """
        Crée une visualisation des données d'interaction utilisateur (par exemple, actions par utilisateur).

        Args:
            data (pd.DataFrame): Données d'interactions des utilisateurs à analyser.
        """
        try:
            logger.info("Generating visualizations...")

            # Visualisation des actions par utilisateur
            action_counts = data["action"].value_counts()
            plt.figure(figsize=(10, 6))
            sns.barplot(x=action_counts.index, y=action_counts.values)
            plt.title("Actions par utilisateur")
            plt.xlabel("Actions")
            plt.ylabel("Nombre d'actions")
            plt.savefig("user_action_distribution.png")
            plt.show()
            logger.info("Data visualizations saved and displayed.")
        except Exception as e:
            logger.error(f"Error visualizing data: {e}")

    def analyze_trends(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        Analyse les tendances dans les interactions des utilisateurs au fil du temps.

        Args:
            data (pd.DataFrame): Données d'interactions des utilisateurs à analyser.

        Returns:
            Dict[str, Any]: Tendances identifiées, comme les pics d'activité.
        """
        try:
            data['timestamp'] = pd.to_datetime(data['timestamp'])
            trend_data = data.groupby(data['timestamp'].dt.date).size()

            trends = {
                "daily_activity_trends": trend_data.to_dict(),
                "max_activity_day": trend_data.idxmax(),
                "max_activity_count": trend_data.max()
            }

            logger.info(f"Trends identified: {trends}")
            return trends
        except Exception as e:
            logger.error(f"Error analyzing trends: {e}")
            return {}

class FileUploadManager:
    """
    Gère le téléchargement et la gestion des fichiers dans l'application.
    """

    def __init__(self, upload_dir: str = "uploads", max_size: int = 10 * 1024 * 1024):
        """
        Initialise le gestionnaire de fichiers.

        Args:
            upload_dir (str): Répertoire où les fichiers seront stockés.
            max_size (int): Taille maximale des fichiers en octets (par défaut 10 Mo).
        """
        self.upload_dir = Path(upload_dir)
        self.upload_dir.mkdir(parents=True, exist_ok=True)
        self.max_size = max_size  # 10MB par défaut
        logger.info(f"FileUploadManager initialized with upload directory: {self.upload_dir}")

    def validate_file(self, file_path: str, allowed_extensions: Optional[List[str]] = None) -> bool:
        """
        Valide un fichier (taille et type).

        Args:
            file_path (str): Chemin du fichier à valider.
            allowed_extensions (Optional[List[str]]): Liste des extensions autorisées (par exemple, ['.jpg', '.png']).

        Returns:
            bool: True si le fichier est valide, sinon False.
        """
        file_size = os.path.getsize(file_path)
        if file_size > self.max_size:
            logger.error(f"File '{file_path}' exceeds size limit of {self.max_size / 1024 / 1024} MB.")
            return False

        if allowed_extensions:
            _, file_extension = os.path.splitext(file_path)
            if file_extension.lower() not in allowed_extensions:
                logger.error(f"File '{file_path}' has an invalid extension '{file_extension}'.")
                return False

        # Validation des types MIME
        mime_type, _ = mimetypes.guess_type(file_path)
        if mime_type and not mime_type.startswith("image/") and not mime_type.startswith("application/"):
            logger.error(f"File '{file_path}' has an invalid MIME type '{mime_type}'.")
            return False

        return True

    def generate_unique_filename(self, original_filename: str) -> str:
        """
        Génère un nom de fichier unique pour éviter les collisions.

        Args:
            original_filename (str): Nom du fichier original.

        Returns:
            str: Nouveau nom de fichier unique.
        """
        file_extension = Path(original_filename).suffix
        unique_filename = f"{uuid.uuid4().hex}{file_extension}"
        return unique_filename

    def upload_file(self, file_path: str, allowed_extensions: Optional[List[str]] = None) -> str:
        """
        Télécharge un fichier après validation.

        Args:
            file_path (str): Chemin du fichier à télécharger.
            allowed_extensions (Optional[List[str]]): Liste des extensions autorisées.

        Returns:
            str: Chemin du fichier téléchargé ou une exception si l'échec.
        """
        if not self.validate_file(file_path, allowed_extensions):
            logger.error(f"File validation failed for '{file_path}'.")
            raise ValueError("File validation failed.")

        unique_filename = self.generate_unique_filename(file_path)
        destination_path = self.upload_dir / unique_filename

        try:
            os.rename(file_path, destination_path)  # Déplace le fichier vers le répertoire de destination
            logger.info(f"File '{file_path}' uploaded successfully as '{unique_filename}'.")
            return str(destination_path)
        except Exception as e:
            logger.error(f"Error uploading file '{file_path}': {e}")
            raise

    def list_uploaded_files(self) -> List[str]:
        """
        Liste tous les fichiers téléchargés dans le répertoire de stockage.

        Returns:
            List[str]: Liste des chemins des fichiers téléchargés.
        """
        files = [str(file) for file in self.upload_dir.iterdir() if file.is_file()]
        logger.info(f"List of uploaded files: {files}")
        return files

    def delete_file(self, file_name: str):
        """
        Supprime un fichier téléchargé.

        Args:
            file_name (str): Nom du fichier à supprimer.
        """
        file_path = self.upload_dir / file_name
        if file_path.exists() and file_path.is_file():
            try:
                os.remove(file_path)
                logger.info(f"File '{file_name}' deleted successfully.")
            except Exception as e:
                logger.error(f"Error deleting file '{file_name}': {e}")
                raise
        else:
            logger.warning(f"File '{file_name}' does not exist.")
            
class RedisCacheManager:
    """
    Gère un cache distribué avec Redis et fallback local.
    """

    def __init__(self, redis_host: str = "localhost", redis_port: int = 6379, cache_dir: str = "cache", ttl: int = 3600):
        """
        Initialise le gestionnaire de cache.

        Args:
            redis_host (str): Adresse du serveur Redis.
            redis_port (int): Port du serveur Redis.
            cache_dir (str): Répertoire pour le fallback local.
            ttl (int): Temps de vie des entrées en secondes.
        """
        self.redis = Redis(host=redis_host, port=redis_port, db=0, decode_responses=True)
        self.cache_dir = cache_dir
        self.ttl = ttl
        os.makedirs(cache_dir, exist_ok=True)
        self.local_cache = TTLCache(maxsize=1000, ttl=ttl)
        logger.info(f"RedisCacheManager initialized. Redis at {redis_host}:{redis_port}, fallback in '{cache_dir}'.")

    def redis_available(self) -> bool:
        """
        Vérifie si Redis est accessible.

        Returns:
            bool: True si Redis est disponible, sinon False.
        """
        try:
            self.redis.ping()
            return True
        except Exception as e:
            logger.warning(f"Redis unavailable: {e}")
            return False

    def get_cache(self, key: str) -> Optional[Any]:
        """
        Récupère une valeur du cache.

        Args:
            key (str): Clé de l'entrée dans le cache.

        Returns:
            Optional[Any]: Valeur associée ou None si non trouvée.
        """
        # Vérifier Redis
        if self.redis_available():
            try:
                value = self.redis.get(key)
                if value:
                    logger.info(f"Cache hit in Redis for key: {key}")
                    return json.loads(value)
            except Exception as e:
                logger.error(f"Error fetching key '{key}' from Redis: {e}")

        # Vérifier le cache local
        if key in self.local_cache:
            logger.info(f"Cache hit in local memory for key: {key}")
            return self.local_cache[key]

        # Vérifier le fallback local
        file_path = os.path.join(self.cache_dir, f"{key}.json")
        if os.path.exists(file_path):
            try:
                with open(file_path, "r") as file:
                    logger.info(f"Cache hit in local fallback for key: {key}")
                    return json.load(file)
            except Exception as e:
                logger.error(f"Error reading local cache file for key '{key}': {e}")

        logger.info(f"Cache miss for key: {key}")
        return None

    def set_cache(self, key: str, value: Any):
        """
        Ajoute une valeur au cache.

        Args:
            key (str): Clé de l'entrée.
            value (Any): Valeur associée à la clé.
        """
        # Ajouter dans Redis
        if self.redis_available():
            try:
                self.redis.setex(key, self.ttl, json.dumps(value))
                logger.info(f"Cache set in Redis for key: {key}")
            except Exception as e:
                logger.error(f"Error setting key '{key}' in Redis: {e}")

        # Ajouter dans le cache local
        self.local_cache[key] = value

        # Ajouter dans le fallback local
        file_path = os.path.join(self.cache_dir, f"{key}.json")
        try:
            with open(file_path, "w") as file:
                json.dump(value, file)
            logger.info(f"Cache set in local fallback for key: {key}")
        except Exception as e:
            logger.error(f"Error writing local cache file for key '{key}': {e}")

    def delete_cache(self, key: str):
        """
        Supprime une entrée du cache.

        Args:
            key (str): Clé de l'entrée à supprimer.
        """
        # Supprimer de Redis
        if self.redis_available():
            try:
                self.redis.delete(key)
                logger.info(f"Cache key '{key}' deleted from Redis.")
            except Exception as e:
                logger.error(f"Error deleting key '{key}' from Redis: {e}")

        # Supprimer du cache local
        if key in self.local_cache:
            del self.local_cache[key]
            logger.info(f"Cache key '{key}' deleted from local memory.")

        # Supprimer du fallback local
        file_path = os.path.join(self.cache_dir, f"{key}.json")
        if os.path.exists(file_path):
            try:
                os.remove(file_path)
                logger.info(f"Cache file '{key}.json' deleted from local fallback.")
            except Exception as e:
                logger.error(f"Error deleting cache file '{key}.json': {e}")

    def clear_cache(self):
        """
        Supprime tout le cache, dans Redis et localement.
        """
        # Effacer Redis
        if self.redis_available():
            try:
                self.redis.flushdb()
                logger.info("All Redis cache cleared.")
            except Exception as e:
                logger.error(f"Error clearing Redis cache: {e}")

        # Effacer le cache local
        self.local_cache.clear()
        try:
            for file in os.listdir(self.cache_dir):
                os.remove(os.path.join(self.cache_dir, file))
            logger.info("All local fallback cache cleared.")
        except Exception as e:
            logger.error(f"Error clearing local cache: {e}")

class EndToEndPipeline:
    """
    Orchestration complète du pipeline : prétraitement, clustering, évaluation et visualisation.
    """

    def __init__(self, preprocessor, clustering_service, evaluator, dashboard_generator):
        """
        Initialise le pipeline avec les composants nécessaires.

        Args:
            preprocessor: Instance de DataPreprocessor.
            clustering_service: Instance de ClusteringService.
            evaluator: Instance de MetricsEvaluator.
            dashboard_generator: Instance de DashboardGenerator.
        """
        self.preprocessor = preprocessor
        self.clustering_service = clustering_service
        self.evaluator = evaluator
        self.dashboard_generator = dashboard_generator

    def process(self, data, clustering_method="kmeans", n_clusters=5):
        """
        Traite les données de bout en bout.

        Args:
            data: Données brutes.
            clustering_method (str): Méthode de clustering ('kmeans', 'dbscan').
            n_clusters (int): Nombre de clusters (pour KMeans).

        Returns:
            dict: Résultats complets incluant l'évaluation et les graphiques.
        """
        # Étape 1 : Prétraitement
        processed_data = self.preprocessor.preprocess(data)

        # Étape 2 : Réduction et clustering
        reduced_data = self.clustering_service.reduce_dimensions(processed_data)
        clustering_results = self.clustering_service.cluster(reduced_data, method=clustering_method, n_clusters=n_clusters)

        # Étape 3 : Évaluation
        evaluation_results = self.evaluator.evaluate_clustering(reduced_data, clustering_results["labels"])

        # Étape 4 : Visualisation
        bar_chart = self.dashboard_generator.create_bar_chart(
            data=evaluation_results, title="Cluster Evaluation Metrics"
        )
        scatter_plot = self.dashboard_generator.create_scatter_plot(
            x=reduced_data[:, 0], y=reduced_data[:, 1], labels=clustering_results["labels"], title="Cluster Scatter Plot"
        )
        dashboard_path = self.dashboard_generator.create_dashboard(
            insights={"Metrics": bar_chart, "Clusters": scatter_plot}, output_file="pipeline_dashboard.html"
        )

        return {
            "evaluation": evaluation_results,
            "dashboard": dashboard_path,
            "reduced_data": reduced_data,
            "clustering_labels": clustering_results["labels"],
        }

class InteractionManager:
    """
    Gère les interactions utilisateur, incluant le cache, les modèles et les visualisations.
    """

    def __init__(self, pipeline_manager, cache_manager=None):
        """
        Initialise le gestionnaire d'interactions.

        Args:
            pipeline_manager: Instance d'AsyncPipelineManager ou équivalent.
            cache_manager: Instance de CacheManager (optionnel).
        """
        self.pipeline_manager = pipeline_manager
        self.cache_manager = cache_manager

    async def handle_request(self, user_id: str, data: Any, **kwargs) -> Dict[str, Any]:
        """
        Gère une requête utilisateur, avec support pour le cache.

        Args:
            user_id (str): Identifiant de l'utilisateur.
            data: Données brutes de la requête.
            **kwargs: Paramètres additionnels pour le pipeline.

        Returns:
            Dict[str, Any]: Résultats du traitement.
        """
        cache_key = f"user_{user_id}_request"
        if self.cache_manager:
            cached_result = self.cache_manager.get(cache_key)
            if cached_result:
                logger.info(f"Cache hit pour l'utilisateur {user_id}.")
                return cached_result

        logger.info(f"Traitement de la requête pour l'utilisateur {user_id}...")
        result = await self.pipeline_manager.process_single(data, **kwargs)

        if self.cache_manager:
            self.cache_manager.set(cache_key, result)

        return result

    async def handle_batch_request(self, user_id: str, batch_data: List[Any], **kwargs) -> List[Dict[str, Any]]:
        """
        Gère un lot de requêtes utilisateur.

        Args:
            user_id (str): Identifiant de l'utilisateur.
            batch_data (List[Any]): Liste des données brutes.
            **kwargs: Paramètres additionnels pour le pipeline.

        Returns:
            List[Dict[str, Any]]: Résultats du traitement pour chaque entrée.
        """
        logger.info(f"Traitement d'un lot de requêtes pour l'utilisateur {user_id}...")
        return await self.pipeline_manager.process_batch(batch_data, **kwargs)
class TaskScheduler:
    """
    Planifie et exécute des tâches périodiques ou programmées.
    """

    def __init__(self):
        """
        Initialise le gestionnaire de tâches.
        """
        self.scheduler = AsyncIOScheduler()
        self.scheduler.start()
        logger.info("TaskScheduler initialized and started.")

    def schedule_task(self, func, interval_seconds: int, task_name: str = None, **kwargs):
        """
        Planifie une tâche périodique.

        Args:
            func: Fonction à exécuter.
            interval_seconds (int): Intervalle entre les exécutions (en secondes).
            task_name (str): Nom de la tâche (optionnel).
            **kwargs: Arguments pour la fonction.
        """
        try:
            self.scheduler.add_job(
                func,
                IntervalTrigger(seconds=interval_seconds),
                id=task_name or func.__name__,
                kwargs=kwargs,
            )
            logger.info(f"Tâche '{task_name or func.__name__}' planifiée toutes les {interval_seconds} secondes.")
        except Exception as e:
            logger.error(f"Erreur lors de la planification de la tâche : {e}")

    def stop_task(self, task_name: str):
        """
        Arrête une tâche planifiée.

        Args:
            task_name (str): Nom de la tâche.
        """
        try:
            self.scheduler.remove_job(task_name)
            logger.info(f"Tâche '{task_name}' arrêtée avec succès.")
        except Exception as e:
            logger.error(f"Erreur lors de l'arrêt de la tâche '{task_name}' : {e}")

    def shutdown(self):
        """
        Arrête le planificateur.
        """
        self.scheduler.shutdown()
        logger.info("TaskScheduler arrêté avec succès.")
class AsyncPipelineManager:
    """
    Gère des pipelines asynchrones pour traiter des ensembles de données ou des requêtes utilisateur volumineux.
    """

    def __init__(self, pipeline):
        """
        Initialise le gestionnaire avec un pipeline.

        Args:
            pipeline: Instance d'un pipeline (e.g., EndToEndPipeline).
        """
        self.pipeline = pipeline

    async def process_single(self, data: Any, **kwargs) -> Dict[str, Any]:
        """
        Traite une seule entrée via le pipeline.

        Args:
            data: Données brutes pour une entrée unique.
            **kwargs: Paramètres additionnels pour le pipeline.

        Returns:
            Dict[str, Any]: Résultats du traitement.
        """
        try:
            return await asyncio.to_thread(self.pipeline.process, data, **kwargs)
        except Exception as e:
            return {"error": f"Erreur lors du traitement des données : {e}"}

    async def process_batch(self, batch_data: List[Any], **kwargs) -> List[Dict[str, Any]]:
        """
        Traite un lot de données en parallèle.

        Args:
            batch_data (List[Any]): Liste des données brutes.
            **kwargs: Paramètres additionnels pour le pipeline.

        Returns:
            List[Dict[str, Any]]: Résultats du traitement pour chaque entrée.
        """
        tasks = [self.process_single(data, **kwargs) for data in batch_data]
        return await asyncio.gather(*tasks)
from sklearn.datasets import load_iris
import pandas as pd

# Charger un jeu de données pour tester
iris = load_iris()
X_train = pd.DataFrame(iris.data, columns=iris.feature_names)

# Maintenant, applique le pipeline
X_train_prepared = pipeline.fit_transform(X_train)
class SentimentAnalyzer:
    """
    Analyse les sentiments des textes avec support multi-langue.
    """

    def __init__(self, model_name: str = "distilbert-base-uncased-finetuned-sst-2-english"):
        """
        Initialise le pipeline d'analyse de sentiment.

        Args:
            model_name (str): Nom du modèle transformers.
        """
        self.pipeline = pipeline("sentiment-analysis", model=model_name)
        self.translator = Translator()
        logger.info(f"SentimentAnalyzer initialized with model: {model_name}")

    def detect_language(self, text: str) -> str:
        """
        Détecte la langue d'un texte.

        Args:
            text (str): Texte brut.

        Returns:
            str: Code ISO de la langue détectée.
        """
        try:
            language = detect(text)
            logger.info(f"Detected language: {language}")
            return language
        except Exception as e:
            logger.warning(f"Error detecting language: {e}")
            return "unknown"

    def translate_text(self, text: str, target_language: str = "en") -> str:
        """
        Traduit un texte dans une langue cible.

        Args:
            text (str): Texte brut.
            target_language (str): Langue cible.

        Returns:
            str: Texte traduit.
        """
        try:
            translated = self.translator.translate(text, dest=target_language).text
            logger.info(f"Text translated to {target_language}.")
            return translated
        except Exception as e:
            logger.error(f"Error translating text: {e}")
            return text

    def analyze_sentiment(self, text: str, target_language: str = "en") -> Dict[str, Any]:
        """
        Analyse le sentiment d'un texte donné.

        Args:
            text (str): Texte brut.
            target_language (str): Langue cible pour le pipeline d'analyse.

        Returns:
            Dict[str, Any]: Résultat contenant le label, le score, et la langue détectée.
        """
        try:
            detected_language = self.detect_language(text)
            if detected_language != target_language:
                logger.info(f"Translating text from {detected_language} to {target_language}...")
                text = self.translate_text(text, target_language)

            logger.info("Running sentiment analysis...")
            result = self.pipeline(text)[0]
            logger.info(f"Sentiment result: {result}")
            return {"label": result["label"], "score": result["score"], "language": detected_language}
        except Exception as e:
            logger.error(f"Error analyzing sentiment: {e}")
            return {"label": "error", "score": 0.0, "language": "unknown"}

    def analyze_batch(self, texts: List[str], target_language: str = "en") -> List[Dict[str, Any]]:
        """
        Analyse les sentiments d'une liste de textes.

        Args:
            texts (List[str]): Liste des textes.
            target_language (str): Langue cible pour le pipeline d'analyse.

        Returns:
            List[Dict[str, Any]]: Liste des résultats pour chaque texte.
        """
        results = []
        logger.info(f"Analyzing batch of {len(texts)} texts...")
        for text in texts:
            result = self.analyze_sentiment(text, target_language)
            results.append(result)
        logger.info("Batch sentiment analysis completed.")
        return results

class DashboardGenerator:
    """
    Génère des tableaux de bord interactifs avec support pour l’exportation.
    """

    def __init__(self, output_dir: str = "dashboards"):
        """
        Initialise la classe DashboardGenerator.

        Args:
            output_dir (str): Répertoire pour sauvegarder les tableaux de bord.
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        logger.info(f"DashboardGenerator initialized. Output directory: {output_dir}")

    def create_dashboard(
        self, data: Dict[str, Dict[str, int]], output_file: str = "dashboard.html"
    ) -> str:
        """
        Crée un tableau de bord interactif basé sur les données fournies.

        Args:
            data (Dict[str, Dict[str, int]]): Données pour générer les graphiques.
            output_file (str): Nom du fichier HTML exporté.

        Returns:
            str: Chemin vers le fichier généré.
        """
        try:
            logger.info("Creating dashboard...")
            fig = make_subplots(
                rows=1,
                cols=len(data),
                subplot_titles=[f"{key}" for key in data.keys()],
            )

            # Ajout des graphiques
            col = 1
            for title, values in data.items():
                fig.add_trace(
                    go.Bar(x=list(values.keys()), y=list(values.values()), name=title),
                    row=1,
                    col=col,
                )
                col += 1

            fig.update_layout(
                title="Dashboard",
                barmode="group",
                template="plotly_dark",
                height=600,
                width=1200,
            )

            # Exporter le tableau de bord
            output_path = os.path.join(self.output_dir, output_file)
            fig.write_html(output_path)
            logger.info(f"Dashboard exported to: {output_path}")
            return output_path
        except Exception as e:
            logger.error(f"Error creating dashboard: {e}")
            return ""

    def add_pie_chart(self, fig: go.Figure, data: Dict[str, int], title: str, row: int, col: int):
        """
        Ajoute un graphique en camembert au tableau de bord.

        Args:
            fig (go.Figure): Figure Plotly existante.
            data (Dict[str, int]): Données pour le camembert.
            title (str): Titre du graphique.
            row (int): Ligne cible.
            col (int): Colonne cible.
        """
        try:
            fig.add_trace(
                go.Pie(labels=list(data.keys()), values=list(data.values()), title=title),
                row=row,
                col=col,
            )
            logger.info(f"Pie chart added for: {title}")
        except Exception as e:
            logger.error(f"Error adding pie chart: {e}")

    def generate_sentiment_dashboard(
        self, sentiment_data: Dict[str, int], output_file: str = "sentiment_dashboard.html"
    ) -> str:
        """
        Génère un tableau de bord pour l'analyse des sentiments.

        Args:
            sentiment_data (Dict[str, int]): Données d’analyse des sentiments.
            output_file (str): Nom du fichier exporté.

        Returns:
            str: Chemin vers le fichier généré.
        """
        try:
            logger.info("Generating sentiment analysis dashboard...")
            fig = make_subplots(
                rows=1, cols=2, subplot_titles=["Sentiment Distribution", "Sentiment Details"]
            )

            # Ajouter un graphique en barre
            self.add_pie_chart(fig, sentiment_data, "Sentiment Distribution", row=1, col=1)

            # Ajouter un graphique détaillé
            fig.add_trace(
                go.Bar(x=list(sentiment_data.keys()), y=list(sentiment_data.values()), name="Details"),
                row=1,
                col=2,
            )

            # Exporter le tableau de bord
            output_path = os.path.join(self.output_dir, output_file)
            fig.write_html(output_path)
            logger.info(f"Sentiment dashboard exported to: {output_path}")
            return output_path
        except Exception as e:
            logger.error(f"Error generating sentiment dashboard: {e}")
            return ""

    def export_to_image(self, input_file: str, output_file: str):
        """
        Exporte un tableau de bord HTML en image (PNG).

        Args:
            input_file (str): Chemin du fichier HTML d’entrée.
            output_file (str): Chemin du fichier image exporté.
        """
        try:
            from selenium import webdriver
            from PIL import Image

            # Charger le fichier HTML avec Selenium
            driver = webdriver.Chrome()
            driver.get(f"file://{os.path.abspath(input_file)}")
            screenshot = driver.get_screenshot_as_png()
            driver.quit()

            # Sauvegarder comme image
            image = Image.open(io.BytesIO(screenshot))
            image.save(output_file)
            logger.info(f"Dashboard exported to image: {output_file}")
        except Exception as e:
            logger.error(f"Error exporting dashboard to image: {e}")

# Sentiment Analysis Action
class ActionAdvancedSentimentAnalysis(Action):
    def name(self) -> str:
        return "action_advanced_sentiment_analysis"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer le message utilisateur
        user_message = tracker.latest_message.get("text")
        if not user_message:
            dispatcher.utter_message(text="Le message est vide ou invalide. Veuillez fournir un texte pour l'analyse.")
            return []

        try:
            # Définir des mots-clés pondérés pour les sentiments
            sentiment_keywords = {
                "positive": {
                    "génial": 2, "excellent": 3, "super": 2, "positif": 2, "joyeux": 1,
                    "j'adore": 3, "heureux": 2, "parfait": 3, "merveilleux": 2
                },
                "negative": {
                    "horrible": 3, "terrible": 3, "mal": 2, "décevant": 2, "nul": 3,
                    "triste": 1, "je déteste": 3, "mauvais": 2, "pire": 2
                },
            }

            # Initialiser les scores
            positive_score = 0
            negative_score = 0

            # Analyser chaque mot-clé dans le message utilisateur
            for sentiment, words in sentiment_keywords.items():
                for word, weight in words.items():
                    if re.search(rf"\b{word}\b", user_message.lower()):
                        if sentiment == "positive":
                            positive_score += weight
                        elif sentiment == "negative":
                            negative_score += weight

            # Calculer les scores totaux et déterminer le sentiment
            total_score = positive_score + negative_score
            if total_score == 0:
                sentiment_label = "NEUTRAL"
                sentiment_confidence = 0.0
                dispatcher.utter_message(
                    text="Le message semble neutre, sans indication claire de sentiment."
                )
            else:
                sentiment_label = (
                    "POSITIVE" if positive_score > negative_score else "NEGATIVE"
                )
                sentiment_confidence = max(positive_score, negative_score) / total_score
                dispatcher.utter_message(
                    text=(
                        f"Sentiment détecté : {sentiment_label} "
                        f"(Confiance : {sentiment_confidence:.2f})."
                    )
                )

            # Log interne pour le débogage
            logger.info(
                f"Analyse de sentiment : POSITIVE={positive_score}, NEGATIVE={negative_score}, TOTAL={total_score}"
            )

            # Mettre à jour les slots pour une utilisation future
            return [
                SlotSet("sentiment_label", sentiment_label),
                SlotSet("sentiment_confidence", sentiment_confidence),
            ]

        except Exception as e:
            # Gestion des erreurs
            logger.error(f"Erreur lors de l'analyse des sentiments : {str(e)}")
            dispatcher.utter_message(
                text="Une erreur s'est produite lors de l'analyse des sentiments."
            )
            return []

class ActionEncryptSensitiveData(Action):
    def name(self) -> str:
        return "action_encrypt_sensitive_data"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer les données sensibles depuis le slot
        user_data = tracker.get_slot("sensitive_data")
        if not user_data:
            dispatcher.utter_message(text="Aucune donnée sensible à chiffrer.")
            return []

        # Vérifier la clé de chiffrement
        db_encryption_key = os.getenv("DB_ENCRYPTION_KEY")
        if not db_encryption_key:
            error_msg = "La clé de chiffrement n'est pas configurée. Veuillez définir 'DB_ENCRYPTION_KEY' dans les variables d'environnement."
            logger.error(error_msg)
            dispatcher.utter_message(text=error_msg)
            return []

        try:
            # Vérifier si la clé est valide pour Fernet
            if len(db_encryption_key.encode()) != 44:  # Clé Fernet doit être de 44 caractères (32 bytes + encodage base64)
                raise ValueError("La clé de chiffrement fournie n'est pas valide.")

            # Initialiser Fernet avec la clé de chiffrement
            fernet = Fernet(db_encryption_key.encode())

            # Chiffrer les données sensibles
            encrypted_data = fernet.encrypt(user_data.encode()).decode()

            # Retourner les données chiffrées à l'utilisateur
            dispatcher.utter_message(text="Données chiffrées avec succès.")
            logger.info(f"Données utilisateur chiffrées avec succès : {encrypted_data}")

            # Mettre à jour le slot avec les données chiffrées
            return [SlotSet("encrypted_data", encrypted_data)]

        except ValueError as ve:
            error_msg = f"Erreur de validation de la clé de chiffrement : {ve}"
            logger.error(error_msg)
            dispatcher.utter_message(text=error_msg)

        except Exception as e:
            # Gestion des erreurs imprévues
            error_msg = f"Erreur lors du chiffrement des données : {e}"
            logger.error(error_msg)
            dispatcher.utter_message(text="Une erreur s'est produite lors du chiffrement des données.")

        return []

# Audio Response Generation Action
class ActionGenerateAudioResponse(Action):
    def name(self) -> str:
        return "action_generate_audio_response"

    async def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer le message utilisateur
        user_message = tracker.latest_message.get("text")
        if not user_message:
            dispatcher.utter_message(text="Je n'ai pas trouvé de message à convertir en audio.")
            return []

        try:
            # Configurer AWS Polly
            polly_client = boto3.client('polly', region_name='us-east-1')

            # Synthèse vocale avec Polly
            response = polly_client.synthesize_speech(
                VoiceId='Joanna',  # Vous pouvez choisir une autre voix
                OutputFormat='mp3',
                Text=user_message
            )

            # Sauvegarder le fichier audio
            output_dir = "audio_responses"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "response.mp3")

            async with aiofiles.open(file_path, mode='wb') as file:
                await file.write(response['AudioStream'].read())

            # Envoyer l'audio en réponse
            dispatcher.utter_message(
                text="Voici une réponse vocale. Vous pouvez écouter l'audio ici :",
                attachment={"type": "audio", "src": file_path}
            )

        except (BotoCoreError, ClientError) as error:
            logger.error(f"Erreur avec AWS Polly : {error}")
            dispatcher.utter_message(text="Une erreur s'est produite lors de la génération de la réponse vocale.")

        except Exception as e:
            logger.error(f"Erreur inattendue : {e}")
            dispatcher.utter_message(text="Une erreur inattendue est survenue.")

        return []


class AdvancedVisualizer:
    """
    Génère des visualisations avancées interactives et exportables.
    """

    def __init__(self, output_dir: str = "visualizations"):
        """
        Initialise le gestionnaire de visualisations.

        Args:
            output_dir (str): Répertoire de sortie pour sauvegarder les visualisations.
        """
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)

    def generate_heatmap(self, data: List[List[float]], x_labels: List[str], y_labels: List[str], title: str) -> go.Figure:
        """
        Génère une heatmap interactive.

        Args:
            data (List[List[float]]): Données pour la heatmap.
            x_labels (List[str]): Labels pour l'axe X.
            y_labels (List[str]): Labels pour l'axe Y.
            title (str): Titre du graphique.

        Returns:
            go.Figure: Graphique interactif.
        """
        if len(data) != len(y_labels) or any(len(row) != len(x_labels) for row in data):
            raise ValueError("Les dimensions des données et des labels doivent correspondre.")

        fig = go.Figure(data=go.Heatmap(z=data, x=x_labels, y=y_labels, colorscale="Viridis"))
        fig.update_layout(title=title, template="plotly_white")
        return fig

    def save_figure(self, fig: go.Figure, file_name: str):
        """
        Sauvegarde une figure Plotly au format HTML.

        Args:
            fig (go.Figure): Figure Plotly.
            file_name (str): Nom du fichier HTML.
        """
        file_path = os.path.join(self.output_dir, file_name)
        fig.write_html(file_path)
        return file_path

class MonitoringService:
    """
    Service de monitoring pour centraliser les métriques et logs.
    """

    def __init__(self):
        """
        Initialise le service de monitoring.
        """
        self.metrics = {}

    def log_metric(self, name: str, value: Any):
        """
        Enregistre une métrique avec son nom et sa valeur.

        Args:
            name (str): Nom de la métrique.
            value (Any): Valeur de la métrique.
        """
        self.metrics[name] = value
        logger.info(f"Métrique enregistrée : {name} = {value}")

    def track_execution_time(self, func):
        """
        Décorateur pour suivre le temps d'exécution d'une fonction.

        Args:
            func: Fonction à surveiller.

        Returns:
            Fonction décorée.
        """
        def wrapper(*args, **kwargs):
            start_time = time.time()
            result = func(*args, **kwargs)
            elapsed_time = time.time() - start_time
            self.log_metric(f"{func.__name__}_execution_time", elapsed_time)
            logger.info(f"Temps d'exécution pour {func.__name__} : {elapsed_time:.2f} secondes")
            return result
        return wrapper

    def get_metrics(self) -> Dict[str, Any]:
        """
        Retourne toutes les métriques enregistrées.

        Returns:
            Dict[str, Any]: Dictionnaire des métriques.
        """
        return self.metrics
class ClusteringService:
    """
    Service avancé pour la réduction de dimensions et le clustering, avec des visualisations interactives.
    """

    def __init__(self, n_neighbors: int = 15, min_dist: float = 0.1, n_components: int = 2, random_state: int = 42):
        """
        Initialise le service avec des paramètres configurables pour UMAP.

        Args:
            n_neighbors (int): Nombre de voisins pour UMAP.
            min_dist (float): Distance minimale pour UMAP.
            n_components (int): Dimensions cibles pour UMAP (2D ou 3D).
            random_state (int): État aléatoire pour reproductibilité.
        """
        self.reducer = UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, random_state=random_state)
        logger.info(f"ClusteringService initialized with {n_components}D UMAP reducer.")

    def reduce_dimensions(self, embeddings: Union[List[List[float]], np.ndarray]) -> np.ndarray:
        """
        Réduit les dimensions des données avec UMAP.

        Args:
            embeddings (Union[List[List[float]], np.ndarray]): Données haute dimension.

        Returns:
            np.ndarray: Données réduites.
        """
        embeddings = self._validate_and_convert_embeddings(embeddings)

        logger.info(f"Reducing dimensions to {self.reducer.n_components}D...")
        try:
            reduced_embeddings = self.reducer.fit_transform(embeddings)
            logger.info("Dimension reduction completed successfully.")
            return reduced_embeddings
        except Exception as e:
            logger.error(f"Error during dimension reduction: {e}")
            raise

    def apply_clustering(self, embeddings: np.ndarray, method: str = "kmeans", **kwargs) -> Dict[str, Any]:
        """
        Applique un clustering sur les données réduites.

        Args:
            embeddings (np.ndarray): Données réduites.
            method (str): Méthode de clustering ('kmeans', 'dbscan', 'hdbscan').
            **kwargs: Paramètres spécifiques à l'algorithme.

        Returns:
            Dict[str, Any]: Résultats avec les labels et le modèle utilisé.
        """
        logger.info(f"Applying clustering using method: {method}...")
        try:
            if method == "kmeans":
                n_clusters = kwargs.get("n_clusters", 5)
                cluster_model = KMeans(n_clusters=n_clusters, random_state=42)
            elif method == "dbscan":
                eps = kwargs.get("eps", 0.5)
                min_samples = kwargs.get("min_samples", 5)
                cluster_model = DBSCAN(eps=eps, min_samples=min_samples, metric="euclidean")
            elif method == "hdbscan":
                min_cluster_size = kwargs.get("min_cluster_size", 5)
                cluster_model = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)
            else:
                raise ValueError(f"Unsupported clustering method: {method}")

            labels = cluster_model.fit_predict(embeddings)
            logger.info(f"Clustering completed. Found {len(set(labels)) - (1 if -1 in labels else 0)} clusters.")
            return {"labels": labels, "model": cluster_model}
        except Exception as e:
            logger.error(f"Error during clustering: {e}")
            raise

    def visualize_clusters(self, embeddings: np.ndarray, labels: List[int], interactive: bool = True, save_path: str = None):
        """
        Visualise les clusters en 2D avec des options interactives.

        Args:
            embeddings (np.ndarray): Données réduites en 2D.
            labels (List[int]): Labels des clusters.
            interactive (bool): Générer une visualisation interactive (Plotly) ou statique (Matplotlib).
            save_path (str): Chemin pour enregistrer la visualisation (facultatif).
        """
        if embeddings.shape[1] != 2:
            raise ValueError("Embeddings must be 2D for visualization.")

        logger.info("Generating cluster visualization...")
        try:
            if interactive:
                # Utilisation de Plotly pour une visualisation interactive
                fig = px.scatter(
                    x=embeddings[:, 0],
                    y=embeddings[:, 1],
                    color=labels,
                    title="Interactive Cluster Visualization",
                    labels={"x": "UMAP Dim 1", "y": "UMAP Dim 2", "color": "Cluster"},
                )
                if save_path:
                    fig.write_html(save_path)
                    logger.info(f"Interactive cluster visualization saved to {save_path}.")
                fig.show()
            else:
                # Visualisation statique avec Matplotlib
                plt.figure(figsize=(10, 8))
                scatter = plt.scatter(embeddings[:, 0], embeddings[:, 1], c=labels, cmap="tab10", s=20)
                plt.title("Static Cluster Visualization")
                plt.xlabel("UMAP Dim 1")
                plt.ylabel("UMAP Dim 2")
                plt.colorbar(scatter, label="Cluster")
                if save_path:
                    plt.savefig(save_path)
                    logger.info(f"Static cluster visualization saved to {save_path}.")
                else:
                    plt.show()
        except Exception as e:
            logger.error(f"Error during cluster visualization: {e}")
            raise

    def cluster_and_visualize(
        self, embeddings: Union[List[List[float]], np.ndarray], method: str = "kmeans", interactive: bool = True, **kwargs
    ) -> Dict[str, Any]:
        """
        Pipeline complet pour réduire les dimensions, clusteriser et visualiser.

        Args:
            embeddings (Union[List[List[float]], np.ndarray]): Données haute dimension.
            method (str): Méthode de clustering ('kmeans', 'dbscan', 'hdbscan').
            interactive (bool): Générer une visualisation interactive ou statique.
            **kwargs: Paramètres spécifiques au clustering.

        Returns:
            Dict[str, Any]: Résultats du clustering.
        """
        logger.info("Starting full clustering pipeline...")
        try:
            reduced_embeddings = self.reduce_dimensions(embeddings)
            clustering_results = self.apply_clustering(reduced_embeddings, method, **kwargs)
            self.visualize_clusters(
                embeddings=reduced_embeddings,
                labels=clustering_results["labels"],
                interactive=interactive,
                save_path=kwargs.get("save_path", None),
            )
            return {"reduced_embeddings": reduced_embeddings, **clustering_results}
        except Exception as e:
            logger.error(f"Error in clustering pipeline: {e}")
            raise

    def _validate_and_convert_embeddings(self, embeddings: Any) -> np.ndarray:
        """
        Valide et convertit les embeddings en numpy array.

        Args:
            embeddings (Any): Données à valider.

        Returns:
            np.ndarray: Données validées et converties.
        """
        if isinstance(embeddings, list):
            embeddings = np.array(embeddings)
        if not isinstance(embeddings, np.ndarray) or embeddings.ndim != 2 or embeddings.size == 0:
            raise ValueError("Embeddings must be a non-empty 2D numpy array or a list of lists.")
        return embeddings


class DataPreprocessor:
    """
    Gère le prétraitement des données pour le clustering ou les modèles.
    """

    def __init__(self, normalize: bool = True, standardize: bool = True):
        """
        Initialise les paramètres de prétraitement.

        Args:
            normalize (bool): Normaliser les données (MinMax Scaling).
            standardize (bool): Standardiser les données (Moyenne=0, Écart-type=1).
        """
        self.normalize = normalize
        self.standardize = standardize

    def preprocess(self, data: Union[List[List[float]], np.ndarray]) -> np.ndarray:
        """
        Applique le prétraitement sur les données.

        Args:
            data (Union[List[List[float]], np.ndarray]): Données brutes.

        Returns:
            np.ndarray: Données prétraitées.
        """
        data = self._validate_and_convert(data)

        if self.standardize:
            data = (data - np.mean(data, axis=0)) / np.std(data, axis=0)
        if self.normalize:
            data = (data - np.min(data, axis=0)) / (np.max(data, axis=0) - np.min(data, axis=0))

        return data

    def _validate_and_convert(self, data: Union[List[List[float]], np.ndarray]) -> np.ndarray:
        """
        Valide et convertit les données en numpy array.

        Args:
            data (Union[List[List[float]], np.ndarray]): Données brutes.

        Returns:
            np.ndarray: Données validées.
        """
        if isinstance(data, list):
            data = np.array(data)
        if not isinstance(data, np.ndarray) or data.ndim != 2 or data.size == 0:
            raise ValueError("Les données doivent être une liste 2D ou un tableau numpy non vide.")
        return data


class MetricsEvaluator:
    """
    Évalue les clusters ou les modèles avec des métriques.
    """

    def evaluate_clustering(self, embeddings: np.ndarray, labels: List[int]) -> Dict[str, float]:
        """
        Évalue la qualité des clusters avec des métriques.

        Args:
            embeddings (np.ndarray): Données réduites.
            labels (List[int]): Labels des clusters.

        Returns:
            Dict[str, float]: Scores calculés.
        """
        if len(set(labels)) <= 1:
            raise ValueError("Impossible d'évaluer le clustering avec moins de 2 clusters.")

        try:
            silhouette = silhouette_score(embeddings, labels)
            davies_bouldin = davies_bouldin_score(embeddings, labels)
            logger.info("Clustering evaluated successfully.")
            return {
                "silhouette_score": silhouette,
                "davies_bouldin_index": davies_bouldin
            }
        except Exception as e:
            logger.error(f"Erreur lors de l'évaluation des clusters : {e}")
            raise

class MultiModelManager:
    """
    Gère plusieurs modèles ONNX avec support pour validation, exécution et gestion centralisée.
    """

    def __init__(self):
        """
        Initialise la classe avec un gestionnaire de modèles vide.
        """
        self.models = {}
        logger.info("MultiModelManager initialized with no models loaded.")

    def load_model(self, model_name: str, model_path: str, device: str = "auto"):
        """
        Charge un modèle ONNX dans le gestionnaire.

        Args:
            model_name (str): Nom du modèle.
            model_path (str): Chemin vers le fichier ONNX.
            device (str): Device à utiliser ('cpu', 'gpu', ou 'auto').
        """
        try:
            device_provider = (
                "CUDAExecutionProvider" if (device == "gpu" or (device == "auto" and ort.get_device() == "GPU"))
                else "CPUExecutionProvider"
            )
            session = ort.InferenceSession(model_path, providers=[device_provider])
            self.models[model_name] = {
                "session": session,
                "input_metadata": {inp.name: inp.shape for inp in session.get_inputs()},
                "output_metadata": {out.name: out.shape for out in session.get_outputs()},
            }
            logger.info(f"Model '{model_name}' loaded from {model_path} on device: {device_provider}.")
        except Exception as e:
            logger.error(f"Error loading model '{model_name}' from {model_path}: {e}")

    def unload_model(self, model_name: str):
        """
        Supprime un modèle du gestionnaire.

        Args:
            model_name (str): Nom du modèle à supprimer.
        """
        if model_name in self.models:
            del self.models[model_name]
            logger.info(f"Model '{model_name}' unloaded successfully.")
        else:
            logger.warning(f"Model '{model_name}' not found in manager.")

    def list_models(self) -> List[str]:
        """
        Liste les modèles actuellement chargés.

        Returns:
            List[str]: Noms des modèles chargés.
        """
        logger.info("Listing all loaded models.")
        return list(self.models.keys())

    def validate_input(self, model_name: str, input_data: Dict[str, Any]) -> bool:
        """
        Valide les données d'entrée pour un modèle spécifique.

        Args:
            model_name (str): Nom du modèle.
            input_data (Dict[str, Any]): Données d'entrée.

        Returns:
            bool: True si les données sont valides, sinon False.
        """
        if model_name not in self.models:
            logger.error(f"Model '{model_name}' not found.")
            return False

        model = self.models[model_name]
        for key, value in input_data.items():
            if key not in model["input_metadata"]:
                logger.error(f"Invalid input key: {key}. Expected keys: {list(model['input_metadata'].keys())}.")
                return False
            if len(value.shape) != len(model["input_metadata"][key]):
                logger.error(f"Shape mismatch for input '{key}': {value.shape} != {model['input_metadata'][key]}.")
                return False

        logger.info(f"Input validation passed for model '{model_name}'.")
        return True

    def predict(self, model_name: str, input_data: Dict[str, Any]) -> List[Any]:
        """
        Effectue une prédiction avec un modèle spécifique.

        Args:
            model_name (str): Nom du modèle.
            input_data (Dict[str, Any]): Données d'entrée.

        Returns:
            List[Any]: Résultats de la prédiction.
        """
        if not self.validate_input(model_name, input_data):
            raise ValueError(f"Invalid input data for model '{model_name}'.")

        try:
            logger.info(f"Running inference for model '{model_name}'...")
            session = self.models[model_name]["session"]
            outputs = session.run(None, input_data)
            logger.info(f"Inference completed for model '{model_name}'.")
            return outputs
        except Exception as e:
            logger.error(f"Error during inference for model '{model_name}': {e}")
            return []

    def predict_all(self, input_data: Dict[str, Dict[str, Any]]) -> Dict[str, List[Any]]:
        """
        Effectue des prédictions pour tous les modèles chargés.

        Args:
            input_data (Dict[str, Dict[str, Any]]): Données d'entrée pour chaque modèle.

        Returns:
            Dict[str, List[Any]]: Résultats des prédictions par modèle.
        """
        predictions = {}
        logger.info("Running predictions for all loaded models.")
        for model_name, data in input_data.items():
            if model_name in self.models:
                predictions[model_name] = self.predict(model_name, data)
            else:
                logger.warning(f"Model '{model_name}' not found.")
                predictions[model_name] = []
        return predictions

    def get_metadata(self, model_name: str) -> Dict[str, Any]:
        """
        Récupère les métadonnées d'un modèle spécifique.

        Args:
            model_name (str): Nom du modèle.

        Returns:
            Dict[str, Any]: Métadonnées du modèle.
        """
        if model_name not in self.models:
            logger.error(f"Model '{model_name}' not found.")
            return {}

        metadata = {
            "inputs": self.models[model_name]["input_metadata"],
            "outputs": self.models[model_name]["output_metadata"],
        }
        logger.info(f"Retrieved metadata for model '{model_name}': {metadata}")
        return metadata


class PredictionService:
    """
    Service centralisé pour gérer les prédictions des modèles.
    """

    def __init__(self, model_manager: Any):
        """
        Initialise le service avec un gestionnaire de modèles.

        Args:
            model_manager (Any): Instance de gestionnaire de modèles (e.g., MultiModelManager).
        """
        self.model_manager = model_manager

    def predict(self, model_name: str, input_data: Dict[str, Any]) -> Any:
        """
        Effectue une prédiction avec un modèle spécifique.

        Args:
            model_name (str): Nom du modèle.
            input_data (Dict[str, Any]): Données d'entrée.

        Returns:
            Any: Résultats de la prédiction.
        """
        if model_name not in self.model_manager.list_models():
            raise ValueError(f"Le modèle '{model_name}' n'est pas chargé.")

        try:
            logger.info(f"Prédiction en cours pour le modèle '{model_name}'...")
            return self.model_manager.predict(model_name, input_data)
        except Exception as e:
            logger.error(f"Erreur lors de la prédiction avec le modèle '{model_name}': {e}")
            raise


class NextLevelAISystem:
    """
    Système AI avancé avec gestion multi-modèle, cache Redis, et analyses enrichies.
    """

    def __init__(self):
        """
        Initialise le système AI de niveau supérieur.
        """
        self.mongo_manager = MongoDBManager()
        self.cache_manager = CacheManager()
        self.nlp_processor = NLPProcessor()
        self.sentiment_analyzer = SentimentAnalyzer()
        self.data_organizer = DataOrganizer()
        self.dashboard_generator = DashboardGenerator()
        self.models = {
            "sentiment": ONNXModelWrapper("sentiment_model.onnx"),
            "intent": ONNXModelWrapper("intent_classification.onnx"),
        }
        logger.info("NextLevelAISystem initialized with advanced components.")

    async def process_message(self, user_id: str, user_message: str, language: str = "auto") -> Dict[str, Any]:
        """
        Traite un message utilisateur avec modèles ONNX et NLP.

        Args:
            user_id (str): ID utilisateur.
            user_message (str): Message envoyé par l'utilisateur.
            language (str): Langue cible (par défaut détectée automatiquement).

        Returns:
            Dict[str, Any]: Résultats du traitement (sentiment, intent, réponse).
        """
        try:
            # Vérifier le cache
            cache_key = f"message_{user_id}_{user_message}"
            cached_response = self.cache_manager.get_cache(cache_key)
            if cached_response:
                logger.info(f"Cache hit for key: {cache_key}")
                return cached_response

            # Détection de langue
            detected_language = self.nlp_processor.detect_language(user_message) if language == "auto" else language
            logger.info(f"Detected language: {detected_language}")

            # Prétraitement
            preprocessed_message = self.nlp_processor.preprocess_text(user_message, target_language="en")

            # Analyse de sentiment via ONNX
            sentiment = self.models["sentiment"].predict({"input_text": preprocessed_message})
            sentiment_result = {"label": "positive" if sentiment[0] > 0.5 else "negative", "score": sentiment[0]}

            # Classification d'intention via ONNX
            intent = self.models["intent"].predict({"input_text": preprocessed_message})
            intent_result = {"intent": "greeting" if intent[0] > 0.5 else "request", "score": intent[0]}

            # Génération de la réponse
            response = (
                f"Detected sentiment: {sentiment_result['label']} "
                f"(Confidence: {sentiment_result['score']:.2f}). "
                f"Intent: {intent_result['intent']}."
            )

            # Sauvegarde des interactions
            metadata = {
                "detected_language": detected_language,
                "sentiment": sentiment_result,
                "intent": intent_result,
            }
            await self.mongo_manager.save_interaction(user_id, user_message, response, metadata)

            # Sauvegarde dans le cache
            result = {"response": response, "sentiment": sentiment_result, "intent": intent_result}
            self.cache_manager.set_cache(cache_key, result)

            logger.info(f"Processed message for user {user_id}")
            return result
        except Exception as e:
            logger.error(f"Error processing message for user {user_id}: {e}")
            return {"response": "Error occurred.", "sentiment": None, "intent": None}

    async def process_batch(self, user_id: str, messages: List[str]) -> List[Dict[str, Any]]:
        """
        Traite un lot de messages utilisateur avec le cache.

        Args:
            user_id (str): ID utilisateur.
            messages (List[str]): Liste des messages utilisateur.

        Returns:
            List[Dict[str, Any]]: Résultats pour chaque message.
        """
        try:
            tasks = [self.process_message(user_id, message) for message in messages]
            results = await asyncio.gather(*tasks)
            logger.info(f"Batch processing completed for user {user_id}")
            return results
        except Exception as e:
            logger.error(f"Error processing batch for user {user_id}: {e}")
            return []

    async def cluster_texts(self, texts: List[str], method: str = "kmeans", **kwargs) -> Dict[str, Any]:
        """
        Organise et clusterise les textes avec des embeddings.

        Args:
            texts (List[str]): Liste des textes.
            method (str): Méthode de clustering ('kmeans', 'dbscan', 'hdbscan').
            **kwargs: Paramètres spécifiques pour le clustering.

        Returns:
            Dict[str, Any]: Résumé des clusters et chemin du fichier exporté.
        """
        try:
            embeddings = self.data_organizer.generate_embeddings(texts)
            clustered_data = self.data_organizer.apply_clustering(embeddings, method=method, **kwargs)
            export_path = self.data_organizer.export_clusters(clustered_data)
            logger.info("Texts clustered successfully.")
            return {"clusters": clustered_data["Cluster"].value_counts().to_dict(), "export_path": export_path}
        except Exception as e:
            logger.error(f"Error clustering texts: {e}")
            return {"clusters": {}, "export_path": None}

    async def generate_dashboard(self, user_id: str) -> str:
        """
        Génère un tableau de bord des interactions utilisateur.

        Args:
            user_id (str): ID utilisateur.

        Returns:
            str: Chemin vers le fichier HTML généré.
        """
        try:
            interactions = await self.mongo_manager.fetch_interactions(user_id)
            sentiment_summary = {}
            for interaction in interactions:
                sentiment = interaction["metadata"].get("sentiment", {}).get("label", "unknown")
                sentiment_summary[sentiment] = sentiment_summary.get(sentiment, 0) + 1

            dashboard_path = self.dashboard_generator.create_dashboard(
                {"Sentiment Distribution": sentiment_summary}, output_file=f"{user_id}_dashboard.html"
            )
            logger.info(f"Dashboard generated for user {user_id}")
            return dashboard_path
        except Exception as e:
            logger.error(f"Error generating dashboard for user {user_id}: {e}")
            return ""



# Intent Classifier
class IntentClassifier:
    """
    Classifie les intentions utilisateur avec support pour plusieurs modèles et pipelines avancés.
    """

    def __init__(self, embedding_model: str = "paraphrase-MiniLM-L6-v2", model_type: str = "random_forest"):
        """
        Initialise la classe IntentClassifier.

        Args:
            embedding_model (str): Modèle SentenceTransformers pour les embeddings avancés.
            model_type (str): Type de modèle d'apprentissage ("random_forest" ou "svm").
        """
        self.embedding_model = SentenceTransformer(embedding_model)
        self.vectorizer = TfidfVectorizer(max_features=3000)
        self.model_type = model_type
        self.model = None
        logger.info(f"IntentClassifier initialized with model type: {model_type} and embedding model: {embedding_model}.")

    def prepare_data(self, data: pd.DataFrame, text_column: str = "text", label_column: str = "label") -> tuple:
        """
        Prépare les données pour l'entraînement.

        Args:
            data (pd.DataFrame): Jeu de données.
            text_column (str): Colonne contenant les textes.
            label_column (str): Colonne contenant les étiquettes.

        Returns:
            tuple: (X_train, X_test, y_train, y_test)
        """
        if text_column not in data.columns or label_column not in data.columns:
            logger.error(f"Columns '{text_column}' or '{label_column}' are missing from the dataset.")
            raise ValueError("Required columns are missing in the dataset.")

        logger.info("Generating embeddings for text data...")
        embeddings = self.embedding_model.encode(data[text_column].tolist(), show_progress_bar=True)
        X_train, X_test, y_train, y_test = train_test_split(embeddings, data[label_column], test_size=0.2, random_state=42)
        logger.info("Data preparation completed.")
        return X_train, X_test, y_train, y_test

    def train_model(self, X_train, y_train, hyperparameters: dict = None):
        """
        Entraîne le modèle sélectionné.

        Args:
            X_train: Données d'entraînement.
            y_train: Étiquettes d'entraînement.
            hyperparameters (dict): Hyperparamètres pour le modèle.
        """
        hyperparameters = hyperparameters or {}
        logger.info(f"Training model: {self.model_type}...")

        if self.model_type == "random_forest":
            self.model = RandomForestClassifier(random_state=42, **hyperparameters)
        elif self.model_type == "svm":
            self.model = SVC(kernel="linear", probability=True, random_state=42, **hyperparameters)
        else:
            logger.error(f"Unsupported model type: {self.model_type}")
            raise ValueError(f"Model type '{self.model_type}' is not supported.")

        self.model.fit(X_train, y_train)
        logger.info("Model training completed.")

    def evaluate_model(self, X_test, y_test):
        """
        Évalue le modèle avec des données de test.

        Args:
            X_test: Données de test.
            y_test: Étiquettes de test.

        Returns:
            float: Précision du modèle.
        """
        logger.info("Evaluating model...")
        y_pred = self.model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        logger.info(f"Accuracy: {accuracy * 100:.2f}%")
        print(classification_report(y_test, y_pred))

        # Afficher la matrice de confusion
        cm = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(10, 8))
        plt.imshow(cm, interpolation="nearest", cmap=plt.cm.Blues)
        plt.title("Confusion Matrix")
        plt.colorbar()
        plt.ylabel("True Label")
        plt.xlabel("Predicted Label")
        plt.show()

        return accuracy

    def predict(self, texts: List[str]) -> List[str]:
        """
        Prédictions pour des textes donnés.

        Args:
            texts (List[str]): Liste des textes.

        Returns:
            List[str]: Liste des prédictions.
        """
        logger.info("Predicting intents...")
        embeddings = self.embedding_model.encode(texts, show_progress_bar=True)
        predictions = self.model.predict(embeddings)
        logger.info("Predictions completed.")
        return predictions

    def tune_hyperparameters(self, X_train, y_train, param_grid: dict):
        """
        Effectue une recherche des meilleurs hyperparamètres.

        Args:
            X_train: Données d'entraînement.
            y_train: Étiquettes d'entraînement.
            param_grid (dict): Grille des hyperparamètres.

        Returns:
            dict: Meilleurs hyperparamètres.
        """
        logger.info("Tuning hyperparameters...")
        if self.model_type == "random_forest":
            model = RandomForestClassifier(random_state=42)
        elif self.model_type == "svm":
            model = SVC(kernel="linear", probability=True, random_state=42)
        else:
            logger.error(f"Unsupported model type for hyperparameter tuning: {self.model_type}")
            raise ValueError("Unsupported model type for hyperparameter tuning.")

        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring="accuracy", verbose=2, n_jobs=-1)
        grid_search.fit(X_train, y_train)
        self.model = grid_search.best_estimator_
        logger.info(f"Best hyperparameters found: {grid_search.best_params_}")
        return grid_search.best_params_
# NLP Processor

class NLPProcessor:
    """
    Prétraitement avancé des textes avec NLP multilingue.
    """

    def __init__(self, language_model: str = "en_core_web_sm", embedding_model: str = "all-MiniLM-L6-v2"):



        """
        Initialise le processeur NLP avec spaCy et SentenceTransformers.

        Args:
            language_model (str): Modèle linguistique spaCy.
            embedding_model (str): Modèle d'embedding SentenceTransformers.
        """
        self.nlp = spacy_load(language_model)
        self.translator = Translator()
        self.embedding_model = SentenceTransformer(embedding_model)
        self.tfidf_vectorizer = TfidfVectorizer(max_features=3000)
        logger.info(f"NLPProcessor initialized with spaCy model '{language_model}' and embedding model '{embedding_model}'.")

    def __init__(self):
        self.generator = pipeline("text-generation", model="gpt2")

    def generate_response(self, user_message: str) -> str:
        """
        Génère une réponse brute à partir du message utilisateur.
        """
        return self.generator(f"User: {user_message}\nBot:", max_length=100, do_sample=True)[0]["generated_text"]

    def adjust_tone(self, text: str, tone: str) -> str:
        """
        Ajuste le ton de la réponse (amical, formel, etc.).
        """
        tone_prefix = {
            "friendly": "Paraphrase this in a friendly tone:",
            "formal": "Paraphrase this in a formal tone:"
        }
        command = f"{tone_prefix.get(tone, '')} {text}"
        return self.generator(command, max_length=100, do_sample=True)[0]["generated_text"]
    def detect_language(self, text: str) -> str:
        """
        Détecte la langue d'un texte.

        Args:
            text (str): Texte à analyser.

        Returns:
            str: Code ISO de la langue détectée.
        """
        try:
            language = detect(text)
            logger.info(f"Language detected: {language}")
            return language
        except Exception as e:
            logger.warning(f"Error detecting language: {e}")
            return "unknown"

    def translate_text(self, text: str, target_language: str = "en") -> str:
        """
        Traduit un texte dans une langue cible.

        Args:
            text (str): Texte brut.
            target_language (str): Langue cible.

        Returns:
            str: Texte traduit.
        """
        try:
            translated = self.translator.translate(text, dest=target_language).text
            logger.info(f"Text translated to {target_language}.")
            return translated
        except Exception as e:
            logger.error(f"Error translating text: {e}")
            return text

    def preprocess_text(self, text: str, target_language: str = "en", remove_stopwords: bool = True) -> str:
        """
        Prétraite un texte : traduction, lemmatisation, suppression des stopwords.

        Args:
            text (str): Texte brut.
            target_language (str): Langue cible.
            remove_stopwords (bool): Supprimer les stopwords ou non.

        Returns:
            str: Texte prétraité.
        """
        try:
            detected_language = self.detect_language(text)
            if detected_language != target_language:
                logger.info(f"Translating text from {detected_language} to {target_language}...")
                text = self.translate_text(text, target_language)

            doc = self.nlp(text)
            preprocessed = [
                token.lemma_ for token in doc if not token.is_punct and (not remove_stopwords or token.text.lower() not in STOP_WORDS)
            ]
            logger.info(f"Preprocessed text: {preprocessed[:5]}...")
            return " ".join(preprocessed)
        except Exception as e:
            logger.error(f"Error during text preprocessing: {e}")
            return ""

    def extract_entities(self, text: str) -> Dict[str, List[str]]:
        """
        Extrait les entités nommées d'un texte.

        Args:
            text (str): Texte brut.

        Returns:
            Dict[str, List[str]]: Dictionnaire des entités nommées par type.
        """
        try:
            doc = self.nlp(text)
            entities = {}
            for ent in doc.ents:
                entities.setdefault(ent.label_, []).append(ent.text)
            logger.info(f"Extracted entities: {entities}")
            return entities
        except Exception as e:
            logger.error(f"Error extracting entities: {e}")
            return {}

    def generate_embeddings(self, texts: List[str]) -> List[List[float]]:
        """
        Génère des embeddings pour une liste de textes.

        Args:
            texts (List[str]): Liste des textes.

        Returns:
            List[List[float]]: Embeddings vectoriels.
        """
        try:
            embeddings = self.embedding_model.encode(texts, show_progress_bar=True)
            logger.info(f"Generated embeddings for {len(texts)} texts.")
            return embeddings
        except Exception as e:
            logger.error(f"Error generating embeddings: {e}")
            return []

    def process_batch(self, texts: List[str], target_language: str = "en", remove_stopwords: bool = True) -> List[str]:
        """
        Prétraite un lot de textes en parallèle.

        Args:
            texts (List[str]): Liste des textes.
            target_language (str): Langue cible.
            remove_stopwords (bool): Supprimer les stopwords ou non.

        Returns:
            List[str]: Textes prétraités.
        """
        try:
            logger.info(f"Processing batch of {len(texts)} texts...")
            results = Parallel(n_jobs=-1)(
                delayed(self.preprocess_text)(text, target_language, remove_stopwords) for text in texts
            )
            logger.info("Batch processing completed.")
            return results
        except Exception as e:
            logger.error(f"Error processing batch: {e}")
            return []

class EliteAISystem:
    """
    Système centralisé pour gérer l'IA avancée, combinant MongoDB, ONNX, NLP et visualisation.
    """

    def __init__(self):
        """
        Initialise tous les composants du système Elite AI.
        """
        self.mongo_manager = MongoDBManager()
        self.onnx_model = ONNXModelWrapper("optimized_model.onnx")
        self.nlp_processor = NLPProcessor()
        self.sentiment_analyzer = SentimentAnalyzer()
        self.data_organizer = DataOrganizer()
        self.dashboard_generator = DashboardGenerator()
        logger.info("EliteAISystem initialized with all components.")

    async def process_message(self, user_id: str, user_message: str, language: str = "auto") -> str:
        """
        Traite un message utilisateur avec analyse de sentiment et sauvegarde.

        Args:
            user_id (str): ID utilisateur.
            user_message (str): Message envoyé par l'utilisateur.
            language (str): Langue cible pour le traitement.

        Returns:
            str: Réponse générée pour l'utilisateur.
        """
        try:
            # Détection de la langue
            detected_language = self.nlp_processor.detect_language(user_message) if language == "auto" else language
            logger.info(f"Detected language: {detected_language}")

            # Prétraitement du message
            preprocessed_message = self.nlp_processor.preprocess_text(user_message, target_language="en")

            # Analyse de sentiment
            sentiment = self.sentiment_analyzer.analyze_sentiment(preprocessed_message, target_language="en")
            logger.info(f"Sentiment analysis result: {sentiment}")

            # Génération d'une réponse
            response = f"Your message sentiment: {sentiment['label']} (Confidence: {sentiment['score']:.2f})."
            logger.info(f"Generated response: {response}")

            # Sauvegarde dans MongoDB
            metadata = {"detected_language": detected_language, "sentiment": sentiment}
            await self.mongo_manager.save_interaction(user_id, user_message, response, metadata)
            return response
        except Exception as e:
            logger.error(f"Error processing message: {e}")
            return "Sorry, an error occurred while processing your message."

    async def process_batch(self, user_id: str, messages: List[str], language: str = "auto") -> List[str]:
        """
        Traite un lot de messages utilisateur.

        Args:
            user_id (str): ID utilisateur.
            messages (List[str]): Liste des messages utilisateur.
            language (str): Langue cible pour le traitement.

        Returns:
            List[str]: Liste des réponses générées pour chaque message.
        """
        try:
            logger.info(f"Processing batch of {len(messages)} messages...")
            tasks = [self.process_message(user_id, message, language) for message in messages]
            responses = await asyncio.gather(*tasks)
            logger.info("Batch processing completed.")
            return responses
        except Exception as e:
            logger.error(f"Error processing batch: {e}")
            return ["Error processing batch."]

    async def generate_dashboard(self, insights: Dict[str, Dict[str, int]], output_file: str = "dashboard.html") -> str:
        """
        Génère un tableau de bord interactif à partir des données.

        Args:
            insights (Dict[str, Dict[str, int]]): Données d'analyse pour générer un tableau de bord.
            output_file (str): Nom du fichier HTML à générer.

        Returns:
            str: Chemin vers le fichier HTML généré.
        """
        try:
            dashboard_path = self.dashboard_generator.create_dashboard(insights, output_file)
            logger.info(f"Dashboard generated: {dashboard_path}")
            return dashboard_path
        except Exception as e:
            logger.error(f"Error generating dashboard: {e}")
            return ""

    async def organize_and_cluster_data(self, texts: List[str], method: str = "kmeans", **kwargs) -> str:
        """
        Organise et clusterise des textes utilisateur.

        Args:
            texts (List[str]): Liste des textes.
            method (str): Méthode de clustering ('kmeans', 'dbscan', 'hdbscan').
            **kwargs: Paramètres spécifiques à chaque méthode.

        Returns:
            str: Chemin du fichier exporté contenant les clusters.
        """
        try:
            # Générer les embeddings
            embeddings = self.data_organizer.generate_embeddings(texts)

            # Appliquer le clustering
            clustered_data = self.data_organizer.apply_clustering(embeddings, method=method, **kwargs)

            # Exporter les résultats
            export_path = self.data_organizer.export_clusters(clustered_data)
            logger.info(f"Data organized and exported to: {export_path}")
            return export_path
        except Exception as e:
            logger.error(f"Error organizing and clustering data: {e}")
            return ""
        
# Data Organizer
class DataOrganizer:
    """
    Organise, clusterise et visualise des données haute dimension.
    """

    def __init__(self, output_dir: str = "data_output"):
        """
        Initialise le gestionnaire de données.

        Args:
            output_dir (str): Répertoire pour sauvegarder les résultats.
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        logger.info(f"DataOrganizer initialized. Output directory: {output_dir}")

    def apply_clustering(self, embeddings: List[List[float]], method: str = "kmeans", **kwargs) -> pd.DataFrame:
        """
        Applique un clustering sur les embeddings.

        Args:
            embeddings (List[List[float]]): Données haute dimension.
            method (str): Méthode de clustering ('kmeans', 'dbscan', 'hdbscan').
            **kwargs: Paramètres spécifiques pour l'algorithme choisi.

        Returns:
            pd.DataFrame: Résultats du clustering avec colonnes 'Text' et 'Cluster'.
        """
        logger.info(f"Applying clustering with method: {method}...")

        if method == "kmeans":
            n_clusters = kwargs.get("n_clusters", 5)
            cluster_model = KMeans(n_clusters=n_clusters, random_state=42)
        elif method == "dbscan":
            eps = kwargs.get("eps", 0.5)
            min_samples = kwargs.get("min_samples", 5)
            cluster_model = DBSCAN(eps=eps, min_samples=min_samples, metric="cosine")
        elif method == "hdbscan":
            min_cluster_size = kwargs.get("min_cluster_size", 5)
            cluster_model = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)
        else:
            logger.error(f"Unsupported clustering method: {method}")
            raise ValueError(f"Unsupported clustering method: {method}")

        labels = cluster_model.fit_predict(embeddings)
        logger.info(f"Clustering completed. Number of clusters: {len(set(labels)) - (1 if -1 in labels else 0)}")
        return pd.DataFrame({"Embedding": embeddings, "Cluster": labels})

    def reduce_dimensions(self, embeddings: List[List[float]], n_components: int = 2) -> List[List[float]]:
        """
        Réduit les dimensions des embeddings avec UMAP.

        Args:
            embeddings (List[List[float]]): Données haute dimension.
            n_components (int): Nombre de dimensions cibles.

        Returns:
            List[List[float]]: Embeddings réduits.
        """
        logger.info(f"Reducing dimensions to {n_components}D with UMAP...")
        reducer = UMAP(n_neighbors=15, min_dist=0.1, n_components=n_components, random_state=42)
        reduced_embeddings = reducer.fit_transform(embeddings)
        logger.info("Dimension reduction completed.")
        return reduced_embeddings

    def visualize_clusters(self, reduced_embeddings: List[List[float]], labels: List[int]):
        """
        Visualise les clusters dans un graphique 2D.

        Args:
            reduced_embeddings (List[List[float]]): Données réduites en 2D.
            labels (List[int]): Labels des clusters.
        """
        logger.info("Visualizing clusters...")
        plt.figure(figsize=(10, 8))
        plt.scatter(
            [e[0] for e in reduced_embeddings],
            [e[1] for e in reduced_embeddings],
            c=labels,
            cmap="tab10",
            s=10
        )
        plt.title("Cluster Visualization")
        plt.xlabel("UMAP Dim 1")
        plt.ylabel("UMAP Dim 2")
        plt.colorbar()
        plt.show()

    def export_clusters(self, data: pd.DataFrame, file_name: str = "clusters.csv"):
        """
        Exporte les clusters dans un fichier CSV.

        Args:
            data (pd.DataFrame): Données des clusters.
            file_name (str): Nom du fichier exporté.
        """
        file_path = os.path.join(self.output_dir, file_name)
        try:
            data.to_csv(file_path, index=False)
            logger.info(f"Clusters exported to: {file_path}")
        except Exception as e:
            logger.error(f"Error exporting clusters: {e}")

    def process_and_cluster(
        self, embeddings: List[List[float]], method: str = "kmeans", n_components: int = 2, **kwargs
    ) -> Dict[str, Any]:
        """
        Pipeline complet : réduction de dimensions, clustering, et visualisation.

        Args:
            embeddings (List[List[float]]): Données haute dimension.
            method (str): Méthode de clustering.
            n_components (int): Dimensions cibles pour la réduction.

        Returns:
            Dict[str, Any]: Résumé des clusters et chemin du fichier exporté.
        """
        reduced_embeddings = self.reduce_dimensions(embeddings, n_components)
        clustered_data = self.apply_clustering(reduced_embeddings, method, **kwargs)
        labels = clustered_data["Cluster"].tolist()

        # Visualisation
        self.visualize_clusters(reduced_embeddings, labels)

        # Exportation
        export_path = os.path.join(self.output_dir, "clusters.csv")
        self.export_clusters(clustered_data, "clusters.csv")
        return {"clusters": clustered_data["Cluster"].value_counts().to_dict(), "export_path": export_path}

class CacheManager:
    """
    Gère un cache distribué avec Redis et un fallback local.
    """

    def __init__(self, redis_host: str = "localhost", redis_port: int = 6379, cache_dir: str = "cache", ttl: int = 3600):
        """
        Initialise la classe CacheManager.

        Args:
            redis_host (str): Adresse du serveur Redis.
            redis_port (int): Port du serveur Redis.
            cache_dir (str): Répertoire local pour le fallback du cache.
            ttl (int): Temps de vie (en secondes) des entrées dans Redis.
        """
        self.redis = Redis(host=redis_host, port=redis_port, db=0, decode_responses=True)
        self.cache_dir = cache_dir
        self.ttl = ttl
        os.makedirs(cache_dir, exist_ok=True)
        logger.info(f"CacheManager initialized. Redis at {redis_host}:{redis_port}, local fallback in '{cache_dir}'.")

    def redis_available(self) -> bool:
        """
        Vérifie si Redis est disponible.

        Returns:
            bool: True si Redis est accessible, sinon False.
        """
        try:
            self.redis.ping()
            return True
        except Exception as e:
            logger.warning(f"Redis unavailable: {e}")
            return False

    def get_cache(self, key: str) -> Optional[Any]:
        """
        Récupère une valeur du cache.

        Args:
            key (str): Clé de l'entrée dans le cache.

        Returns:
            Optional[Any]: Valeur associée à la clé ou None si non trouvée.
        """
        # Vérifier Redis
        if self.redis_available():
            try:
                value = self.redis.get(key)
                if value:
                    logger.info(f"Cache hit in Redis for key: {key}")
                    return json.loads(value)
            except Exception as e:
                logger.error(f"Error fetching key '{key}' from Redis: {e}")

        # Vérifier le cache local
        file_path = os.path.join(self.cache_dir, f"{key}.json")
        if os.path.exists(file_path):
            try:
                with open(file_path, "r") as file:
                    logger.info(f"Cache hit in local fallback for key: {key}")
                    return json.load(file)
            except Exception as e:
                logger.error(f"Error reading local cache file for key '{key}': {e}")

        logger.info(f"Cache miss for key: {key}")
        return None

    def set_cache(self, key: str, value: Any):
        """
        Ajoute une valeur au cache.

        Args:
            key (str): Clé de l'entrée.
            value (Any): Valeur associée à la clé.
        """
        # Ajouter dans Redis
        if self.redis_available():
            try:
                self.redis.setex(key, self.ttl, json.dumps(value))
                logger.info(f"Cache set in Redis for key: {key}")
            except Exception as e:
                logger.error(f"Error setting key '{key}' in Redis: {e}")

        # Ajouter dans le fallback local
        file_path = os.path.join(self.cache_dir, f"{key}.json")
        try:
            with open(file_path, "w") as file:
                json.dump(value, file)
            logger.info(f"Cache set in local fallback for key: {key}")
        except Exception as e:
            logger.error(f"Error writing local cache file for key '{key}': {e}")

    def delete_cache(self, key: str):
        """
        Supprime une entrée du cache.

        Args:
            key (str): Clé de l'entrée à supprimer.
        """
        # Supprimer de Redis
        if self.redis_available():
            try:
                self.redis.delete(key)
                logger.info(f"Cache key '{key}' deleted from Redis.")
            except Exception as e:
                logger.error(f"Error deleting key '{key}' from Redis: {e}")

        # Supprimer du fallback local
        file_path = os.path.join(self.cache_dir, f"{key}.json")
        if os.path.exists(file_path):
            try:
                os.remove(file_path)
                logger.info(f"Cache file '{key}.json' deleted from local fallback.")
            except Exception as e:
                logger.error(f"Error deleting cache file '{key}.json': {e}")

    def clear_cache(self):
        """
        Supprime tout le cache, dans Redis et localement.
        """
        # Effacer Redis
        if self.redis_available():
            try:
                self.redis.flushdb()
                logger.info("All Redis cache cleared.")
            except Exception as e:
                logger.error(f"Error clearing Redis cache: {e}")

        # Effacer le cache local
        try:
            for file in os.listdir(self.cache_dir):
                os.remove(os.path.join(self.cache_dir, file))
            logger.info("All local cache cleared.")
        except Exception as e:
            logger.error(f"Error clearing local cache: {e}")

class ONNXModelWrapper:
    """
    Encapsulation pour les modèles ONNX avec support multi-device et gestion des erreurs.
    """

    def __init__(self, model_path: str, device_preference: str = "auto"):
        """
        Initialise la classe avec un chemin de modèle ONNX.

        Args:
            model_path (str): Chemin vers le fichier ONNX.
            device_preference (str): Préférence de device ('cpu', 'gpu', ou 'auto').
        """
        self.model_path = model_path
        self.device = self._select_device(device_preference)
        self.session = ort.InferenceSession(model_path, providers=[self.device])
        self.input_metadata = {input.name: input.shape for input in self.session.get_inputs()}
        self.output_metadata = {output.name: output.shape for output in self.session.get_outputs()}
        logger.info(f"Model loaded from {model_path} on device: {self.device}")

    def _select_device(self, preference: str) -> str:
        """
        Sélectionne le device en fonction de la préférence et de la disponibilité.

        Args:
            preference (str): Préférence de device ('cpu', 'gpu', ou 'auto').

        Returns:
            str: Device sélectionné.
        """
        if preference == "gpu" or (preference == "auto" and ort.get_device() == "GPU"):
            return "CUDAExecutionProvider"
        return "CPUExecutionProvider"

    def validate_input(self, input_data: Dict[str, Any]) -> bool:
        """
        Valide les données d'entrée pour le modèle ONNX.

        Args:
            input_data (Dict[str, Any]): Données d'entrée.

        Returns:
            bool: True si les données sont valides, sinon False.
        """
        for key, value in input_data.items():
            if key not in self.input_metadata:
                logger.error(f"Invalid input key: {key}. Expected keys: {list(self.input_metadata.keys())}")
                return False
            if len(value.shape) != len(self.input_metadata[key]):
                logger.error(f"Shape mismatch for input '{key}': {value.shape} != {self.input_metadata[key]}")
                return False
        logger.info("Input validation passed.")
        return True

    def predict(self, input_data: Dict[str, Any]) -> List[Any]:
        """
        Effectue une prédiction avec le modèle ONNX.

        Args:
            input_data (Dict[str, Any]): Données d'entrée au modèle.

        Returns:
            List[Any]: Résultats de la prédiction.
        """
        if not self.validate_input(input_data):
            raise ValueError("Invalid input data provided.")

        try:
            logger.info(f"Running inference on model: {self.model_path}")
            outputs = self.session.run(None, input_data)
            logger.info("Inference completed successfully.")
            return outputs
        except Exception as e:
            logger.error(f"Error during inference: {e}")
            return []

    def get_model_metadata(self) -> Dict[str, Any]:
        """
        Récupère les métadonnées du modèle ONNX.

        Returns:
            Dict[str, Any]: Métadonnées incluant les entrées et sorties.
        """
        metadata = {
            "inputs": self.input_metadata,
            "outputs": self.output_metadata,
        }
        logger.info(f"Model metadata: {metadata}")
        return metadata

    def warmup(self, sample_input: Dict[str, Any]):
        """
        Réalise une pré-exécution pour réduire la latence initiale.

        Args:
            sample_input (Dict[str, Any]): Exemple de données d'entrée.
        """
        try:
            logger.info("Warming up ONNX model...")
            self.predict(sample_input)
            logger.info("Warmup completed successfully.")
        except Exception as e:
            logger.error(f"Error during warmup: {e}")





class DashboardGenerator:
    """
    Générateur de dashboards interactifs avec des graphiques personnalisés, dynamiques et flexibles.
    """

    def __init__(self, output_dir: str = "dashboards", template: str = "plotly_white"):
        """
        Initialise le générateur de dashboards.

        Args:
            output_dir (str): Répertoire pour sauvegarder les fichiers de dashboards.
            template (str): Thème par défaut pour les graphiques (Plotly template).
        """
        self.output_dir = output_dir
        self.template = template
        os.makedirs(self.output_dir, exist_ok=True)
        logger.info(f"DashboardGenerator initialized. Output directory: {output_dir}")

    def create_bar_chart(
            self,
            data: Dict[str, Union[int, float]],
            title: str = "Bar Chart",
            xaxis_title: str = "Categories",
            yaxis_title: str = "Values",
    ) -> go.Figure:
        """
        Crée un graphique en barres.

        Args:
            data (Dict[str, Union[int, float]]): Données sous forme de {catégorie: valeur}.
            title (str): Titre du graphique.
            xaxis_title (str): Titre de l'axe X.
            yaxis_title (str): Titre de l'axe Y.

        Returns:
            go.Figure: Graphique Plotly interactif.
        """
        if not isinstance(data, dict) or not data:
            raise ValueError("Les données pour le bar chart doivent être un dictionnaire non vide.")

        try:
            fig = go.Figure()
            fig.add_trace(go.Bar(x=list(data.keys()), y=list(data.values())))
            fig.update_layout(
                title=title,
                xaxis_title=xaxis_title,
                yaxis_title=yaxis_title,
                template=self.template,
            )
            logger.info(f"Bar chart created with title: {title}")
            return fig
        except Exception as e:
            logger.error(f"Error creating bar chart: {e}")
            raise

    def create_scatter_plot(
            self,
            x: List[float],
            y: List[float],
            labels: Optional[List[str]] = None,
            title: str = "Scatter Plot",
            xaxis_title: str = "X-axis",
            yaxis_title: str = "Y-axis",
            marker_size: int = 10,
            color: Optional[List[str]] = None,
    ) -> go.Figure:
        """
        Crée un nuage de points interactif.

        Args:
            x (List[float]): Coordonnées X.
            y (List[float]): Coordonnées Y.
            labels (Optional[List[str]]): Labels pour les points.
            title (str): Titre du graphique.
            xaxis_title (str): Titre de l'axe X.
            yaxis_title (str): Titre de l'axe Y.
            marker_size (int): Taille des marqueurs.
            color (Optional[List[str]]): Couleurs des points.

        Returns:
            go.Figure: Graphique Plotly interactif.
        """
        if not x or not y or len(x) != len(y):
            raise ValueError("Les listes X et Y doivent être non vides et de même longueur.")

        try:
            fig = go.Figure(
                data=go.Scatter(
                    x=x,
                    y=y,
                    mode="markers",
                    text=labels,
                    marker=dict(size=marker_size, color=color, showscale=True),
                )
            )
            fig.update_layout(
                title=title,
                xaxis_title=xaxis_title,
                yaxis_title=yaxis_title,
                template=self.template,
            )
            logger.info(f"Scatter plot created with title: {title}")
            return fig
        except Exception as e:
            logger.error(f"Error creating scatter plot: {e}")
            raise

    def create_dashboard(
            self,
            insights: Dict[str, go.Figure],
            output_file: str = "dashboard.html",
            rows: Optional[int] = None,
            cols: Optional[int] = None,
    ) -> str:
        """
        Génère un dashboard interactif à partir d'un ensemble de graphiques.

        Args:
            insights (Dict[str, go.Figure]): Dictionnaire de graphiques {titre: figure}.
            output_file (str): Nom du fichier HTML à générer.
            rows (Optional[int]): Nombre de lignes dans la disposition (optionnel).
            cols (Optional[int]): Nombre de colonnes dans la disposition (optionnel).

        Returns:
            str: Chemin du fichier HTML généré.
        """
        if not insights or not isinstance(insights, dict):
            raise ValueError("Les insights doivent être un dictionnaire non vide.")
        if rows is None or cols is None:
            rows, cols = self._auto_layout(len(insights))

        try:
            fig = make_subplots(
                rows=rows,
                cols=cols,
                subplot_titles=list(insights.keys()),
                horizontal_spacing=0.2,
                vertical_spacing=0.2,
            )

            for idx, (chart_title, chart_fig) in enumerate(insights.items()):
                row = idx // cols + 1
                col = idx % cols + 1
                for trace in chart_fig.data:
                    fig.add_trace(trace, row=row, col=col)

            fig.update_layout(
                title="Interactive Dashboard",
                template=self.template,
                showlegend=False,
                height=600 * rows,  # Dynamically scale height
            )

            file_path = os.path.join(self.output_dir, output_file)
            fig.write_html(file_path)
            logger.info(f"Dashboard generated and saved to: {file_path}")
            return file_path
        except Exception as e:
            logger.error(f"Error generating dashboard: {e}")
            raise

    def save_figure(self, fig: go.Figure, file_name: str):
        """
        Sauvegarde un graphique interactif au format HTML.

        Args:
            fig (go.Figure): Graphique Plotly.
            file_name (str): Nom du fichier HTML à sauvegarder.
        """
        if not isinstance(fig, go.Figure):
            raise ValueError("L'objet fig doit être une instance de plotly.graph_objects.Figure.")

        try:
            file_path = os.path.join(self.output_dir, file_name)
            fig.write_html(file_path)
            logger.info(f"Figure saved to: {file_path}")
        except Exception as e:
            logger.error(f"Error saving figure: {e}")
            raise

    @staticmethod
    def _auto_layout(num_charts: int) -> (int, int):
        """
        Calcule une disposition automatique pour les graphiques.

        Args:
            num_charts (int): Nombre total de graphiques.

        Returns:
            (int, int): Nombre de lignes et de colonnes.
        """
        import math
        cols = math.ceil(math.sqrt(num_charts))
        rows = math.ceil(num_charts / cols)
        return rows, cols


class LoggerService:
    """
    Gère la configuration et l'utilisation centralisée des logs.
    """

    @staticmethod
    def configure_logger(name: str, log_file: str = "system.log", level: int = logging.INFO):
        """
        Configure le logger.

        Args:
            name (str): Nom du logger.
            log_file (str): Fichier de log.
            level (int): Niveau de logging.
        """
        logger = logging.getLogger(name)
        logger.setLevel(level)
        file_handler = logging.FileHandler(log_file)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
        logger.info(f"Logger '{name}' configuré avec succès.")
        return logger
class SecureAISystem:
    """
    Système AI sécurisé avec chiffrement AES et suppression conforme RGPD.
    """

    def __init__(self, encryption_key: str = None, db_manager=None):
        """
        Initialise le système AI sécurisé.

        Args:
            encryption_key (str): Clé AES pour le chiffrement.
            db_manager: Gestionnaire de base de données (MongoDB, PostgreSQL).
        """
        self.encryption_key = self._derive_key(encryption_key or os.getenv("SECURE_AI_KEY", "default_secure_key"))
        self.db_manager = db_manager
        logger.info("SecureAISystem initialized with encryption and secure data management.")

    def _derive_key(self, passphrase: str) -> bytes:
        """
        Génére une clé AES à partir d'une passphrase.

        Args:
            passphrase (str): Passphrase utilisée pour générer la clé.

        Returns:
            bytes: Clé dérivée.
        """
        salt = b"secure_salt"
        kdf = PBKDF2HMAC(
            algorithm=hashes.SHA256(),
            length=32,
            salt=salt,
            iterations=100000,
            backend=default_backend()
        )
        return base64.urlsafe_b64encode(kdf.derive(passphrase.encode()))

    def encrypt_data(self, data: str) -> str:
        """
        Chiffre une chaîne de caractères.

        Args:
            data (str): Données à chiffrer.

        Returns:
            str: Données chiffrées en base64.
        """
        iv = os.urandom(16)
        cipher = Cipher(algorithms.AES(self.encryption_key), modes.CFB(iv), backend=default_backend())
        encryptor = cipher.encryptor()
        encrypted_data = encryptor.update(data.encode()) + encryptor.finalize()
        return base64.b64encode(iv + encrypted_data).decode()

    def decrypt_data(self, encrypted_data: str) -> str:
        """
        Déchiffre une chaîne de caractères.

        Args:
            encrypted_data (str): Données chiffrées en base64.

        Returns:
            str: Données déchiffrées.
        """
        encrypted_bytes = base64.b64decode(encrypted_data)
        iv = encrypted_bytes[:16]
        cipher = Cipher(algorithms.AES(self.encryption_key), modes.CFB(iv), backend=default_backend())
        decryptor = cipher.decryptor()
        decrypted_data = decryptor.update(encrypted_bytes[16:]) + decryptor.finalize()
        return decrypted_data.decode()

    async def save_interaction(self, user_id: str, message: str, response: str, metadata: Dict[str, Any] = None):
        """
        Sauvegarde une interaction utilisateur avec chiffrement.

        Args:
            user_id (str): ID utilisateur.
            message (str): Message utilisateur.
            response (str): Réponse générée.
            metadata (Dict[str, Any]): Métadonnées supplémentaires.
        """
        try:
            encrypted_message = self.encrypt_data(message)
            encrypted_response = self.encrypt_data(response)
            metadata = metadata or {}
            metadata.update({"timestamp": asyncio.get_event_loop().time()})

            await self.db_manager.save_interaction(user_id, encrypted_message, encrypted_response, metadata)
            logger.info(f"Encrypted interaction saved for user: {user_id}")
        except Exception as e:
            logger.error(f"Error saving interaction: {e}")

    async def fetch_interactions(self, user_id: str) -> Dict[str, Any]:
        """
        Récupère et déchiffre les interactions utilisateur.

        Args:
            user_id (str): ID utilisateur.

        Returns:
            Dict[str, Any]: Interactions déchiffrées.
        """
        try:
            interactions = await self.db_manager.fetch_interactions(user_id)
            for interaction in interactions:
                interaction["message"] = self.decrypt_data(interaction["message"])
                interaction["response"] = self.decrypt_data(interaction["response"])
            logger.info(f"Fetched {len(interactions)} interactions for user: {user_id}")
            return interactions
        except Exception as e:
            logger.error(f"Error fetching interactions: {e}")
            return []

    async def delete_user_data(self, user_id: str):
        """
        Supprime toutes les données associées à un utilisateur.

        Args:
            user_id (str): ID utilisateur.
        """
        try:
            await self.db_manager.delete_user_data(user_id)
            logger.info(f"All data deleted for user: {user_id}")
        except Exception as e:
            logger.error(f"Error deleting user data: {e}")


class NextGenAISystem:
    """
    Système AI avancé avec gestion multi-base, NLP, clustering et visualisation.
    """

    def __init__(self, use_postgres: bool = False, embedding_model: str = "all-MiniLM-L6-v2"):
        """
        Initialise le système AI de nouvelle génération.

        Args:
            use_postgres (bool): Définit si PostgreSQL doit être utilisé.
            embedding_model (str): Modèle SentenceTransformers pour les embeddings.
        """
        self.db_manager = (
            PostgreSQLManager(db_name="nextgen_ai", user="postgres", password="securepassword")
            if use_postgres
            else MongoDBManager(db_name="nextgen_ai")
        )
        self.nlp_processor = NLPProcessor(embedding_model=embedding_model)
        self.sentiment_analyzer = SentimentAnalyzer()
        self.data_organizer = DataOrganizer()
        self.dashboard_generator = DashboardGenerator()
        self.models = {
            "sentiment": ONNXModelWrapper("sentiment_model.onnx"),
            "intent": ONNXModelWrapper("intent_classification.onnx"),
        }
        logger.info("NextGenAISystem initialized.")

    async def process_message(self, user_id: str, user_message: str, language: str = "auto") -> Dict[str, Any]:
        """
        Traite un message utilisateur avec NLP et modèles ONNX.

        Args:
            user_id (str): ID utilisateur.
            user_message (str): Message envoyé par l'utilisateur.
            language (str): Langue cible (détectée automatiquement si "auto").

        Returns:
            Dict[str, Any]: Résultats du traitement (sentiment, intent, réponse).
        """
        try:
            logger.info(f"Processing message for user {user_id}...")

            # Prétraitement du texte
            preprocessed_message = self.nlp_processor.preprocess_text(user_message, target_language="en")

            # Analyse de sentiment avec ONNX
            sentiment_result = self.models["sentiment"].predict({"input_text": preprocessed_message})
            sentiment_label = "positive" if sentiment_result[0] > 0.5 else "negative"

            # Classification d'intention
            intent_result = self.models["intent"].predict({"input_text": preprocessed_message})
            intent_label = "greeting" if intent_result[0] > 0.5 else "request"

            # Réponse générée
            response = (
                f"Sentiment: {sentiment_label} (Confidence: {sentiment_result[0]:.2f}), "
                f"Intent: {intent_label}."
            )

            # Sauvegarder l'interaction
            metadata = {
                "sentiment": {"label": sentiment_label, "confidence": sentiment_result[0]},
                "intent": {"label": intent_label, "confidence": intent_result[0]},
            }
            await self.db_manager.save_interaction(user_id, user_message, response, metadata)
            logger.info(f"Message processed for user {user_id}.")
            return {"response": response, "sentiment": sentiment_label, "intent": intent_label}
        except Exception as e:
            logger.error(f"Error processing message for user {user_id}: {e}")
            return {"response": "Error occurred.", "sentiment": None, "intent": None}

    async def process_batch(self, user_id: str, messages: List[str]) -> List[Dict[str, Any]]:
        """
        Traite un lot de messages utilisateur.

        Args:
            user_id (str): ID utilisateur.
            messages (List[str]): Liste des messages utilisateur.

        Returns:
            List[Dict[str, Any]]: Résultats pour chaque message.
        """
        try:
            logger.info(f"Processing batch for user {user_id}...")
            tasks = [self.process_message(user_id, message) for message in messages]
            results = await asyncio.gather(*tasks)
            logger.info(f"Batch processing completed for user {user_id}.")
            return results
        except Exception as e:
            logger.error(f"Error processing batch for user {user_id}: {e}")
            return []

    async def generate_dashboard(self, user_id: str) -> str:
        """
        Génère un tableau de bord des interactions utilisateur.

        Args:
            user_id (str): ID utilisateur.

        Returns:
            str: Chemin vers le tableau de bord HTML généré.
        """
        try:
            interactions = await self.db_manager.fetch_interactions(user_id)
            sentiment_summary = {}
            for interaction in interactions:
                sentiment = interaction["metadata"].get("sentiment", {}).get("label", "unknown")
                sentiment_summary[sentiment] = sentiment_summary.get(sentiment, 0) + 1

            dashboard_path = self.dashboard_generator.generate_sentiment_dashboard(
                sentiment_summary, output_file=f"{user_id}_dashboard.html"
            )
            logger.info(f"Dashboard generated for user {user_id}.")
            return dashboard_path
        except Exception as e:
            logger.error(f"Error generating dashboard for user {user_id}: {e}")
            return ""


class EmotionContextualizer(Action):
    def name(self) -> str:
        return "action_emotion_contextualizer"

    def __init__(self):
        # Historique des émotions, indexé par utilisateur
        self.emotion_history = defaultdict(list)

    def detect_emotion(self, user_message: str) -> str:
        """
        Détection simple d'émotions basée sur des mots-clés.
        À remplacer par un modèle NLP si nécessaire.
        """
        if any(word in user_message for word in ["bien", "heureux", "joyeux"]):
            return "positif"
        elif any(word in user_message for word in ["triste", "fatigué", "stressé"]):
            return "négatif"
        else:
            return "neutre"

    def calculate_trend(self, emotions: List[str]) -> str:
        """
        Analyse la tendance des émotions sur les 5 derniers messages.
        """
        recent_emotions = emotions[-5:]  # Derniers 5 messages
        positive_count = recent_emotions.count("positif")
        negative_count = recent_emotions.count("négatif")

        if positive_count > 3:
            return "tendance positive"
        elif negative_count > 3:
            return "tendance négative"
        else:
            return "tendance équilibrée"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        user_id = tracker.sender_id
        user_message = tracker.latest_message.get("text")

        # Étape 1 : Détecter l'émotion actuelle
        current_emotion = self.detect_emotion(user_message)
        self.emotion_history[user_id].append(current_emotion)

        # Étape 2 : Calculer la tendance
        trend = self.calculate_trend(self.emotion_history[user_id])

        # Étape 3 : Répondre en fonction de la tendance
        if trend == "tendance positive":
            dispatcher.utter_message(text="Vous semblez dans une belle énergie ! Continuons comme ça. 😊")
        elif trend == "tendance négative":
            dispatcher.utter_message(text="Je ressens un peu de tension dans nos échanges. Puis-je vous aider à alléger cela ? 😔")
        else:
            dispatcher.utter_message(text="Votre état émotionnel est assez équilibré. Continuons notre conversation. 😌")

        # Optionnel : Stocker la tendance dans un slot
        return [SlotSet("emotion_trend", trend)]

class EthicalDecisionAdvisor(Action):
    def name(self) -> str:
        return "action_ethical_decision_advisor"

    def __init__(self):
        # Grille éthique : Actions acceptées ou refusées
        self.ethical_rules = {
            "action_share_sensitive_data": False,
            "action_encrypt_sensitive_data": True,
            "action_advanced_sentiment_analysis": True,
            "action_generate_audio_response": True,
        }

    def evaluate_action(self, action_name: str) -> bool:
        """
        Évalue si une action est autorisée selon la grille éthique.
        """
        return self.ethical_rules.get(action_name, True)  # Par défaut : accepté

    def explain_decision(self, action_name: str) -> str:
        """
        Donne une explication claire de la décision.
        """
        if not self.ethical_rules.get(action_name, True):
            return f"L'action '{action_name}' a été rejetée car elle pourrait violer les principes éthiques (ex. : vie privée, sécurité)."
        return f"L'action '{action_name}' est approuvée conformément à nos règles éthiques."

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Obtenir l'action demandée depuis le slot
        requested_action = tracker.get_slot("requested_action")

        if not requested_action:
            dispatcher.utter_message(text="Aucune action n'a été demandée.")
            return []

        # Étape 1 : Évaluer l'action demandée
        is_ethical = self.evaluate_action(requested_action)

        # Étape 2 : Fournir une explication
        explanation = self.explain_decision(requested_action)
        dispatcher.utter_message(text=explanation)

        # Optionnel : Marquer l'action comme refusée dans un slot
        return [SlotSet("is_action_ethical", is_ethical)]

class PersonalizedMindfulnessAssistant(Action):
    def name(self) -> str:
        return "action_personalized_mindfulness"

    def suggest_exercise(self, emotion: str) -> str:
        """
        Propose un exercice de pleine conscience basé sur l'émotion détectée.
        """
        exercises = {
            "stress": "Prenez un moment pour respirer profondément : inspirez 4 secondes, retenez votre souffle 4 secondes, puis expirez lentement pendant 4 secondes. Répétez cela 5 fois.",
            "positif": "Prenez un moment pour réfléchir à ce qui vous rend heureux aujourd'hui. Écrivez-le si vous le souhaitez. 😊",
            "négatif": "Essayez cet exercice de visualisation : imaginez un endroit paisible où vous vous sentez en sécurité et détendu, comme une plage ou une forêt.",
            "neutre": "Faites une pause d'une minute en fermant les yeux. Concentrez-vous sur les sons autour de vous et laissez vos pensées passer sans jugement.",
        }
        return exercises.get(emotion, "Prenez une pause et buvez un verre d'eau pour vous recentrer.")

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer l'émotion détectée
        emotion = tracker.get_slot("emotion") or "neutre"  # Par défaut : neutre

        # Proposer un exercice basé sur l'émotion
        exercise = self.suggest_exercise(emotion)
        dispatcher.utter_message(text=exercise)

        # Retourner un slot avec l'exercice proposé
        return [SlotSet("suggested_exercise", exercise)]

class AI_EmpathyEnhancer(Action):
    def name(self) -> str:
        return "action_empathy_enhancer"

    def generate_empathic_response(self, user_message: str) -> str:
        """
        Génère une réponse empathique basée sur le message de l'utilisateur.
        """
        if any(word in user_message for word in ["fatigué", "stressé", "triste"]):
            return "Je comprends que cela peut être difficile. Prenez un moment pour vous détendre, je suis là pour vous aider. 🌿"
        elif any(word in user_message for word in ["heureux", "joyeux", "bien"]):
            return "C'est génial à entendre ! Continuons sur cette belle énergie. 😊"
        elif any(word in user_message for word in ["colère", "énervé"]):
            return "Je vois que vous êtes contrarié. Souhaitez-vous que je vous aide à résoudre ce problème ? 😔"
        else:
            return "Merci de partager cela avec moi. Je suis là pour rendre les choses plus faciles pour vous. 😌"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer le dernier message de l'utilisateur
        user_message = tracker.latest_message.get("text")

        # Générer une réponse empathique
        response = self.generate_empathic_response(user_message)

        # Envoyer la réponse à l'utilisateur
        dispatcher.utter_message(text=response)

        # Pas de slots mis à jour, retour vide
        return []

class DynamicClusterVisualizer(Action):
    def name(self) -> str:
        return "action_dynamic_cluster_visualizer"

    def generate_cluster_plot(self, clusters: Dict[str, List[str]]) -> str:
        """
        Génère un graphique représentant les clusters.
        Retourne une image encodée en base64 pour un affichage direct.
        """
        try:
            # Initialisation du graphique
            fig, ax = plt.subplots(figsize=(8, 6))

            # Couleurs et styles
            colors = ['red', 'blue', 'green', 'orange', 'purple']
            markers = ['o', 's', 'D', '^', 'v']

            for i, (cluster_label, items) in enumerate(clusters.items()):
                x = [i] * len(items)
                y = list(range(len(items)))
                ax.scatter(x, y, label=cluster_label, color=colors[i % len(colors)], marker=markers[i % len(markers)])
                for j, item in enumerate(items):
                    ax.text(i, j, item, fontsize=9, ha='right')

            # Ajout des labels et du titre
            ax.set_title("Visualisation des Clusters")
            ax.set_xticks(range(len(clusters)))
            ax.set_xticklabels(clusters.keys())
            ax.set_xlabel("Clusters")
            ax.set_ylabel("Éléments")
            ax.legend()

            # Conversion en image base64
            buf = io.BytesIO()
            plt.savefig(buf, format="png")
            buf.seek(0)
            image_base64 = base64.b64encode(buf.read()).decode('utf-8')
            buf.close()
            plt.close(fig)

            return f"data:image/png;base64,{image_base64}"
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la génération du graphique : {e}")

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de clusters (à remplacer par vos données)
        clusters = {
            "Cluster 1": ["Élément A", "Élément B", "Élément C"],
            "Cluster 2": ["Élément D", "Élément E"],
            "Cluster 3": ["Élément F", "Élément G", "Élément H", "Élément I"]
        }

        try:
            # Générer le graphique
            image_base64 = self.generate_cluster_plot(clusters)

            # Envoyer le graphique à l'utilisateur
            dispatcher.utter_message(text="Voici la visualisation des clusters générée :", image=image_base64)

            # Mettre à jour un slot avec les clusters pour un suivi
            return [SlotSet("cluster_data", clusters)]
        except Exception as e:
            dispatcher.utter_message(text=f"Je n'ai pas pu générer le graphique en raison de l'erreur suivante : {e}")
            return []

class ActionTrainAndOptimizeModel(Action):
    def name(self) -> str:
        return "action_train_and_optimize_model"

    def train_and_optimize(self, X: np.ndarray, y: np.ndarray) -> Dict[str, Any]:
        """
        Entraîne et optimise un modèle RandomForestClassifier avec GridSearchCV.

        Args:
            X (np.ndarray): Caractéristiques d'entrée.
            y (np.ndarray): Cibles associées.

        Returns:
            Dict[str, Any]: Modèle optimisé, meilleurs paramètres et score associé.
        """
        try:
            logger.info("Démarrage de l'entraînement et de l'optimisation du modèle.")

            # Définir les hyperparamètres à tester
            param_grid = {
                'n_estimators': [50, 100, 200],
                'max_depth': [None, 10, 20],
                'min_samples_split': [2, 5, 10]
            }

            # Instancier le modèle et GridSearch
            model = RandomForestClassifier(random_state=42)
            grid_search = GridSearchCV(
                estimator=model,
                param_grid=param_grid,
                cv=5,
                scoring='accuracy',
                n_jobs=-1,
                verbose=1
            )

            # Optimiser le modèle
            grid_search.fit(X, y)

            best_model = grid_search.best_estimator_
            best_params = grid_search.best_params_
            best_score = grid_search.best_score_

            logger.info(f"Optimisation réussie. Meilleurs paramètres : {best_params}. Score : {best_score:.4f}")

            return {
                "model": best_model,
                "best_params": best_params,
                "best_score": best_score
            }

        except ValueError as ve:
            logger.error(f"Erreur dans les données fournies : {ve}")
            raise ValueError("Vérifiez les dimensions et la validité des données d'entrée.")
        except Exception as e:
            logger.error(f"Erreur lors de l'optimisation du modèle : {e}")
            raise RuntimeError("Impossible d'optimiser le modèle.")

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        """
        Exécute l'action pour entraîner et optimiser un modèle.

        Args:
            dispatcher: Pour envoyer des messages à l'utilisateur.
            tracker: Suivi de l'état de la conversation.
            domain: Domaine de l'application.

        Returns:
            List[Dict[str, Any]]: Slots mis à jour avec les meilleurs paramètres et score.
        """
        try:
            # Simulation de données utilisateur (à remplacer par des données réelles)
            X = np.random.rand(100, 5)  # 100 échantillons, 5 caractéristiques
            y = np.random.choice([0, 1], size=100)  # Classes binaires

            logger.info("Données générées pour le modèle.")

            # Entraîner et optimiser le modèle
            optimization_result = self.train_and_optimize(X, y)

            # Préparer la réponse
            best_params = optimization_result["best_params"]
            best_score = optimization_result["best_score"]

            response = (
                f"Modèle entraîné avec succès ! 🎉\n"
                f"Meilleurs hyperparamètres : {best_params}\n"
                f"Meilleure précision obtenue : {best_score:.2f}"
            )
            dispatcher.utter_message(text=response)

            # Sauvegarde du modèle optimisé pour réutilisation
            with open("best_random_forest_model.pkl", "wb") as f:
                pickle.dump(optimization_result["model"], f)
            logger.info("Modèle optimisé sauvegardé sous 'best_random_forest_model.pkl'.")

            # Retourner les paramètres pour usage futur
            return [
                SlotSet("best_model_params", best_params),
                SlotSet("best_model_score", best_score)
            ]

        except Exception as e:
            logger.error(f"Erreur lors de l'exécution de l'action : {e}")
            dispatcher.utter_message(text=f"Une erreur est survenue lors de l'entraînement du modèle : {e}")
            return []

class AdaptiveUserInsightsManager(Action):
    def name(self) -> str:
        return "action_adaptive_user_insights_manager"

    def analyze_behavior(self, user_message: str) -> str:
        """
        Analyse le message utilisateur pour détecter des besoins implicites.
        """
        if "?" in user_message or "aide" in user_message:
            return "hésitation"
        elif any(word in user_message for word in ["urgent", "vite", "immédiat"]):
            return "besoin immédiat"
        elif any(word in user_message for word in ["merci", "parfait", "cool"]):
            return "satisfaction"
        else:
            return "neutre"

    def generate_recommendation(self, behavior: str) -> str:
        """
        Génère une recommandation basée sur le comportement détecté.
        """
        recommendations = {
            "hésitation": [
                "Souhaitez-vous que je vous explique cela plus en détail ? 😊",
                "Je peux vous guider pas à pas si vous le souhaitez."
            ],
            "besoin immédiat": [
                "D'accord, je vais traiter cela tout de suite pour vous. 🚀",
                "Je m'en charge immédiatement, restez détendu !"
            ],
            "satisfaction": [
                "Merci pour votre retour positif, ça me motive à continuer à vous aider. 😄",
                "Je suis ravi que tout se passe bien. Continuons comme ça !"
            ],
            "neutre": [
                "Comment puis-je vous aider davantage ?",
                "N'hésitez pas à poser une question ou à demander une assistance."
            ]
        }
        return random.choice(recommendations.get(behavior, ["Je suis là pour vous aider."]))

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer le dernier message utilisateur
        user_message = tracker.latest_message.get("text")

        try:
            # Analyse du comportement
            detected_behavior = self.analyze_behavior(user_message)
            logger.info(f"Comportement détecté : {detected_behavior}")

            # Génération de recommandation
            recommendation = self.generate_recommendation(detected_behavior)

            # Réponse au message utilisateur
            dispatcher.utter_message(text=recommendation)

            # Optionnel : enregistrer les insights dans un slot
            return [SlotSet("detected_behavior", detected_behavior)]
        except Exception as e:
            logger.error(f"Erreur lors de l'analyse du comportement : {e}")
            dispatcher.utter_message(text="Je n'ai pas pu analyser votre demande, désolé.")
            return []

class ActionRealTimeSuggestions(Action):
    def name(self) -> str:
        return "action_real_time_suggestions"

    def suggest_action(self, user_data: Dict[str, Any]) -> str:
        """
        Génère une suggestion d'action basée sur les données utilisateur.
        """
        # Exemple de logique basée sur les données utilisateur
        if user_data.get("frequent_intent") == "order_pizza":
            return "Souhaitez-vous commander une pizza à nouveau ? 🍕"
        elif user_data.get("last_emotion") == "stress":
            return "Vous semblez stressé récemment. Puis-je vous proposer un exercice de relaxation ? 🌿"
        elif user_data.get("frequent_intent") == "check_balance":
            return "Voulez-vous vérifier votre solde bancaire à nouveau ? 💰"
        else:
            return "Puis-je vous aider avec quelque chose de spécifique ? 😊"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer les données utilisateur depuis les slots
        user_data = {
            "frequent_intent": tracker.get_slot("frequent_intent"),
            "last_emotion": tracker.get_slot("last_emotion"),
        }

        # Générer une suggestion
        try:
            suggestion = self.suggest_action(user_data)
            logger.info(f"Suggestion générée : {suggestion}")

            # Envoyer la suggestion à l'utilisateur
            dispatcher.utter_message(text=suggestion)

            # Retourner les données mises à jour si nécessaire
            return [SlotSet("last_suggestion", suggestion)]
        except Exception as e:
            logger.error(f"Erreur lors de la génération de suggestion : {e}")
            dispatcher.utter_message(text="Je n'ai pas pu générer une suggestion, désolé.")
            return []

class ExistencePhilosopher(Action):
    def name(self) -> str:
        return "action_existence_philosopher"

    def generate_philosophical_response(self, user_message: str) -> str:
        """
        Analyse le message utilisateur et retourne une réponse philosophique.
        """
        # Réponses basées sur des thèmes philosophiques
        existential_themes = {
            "sens": [
                "Le sens de la vie n’est pas une réponse universelle, mais une quête personnelle. Quelle est votre quête ?",
                "Peut-être que le sens est simplement ce que nous créons à travers nos actions et nos relations."
            ],
            "bonheur": [
                "Le bonheur est souvent trouvé dans les petites choses. Quel moment récent vous a fait sourire ?",
                "Pensez-vous que le bonheur est un objectif, ou une manière de voyager ?"
            ],
            "choix": [
                "Faire un choix peut être difficile, mais chaque décision ouvre une nouvelle porte. Quelle porte voulez-vous ouvrir ?",
                "Même ne pas choisir est un choix en soi. Quelle est votre réflexion sur cela ?"
            ],
            "éthique": [
                "L’éthique est la lumière qui guide nos actions. Pensez-vous que vos décisions reflètent vos valeurs profondes ?",
                "Agir avec éthique, c’est choisir ce qui est juste, même lorsque personne ne regarde. Qu’en pensez-vous ?"
            ]
        }

        # Identifier le thème du message utilisateur
        if any(word in user_message.lower() for word in ["sens", "vie", "objectif"]):
            theme = "sens"
        elif any(word in user_message.lower() for word in ["bonheur", "heureux"]):
            theme = "bonheur"
        elif any(word in user_message.lower() for word in ["choix", "décision"]):
            theme = "choix"
        elif any(word in user_message.lower() for word in ["éthique", "morale"]):
            theme = "éthique"
        else:
            return "La philosophie est vaste. Quelle question avez-vous en tête ?"

        # Choisir une réponse aléatoire dans le thème
        return random.choice(existential_themes[theme])

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer le dernier message utilisateur
        user_message = tracker.latest_message.get("text")

        # Générer une réponse philosophique
        response = self.generate_philosophical_response(user_message)

        # Envoyer la réponse à l'utilisateur
        dispatcher.utter_message(text=response)

        # Pas de mise à jour de slot nécessaire
        return []




class TextSummaryOptimizer(Action):
    def name(self) -> str:
        return "action_text_summary_optimizer"

    def summarize_text(self, text: str) -> str:
        """
        Résume un texte en utilisant un modèle NLP de résumé.
        """
        try:
            summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
            summary = summarizer(text, max_length=50, min_length=25, do_sample=False)
            return summary[0]["summary_text"]
        except Exception as e:
            return f"Erreur lors du résumé : {str(e)}"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        user_text = tracker.latest_message.get("text")
        if not user_text or len(user_text.split()) < 30:
            dispatcher.utter_message(
                text="Votre texte est trop court pour être résumé. Veuillez fournir un texte plus long."
            )
            return []
        summary = self.summarize_text(user_text)
        dispatcher.utter_message(text=f"Voici un résumé de votre texte :\n\n{summary}")
        return []


class ConversationalParaphraser(Action):
    def name(self) -> str:
        return "action_conversational_paraphraser"

    def paraphrase_text(self, text: str, tone: str = "neutral") -> str:
        """
        Reformule un texte avec un modèle NLP, ajustant le ton si nécessaire.
        """
        try:
            # Charger un pipeline de reformulation
            paraphraser = pipeline("text2text-generation", model="t5-small")

            # Préparer la commande pour ajuster le ton
            if tone == "friendly":
                command = f"paraphrase: {text} in a friendly tone"
            elif tone == "formal":
                command = f"paraphrase: {text} in a formal tone"
            else:
                command = f"paraphrase: {text}"

            # Générer le texte reformulé
            paraphrased_text = paraphraser(command, max_length=50, num_return_sequences=1)
            return paraphrased_text[0]["generated_text"]
        except Exception as e:
            return f"Erreur lors de la reformulation : {str(e)}"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer le texte et le ton depuis les slots ou le dernier message
        user_text = tracker.latest_message.get("text")
        tone = tracker.get_slot("tone_preference") or "neutral"

        if not user_text:
            dispatcher.utter_message(text="Je n'ai reçu aucun texte à reformuler.")
            return []

        # Reformuler le texte
        paraphrased_text = self.paraphrase_text(user_text, tone)

        # Répondre à l'utilisateur avec le texte reformulé
        dispatcher.utter_message(text=f"Voici une reformulation de votre message :\n\n{paraphrased_text}")

        # Optionnel : stocker le texte reformulé
        return [SlotSet("paraphrased_text", paraphrased_text)]

class ContextualMemoryArchitect(Action):
    def name(self) -> str:
        return "action_contextual_memory_architect"

    def update_contextual_memory(self, tracker, memory: Dict[str, Any]) -> Dict[str, Any]:
        """
        Met à jour la mémoire contextuelle avec les dernières interactions utilisateur.
        """
        user_message = tracker.latest_message.get("text")
        user_intent = tracker.latest_message.get("intent", {}).get("name", "unknown")
        user_entities = tracker.latest_message.get("entities", [])

        # Mise à jour de la mémoire avec les nouvelles informations
        memory["recent_messages"].append(user_message)
        memory["recent_intents"].append(user_intent)

        for entity in user_entities:
            memory["entities"][entity["entity"]] = entity["value"]

        # Limiter la taille des messages/intents stockés pour éviter une surcharge
        memory["recent_messages"] = memory["recent_messages"][-10:]
        memory["recent_intents"] = memory["recent_intents"][-10:]

        return memory

    def generate_personalized_response(self, memory: Dict[str, Any]) -> str:
        """
        Génère une réponse basée sur la mémoire contextuelle.
        """
        if memory["recent_intents"][-1] == "order_pizza":
            return "Je vois que vous avez commandé une pizza récemment. Souhaitez-vous la même chose ou essayer une nouvelle recette ? 🍕"
        elif memory["recent_intents"][-1] == "check_balance":
            return "Vous avez récemment vérifié votre solde. Puis-je vous aider avec une autre opération bancaire ? 💰"
        elif len(memory["recent_messages"]) > 0 and "merci" in memory["recent_messages"][-1].lower():
            return "De rien ! Je suis toujours là pour vous aider. 😊"
        else:
            return "Je suis ici pour vous aider. Que puis-je faire pour vous ?"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer la mémoire contextuelle depuis un slot
        memory = tracker.get_slot("contextual_memory") or {
            "recent_messages": [],
            "recent_intents": [],
            "entities": {}
        }

        # Mettre à jour la mémoire avec les dernières interactions
        updated_memory = self.update_contextual_memory(tracker, memory)

        # Générer une réponse personnalisée
        personalized_response = self.generate_personalized_response(updated_memory)

        # Envoyer la réponse à l'utilisateur
        dispatcher.utter_message(text=personalized_response)

        # Retourner la mémoire mise à jour pour la conversation future
        return [SlotSet("contextual_memory", updated_memory)]

class MultilingualIntentEnhancer(Action):
    def name(self) -> str:
        return "action_multilingual_intent_enhancer"

    def detect_language(self, text: str) -> str:
        """
        Détecte la langue d'un texte à l'aide de langdetect.
        """
        try:
            return detect(text)
        except Exception as e:
            return "unknown"

    def translate_intent(self, intent: str, language: str) -> str:
        """
        Traduit l'intention en anglais pour la traiter (simulation).
        """
        translations = {
            "fr": {
                "commander_pizza": "order_pizza",
                "vérifier_solde": "check_balance",
                "poser_question": "ask_question"
            },
            "es": {
                "pedir_pizza": "order_pizza",
                "consultar_saldo": "check_balance",
                "hacer_pregunta": "ask_question"
            }
        }
        return translations.get(language, {}).get(intent, intent)

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer le dernier message utilisateur
        user_message = tracker.latest_message.get("text")
        user_intent = tracker.latest_message.get("intent", {}).get("name", "unknown")

        # Détecter la langue
        detected_language = self.detect_language(user_message)
        dispatcher.utter_message(text=f"Langue détectée : {detected_language}")

        # Si la langue est autre que l'anglais, traduire l'intention
        if detected_language != "en":
            translated_intent = self.translate_intent(user_intent, detected_language)
            dispatcher.utter_message(
                text=f"Votre intention '{user_intent}' a été traduite en anglais : '{translated_intent}'."
            )
            return [SlotSet("detected_language", detected_language), SlotSet("translated_intent", translated_intent)]
        else:
            dispatcher.utter_message(text="Votre intention est déjà en anglais. Pas de traduction nécessaire.")
            return [SlotSet("detected_language", detected_language)]

class EthicalLanguageNormalizer(Action):
    def name(self) -> str:
        return "action_ethical_language_normalizer"

    def analyze_and_normalize(self, text: str) -> Dict[str, Any]:
        """
        Analyse un texte pour détecter des termes non éthiques et propose une reformulation.
        """
        # Liste simplifiée de mots/expressions à surveiller
        flagged_terms = {
            "insulte": ["stupide", "idiot", "nul"],
            "discrimination": ["femme au volant", "il/elle ne vaut rien"],
            "agressivité": ["tais-toi", "dégage"]
        }

        # Remplacements recommandés
        replacements = {
            "stupide": "mal avisé",
            "idiot": "malin dans d'autres contextes",
            "nul": "à améliorer",
            "tais-toi": "pourrais-tu rester silencieux un instant ?",
            "dégage": "pourrais-tu t'écarter, s'il te plaît ?"
        }

        # Analyse et suggestions
        flagged_detected = []
        normalized_text = text

        for category, terms in flagged_terms.items():
            for term in terms:
                if term in text.lower():
                    flagged_detected.append((category, term))
                    normalized_text = normalized_text.replace(term, replacements.get(term, "[terme à remplacer]"))

        return {
            "flagged_detected": flagged_detected,
            "normalized_text": normalized_text
        }

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer le message utilisateur
        user_message = tracker.latest_message.get("text")

        if not user_message:
            dispatcher.utter_message(text="Je n'ai pas reçu de texte à analyser.")
            return []

        # Analyse et reformulation
        analysis_result = self.analyze_and_normalize(user_message)

        # Préparer la réponse
        if analysis_result["flagged_detected"]:
            flagged_terms = ", ".join([term[1] for term in analysis_result["flagged_detected"]])
            response = (
                f"J'ai détecté des termes sensibles ou non éthiques dans votre message : {flagged_terms}.\n"
                f"Voici une reformulation plus appropriée :\n\n{analysis_result['normalized_text']}"
            )
        else:
            response = "Votre message semble respecter toutes les normes éthiques. 😊"

        # Envoyer la réponse
        dispatcher.utter_message(text=response)

        # Retourner les termes détectés pour suivi (facultatif)
        return [SlotSet("flagged_terms", analysis_result["flagged_detected"])]




class summarizeText(Action):
    def name(self) -> str:
        return "action_summarize_text"

    def run(self, dispatcher: CollectingDispatcher,
            tracker: Tracker,
            domain: DomainDict) -> list:
        # Récupérer le texte utilisateur
        user_message = tracker.latest_message.get('text', None)

        if not user_message:
            dispatcher.utter_message(
                text="Je n'ai pas trouvé de texte à résumer. Pouvez-vous réessayer avec plus d'informations ?")
            return []

        # Vérification de la longueur du texte
        if len(user_message.split()) < 30:  # Minimum requis pour un résumé cohérent
            dispatcher.utter_message(
                text="Le texte est trop court pour être résumé. Pouvez-vous fournir un contenu plus long ?")
            return []

        try:
            # Génération du résumé avec `transformers`
            summarized_text = summarizer(user_message, max_length=130, min_length=30, do_sample=False)
            summary = summarized_text[0]['summary_text']

            if not summary.strip():  # Vérifie si le résumé est vide
                dispatcher.utter_message(text="Je n'ai pas pu générer un résumé utile. Essayez avec un autre texte.")
            else:
                dispatcher.utter_message(text=f"Voici le résumé :\n{summary}")

        except Exception as e:
            dispatcher.utter_message(text="Une erreur s'est produite lors du résumé. Merci de réessayer.")

        return []
class SelfContainedNLPAnalyzer(Action):
    def name(self) -> str:
        return "action_self_contained_nlp_analyzer"

    def analyze_text(self, text: str) -> Dict[str, Any]:
        """
        Analyse un texte pour détecter des patterns simples et en extraire des informations.
        """
        # Exemple de détection de mots-clés ou expressions spécifiques
        keywords = {
            "commande": ["commander", "acheter", "réserver"],
            "information": ["infos", "information", "détails"],
            "problème": ["erreur", "problème", "bug"]
        }

        detected_categories = []

        for category, words in keywords.items():
            for word in words:
                if re.search(rf"\b{word}\b", text.lower()):
                    detected_categories.append(category)

        return {
            "categories": detected_categories,
            "text_length": len(text.split())
        }

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer le message utilisateur
        user_message = tracker.latest_message.get("text")

        if not user_message:
            dispatcher.utter_message(text="Je n'ai pas reçu de texte à analyser.")
            return []

        # Analyser le texte
        analysis_result = self.analyze_text(user_message)

        # Répondre à l'utilisateur avec les catégories détectées
        if analysis_result["categories"]:
            response = f"J'ai détecté les catégories suivantes dans votre message : {', '.join(analysis_result['categories'])}."
        else:
            response = "Je n'ai détecté aucune catégorie particulière dans votre message."

        dispatcher.utter_message(text=response)

        # Retourner un slot mis à jour pour suivi
        return [SlotSet("analyzed_categories", analysis_result["categories"])]
class PostgreSQLManager:
    """
    Gère PostgreSQL avec chiffrement et validation des données.
    """

    def __init__(self, db_name: str, user: str, password: str, host: str = "localhost", port: int = 5432, encryption_enabled: bool = True):
        """
        Initialise la connexion PostgreSQL.

        Args:
            db_name (str): Nom de la base de données.
            user (str): Utilisateur PostgreSQL.
            password (str): Mot de passe PostgreSQL.
            host (str): Hôte du serveur PostgreSQL.
            port (int): Port de PostgreSQL.
            encryption_enabled (bool): Activer ou désactiver le chiffrement des données sensibles.
        """
        try:
            self.connection = psycopg2.connect(
                dbname=db_name,
                user=user,
                password=password,
                host=host,
                port=port,
                cursor_factory=RealDictCursor
            )
            self.cursor = self.connection.cursor()
            self.encryption_enabled = encryption_enabled
            self.encryption_key = os.getenv("DB_ENCRYPTION_KEY", "thisisaverysecurekey").encode()
            logger.info(f"PostgreSQLManager connected to DB: {db_name} on {host}:{port}")
            asyncio.run(self.initialize_tables())
        except Exception as e:
            logger.error(f"Error connecting to PostgreSQL: {e}")
            raise

    def encrypt_data(self, data: str) -> bytes:
        """
        Chiffre une chaîne de caractères.

        Args:
            data (str): Données à chiffrer.

        Returns:
            bytes: Données chiffrées.
        """
        iv = secrets.token_bytes(16)  # Génère un IV aléatoire de 16 octets
        cipher = Cipher(algorithms.AES(self.encryption_key), modes.CFB(iv), backend=default_backend())
        encryptor = cipher.encryptor()
        encrypted_data = encryptor.update(data.encode()) + encryptor.finalize()
        return iv + encrypted_data  # Combine IV et données chiffrées

    def decrypt_data(self, encrypted_data: bytes) -> str:
        """
        Déchiffre une chaîne de caractères.

        Args:
            encrypted_data (bytes): Données chiffrées.

        Returns:
            str: Données déchiffrées.
        """
        iv = encrypted_data[:16]  # Extraire l'IV
        data = encrypted_data[16:]  # Extraire les données chiffrées
        cipher = Cipher(algorithms.AES(self.encryption_key), modes.CFB(iv), backend=default_backend())
        decryptor = cipher.decryptor()
        return decryptor.update(data).decode()

    async def initialize_tables(self):
        """
        Initialise les tables nécessaires dans la base de données si elles n'existent pas.
        """
        query = """
        CREATE TABLE IF NOT EXISTS interactions (
            id SERIAL PRIMARY KEY,
            user_id VARCHAR(255),
            message BYTEA,
            response BYTEA,
            metadata JSONB,
            timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        """
        await asyncio.to_thread(self.cursor.execute, query)
        self.connection.commit()
        logger.info("Tables initialized successfully.")

    async def save_interaction(self, user_id: str, message: str, response: str, metadata: dict = {}):
        """
        Sauvegarde une interaction utilisateur.

        Args:
            user_id (str): ID utilisateur.
            message (str): Message envoyé par l'utilisateur.
            response (str): Réponse générée.
            metadata (dict): Métadonnées supplémentaires.
        """
        try:
            if self.encryption_enabled:
                message = self.encrypt_data(message)
                response = self.encrypt_data(response)

            query = """
            INSERT INTO interactions (user_id, message, response, metadata)
            VALUES (%s, %s, %s, %s);
            """
            await asyncio.to_thread(self.cursor.execute, query, (user_id, message, response, metadata))
            self.connection.commit()
            logger.info(f"Interaction saved for user: {user_id}")
        except Exception as e:
            logger.error(f"Error saving interaction for user {user_id}: {e}")

    async def fetch_interactions(self, user_id: str, limit: int = 10, offset: int = 0) -> list:
        """
        Récupère toutes les interactions d'un utilisateur.

        Args:
            user_id (str): ID utilisateur.
            limit (int): Nombre maximum de résultats.
            offset (int): Décalage pour la pagination.

        Returns:
            list: Liste des interactions.
        """
        try:
            query = """
            SELECT id, user_id, message, response, metadata, timestamp
            FROM interactions
            WHERE user_id = %s
            ORDER BY timestamp DESC
            LIMIT %s OFFSET %s;
            """
            await asyncio.to_thread(self.cursor.execute, query, (user_id, limit, offset))
            records = self.cursor.fetchall()

            results = []
            for record in records:
                if self.encryption_enabled:
                    record["message"] = self.decrypt_data(record["message"])
                    record["response"] = self.decrypt_data(record["response"])
                results.append(record)

            logger.info(f"Fetched {len(results)} interactions for user: {user_id}")
            return results
        except Exception as e:
            logger.error(f"Error fetching interactions for user {user_id}: {e}")
            return []
class SentimentAndToneBalancer(Action):
    def name(self) -> str:
        return "action_sentiment_and_tone_balancer"

    def detect_tone(self, text: str) -> str:
        """
        Détecte un ton émotionnel simple basé sur des mots-clés.
        """
        tone_keywords = {
            "positif": ["merci", "super", "génial", "excellent"],
            "négatif": ["nul", "problème", "déçu", "fatigué"],
            "neutre": ["ok", "d'accord", "normal"]
        }

        for tone, keywords in tone_keywords.items():
            for keyword in keywords:
                if keyword in text.lower():
                    return tone

        return "inconnu"

    def generate_balanced_response(self, tone: str) -> str:
        """
        Propose une réponse en équilibrant le ton détecté.
        """
        responses = {
            "positif": "Merci pour votre retour positif ! Je suis ravi de vous aider. 😊",
            "négatif": "Je suis désolé si quelque chose vous déçoit. Que puis-je faire pour améliorer cela ?",
            "neutre": "Merci pour votre retour. Comment puis-je vous aider davantage ?",
            "inconnu": "Pouvez-vous m’en dire plus pour que je comprenne mieux votre besoin ?"
        }
        return responses.get(tone, "Je suis là pour vous aider.")

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer le message utilisateur
        user_message = tracker.latest_message.get("text")

        if not user_message:
            dispatcher.utter_message(text="Je n'ai pas reçu de texte à analyser.")
            return []

        # Détecter le ton du message
        detected_tone = self.detect_tone(user_message)

        # Générer une réponse équilibrée
        balanced_response = self.generate_balanced_response(detected_tone)

        # Envoyer la réponse
        dispatcher.utter_message(text=balanced_response)

        # Optionnel : Retourner un slot mis à jour avec le ton détecté
        return [SlotSet("detected_tone", detected_tone)]

class BiasDetectionManager(Action):
    def name(self) -> str:
        return "action_bias_detection_manager"

    def detect_bias(self, text: str) -> Dict[str, Any]:
        """
        Analyse un texte pour détecter des biais implicites (discriminations, stéréotypes).
        """
        # Dictionnaire de mots-clés liés à des biais
        bias_keywords = {
            "genre": [
                r"\bhomme\b", r"\bfemme\b", r"\bsexe faible\b", r"\bdominant\b",
                r"\bféminin\b", r"\bmasculin\b"
            ],
            "origine": [
                r"\bétranger\b", r"\bimmigré\b", r"\brace\b", r"\bethnie\b", r"\bnationalité\b"
            ],
            "âge": [
                r"\bvieux\b", r"\bjeune\b", r"\bgénération Z\b", r"\bboomer\b"
            ],
            "statut social": [
                r"\bchômeur\b", r"\bprécarité\b", r"\briche\b", r"\bclasse moyenne\b"
            ],
            "orientation sexuelle": [
                r"\bhomosexuel\b", r"\blgbt\b", r"\btransgenre\b", r"\bhétéro\b"
            ]
        }

        flagged_terms = []

        for category, patterns in bias_keywords.items():
            for pattern in patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    flagged_terms.append((category, match.group()))

        return {"flagged_terms": flagged_terms, "text": text}

    def generate_response(self, flagged_terms: List[Tuple[str, str]]) -> str:
        """
        Génère une réponse en fonction des biais détectés.
        """
        if not flagged_terms:
            return "Votre message est exempt de biais détectés. Merci pour votre langage respectueux ! 😊"

        details = "\n".join(
            [f"- Terme : '{term[1]}' (Catégorie : {term[0]})" for term in flagged_terms]
        )
        suggestions = (
            "Essayez d'utiliser des termes plus neutres ou inclusifs pour éviter les malentendus. "
            "Par exemple : remplacez 'sexe faible' par 'genre sous-représenté'. 😊"
        )
        return f"J'ai détecté des termes potentiellement biaisés :\n{details}\n\n{suggestions}"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer le message utilisateur
        user_message = tracker.latest_message.get("text")

        if not user_message:
            dispatcher.utter_message(text="Je n'ai pas reçu de texte à analyser. Veuillez réessayer.")
            return []

        # Analyse des biais
        bias_result = self.detect_bias(user_message)

        # Génération de la réponse
        response = self.generate_response(bias_result["flagged_terms"])
        dispatcher.utter_message(text=response)

        # Retour des biais détectés (optionnel pour logs ou interface avancée)
        return [SlotSet("bias_detected", bias_result["flagged_terms"])]

class JusticeDecisionAssistant(Action):
    def name(self) -> str:
        return "action_justice_decision_assistant"

    def evaluate_arguments(self, arguments: List[str]) -> str:
        """
        Analyse une liste d'arguments et retourne une recommandation impartiale.
        """
        # Simplification : Compte les arguments positifs et négatifs
        positive_keywords = ["bien", "avantage", "utile", "juste", "équitable"]
        negative_keywords = ["mal", "injustice", "problème", "désavantage", "discrimination"]

        scores = {"positif": 0, "négatif": 0}

        for argument in arguments:
            for word in positive_keywords:
                if word in argument.lower():
                    scores["positif"] += 1
            for word in negative_keywords:
                if word in argument.lower():
                    scores["négatif"] += 1

        if scores["positif"] > scores["négatif"]:
            return "Après analyse, les arguments en faveur de cette action semblent l'emporter."
        elif scores["négatif"] > scores["positif"]:
            return "Après analyse, les arguments contre cette action semblent l'emporter."
        else:
            return "Les arguments semblent équilibrés. Je recommande une discussion supplémentaire pour trancher."

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple d'arguments (peut être remplacé par des slots utilisateur)
        arguments = tracker.get_slot("arguments_list") or [
            "C'est bien pour tout le monde.",
            "Cela crée une injustice.",
            "C'est utile pour résoudre un problème."
        ]

        # Évaluer les arguments
        recommendation = self.evaluate_arguments(arguments)

        # Réponse utilisateur
        dispatcher.utter_message(text=f"Analyse des arguments : {recommendation}")

        return []

class ActionShowOptions(Action):
    def name(self) -> str:
        return "action_show_options"

    def run(
        self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        # Définition des options (peut être dynamique)
        options = [
            {"title": "Option 1", "payload": "/choose_option_1"},
            {"title": "Option 2", "payload": "/choose_option_2"},
            {"title": "Option 3", "payload": "/choose_option_3"},
        ]

        # Générer les boutons
        buttons = [
            {"title": option["title"], "payload": option["payload"]}
            for option in options
        ]

        # Envoyer les options avec des boutons interactifs
        dispatcher.utter_message(
            text="Voici les options disponibles :",
            buttons=buttons
        )

        return []

class ConflictResolutionAdvisor(Action):
    def name(self) -> str:
        return "action_conflict_resolution_advisor"

    def propose_resolution(self, conflict_points: List[Dict[str, Any]]) -> str:
        """
        Analyse les points de conflit et propose une solution équilibrée.
        """
        solutions = []

        for point in conflict_points:
            issue = point.get("issue")
            perspectives = point.get("perspectives", {})

            # Trouver les intérêts communs ou compromis possibles
            common_interests = [
                interest for interest in perspectives.get("side_a", [])
                if interest in perspectives.get("side_b", [])
            ]

            if common_interests:
                solutions.append(f"Pour '{issue}', les deux parties partagent des intérêts communs : {', '.join(common_interests)}.")
            else:
                solutions.append(f"Pour '{issue}', il serait utile d'explorer des compromis ou intérêts partagés.")

        if solutions:
            return "\n".join(solutions)
        else:
            return "Je n'ai pas assez d'informations pour proposer une résolution. Pouvez-vous fournir plus de détails ?"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de points de conflit (peut être remplacé par des slots utilisateur)
        conflict_points = tracker.get_slot("conflict_points") or [
            {
                "issue": "Prolongation des délais",
                "perspectives": {
                    "side_a": ["plus de temps pour bien faire", "moins de pression"],
                    "side_b": ["respect des délais", "impact sur les livraisons"]
                }
            },
            {
                "issue": "Répartition des tâches",
                "perspectives": {
                    "side_a": ["équité dans les efforts"],
                    "side_b": ["compétences spécialisées"]
                }
            }
        ]

        # Proposer une résolution basée sur les points de conflit
        resolution = self.propose_resolution(conflict_points)

        # Réponse utilisateur
        dispatcher.utter_message(text=f"Voici mes propositions pour résoudre ces conflits :\n\n{resolution}")

        return []

class FairResourceAllocator(Action):
    def name(self) -> str:
        return "action_fair_resource_allocator"

    def allocate_resources(self, requests: List[Dict[str, Any]], total_resources: int = 100) -> Dict[str, Any]:
        """
        Alloue des ressources équitablement entre plusieurs demandes, avec gestion des priorités.
        """
        # Trier les demandes par priorité décroissante
        sorted_requests = sorted(requests, key=lambda x: x.get("priority", 0), reverse=True)
        allocation = {}

        # Calculer le total des priorités pour l'allocation proportionnelle
        total_priority = sum(request.get("priority", 1) for request in sorted_requests)
        if total_priority == 0:
            total_priority = len(sorted_requests)  # Éviter division par 0

        for request in sorted_requests:
            user_id = request.get("user_id")
            requested = request.get("amount", 0)
            priority = request.get("priority", 0)

            # Allocation proportionnelle basée sur les priorités
            share = (priority / total_priority) * total_resources
            allocated = min(requested, int(share))
            allocation[user_id] = {
                "requested": requested,
                "allocated": allocated,
                "priority": priority
            }

            # Réduire les ressources restantes
            total_resources -= allocated
            if total_resources <= 0:
                break

        return allocation

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Récupérer les demandes depuis un slot (ou exemple par défaut)
        requests = tracker.get_slot("resource_requests") or [
            {"user_id": "user_1", "amount": 50, "priority": 3},
            {"user_id": "user_2", "amount": 30, "priority": 2},
            {"user_id": "user_3", "amount": 40, "priority": 1}
        ]

        # Allouer les ressources
        total_resources = tracker.get_slot("total_resources") or 100
        allocation = self.allocate_resources(requests, total_resources)

        # Préparer une réponse utilisateur
        response = "Voici l'allocation des ressources :\n"
        for user_id, details in allocation.items():
            response += (
                f"- Utilisateur {user_id} : demandé {details['requested']}, "
                f"attribué {details['allocated']} (priorité {details['priority']}).\n"
            )

        if total_resources > 0:
            response += f"\nRessources restantes : {total_resources} unités.\n"
        else:
            response += "\nToutes les ressources ont été allouées.\n"

        dispatcher.utter_message(text=response)

        # Retourner les allocations pour suivi (facultatif)
        return [
            SlotSet("resource_allocation", allocation),
            SlotSet("remaining_resources", total_resources)
        ]

class JusticeFeedbackAnalyzer(Action):
    def name(self) -> str:
        return "action_justice_feedback_analyzer"

    def analyze_feedback(self, feedbacks: List[Dict[str, Any]]) -> Dict[str, int]:
        """
        Analyse les retours utilisateurs pour identifier les perceptions d'injustice.
        """
        results = {"positive": 0, "negative": 0}

        for feedback in feedbacks:
            if feedback.get("sentiment") == "positive":
                results["positive"] += 1
            elif feedback.get("sentiment") == "negative":
                results["negative"] += 1

        return results

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de feedbacks collectés (peut venir de slots ou d'une base)
        feedbacks = tracker.get_slot("feedbacks") or [
            {"user_id": "user_1", "sentiment": "positive"},
            {"user_id": "user_2", "sentiment": "negative"}
        ]

        # Analyser les feedbacks
        results = self.analyze_feedback(feedbacks)

        # Préparer une réponse
        response = (
            f"J'ai reçu {results['positive']} retours positifs et {results['negative']} retours négatifs. "
            "Je vais ajuster mes décisions pour mieux correspondre à vos attentes."
        )

        dispatcher.utter_message(text=response)

        # Retourner les résultats pour ajustement (optionnel)
        return [SlotSet("feedback_analysis", results)]

class EqualityAuditManager(Action):
    def name(self) -> str:
        return "action_equality_audit_manager"

    def audit_interactions(self, logs: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Audite les interactions pour vérifier l'équité entre les utilisateurs.
        """
        user_stats = {}

        for log in logs:
            user_id = log.get("user_id")
            if user_id not in user_stats:
                user_stats[user_id] = {"total_interactions": 0, "resources_allocated": 0}
            user_stats[user_id]["total_interactions"] += 1
            user_stats[user_id]["resources_allocated"] += log.get("resources", 0)

        # Vérifier les déséquilibres
        fairness_issues = [
            user_id for user_id, stats in user_stats.items()
            if stats["resources_allocated"] < 10  # Exemple de seuil
        ]

        return {"user_stats": user_stats, "fairness_issues": fairness_issues}

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de logs d'interactions
        logs = tracker.get_slot("interaction_logs") or [
            {"user_id": "user_1", "resources": 50},
            {"user_id": "user_2", "resources": 5},
            {"user_id": "user_3", "resources": 15}
        ]

        # Effectuer l'audit
        audit_result = self.audit_interactions(logs)

        # Préparer une réponse
        if audit_result["fairness_issues"]:
            response = (
                f"Des déséquilibres ont été détectés pour les utilisateurs suivants : {', '.join(audit_result['fairness_issues'])}. "
                "Des ajustements seront effectués."
            )
        else:
            response = "Aucun déséquilibre détecté. Les ressources semblent réparties équitablement."

        dispatcher.utter_message(text=response)

        # Retourner les résultats pour suivi
        return [SlotSet("audit_results", audit_result)]

class EthicsDrivenRecommendation(Action):
    """
    Propose des recommandations basées sur les préférences utilisateur, en respectant des critères éthiques.
    """

    def name(self) -> str:
        return "action_ethics_driven_recommendation"

    def filter_unethical_recommendations(self, recommendations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Filtre les recommandations qui pourraient être contraires aux principes éthiques.

        Args:
            recommendations (List[Dict[str, Any]]): Liste des recommandations possibles.

        Returns:
            List[Dict[str, Any]]: Liste filtrée des recommandations éthiques.
        """
        return [rec for rec in recommendations if rec.get("ethical", True)]

    def rank_recommendations(self, recommendations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Classe les recommandations par pertinence.

        Args:
            recommendations (List[Dict[str, Any]]): Liste des recommandations filtrées.

        Returns:
            List[Dict[str, Any]]: Liste des recommandations triées.
        """
        return sorted(recommendations, key=lambda x: x.get("priority", 0), reverse=True)

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemples de recommandations récupérées (peuvent venir de bases de données ou d'APIs)
        raw_recommendations = [
            {"title": "Adopter une routine sportive", "priority": 10, "ethical": True},
            {"title": "Investir dans un portefeuille à risque élevé", "priority": 5, "ethical": False},
            {"title": "Méditer quotidiennement", "priority": 8, "ethical": True}
        ]

        # Filtrer et classer les recommandations
        ethical_recommendations = self.filter_unethical_recommendations(raw_recommendations)
        ranked_recommendations = self.rank_recommendations(ethical_recommendations)

        # Réponse pour l'utilisateur
        if ranked_recommendations:
            recommendations_text = "\n".join([rec["title"] for rec in ranked_recommendations])
            dispatcher.utter_message(text=f"Voici mes recommandations :\n{recommendations_text}")
        else:
            dispatcher.utter_message(text="Je n'ai trouvé aucune recommandation éthique adaptée.")

        return []

class TransparencyResponseManager(Action):
    """
    Fournit des explications détaillées sur les décisions ou recommandations prises par le bot.
    """

    def name(self) -> str:
        return "action_transparency_response_manager"

    def generate_explanation(self, decision_context: Dict[str, Any]) -> str:
        """
        Génère une explication basée sur le contexte de la décision.

        Args:
            decision_context (Dict[str, Any]): Contexte contenant les critères de décision.

        Returns:
            str: Explication claire pour l'utilisateur.
        """
        reason = decision_context.get("reason", "Aucune raison spécifiée.")
        criteria = decision_context.get("criteria", [])

        explanation = f"La décision a été prise pour la raison suivante : {reason}.\n"
        if criteria:
            explanation += "Voici les critères utilisés dans cette décision :\n"
            explanation += "\n".join([f"- {criterion}" for criterion in criteria])
        else:
            explanation += "Aucun critère spécifique n'a été utilisé."

        return explanation

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de contexte de décision (remplaçable par des slots ou une API)
        decision_context = tracker.get_slot("decision_context") or {
            "reason": "Priorité élevée et conformité aux principes éthiques.",
            "criteria": ["Pertinence élevée", "Impact positif sur l'utilisateur"]
        }

        # Générer une explication basée sur le contexte
        explanation = self.generate_explanation(decision_context)

        # Réponse utilisateur
        dispatcher.utter_message(text=f"Voici pourquoi cette décision a été prise :\n\n{explanation}")

        # Optionnel : retour du contexte d'explication
        return [SlotSet("explanation_generated", explanation)]

class UserFeedbackLoop(Action):
    """
    Gère une boucle de feedback utilisateur pour ajuster les décisions ou recommandations.
    """

    def name(self) -> str:
        return "action_user_feedback_loop"

    def collect_feedback(self, feedback: Dict[str, str]) -> Dict[str, int]:
        """
        Analyse les retours des utilisateurs.

        Args:
            feedback (Dict[str, str]): Feedback utilisateur avec une note (positive ou négative).

        Returns:
            Dict[str, int]: Compte des feedbacks positifs et négatifs.
        """
        positive = 0
        negative = 0

        for response in feedback.values():
            if response.lower() in ["positif", "bien", "ok"]:
                positive += 1
            elif response.lower() in ["négatif", "pas bien", "mauvais"]:
                negative += 1

        return {"positive": positive, "negative": negative}

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de feedbacks utilisateur (peut être remplacé par des slots ou des logs)
        feedback = tracker.get_slot("user_feedback") or {
            "recommendation_1": "positif",
            "recommendation_2": "négatif",
            "recommendation_3": "positif"
        }

        # Analyser les feedbacks
        feedback_summary = self.collect_feedback(feedback)

        # Préparer une réponse utilisateur
        response = (
            f"Merci pour vos retours ! Voici un résumé :\n"
            f"- Feedbacks positifs : {feedback_summary['positive']}\n"
            f"- Feedbacks négatifs : {feedback_summary['negative']}\n"
        )
        if feedback_summary["negative"] > 0:
            response += "Je vais ajuster mes recommandations pour mieux répondre à vos attentes."

        dispatcher.utter_message(text=response)

        # Retour facultatif pour suivre les feedbacks
        return [SlotSet("feedback_summary", feedback_summary)]

class DecisionAuditTrail(Action):
    """
    Crée un historique des décisions prises par le bot.
    """

    def name(self) -> str:
        return "action_decision_audit_trail"

    def log_decision(self, decision: Dict[str, Any], audit_log: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Ajoute une décision au journal d'audit.

        Args:
            decision (Dict[str, Any]): Détails de la décision à enregistrer.
            audit_log (List[Dict[str, Any]]): Journal d'audit existant.

        Returns:
            List[Dict[str, Any]]: Journal d'audit mis à jour.
        """
        audit_log.append(decision)
        return audit_log[-100:]  # Limite à 100 entrées pour éviter la surcharge

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de décision à enregistrer (peut être remplacé par des slots ou logs)
        decision = tracker.get_slot("current_decision") or {
            "type": "recommendation",
            "details": "Recommander une activité physique",
            "timestamp": "2024-11-12T12:00:00Z",
            "criteria": ["pertinence élevée", "impact positif"]
        }

        # Charger le journal d'audit existant
        audit_log = tracker.get_slot("audit_log") or []

        # Enregistrer la décision
        updated_audit_log = self.log_decision(decision, audit_log)

        # Confirmer l'ajout au journal
        dispatcher.utter_message(text="La décision a été enregistrée dans le journal d'audit.")

        # Retourner le journal mis à jour
        return [SlotSet("audit_log", updated_audit_log)]

class EthicalRiskMonitor(Action):
    """
    Surveille les décisions pour détecter des risques éthiques potentiels.
    """

    def name(self) -> str:
        return "action_ethical_risk_monitor"

    def check_risks(self, decision: Dict[str, Any]) -> bool:
        """
        Vérifie si une décision présente des risques éthiques.

        Args:
            decision (Dict[str, Any]): Détails de la décision.

        Returns:
            bool: True si des risques sont détectés, False sinon.
        """
        prohibited_criteria = ["impact négatif", "non conforme", "discrimination"]
        return any(criterion in decision.get("criteria", []) for criterion in prohibited_criteria)

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de décision actuelle
        decision = tracker.get_slot("current_decision") or {
            "type": "allocation",
            "details": "Allouer des ressources supplémentaires",
            "criteria": ["impact positif", "non conforme"]
        }

        # Vérifier les risques
        risk_detected = self.check_risks(decision)

        if risk_detected:
            dispatcher.utter_message(
                text="Attention : Une décision a été détectée comme potentiellement non conforme aux principes éthiques."
            )
        else:
            dispatcher.utter_message(
                text="Aucun risque éthique détecté pour cette décision."
            )

        return [SlotSet("risk_detected", risk_detected)]

class AdaptiveBehaviorManager(Action):
    """
    Gère l'adaptation dynamique du comportement du bot en fonction du contexte et des préférences utilisateur.
    """

    def name(self) -> str:
        return "action_adaptive_behavior_manager"

    def determine_behavior(self, user_profile: Dict[str, Any]) -> str:
        """
        Détermine le comportement optimal en fonction du profil utilisateur.

        Args:
            user_profile (Dict[str, Any]): Profil utilisateur avec des préférences.

        Returns:
            str: Comportement adapté (exemple : "formel", "amical").
        """
        if user_profile.get("interaction_frequency", 0) > 10:
            return "amical"
        elif user_profile.get("feedback_score", 0) < 5:
            return "formel"
        else:
            return "neutre"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Charger le profil utilisateur (peut être alimenté par des slots ou une base)
        user_profile = tracker.get_slot("user_profile") or {
            "interaction_frequency": 15,
            "feedback_score": 7,
            "preferred_tone": "amical"
        }

        # Déterminer le comportement approprié
        behavior = self.determine_behavior(user_profile)

        # Réponse utilisateur selon le comportement
        if behavior == "amical":
            dispatcher.utter_message(text="Salut ! Content de te revoir ! 😊 Comment puis-je t’aider aujourd’hui ?")
        elif behavior == "formel":
            dispatcher.utter_message(text="Bonjour. Je suis ici pour répondre à vos questions. Comment puis-je vous aider ?")
        else:
            dispatcher.utter_message(text="Bonjour ! Que puis-je faire pour vous ?")

        # Retourner le comportement pour suivi
        return [SlotSet("user_behavior", behavior)]

class ProactiveEngagementManager(Action):
    """
    Propose des actions ou des suggestions basées sur le comportement et l'historique utilisateur.
    """

    def name(self) -> str:
        return "action_proactive_engagement_manager"

    def generate_proactive_suggestion(self, user_history: Dict[str, Any]) -> str:
        """
        Génère une suggestion proactive basée sur l'historique utilisateur.

        Args:
            user_history (Dict[str, Any]): Historique des interactions utilisateur.

        Returns:
            str: Suggestion proactive.
        """
        if user_history.get("last_action") == "check_balance":
            return "Souhaitez-vous aussi vérifier les transactions récentes  ?"
        elif user_history.get("last_action") == "order_pizza":
            return "La dernière fois, vous avez commandé une pizza. Voulez-vous la même aujourd’hui ?"
        else:
            return "Puis-je vous proposer une assistance supplémentaire ?"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Charger l'historique utilisateur (peut être alimenté par des slots ou une base)
        user_history = tracker.get_slot("user_history") or {
            "last_action": "check_balance",
            "last_interaction": "2024-11-10"
        }

        # Générer une suggestion proactive
        suggestion = self.generate_proactive_suggestion(user_history)

        # Envoyer la suggestion
        dispatcher.utter_message(text=suggestion)

        # Retourner une mise à jour de l'historique (facultatif)
        return [SlotSet("last_suggestion", suggestion)]

class SentimentTrendAnalyzer(Action):
    """
    Analyse les tendances des sentiments des utilisateurs sur une période donnée.
    """

    def name(self) -> str:
        return "action_sentiment_trend_analyzer"

    def calculate_sentiment_trend(self, sentiment_logs: List[int]) -> str:
        """
        Analyse les tendances des sentiments.

        Args:
            sentiment_logs (List[int]): Liste des scores de sentiment sur une période.

        Returns:
            str: Résultat de l'analyse de tendance (positif, négatif, stable).
        """
        if len(sentiment_logs) < 2:
            return "Données insuffisantes pour analyser les tendances."

        trend = sentiment_logs[-1] - sentiment_logs[0]

        if trend > 0:
            return "positif"
        elif trend < 0:
            return "négatif"
        else:
            return "stable"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de logs de sentiment (peut venir de slots ou d'une base)
        sentiment_logs = tracker.get_slot("sentiment_logs") or [3, 4, 5, 5, 6]

        # Calculer la tendance
        trend = self.calculate_sentiment_trend(sentiment_logs)

        # Préparer une réponse utilisateur
        if trend == "positif":
            response = "Les retours montrent une amélioration continue. Merci pour votre confiance ! 😊"
        elif trend == "négatif":
            response = "Les retours indiquent une frustration croissante. Que puis-je faire pour m'améliorer  ?"
        else:
            response = "Les retours sont stables. Continuons sur cette lancée."

        dispatcher.utter_message(text=response)

        # Retour facultatif des tendances analysées
        return [SlotSet("sentiment_trend", trend)]

class ContextualKnowledgeEnhancer(Action):
    """
    Enrichit les réponses avec des informations contextuelles pertinentes.
    """

    def name(self) -> str:
        return "action_contextual_knowledge_enhancer"

    def enrich_response(self, user_context: Dict[str, Any], base_response: str) -> str:
        """
        Ajoute des informations contextuelles à une réponse de base.

        Args:
            user_context (Dict[str, Any]): Contexte utilisateur.
            base_response (str): Réponse de base.

        Returns:
            str: Réponse enrichie.
        """
        # Enrichir en fonction de la langue
        if user_context.get("preferred_language") == "français":
            base_response += " (Réponse adaptée à votre langue préférée : français.)"
        elif user_context.get("preferred_language") == "anglais":
            base_response += " (Response adapted to your preferred language: English.)"

        # Ajouter un enrichissement lié au sujet récent
        recent_topic = user_context.get("recent_topic")
        if recent_topic:
            if recent_topic == "santé":
                base_response += " J'ai remarqué que vous vous intéressez à la santé. Voici quelques conseils pour un mode de vie sain."
            elif recent_topic == "technologie":
                base_response += " Vous semblez intéressé par la technologie. Puis-je vous parler des dernières tendances ?"

        # Ajouter une personnalisation avec le nom
        if user_context.get("name"):
            base_response = f"{user_context['name']}, " + base_response

        return base_response

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Exemple de contexte utilisateur (peut être issu de slots ou API)
        user_context = tracker.get_slot("user_context") or {
            "preferred_language": "français",
            "recent_topic": "santé",
            "name": "Jean"
        }

        # Réponse de base
        base_response = "Je suis ici pour vous aider avec toutes vos questions."

        # Enrichir la réponse avec le contexte utilisateur
        enriched_response = self.enrich_response(user_context, base_response)

        # Répondre à l'utilisateur
        dispatcher.utter_message(text=enriched_response)

        # Retourner le contexte mis à jour (facultatif)
        return []

class MultiUserPriorityBalancer(Action):
    """
    Gère les priorités entre plusieurs utilisateurs pour répartir équitablement les ressources.
    """

    def name(self) -> str:
        return "action_multi_user_priority_balancer"

    def allocate_priority(self, users: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Attribue les priorités aux utilisateurs en fonction de leur contexte.

        Args:
            users (List[Dict[str, Any]]): Liste des utilisateurs avec leur contexte.

        Returns:
            List[Dict[str, Any]]: Liste triée par priorité.
        """
        return sorted(users, key=lambda x: x.get("priority", 0), reverse=True)

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de liste d'utilisateurs (peut être remplacé par des données réelles)
        users = tracker.get_slot("user_list") or [
            {"user_id": "user_1", "priority": 10},
            {"user_id": "user_2", "priority": 5},
            {"user_id": "user_3", "priority": 8}
        ]

        # Allouer les priorités
        sorted_users = self.allocate_priority(users)

        # Réponse pour l'utilisateur principal
        dispatcher.utter_message(
            text="Voici les priorités actuelles :\n" +
            "\n".join([f"Utilisateur {u['user_id']} - Priorité {u['priority']}" for u in sorted_users])
        )

        return []

class PredictiveTaskAssigner(Action):
    """
    Prédit les tâches ou questions futures des utilisateurs pour proposer des solutions proactives.
    """

    def name(self) -> str:
        return "action_predictive_task_assigner"

    def predict_next_task(self, user_history: Dict[str, Any]) -> str:
        """
        Prédit la prochaine tâche probable de l'utilisateur.

        Args:
            user_history (Dict[str, Any]): Historique des interactions utilisateur.

        Returns:
            str: Tâche ou question prédite.
        """
        if user_history.get("last_action") == "check_balance":
            return "vérifier les transactions récentes"
        elif user_history.get("last_action") == "order_pizza":
            return "suivre la livraison de la commande"
        else:
            return "poser une question générale"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Historique utilisateur (peut être remplacé par une base ou des slots)
        user_history = tracker.get_slot("user_history") or {
            "last_action": "check_balance"
        }

        # Prédire la prochaine tâche
        predicted_task = self.predict_next_task(user_history)

        # Réponse utilisateur
        dispatcher.utter_message(
            text=f"Je prévois que vous pourriez vouloir {predicted_task}. Souhaitez-vous que je vous aide ?"
        )

        return []

class DynamicIntentRedirector(Action):
    """
    Redirige dynamiquement les intentions utilisateur vers des services plus précis.
    """

    def name(self) -> str:
        return "action_dynamic_intent_redirector"

    def map_intent(self, intent: str) -> str:
        """
        Associe une intention générique à une intention spécifique.

        Args:
            intent (str): Intention détectée.

        Returns:
            str: Intention redirigée.
        """
        intent_mapping = {
            "help": "provide_support",
            "order": "order_pizza",
            "check": "check_balance",
            "general_question": "faq_general"
        }
        return intent_mapping.get(intent, "fallback")

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer l'intention détectée
        detected_intent = tracker.latest_message.get("intent", {}).get("name", "unknown")

        # Rediriger l'intention
        redirected_intent = self.map_intent(detected_intent)

        # Réponse utilisateur
        dispatcher.utter_message(
            text=f"Votre demande a été redirigée vers le service correspondant : {redirected_intent}."
        )

        # Retourner l'intention redirigée pour suivi
        return [SlotSet("redirected_intent", redirected_intent)]

class EthicalLanguageRefiner(Action):
    """
    Affine le langage utilisé par le bot pour garantir des réponses éthiques et adaptées.
    """

    def name(self) -> str:
        return "action_ethical_language_refiner"

    def refine_message(self, message: str) -> str:
        """
        Affine une réponse pour garantir son éthique.

        Args:
            message (str): Message initial.

        Returns:
            str: Message raffiné.
        """
        # Liste de mots ou expressions à remplacer
        refinements = {
            "stupide": "mal avisé",
            "idiot": "peu optimal",
            "problème": "défi"
        }

        refined_message = message
        for word, replacement in refinements.items():
            refined_message = refined_message.replace(word, replacement)

        return refined_message

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer le dernier message généré par le bot
        bot_message = tracker.get_slot("bot_message") or "Ce choix est stupide et crée un problème."

        # Affiner le message
        refined_message = self.refine_message(bot_message)

        # Répondre à l'utilisateur avec le message raffiné
        dispatcher.utter_message(text=refined_message)

        # Retourner le message raffiné pour suivi
        return [SlotSet("refined_message", refined_message)]
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler

# Pipeline pour préparation des données
pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

# Préparation des données
X_train_prepared = pipeline.fit_transform(X_train)
X_test_prepared = pipeline.transform(X_test)

# Encodage ciblé
train['target_mean'] = train.groupby('category')['target'].transform('mean')
test['target_mean'] = test['category'].map(train.groupby('category')['target'].mean())

from lightgbm import LGBMRegressor

# Modèle LightGBM
model = LGBMRegressor(n_estimators=1000, learning_rate=0.05, max_depth=10)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

# Réseau simple
model = Sequential([
    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.2),
    Dense(1, activation='linear')
])

model.compile(optimizer='adam', loss='mse')
model.fit(X_train, y_train, epochs=50, batch_size=32)

from sklearn.model_selection import GridSearchCV

param_grid = {
    'learning_rate': [0.01, 0.05, 0.1],
    'max_depth': [5, 10, 15]
}

grid_search = GridSearchCV(estimator=LGBMRegressor(), param_grid=param_grid, cv=5)
grid_search.fit(X_train, y_train)
print("Best Parameters:", grid_search.best_params_)

from sklearn.ensemble import StackingRegressor

# Stacking
stack = StackingRegressor(estimators=[
    ('xgb', XGBRegressor(n_estimators=500)),
    ('lgbm', LGBMRegressor(n_estimators=500))
], final_estimator=Ridge())

stack.fit(X_train, y_train)
y_pred = stack.predict(X_test)
import pandas as pd

# Génération du fichier de soumission
submission = pd.DataFrame({
    'Id': test['Id'],
    'Target': y_pred
})
submission.to_csv('submission.csv', index=False)

from sklearn.model_selection import KFold

kf = KFold(n_splits=5)
for train_index, val_index in kf.split(X):
    X_train, X_val = X[train_index], X[val_index]
    y_train, y_val = y[train_index], y[val_index]
    model.fit(X_train, y_train)
    val_pred = model.predict(X_val)

from transformers import BertTokenizer, TFBertForSequenceClassification

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

tokens = tokenizer(X_train.tolist(), padding=True, truncation=True, return_tensors="tf")
model.fit(tokens['input_ids'], y_train, epochs=3)
from tensorflow.keras.applications import EfficientNetB0

model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

import mlflow

mlflow.start_run()
mlflow.log_param("learning_rate", 0.05)
mlflow.log_metric("accuracy", 0.95)
mlflow.end_run()

class MultiStepActionHandler(Action):
    """
    Gère les actions nécessitant plusieurs étapes pour une exécution complète.
    """

    def name(self) -> str:
        return "action_multi_step_action_handler"

    def execute_step(self, step: int) -> str:
        """
        Exécute une étape spécifique.

        Args:
            step (int): Numéro de l'étape.

        Returns:
            str: Résultat de l'étape.
        """
        steps = {
            1: "Étape 1 : Vérification des informations.",
            2: "Étape 2 : Confirmation des détails.",
            3: "Étape 3 : Exécution de l'action."
        }
        return steps.get(step, "Étape inconnue.")

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer l'étape actuelle
        current_step = tracker.get_slot("current_step") or 1

        # Exécuter l'étape
        step_result = self.execute_step(current_step)

        # Préparer la réponse
        dispatcher.utter_message(text=step_result)

        # Passer à l'étape suivante
        next_step = current_step + 1 if current_step < 3 else None

        return [SlotSet("current_step", next_step)]

class AdvancedInteractionAnalyzer:
    """
    Analyse les interactions utilisateur pour détecter des tendances et des comportements.
    """

    def __init__(self, db_manager):
        """
        Initialise l'analyseur avec un gestionnaire de base de données.

        Args:
            db_manager: Gestionnaire de base de données pour récupérer les interactions.
        """
        self.db_manager = db_manager
        logger.info("AdvancedInteractionAnalyzer initialized.")

    async def analyze_user_trends(self, user_id: str) -> Dict[str, Any]:
        """
        Analyse les tendances des interactions utilisateur.

        Args:
            user_id (str): ID utilisateur.

        Returns:
            Dict[str, Any]: Tendances détectées.
        """
        interactions = await self.db_manager.fetch_interactions(user_id)
        topics = [interaction["metadata"].get("topic") for interaction in interactions if "topic" in interaction["metadata"]]
        topic_counts = Counter(topics)
        logger.info(f"User trends for {user_id}: {topic_counts}")
        return dict(topic_counts)

    async def recommend_actions(self, user_id: str) -> str:
        """
        Recommande une action basée sur les tendances utilisateur.

        Args:
            user_id (str): ID utilisateur.

        Returns:
            str: Recommandation.
        """
        trends = await self.analyze_user_trends(user_id)
        if trends.get("finance", 0) > 5:
            return "Proposer des conseils financiers."
        elif trends.get("health", 0) > 3:
            return "Partager des astuces santé."
        return "Aucune recommandation spécifique."

class MultiTenantManager:
    """
    Gère les données et configurations pour des utilisateurs ou organisations multiples.
    """

    def __init__(self):
        """
        Initialise le gestionnaire multi-tenant.
        """
        self.tenants = {}
        logger.info("MultiTenantManager initialized.")

    def add_tenant(self, tenant_id: str, config: Dict[str, Any]):
        """
        Ajoute une organisation ou un utilisateur au système.

        Args:
            tenant_id (str): ID unique de l'organisation/utilisateur.
            config (Dict[str, Any]): Configuration spécifique.
        """
        self.tenants[tenant_id] = config
        logger.info(f"Tenant {tenant_id} added.")

    def get_tenant_config(self, tenant_id: str) -> Optional[Dict[str, Any]]:
        """
        Récupère la configuration d'une organisation/utilisateur.

        Args:
            tenant_id (str): ID unique.

        Returns:
            Optional[Dict[str, Any]]: Configuration, ou None si non trouvé.
        """
        return self.tenants.get(tenant_id)

    def list_tenants(self) -> List[str]:
        """
        Liste tous les tenants dans le système.

        Returns:
            List[str]: Liste des IDs de tenants.
        """
        return list(self.tenants.keys())

class EthicalAIValidator:
    """
    Valide les réponses et actions pour s'assurer qu'elles respectent les normes éthiques.
    """

    def __init__(self):
        """
        Initialise le validateur éthique.
        """
        logger.info("EthicalAIValidator initialized.")

    def validate_response(self, response: str) -> bool:
        """
        Valide une réponse.

        Args:
            response (str): Réponse à valider.

        Returns:
            bool: True si la réponse est éthique, sinon False.
        """
        unethical_phrases = ["offensive", "discriminatory"]
        for phrase in unethical_phrases:
            if phrase in response.lower():
                logger.warning(f"Unethical content detected in response: {response}")
                return False
        return True

    def enforce_policy(self, response: str) -> str:
        """
        Applique des corrections aux réponses non conformes.

        Args:
            response (str): Réponse initiale.

        Returns:
            str: Réponse corrigée.
        """
        if not self.validate_response(response):
            return "Je suis désolé, je ne peux pas répondre à cette demande."
        return response



class ActionAnalyzeSentiment(Action):
    def name(self) -> str:
        return "action_analyze_sentiment"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer le message utilisateur
        user_message = tracker.latest_message.get("text")
        if not user_message:
            dispatcher.utter_message(text="Le message est vide ou invalide.")
            return []

        try:
            # Charger un pipeline pré-entraîné pour l'analyse de sentiments
            sentiment_analyzer = pipeline("sentiment-analysis", model="bert-base-uncased-finetuned-sst-2-english")
            sentiment = sentiment_analyzer(user_message)[0]

            # Envoyer le sentiment détecté et son score de confiance à l'utilisateur
            dispatcher.utter_message(
                text=f"Sentiment détecté : {sentiment['label']} (Score : {sentiment['score']:.2f})"
            )

            # Optionnel : stocker le sentiment dans un slot pour un usage futur
            return [SlotSet("sentiment", sentiment["label"])]

        except Exception as e:
            # Loguer l'erreur et informer l'utilisateur
            logger.error(f"Erreur dans l'analyse des sentiments : {e}")
            dispatcher.utter_message(text="Erreur lors de l'analyse des sentiments.")
            return []



class ActionMathOperations(Action):
    def name(self) -> str:
        return "action_math_operations"

    def identify_operation(self, user_message: str) -> str:
        """
        Identifie l'opération mathématique demandée à partir du message utilisateur.
        """
        operations = {
            "addition": ["plus", "addition"],
            "soustraction": ["moins", "soustraction"],
            "multiplication": ["multiplie", "fois", "multiplication"],
            "division": ["divise", "division"],
            "puissance": ["puissance", "exposant"],
            "modulo": ["modulo"],
            "racine carrée": ["racine carrée", "sqrt"],
            "logarithme": ["logarithme", "log"],
            "factorielle": ["factorielle"]
        }

        for operation, keywords in operations.items():
            if any(keyword in user_message for keyword in keywords):
                return operation
        return ""

    def perform_operation(self, operation: str, number1: float, number2: float = None) -> str:
        """
        Effectue l'opération mathématique spécifiée.

        Args:
            operation (str): Type d'opération.
            number1 (float): Premier nombre.
            number2 (float, optional): Deuxième nombre.

        Returns:
            str: Résultat ou message d'erreur.
        """
        try:
            if operation == "addition":
                return f"{number1 + number2:.2f}"
            elif operation == "soustraction":
                return f"{number1 - number2:.2f}"
            elif operation == "multiplication":
                return f"{number1 * number2:.2f}"
            elif operation == "division":
                if number2 == 0:
                    return "Erreur : division par zéro."
                return f"{number1 / number2:.2f}"
            elif operation == "puissance":
                return f"{number1 ** number2:.2f}"
            elif operation == "modulo":
                if number2 == 0:
                    return "Erreur : modulo par zéro."
                return f"{number1 % number2:.2f}"
            elif operation == "racine carrée":
                if number1 < 0:
                    return "Erreur : racine carrée d'un nombre négatif."
                return f"{math.sqrt(number1):.2f}"
            elif operation == "logarithme":
                if number1 <= 0 or (number2 is not None and number2 <= 0):
                    return "Erreur : logarithme d'un nombre négatif ou base invalide."
                base = number2 if number2 else math.e
                return f"{math.log(number1, base):.2f}"
            elif operation == "factorielle":
                if number1 < 0 or not float(number1).is_integer():
                    return "Erreur : factorielle d'un nombre négatif ou non entier."
                return f"{math.factorial(int(number1))}"
            else:
                return "Je n'ai pas compris l'opération demandée."
        except Exception as e:
            return f"Une erreur s'est produite lors du calcul : {str(e)}"

    def run(
        self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        # Récupération des données utilisateur
        user_message = tracker.latest_message.get("text", "").lower()
        number1 = tracker.get_slot("number1")
        number2 = tracker.get_slot("number2")

        # Vérification des données nécessaires
        if number1 is None:
            dispatcher.utter_message(text="Veuillez fournir au moins un nombre pour effectuer le calcul.")
            return []

        # Identifier l'opération
        operation = self.identify_operation(user_message)
        if not operation:
            dispatcher.utter_message(text="Je n'ai pas compris l'opération que vous voulez effectuer.")
            return []

        # Effectuer l'opération
        result = self.perform_operation(operation, number1, number2)

        # Envoyer le résultat
        dispatcher.utter_message(
            text=f"Le résultat de l'opération {operation} est : {result}" if "Erreur" not in result else result
        )

        return []

class PredictiveInsightGenerator(Action):
    def name(self) -> str:
        return "action_predictive_insight_generator"

    def train_model(self) -> LinearRegression:
        """
        Entraîne un modèle simple de régression linéaire.
        Dans une application réelle, le modèle pourrait être chargé depuis un fichier pré-entraîné.
        """
        # Exemple de données fictives
        data = pd.DataFrame({
            "feature_1": [1, 2, 3, 4, 5],
            "feature_2": [10, 20, 30, 40, 50],
            "target": [100, 200, 300, 400, 500]
        })

        # Entraîner un modèle de régression linéaire
        model = LinearRegression()
        model.fit(data[["feature_1", "feature_2"]], data["target"])
        return model

    def validate_features(self, feature_1: Any, feature_2: Any) -> bool:
        """
        Valide les entrées utilisateur pour s'assurer qu'elles sont des nombres.
        """
        try:
            float(feature_1)
            float(feature_2)
            return True
        except (TypeError, ValueError):
            return False

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Charger ou entraîner le modèle
        model = self.train_model()

        # Extraire les données utilisateur
        feature_1 = tracker.get_slot("feature_1")
        feature_2 = tracker.get_slot("feature_2")

        # Valider les entrées utilisateur
        if not self.validate_features(feature_1, feature_2):
            dispatcher.utter_message(text="Les données fournies ne sont pas valides. Assurez-vous de fournir des nombres.")
            return []

        # Convertir les données en float
        feature_1 = float(feature_1)
        feature_2 = float(feature_2)

        # Effectuer une prédiction
        try:
            prediction = model.predict([[feature_1, feature_2]])[0]
        except Exception as e:
            dispatcher.utter_message(
                text=f"Une erreur est survenue lors de la prédiction : {str(e)}."
            )
            return []

        # Retourner la prédiction à l'utilisateur
        dispatcher.utter_message(
            text=f"Basé sur vos données ({feature_1}, {feature_2}), la prédiction est : {prediction:.2f}."
        )
        return []

class AnomalyDetector(Action):
    def name(self) -> str:
        return "action_anomaly_detector"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        # Extraire les données utilisateur à partir des slots
        raw_data = tracker.get_slot("data_points")

        if not raw_data:
            dispatcher.utter_message(text="Je n'ai pas reçu de données à analyser. Veuillez fournir vos points de données.")
            return []

        try:
            # Convertir les données utilisateur en liste
            data = np.array(ast.literal_eval(raw_data))  # Exemple : "[[10, 20], [12, 21], [1000, 2000]]"
            if data.ndim == 1:  # Si les données sont 1D, les transformer en 2D
                data = data.reshape(-1, 1)

            # Appliquer Isolation Forest pour détecter les anomalies
            model = IsolationForest(contamination=0.1, random_state=42)
            predictions = model.fit_predict(data)

            # Identifier les anomalies
            anomalies = data[predictions == -1]
            anomalies_list = anomalies.tolist()

            if len(anomalies_list) == 0:
                dispatcher.utter_message(text="Aucune anomalie n'a été détectée dans vos données.")
            else:
                dispatcher.utter_message(
                    text=f"J'ai détecté des anomalies dans vos données : {anomalies_list}"
                )

        except Exception as e:
            dispatcher.utter_message(
                text=f"Une erreur s'est produite lors de l'analyse des anomalies : {str(e)}"
            )

        return []


class StatisticalSummaryGenerator(Action):
    def name(self) -> str:
        return "action_statistical_summary_generator"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Extraire les données utilisateur
        raw_data = tracker.get_slot("numeric_data")

        if not raw_data:
            dispatcher.utter_message(
                text="Je n'ai pas reçu de données à analyser. Veuillez fournir une liste de nombres.")
            return []

        try:
            # Convertir les données utilisateur en une liste de nombres
            data = np.array(ast.literal_eval(raw_data))  # Exemple : "[10, 12, 23, 23, 17, 19, 23, 29, 31]"

            # Vérifier si les données sont valides
            if data.size == 0:
                dispatcher.utter_message(
                    text="Les données fournies sont vides. Veuillez fournir une liste valide de nombres.")
                return []

            if not np.issubdtype(data.dtype, np.number):
                dispatcher.utter_message(text="Les données doivent être numériques. Veuillez réessayer.")
                return []

            # Calculer les statistiques descriptives
            mean = np.mean(data)
            median = np.median(data)
            std_dev = np.std(data)
            quartiles = np.percentile(data, [25, 50, 75])
            min_val = np.min(data)
            max_val = np.max(data)

            # Identifier les valeurs aberrantes (par méthode des IQR)
            q1, q3 = quartiles[0], quartiles[2]
            iqr = q3 - q1
            lower_bound = q1 - 1.5 * iqr
            upper_bound = q3 + 1.5 * iqr
            outliers = data[(data < lower_bound) | (data > upper_bound)]

            # Générer une visualisation des données
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "statistical_summary_visualization.png")

            plt.figure(figsize=(8, 5))
            plt.boxplot(data, vert=False, patch_artist=True, boxprops=dict(facecolor="lightblue"))
            plt.title("Distribution des données")
            plt.xlabel("Valeurs")
            plt.savefig(file_path)
            plt.close()

            # Construire la réponse
            summary = (
                f"Voici les statistiques des données fournies :\n"
                f"- Moyenne : {mean:.2f}\n"
                f"- Médiane : {median:.2f}\n"
                f"- Écart-type : {std_dev:.2f}\n"
                f"- Min : {min_val}, Max : {max_val}\n"
                f"- Quartiles : Q1={quartiles[0]}, Q2={quartiles[1]}, Q3={quartiles[2]}\n"
            )

            if len(outliers) > 0:
                summary += f"- Valeurs aberrantes détectées : {list(outliers)}\n"
            else:
                summary += "- Aucune valeur aberrante détectée.\n"

            dispatcher.utter_message(text=summary)
            dispatcher.utter_message(
                text=f"Une visualisation de la distribution a été générée et sauvegardée : {file_path}")

        except ValueError as ve:
            dispatcher.utter_message(
                text=f"Les données fournies ne sont pas valides. Veuillez fournir une liste de nombres. Détail : {str(ve)}")
        except Exception as e:
            dispatcher.utter_message(text=f"Une erreur s'est produite lors de l'analyse des données : {str(e)}")

        return []

class ClusterVisualizer(Action):
    def name(self) -> str:
        return "action_cluster_visualizer"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Extraire les données utilisateur
        raw_data = tracker.get_slot("clustering_data")
        n_clusters = tracker.get_slot("n_clusters") or 2  # Nombre de clusters par défaut : 2

        if not raw_data:
            dispatcher.utter_message(text="Je n'ai pas reçu de données à analyser. Veuillez fournir une liste de points.")
            return []

        try:
            # Convertir les données utilisateur en un tableau numpy
            data = np.array(ast.literal_eval(raw_data))  # Exemple : "[[1, 2], [2, 3], [8, 9], [10, 11]]"

            # Vérifier si les données sont valides
            if data.ndim != 2 or data.shape[0] < n_clusters:
                dispatcher.utter_message(text="Les données doivent être une liste de points avec au moins autant de points que de clusters.")
                return []

            # Réduction des dimensions si nécessaire
            if data.shape[1] > 2:
                dispatcher.utter_message(text="Réduction des dimensions pour visualiser les clusters...")
                reducer = PCA(n_components=2)
                reduced_data = reducer.fit_transform(data)
            else:
                reduced_data = data

            # Appliquer KMeans pour le clustering
            n_clusters = int(n_clusters)
            model = KMeans(n_clusters=n_clusters, random_state=42)
            labels = model.fit_predict(reduced_data)

            # Générer un graphique des clusters
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "cluster_visualization.png")

            plt.figure(figsize=(8, 6))
            plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=labels, cmap="viridis", s=50, alpha=0.8)
            plt.title(f"Clustering avec {n_clusters} clusters")
            plt.xlabel("Dimension 1")
            plt.ylabel("Dimension 2")
            plt.colorbar(label="Cluster")
            plt.savefig(file_path)
            plt.close()

            # Construire la réponse
            dispatcher.utter_message(
                text=f"Clustering effectué avec succès ! Les données ont été regroupées en {n_clusters} clusters."
            )
            dispatcher.utter_message(
                text=f"Un graphique des clusters a été généré et sauvegardé : {file_path}"
            )

        except ValueError as ve:
            dispatcher.utter_message(text=f"Erreur dans les données fournies : {str(ve)}")
        except Exception as e:
            dispatcher.utter_message(
                text=f"Une erreur s'est produite lors du clustering : {str(e)}"
            )

        return []

class AdvancedDataInsightGenerator(Action):
    def name(self) -> str:
        return "action_advanced_data_insight_generator"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Récupérer les données utilisateur
        numeric_data = tracker.get_slot("numeric_data")
        data_series = tracker.get_slot("data_series")
        analysis_type = tracker.get_slot("analysis_type")

        # Analyse Statistique
        if analysis_type == "statistique" and numeric_data:
            return self.analyze_statistics(numeric_data, dispatcher)

        # Prévisions temporelles
        elif analysis_type == "prévision" and data_series:
            return self.forecast_time_series(data_series, dispatcher)

        # Détection des anomalies
        elif analysis_type == "anomalie" and numeric_data:
            return self.detect_anomalies(numeric_data, dispatcher)

        # Si aucun cas ne correspond
        dispatcher.utter_message(
            text="Je n'ai pas compris votre demande ou les données sont manquantes. Veuillez réessayer."
        )
        return []

    def analyze_statistics(self, numeric_data: str, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Analyse statistique des données numériques."""
        try:
            data = np.array(ast.literal_eval(numeric_data))

            if data.size == 0:
                dispatcher.utter_message(text="Les données fournies sont vides. Veuillez fournir une liste de nombres.")
                return []

            # Calcul des statistiques descriptives
            mean = np.mean(data)
            median = np.median(data)
            std_dev = np.std(data)
            variance = np.var(data)
            min_val = np.min(data)
            max_val = np.max(data)
            quartiles = np.percentile(data, [25, 50, 75])

            # Résumé des statistiques
            summary = (
                f"Voici les statistiques des données fournies :\n"
                f"- Moyenne : {mean:.2f}\n"
                f"- Médiane : {median:.2f}\n"
                f"- Écart-type : {std_dev:.2f}\n"
                f"- Variance : {variance:.2f}\n"
                f"- Min : {min_val}, Max : {max_val}\n"
                f"- Quartiles : Q1={quartiles[0]}, Q2={quartiles[1]}, Q3={quartiles[2]}\n"
            )

            # Générer un graphique
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "statistics_visualization.png")
            plt.figure(figsize=(8, 5))
            plt.boxplot(data, vert=False, patch_artist=True, boxprops=dict(facecolor="lightblue"))
            plt.title("Distribution des données")
            plt.xlabel("Valeurs")
            plt.savefig(file_path)
            plt.close()

            dispatcher.utter_message(text=summary)
            dispatcher.utter_message(
                text=f"Un graphique illustrant la distribution des données a été sauvegardé : {file_path}"
            )

        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de l'analyse statistique : {str(e)}")

        return []

    def forecast_time_series(self, data_series: str, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Prévision de séries temporelles."""
        try:
            # Convertir les données utilisateur en DataFrame
            data = pd.DataFrame(ast.literal_eval(data_series), columns=["ds", "y"])
            data["ds"] = pd.to_datetime(data["ds"])

            # Construire le modèle Prophet
            model = Prophet()
            model.fit(data)

            # Faire une prédiction pour les 7 prochains jours
            future = model.make_future_dataframe(periods=7)
            forecast = model.predict(future)

            # Extraire les prévisions
            predictions = forecast[["ds", "yhat"]].tail(7)

            # Générer un graphique
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "forecast_visualization.png")
            fig = model.plot(forecast)
            plt.title("Prévisions pour les 7 prochains jours")
            plt.savefig(file_path)
            plt.close()

            dispatcher.utter_message(text=f"Voici les prévisions pour les 7 prochains jours :\n{predictions.to_string(index=False)}")
            dispatcher.utter_message(
                text=f"Un graphique des prévisions a été généré et sauvegardé : {file_path}"
            )

        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de la prévision des séries temporelles : {str(e)}")

        return []

    def detect_anomalies(self, numeric_data: str, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Détection des anomalies dans les données numériques."""
        try:
            data = np.array(ast.literal_eval(numeric_data))

            if data.size == 0:
                dispatcher.utter_message(text="Les données fournies sont vides. Veuillez fournir une liste de nombres.")
                return []

            # Appliquer Isolation Forest pour détecter les anomalies
            model = IsolationForest(contamination=0.1, random_state=42)
            predictions = model.fit_predict(data.reshape(-1, 1))

            # Identifier les anomalies
            anomalies = data[predictions == -1]
            anomalies_list = anomalies.tolist()

            if len(anomalies_list) == 0:
                dispatcher.utter_message(text="Aucune anomalie détectée dans vos données.")
            else:
                dispatcher.utter_message(text=f"Anomalies détectées : {anomalies_list}")

            # Générer un graphique
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "anomaly_detection.png")
            plt.figure(figsize=(8, 5))
            plt.scatter(range(len(data)), data, c=(predictions == -1), cmap="coolwarm", s=50)
            plt.title("Détection des anomalies")
            plt.xlabel("Index")
            plt.ylabel("Valeur")
            plt.savefig(file_path)
            plt.close()

            dispatcher.utter_message(
                text=f"Un graphique des anomalies détectées a été sauvegardé : {file_path}"
            )

        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de la détection des anomalies : {str(e)}")

        return []

class FeatureImportanceExplainer(Action):
    def name(self) -> str:
        return "action_feature_importance_explainer"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Récupérer les données utilisateur
        raw_data = tracker.get_slot("input_features")
        target_variable = tracker.get_slot("target_variable")
        model_type = tracker.get_slot("model_type") or "random_forest"

        if not raw_data or not target_variable:
            dispatcher.utter_message(text="Je n'ai pas reçu de données suffisantes pour effectuer l'analyse. Fournissez les caractéristiques et la variable cible.")
            return []

        try:
            # Convertir les données utilisateur en DataFrame
            data = pd.DataFrame(ast.literal_eval(raw_data))

            if target_variable not in data.columns:
                dispatcher.utter_message(text=f"La variable cible '{target_variable}' n'est pas présente dans les données fournies.")
                return []

            features = data.drop(columns=[target_variable])
            target = data[target_variable]

            # Vérifier qu'il y a au moins deux colonnes
            if features.shape[1] < 1:
                dispatcher.utter_message(text="Les données doivent contenir au moins une caractéristique pour effectuer l'analyse.")
                return []

            # Construire le modèle
            if model_type == "linear_regression":
                model = LinearRegression()
            elif model_type == "random_forest":
                model = RandomForestRegressor(random_state=42)
            else:
                dispatcher.utter_message(text=f"Modèle '{model_type}' non pris en charge. Utilisez 'linear_regression' ou 'random_forest'.")
                return []

            model.fit(features, target)

            # Appliquer SHAP pour expliquer les prédictions
            explainer = shap.Explainer(model, features)
            shap_values = explainer(features)

            # Créer un répertoire pour sauvegarder les visualisations
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)

            # Générer des graphiques SHAP
            bar_plot_path = os.path.join(output_dir, "feature_importance_bar.png")
            summary_plot_path = os.path.join(output_dir, "feature_importance_summary.png")

            shap.summary_plot(shap_values, features, plot_type="bar", show=False)
            plt.savefig(bar_plot_path)
            plt.close()

            shap.summary_plot(shap_values, features, show=False)
            plt.savefig(summary_plot_path)
            plt.close()

            # Résumé des explications
            feature_importance = pd.DataFrame({
                "Feature": features.columns,
                "Importance": np.abs(shap_values.values).mean(axis=0)
            }).sort_values(by="Importance", ascending=False)

            summary = (
                f"Analyse terminée ! Voici les caractéristiques les plus importantes pour prédire '{target_variable}' :\n"
                f"{feature_importance.head(5).to_string(index=False)}\n\n"
                f"Deux graphiques ont été générés pour explorer plus en détail :\n"
                f"- '{bar_plot_path}' : Importances moyennes des variables.\n"
                f"- '{summary_plot_path}' : Distribution des impacts SHAP sur les prédictions."
            )

            dispatcher.utter_message(text=summary)

        except ValueError as ve:
            dispatcher.utter_message(text=f"Erreur dans les données fournies : {str(ve)}")
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de l'analyse des caractéristiques : {str(e)}")

        return []

class UltimateDataAnalyzer(Action):
    def name(self) -> str:
        return "action_ultimate_data_analyzer"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Extraire les données utilisateur
        data_input = tracker.get_slot("data_input")
        analysis_goal = tracker.get_slot("analysis_goal") or "exploration"
        prediction_target = tracker.get_slot("prediction_target")
        model_type = tracker.get_slot("model_type") or "random_forest"

        if not data_input:
            dispatcher.utter_message(text="Je n'ai pas reçu de données à analyser. Veuillez fournir vos données.")
            return []

        try:
            # Convertir les données utilisateur
            data = pd.DataFrame(ast.literal_eval(data_input))

            # Vérifier l'objectif de l'analyse
            if analysis_goal == "exploration":
                return self.perform_eda(data, dispatcher)
            elif analysis_goal == "anomalie":
                return self.detect_anomalies(data, dispatcher)
            elif analysis_goal == "prévision" and {"ds", "y"}.issubset(data.columns):
                return self.forecast_time_series(data, dispatcher)
            elif analysis_goal == "prédiction" and prediction_target:
                return self.predict_with_explanation(data, prediction_target, model_type, dispatcher)
            else:
                dispatcher.utter_message(text="Je n'ai pas compris votre demande. Veuillez préciser votre objectif.")
                return []

        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors du traitement : {str(e)}")
            return []

    def perform_eda(self, data: pd.DataFrame, dispatcher: CollectingDispatcher):
        """Analyse exploratoire des données."""
        try:
            description = data.describe().to_string()
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "pairplot.png")

            sns.pairplot(data)
            plt.savefig(file_path)
            plt.close()

            dispatcher.utter_message(
                text=f"Analyse exploratoire effectuée. Voici un résumé :\n{description}\nUn graphique des relations a été sauvegardé sous '{file_path}'."
            )
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de l'analyse exploratoire : {str(e)}")
        return []

    def detect_anomalies(self, data: pd.DataFrame, dispatcher: CollectingDispatcher):
        """Détection des anomalies avec Isolation Forest."""
        try:
            reshaped_data = data.values.reshape(-1, 1) if data.shape[1] == 1 else data.values
            model = IsolationForest(contamination=0.1, random_state=42)
            predictions = model.fit_predict(reshaped_data)
            anomalies = data[predictions == -1]

            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "anomalies.png")

            sns.scatterplot(x=data.index, y=data.values[:, 0], hue=predictions, palette="coolwarm", s=50)
            plt.title("Détection des anomalies")
            plt.savefig(file_path)
            plt.close()

            if anomalies.empty:
                dispatcher.utter_message(text="Aucune anomalie détectée.")
            else:
                dispatcher.utter_message(
                    text=f"Anomalies détectées :\n{anomalies.to_string()}\nUn graphique a été sauvegardé sous '{file_path}'."
                )
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de la détection des anomalies : {str(e)}")
        return []

    def forecast_time_series(self, data: pd.DataFrame, dispatcher: CollectingDispatcher):
        """Prévisions temporelles avec Prophet."""
        try:
            model = Prophet()
            model.fit(data)
            future = model.make_future_dataframe(periods=7)
            forecast = model.predict(future)

            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "forecast.png")

            fig = model.plot(forecast)
            plt.title("Prévisions pour les 7 prochains jours")
            plt.savefig(file_path)
            plt.close()

            dispatcher.utter_message(
                text=f"Prévisions effectuées. Un graphique des prévisions a été sauvegardé sous '{file_path}'."
            )
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de la prévision des séries temporelles : {str(e)}")
        return []

    def predict_with_explanation(self, data: pd.DataFrame, target: str, model_type: str, dispatcher: CollectingDispatcher):
        """Prédictions avec explicabilité (SHAP)."""
        try:
            features = data.drop(columns=[target])
            target_data = data[target]

            if model_type == "random_forest":
                model = RandomForestRegressor(random_state=42)
            elif model_type == "linear_regression":
                model = LinearRegression()
            else:
                dispatcher.utter_message(text=f"Modèle {model_type} non pris en charge.")
                return []

            model.fit(features, target_data)

            explainer = shap.Explainer(model, features)
            shap_values = explainer(features)

            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "shap_bar.png")

            shap.summary_plot(shap_values, features, plot_type="bar", show=False)
            plt.savefig(file_path)
            plt.close()

            dispatcher.utter_message(
                text=f"Prédictions et analyse des caractéristiques effectuées. Un graphique explicatif a été sauvegardé sous '{file_path}'."
            )
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de l'analyse des caractéristiques : {str(e)}")
        return []

class AutomatedDataPipeline(Action):
    def name(self) -> str:
        return "action_automated_data_pipeline"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Récupérer les données utilisateur
        pipeline_data = tracker.get_slot("pipeline_data")
        target_variable = tracker.get_slot("target_variable")
        analysis_goal = tracker.get_slot("analysis_goal")
        export_format = tracker.get_slot("export_format") or "PDF"

        if not pipeline_data:
            dispatcher.utter_message(text="Je n'ai pas reçu de données pour le pipeline. Veuillez fournir vos données.")
            return []

        try:
            # Convertir les données utilisateur
            data = pd.DataFrame(ast.literal_eval(pipeline_data))

            # Créer un répertoire pour les visualisations
            output_dir = "pipeline_visualizations"
            os.makedirs(output_dir, exist_ok=True)

            # Étape 1 : Analyse exploratoire
            self.perform_eda(data, output_dir)

            # Étape 2 : Détection des anomalies
            anomalies = self.detect_anomalies(data, output_dir)

            # Étape 3 : Prédictions ou prévisions
            predictions = None
            if analysis_goal == "prévision" and {"ds", "y"}.issubset(data.columns):
                predictions = self.forecast_time_series(data, output_dir)
            elif analysis_goal == "prédiction" and target_variable:
                predictions = self.predict_with_explanation(data, target_variable, output_dir)

            # Étape 4 : Générer un rapport
            report_path = self.generate_report(data, anomalies, predictions, export_format, output_dir)

            dispatcher.utter_message(
                text=f"Pipeline terminé avec succès ! Le rapport consolidé a été généré : {report_path}"
            )
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors du pipeline : {str(e)}")
        return []

    def perform_eda(self, data: pd.DataFrame, output_dir: str):
        """Analyse exploratoire des données."""
        try:
            sns.pairplot(data)
            eda_path = os.path.join(output_dir, "pairplot.png")
            plt.savefig(eda_path)
            plt.close()
        except Exception as e:
            print(f"Erreur dans l'analyse exploratoire : {str(e)}")

    def detect_anomalies(self, data: pd.DataFrame, output_dir: str):
        """Détection des anomalies avec Isolation Forest."""
        try:
            model = IsolationForest(contamination=0.1, random_state=42)
            predictions = model.fit_predict(data.values)
            anomalies = data[predictions == -1]

            anomaly_path = os.path.join(output_dir, "anomalies.png")
            sns.scatterplot(x=range(len(data)), y=data.values[:, 0], hue=predictions, palette="coolwarm", s=50)
            plt.savefig(anomaly_path)
            plt.close()
            return anomalies
        except Exception as e:
            print(f"Erreur lors de la détection des anomalies : {str(e)}")
            return None

    def forecast_time_series(self, data: pd.DataFrame, output_dir: str):
        """Prévisions temporelles avec Prophet."""
        try:
            model = Prophet()
            model.fit(data)
            future = model.make_future_dataframe(periods=7)
            forecast = model.predict(future)

            forecast_path = os.path.join(output_dir, "forecast.png")
            model.plot(forecast)
            plt.savefig(forecast_path)
            plt.close()
            return forecast[["ds", "yhat"]].tail(7)
        except Exception as e:
            print(f"Erreur dans les prévisions temporelles : {str(e)}")
            return None

    def predict_with_explanation(self, data: pd.DataFrame, target: str, output_dir: str):
        """Prédictions avec explicabilité (SHAP)."""
        try:
            features = data.drop(columns=[target])
            target_data = data[target]
            model = RandomForestRegressor(random_state=42)
            model.fit(features, target_data)
            explainer = shap.Explainer(model, features)
            shap_values = explainer(features)

            shap_path = os.path.join(output_dir, "shap_bar.png")
            shap.summary_plot(shap_values, features, plot_type="bar", show=False)
            plt.savefig(shap_path)
            plt.close()
            return shap_values
        except Exception as e:
            print(f"Erreur dans les prédictions explicables : {str(e)}")
            return None

    def generate_report(self, data, anomalies, predictions, export_format, output_dir):
        """Générer un rapport consolidé."""
        try:
            if export_format.lower() == "pdf":
                pdf = FPDF()
                pdf.add_page()
                pdf.set_font("Arial", size=12)

                pdf.cell(200, 10, txt="Rapport Consolidé", ln=True, align="C")
                pdf.ln(10)

                # Section 1 : Analyse exploratoire
                pdf.cell(200, 10, txt="1. Analyse Exploratoire", ln=True)
                eda_path = os.path.join(output_dir, "pairplot.png")
                pdf.image(eda_path, x=10, y=40, w=180)

                # Section 2 : Détection des anomalies
                pdf.add_page()
                pdf.cell(200, 10, txt="2. Détection des Anomalies", ln=True)
                anomaly_path = os.path.join(output_dir, "anomalies.png")
                pdf.image(anomaly_path, x=10, y=40, w=180)

                # Section 3 : Prédictions
                if predictions is not None:
                    pdf.add_page()
                    pdf.cell(200, 10, txt="3. Prédictions", ln=True)
                    forecast_path = os.path.join(output_dir, "forecast.png")
                    pdf.image(forecast_path, x=10, y=40, w=180)

                # Sauvegarder le fichier PDF
                report_path = os.path.join(output_dir, "pipeline_report.pdf")
                pdf.output(report_path)
                return report_path

            # Formats CSV ou autres peuvent être ajoutés ici
        except Exception as e:
            print(f"Erreur lors de la génération du rapport : {str(e)}")
            return None

class LanguageProcessor:
    """
    Gère la détection, la traduction et la gestion multilingue.
    """

    def __init__(self, target_language: str = "en"):
        """
        Initialise le gestionnaire multilingue.

        Args:
            target_language (str): Langue cible pour la traduction.
        """
        self.translator = Translator()
        self.target_language = target_language

    def detect_language(self, text: str) -> str:
        """
        Détecte la langue d'un texte.

        Args:
            text (str): Texte brut.

        Returns:
            str: Code ISO de la langue détectée.
        """
        try:
            return self.translator.detect(text).lang
        except Exception as e:
            return "unknown"

    def translate_to_target(self, text: str, source_language: str = None) -> str:
        """
        Traduit un texte vers la langue cible.

        Args:
            text (str): Texte brut.
            source_language (str): Langue source (optionnel).

        Returns:
            str: Texte traduit.
        """
        try:
            translated = self.translator.translate(text, src=source_language, dest=self.target_language)
            return translated.text
        except Exception as e:
            return text

    def process(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """
        Traduit une requête complète dans la langue cible.

        Args:
            request (Dict[str, Any]): Requête utilisateur.

        Returns:
            Dict[str, Any]: Requête traitée.
        """
        if "text" in request:
            source_language = self.detect_language(request["text"])
            request["text"] = self.translate_to_target(request["text"], source_language)
            request["source_language"] = source_language
        return request

class TestSuite:
    """
    Suite de tests pour valider les actions et pipelines.
    """

    def __init__(self, orchestrator, test_cases: List[Dict[str, Any]]):
        """
        Initialise la suite de tests.

        Args:
            orchestrator: Orchestrateur global à tester.
            test_cases (List[Dict[str, Any]]): Cas de test.
        """
        self.orchestrator = orchestrator
        self.test_cases = test_cases

    def run_tests(self) -> Dict[str, Any]:
        """
        Exécute tous les tests et retourne les résultats.

        Returns:
            Dict[str, Any]: Résultats des tests.
        """
        results = {}
        for idx, test_case in enumerate(self.test_cases):
            try:
                response = self.orchestrator.process_request(test_case["input"])
                results[f"Test {idx + 1}"] = {
                    "input": test_case["input"],
                    "expected_output": test_case["expected_output"],
                    "actual_output": response,
                    "success": response == test_case["expected_output"],
                }
            except Exception as e:
                results[f"Test {idx + 1}"] = {"error": str(e), "success": False}
        return results
class PipelineOrchestrator:
    """
    Orchestration des pipelines utilisateur, actions et résultats.
    """

    def __init__(self, actions: Dict[str, Any], cache_manager=None, language_processor=None):
        """
        Initialise l'orchestrateur.

        Args:
            actions (Dict[str, Any]): Actions disponibles dans le système.
            cache_manager: Gestionnaire de cache pour optimiser les appels.
            language_processor: Gestionnaire multilingue (optionnel).
        """
        self.actions = actions
        self.cache_manager = cache_manager
        self.language_processor = language_processor

    def process_request(self, user_request: Dict[str, Any]) -> Dict[str, Any]:
        """
        Gère une requête utilisateur.

        Args:
            user_request (Dict[str, Any]): Détails de la requête utilisateur.

        Returns:
            Dict[str, Any]: Résultats de la requête.
        """
        try:
            action_name = user_request.get("action")
            if not action_name or action_name not in self.actions:
                raise ValueError(f"Action inconnue : {action_name}")

            # Gestion du cache si activé
            cache_key = f"user_{user_request['user_id']}_action_{action_name}"
            if self.cache_manager:
                cached_result = self.cache_manager.get(cache_key)
                if cached_result:
                    return cached_result

            # Prétraitement multilingue
            if self.language_processor:
                user_request = self.language_processor.process(user_request)

            # Appel de l'action demandée
            result = self.actions[action_name].run(user_request)

            # Sauvegarde dans le cache
            if self.cache_manager:
                self.cache_manager.set(cache_key, result)

            return result
        except Exception as e:
            return {"error": f"Erreur lors du traitement de la requête : {e}"}

class DynamicPipelineOrchestrator(Action):
    def name(self) -> str:
        return "action_dynamic_pipeline_orchestrator"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        raw_data = tracker.get_slot("raw_data")
        auto_detect = tracker.get_slot("auto_detect") or True

        if not raw_data:
            dispatcher.utter_message(text="Aucune donnée fournie. Veuillez fournir vos données.")
            return []

        try:
            # Convertir les données utilisateur
            data = pd.DataFrame(ast.literal_eval(raw_data))

            # Étape 1 : Détection automatique des données
            if auto_detect:
                analysis_plan = self.auto_detect_pipeline(data)
                dispatcher.utter_message(text=f"Pipeline détecté automatiquement : {analysis_plan}")

            # Étape 2 : Exécution des étapes du pipeline
            results = self.execute_pipeline(data, analysis_plan)
            dispatcher.utter_message(text=f"Pipeline terminé avec succès. Résultats : {results}")

        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors du pipeline dynamique : {str(e)}")
        return []

    def auto_detect_pipeline(self, data: pd.DataFrame) -> dict:
        """Détecte automatiquement les besoins en fonction des données."""
        plan = {}
        if "ds" in data.columns and "y" in data.columns:
            plan["step"] = "forecast"
        elif data.dtypes.value_counts().get("object", 0) > 0:
            plan["step"] = "categorical_analysis"
        elif data.select_dtypes(include=["number"]).shape[1] > 0:
            plan["step"] = "numerical_analysis"
        else:
            plan["step"] = "unsupervised_analysis"
        return plan

    def execute_pipeline(self, data: pd.DataFrame, plan: dict) -> dict:
        """Exécute les étapes du pipeline en fonction du plan."""
        if plan["step"] == "forecast":
            return self.forecast_time_series(data)
        elif plan["step"] == "categorical_analysis":
            return self.analyze_categorical(data)
        elif plan["step"] == "numerical_analysis":
            return self.analyze_numerical(data)
        elif plan["step"] == "unsupervised_analysis":
            return self.unsupervised_clustering(data)
        return {"error": "Plan non reconnu."}

    def forecast_time_series(self, data: pd.DataFrame) -> dict:
        """Prévisions temporelles."""
        model = Prophet()
        model.fit(data)
        future = model.make_future_dataframe(periods=7)
        forecast = model.predict(future)
        return forecast[["ds", "yhat"]].tail(7).to_dict()

    def analyze_categorical(self, data: pd.DataFrame) -> dict:
        """Analyse des données catégoriques."""
        encoded_data = {}
        for col in data.select_dtypes(include=["object"]).columns:
            encoder = LabelEncoder()
            encoded_data[col] = encoder.fit_transform(data[col]).tolist()
        return encoded_data

    def analyze_numerical(self, data: pd.DataFrame) -> dict:
        """Analyse des données numériques."""
        summary = data.describe().to_dict()
        scaler = StandardScaler()
        scaled_data = scaler.fit_transform(data.select_dtypes(include=["number"]))
        return {"summary": summary, "scaled_data": scaled_data.tolist()}

    def unsupervised_clustering(self, data: pd.DataFrame) -> dict:
        """Clustering non supervisé."""
        from sklearn.cluster import KMeans
        model = KMeans(n_clusters=3, random_state=42)
        clusters = model.fit_predict(data)
        return {"clusters": clusters.tolist()}
    
class IntelligentPipelineManager(Action):
    def name(self) -> str:
        return "action_intelligent_pipeline_manager"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Extraire les étapes du pipeline
        pipeline_steps = tracker.get_slot("pipeline_steps") or []
        user_feedback = tracker.get_slot("user_feedback")

        # Si l'utilisateur donne un feedback
        if user_feedback:
            pipeline_steps = self.modify_pipeline(pipeline_steps, user_feedback)
            dispatcher.utter_message(text=f"Pipeline mis à jour : {pipeline_steps}")
            return []

        # Si le pipeline est vide, recommander des étapes
        if not pipeline_steps:
            recommended_steps = self.recommend_pipeline_steps(tracker)
            dispatcher.utter_message(
                text=f"Voici les étapes recommandées pour vos données : {recommended_steps}\n"
                     f"Souhaitez-vous les modifier ?"
            )
            return []

        # Exécuter le pipeline
        try:
            results = self.execute_pipeline(pipeline_steps, tracker)
            dispatcher.utter_message(text=f"Pipeline exécuté avec succès. Résultats consolidés : {results}")
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de l'exécution du pipeline : {str(e)}")

        return []

    def recommend_pipeline_steps(self, tracker: Tracker) -> List[str]:
        """Recommande des étapes en fonction des données utilisateur."""
        raw_data = tracker.get_slot("raw_data")
        if not raw_data:
            return ["collect_data"]
        try:
            data = pd.DataFrame(ast.literal_eval(raw_data))
            steps = []
            if {"ds", "y"}.issubset(data.columns):
                steps.append("forecast_time_series")
            if data.select_dtypes(include=["number"]).shape[1] > 0:
                steps.extend(["detect_anomalies", "analyze_numerical"])
            if data.select_dtypes(include=["object"]).shape[1] > 0:
                steps.append("analyze_categorical")
            return steps
        except Exception:
            return ["collect_data"]

    def modify_pipeline(self, steps: List[str], feedback: str) -> List[str]:
        """Modifie le pipeline selon les retours utilisateur."""
        if "ajoute" in feedback or "ajouter" in feedback:
            if "anomalie" in feedback:
                steps.append("detect_anomalies")
            if "prévision" in feedback:
                steps.append("forecast_time_series")
        elif "supprime" in feedback or "retire" in feedback:
            if "anomalie" in feedback:
                steps = [step for step in steps if step != "detect_anomalies"]
            if "prévision" in feedback:
                steps = [step for step in steps if step != "forecast_time_series"]
        return steps

    def execute_pipeline(self, steps: List[str], tracker: Tracker) -> Dict[str, Any]:
        """Exécute les étapes du pipeline."""
        raw_data = tracker.get_slot("raw_data")
        if not raw_data:
            raise ValueError("Aucune donnée fournie pour exécuter le pipeline.")

        data = pd.DataFrame(ast.literal_eval(raw_data))
        results = {}
        for step in steps:
            if step == "forecast_time_series":
                results["forecast"] = self.forecast_time_series(data)
            elif step == "detect_anomalies":
                results["anomalies"] = self.detect_anomalies(data)
            elif step == "analyze_numerical":
                results["numerical_analysis"] = self.analyze_numerical(data)
            elif step == "analyze_categorical":
                results["categorical_analysis"] = self.analyze_categorical(data)
        return results

    def forecast_time_series(self, data: pd.DataFrame) -> Dict[str, Any]:
        """Prévisions temporelles."""
        try:
            model = Prophet()
            model.fit(data)
            future = model.make_future_dataframe(periods=7)
            forecast = model.predict(future)
            return forecast[["ds", "yhat"]].tail(7).to_dict(orient="records")
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la prévision des séries temporelles : {str(e)}")

    def detect_anomalies(self, data: pd.DataFrame) -> Dict[str, Any]:
        """Détection des anomalies."""
        try:
            model = IsolationForest(contamination=0.1, random_state=42)
            predictions = model.fit_predict(data.values)
            anomalies = data[predictions == -1]
            return anomalies.to_dict(orient="records")
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la détection des anomalies : {str(e)}")

    def analyze_numerical(self, data: pd.DataFrame) -> Dict[str, Any]:
        """Analyse des données numériques."""
        try:
            summary = data.describe().to_dict()
            return summary
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'analyse numérique : {str(e)}")

    def analyze_categorical(self, data: pd.DataFrame) -> Dict[str, Any]:
        """Analyse des données catégoriques."""
        try:
            encoded_data = {}
            for col in data.select_dtypes(include=["object"]).columns:
                encoder = LabelEncoder()
                encoded_data[col] = encoder.fit_transform(data[col]).tolist()
            return encoded_data
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'analyse catégorique : {str(e)}")

class RealTimeTranslator(Action):
    def name(self) -> str:
        return "action_real_time_translator"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        # Récupérer les slots nécessaires
        text_to_translate = tracker.get_slot("text_to_translate")
        target_language = tracker.get_slot("target_language") or "en"

        if not text_to_translate:
            dispatcher.utter_message(text="Je n'ai pas trouvé de texte à traduire. Peux-tu me le donner ?")
            return []

        if target_language not in LANGUAGES.keys():
            dispatcher.utter_message(
                text=f"La langue cible '{target_language}' n'est pas prise en charge. Veuillez en choisir une autre."
            )
            return []

        try:
            # Initialiser le traducteur
            translator = Translator()

            # Détecter la langue source
            detected_language = translator.detect(text_to_translate).lang
            if detected_language == target_language:
                dispatcher.utter_message(text="Le texte est déjà dans la langue cible.")
                return [SlotSet("translated_text", text_to_translate)]

            # Traduire le texte
            translated_text = translator.translate(text_to_translate, src=detected_language, dest=target_language).text

            # Retourner les informations à l'utilisateur
            dispatcher.utter_message(
                text=(
                    f"Texte détecté en langue '{LANGUAGES[detected_language]}'.\n"
                    f"Traduction en '{LANGUAGES[target_language]}': {translated_text}"
                )
            )
            return [
                SlotSet("translated_text", translated_text),
                SlotSet("detected_language", detected_language),
            ]

        except Exception as e:
            dispatcher.utter_message(text=f"Une erreur s'est produite lors de la traduction : {str(e)}")
            return []


class CustomKnowledgeBaseAnswerer(Action):
    def name(self) -> str:
        return "action_custom_knowledge_base_answerer"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Charger une base de données simulée
        data = {
            "Product": ["Laptop", "Phone", "Tablet"],
            "Price": [1000, 500, 300],
            "Stock": [50, 200, 150],
            "Description": [
                "Un ordinateur portable performant pour les professionnels.",
                "Un smartphone avec une excellente autonomie.",
                "Une tablette idéale pour les loisirs et la productivité.",
            ],
        }
        df = pd.DataFrame(data)

        # Extraire la requête de l’utilisateur
        query = tracker.get_slot("user_query")
        if not query:
            dispatcher.utter_message(text="Je n'ai pas compris votre question. Veuillez reformuler.")
            return []

        # Rechercher dans la base
        try:
            # Recherche intelligente (correspondance partielle sur le nom du produit)
            result = df[df["Product"].str.contains(query, case=False, na=False)].to_dict("records")

            # Si aucun résultat n'est trouvé
            if not result:
                dispatcher.utter_message(
                    text="Je n'ai trouvé aucun produit correspondant à votre requête. "
                         "Pouvez-vous préciser votre demande ?"
                )
                return []

            # Préparer une réponse formatée
            response = "Voici les informations disponibles :\n"
            for item in result:
                response += (
                    f"- **Produit** : {item['Product']}\n"
                    f"  - **Prix** : {item['Price']} €\n"
                    f"  - **Stock** : {item['Stock']} unités disponibles\n"
                    f"  - **Description** : {item['Description']}\n\n"
                )

            dispatcher.utter_message(text=response)

        except Exception as e:
            dispatcher.utter_message(text=f"Une erreur est survenue lors de la recherche : {str(e)}")

        return []


class MathCompetitionManager(Action):
    def name(self) -> str:
        return "action_math_competition_manager"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Récupérer le problème mathématique soumis par l'utilisateur
        math_problem = tracker.get_slot("math_problem")

        if not math_problem:
            dispatcher.utter_message(
                text="Je n'ai pas trouvé de problème mathématique à résoudre. Peux-tu m'en donner un ?"
            )
            return []

        try:
            # Analyser et valider le problème mathématique
            parsed_problem = sp.sympify(math_problem)
            result = None

            if isinstance(parsed_problem, sp.Equality):  # Équation
                solutions = sp.solve(parsed_problem)
                result = f"Les solutions de l'équation '{math_problem}' sont : {solutions}"
                slot_value = str(solutions)

            elif "Integral" in str(parsed_problem):  # Intégrale
                integral = sp.integrate(parsed_problem)
                result = f"L'intégrale de '{math_problem}' est : {integral}"
                slot_value = str(integral)

            elif "Derivative" in str(parsed_problem):  # Dérivée
                derivative = sp.diff(parsed_problem)
                result = f"La dérivée de '{math_problem}' est : {derivative}"
                slot_value = str(derivative)

            elif isinstance(parsed_problem, sp.Sum):  # Série
                summation = sp.summation(parsed_problem)
                result = f"La somme de la série '{math_problem}' est : {summation}"
                slot_value = str(summation)

            elif isinstance(parsed_problem, sp.Limit):  # Limite
                limit = sp.limit(parsed_problem)
                result = f"La limite de '{math_problem}' est : {limit}"
                slot_value = str(limit)

            else:  # Simplification ou évaluation d'une expression
                simplified_result = sp.simplify(parsed_problem)
                result = f"Le résultat de '{math_problem}' est : {simplified_result}"
                slot_value = str(simplified_result)

            dispatcher.utter_message(text=result)
            return [SlotSet("math_result", slot_value)]

        except sp.SympifyError:
            dispatcher.utter_message(
                text=(
                    "Je n'ai pas pu comprendre votre problème mathématique. "
                    "Assurez-vous qu'il est bien formulé avec des symboles valides. Exemple : x**2 + 2*x - 8 = 0"
                )
            )
            return []
        except Exception as e:
            dispatcher.utter_message(
                text=f"Une erreur est survenue lors de la résolution du problème mathématique : {str(e)}"
            )
            return []


class QuizCompetitionManager(Action):
    def name(self) -> str:
        return "action_quiz_competition_manager"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        # Exemple de questions (peut être extrait d'une base de données)
        questions = [
            {"question": "Quelle est la capitale de la France?", "answer": "Paris"},
            {"question": "Combien de continents y a-t-il?", "answer": "7"},
            {"question": "Quel est l'élément chimique dont le symbole est H?", "answer": "Hydrogène"},
            {"question": "En quelle année l'homme a-t-il marché sur la Lune?", "answer": "1969"},
            {"question": "Qui a peint la Joconde?", "answer": "Léonard de Vinci"},
        ]

        # Choisir une question aléatoire
        question = random.choice(questions)

        # Enregistrer la question et sa réponse correcte dans les slots
        dispatcher.utter_message(text=f"Voici une question : {question['question']}")
        return [
            SlotSet("current_quiz_question", question["question"]),
            SlotSet("current_quiz_answer", question["answer"]),
        ]

class ValidateQuizAnswer(Action):
    def name(self) -> str:
        return "action_validate_quiz_answer"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        user_answer = tracker.get_slot("user_answer")
        correct_answer = tracker.get_slot("current_quiz_answer")

        if not user_answer:
            dispatcher.utter_message(text="Je n'ai pas reçu ta réponse. Peux-tu la répéter?")
            return []

        if user_answer.lower() == correct_answer.lower():
            dispatcher.utter_message(text="Bravo! Ta réponse est correcte 🎉.")
            return [SlotSet("quiz_score", tracker.get_slot("quiz_score") + 1)]
        else:
            dispatcher.utter_message(
                text=f"Dommage, la réponse correcte était : {correct_answer}. On continue?"
            )
            return []

        return "action_strategy_competition_manager"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        # Exemple de jeu de type "X et O" (tic-tac-toe) ou autre jeu simple
        game_state = tracker.get_slot("game_state") or [" "]*9  # Plateau de jeu

        # Vérifier si le jeu est terminé
        winner = self.check_winner(game_state)
        if winner:
            dispatcher.utter_message(text=f"Le jeu est terminé ! Le gagnant est : {winner}.")
            return [SlotSet("game_state", game_state)]

        # Calculer le meilleur coup
        best_move = self.calculate_best_move(game_state)
        game_state[best_move] = "O"  # Le bot joue "O"
        dispatcher.utter_message(text=f"Je joue ma stratégie. Voici mon coup : {best_move}.")

        # Retourner l'état mis à jour
        return [SlotSet("game_state", game_state)]

    def check_winner(self, game_state):
        # Vérifie les lignes gagnantes dans le jeu
        winning_positions = [
            [0, 1, 2], [3, 4, 5], [6, 7, 8],  # Lignes
            [0, 3, 6], [1, 4, 7], [2, 5, 8],  # Colonnes
            [0, 4, 8], [2, 4, 6],            # Diagonales
        ]
        for line in winning_positions:
            if game_state[line[0]] == game_state[line[1]] == game_state[line[2]] != " ":
                return game_state[line[0]]  # Retourne "X" ou "O"
        return None

    def calculate_best_move(self, game_state):
        # Stratégie simple : choisir la première case vide
        for i in range(len(game_state)):
            if game_state[i] == " ":
                return i
        return None


class AdvancedStrategySimulator(Action):
    def name(self) -> str:
        return "action_advanced_strategy_simulator"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        # Récupérer l'état du jeu
        game_state = tracker.get_slot("game_state") or [" "] * 9  # Plateau 3x3
        player_symbol = "X"  # Joueur humain
        bot_symbol = "O"  # Bot

        # Vérifier si le jeu est terminé
        winner = self.check_winner(game_state)
        if winner:
            dispatcher.utter_message(text=f"Le jeu est terminé ! Le gagnant est : {winner}.")
            return [SlotSet("game_state", game_state)]

        # Calculer le meilleur coup avec l'algorithme Minimax
        best_move = self.minimax(game_state, bot_symbol)["position"]
        game_state[best_move] = bot_symbol
        dispatcher.utter_message(text=f"Je joue ma stratégie ! Voici mon coup : {best_move + 1}.")

        # Vérifier après le coup du bot
        winner_after_bot = self.check_winner(game_state)
        if winner_after_bot:
            dispatcher.utter_message(text=f"Le jeu est terminé ! Le gagnant est : {winner_after_bot}.")

        return [SlotSet("game_state", game_state)]

    def check_winner(self, game_state):
        # Vérifie les lignes gagnantes
        winning_positions = [
            [0, 1, 2], [3, 4, 5], [6, 7, 8],  # Lignes
            [0, 3, 6], [1, 4, 7], [2, 5, 8],  # Colonnes
            [0, 4, 8], [2, 4, 6],  # Diagonales
        ]
        for line in winning_positions:
            if game_state[line[0]] == game_state[line[1]] == game_state[line[2]] != " ":
                return game_state[line[0]]
        return None

    def minimax(self, game_state, current_symbol):
        opponent_symbol = "X" if current_symbol == "O" else "O"
        winner = self.check_winner(game_state)

        # Base : si le jeu est terminé
        if winner == "O":
            return {"score": 1}  # Bot gagne
        elif winner == "X":
            return {"score": -1}  # Joueur gagne
        elif " " not in game_state:
            return {"score": 0}  # Match nul

        # Initialiser les mouvements possibles
        moves = []
        for i in range(len(game_state)):
            if game_state[i] == " ":
                # Simuler le coup
                game_state[i] = current_symbol
                result = self.minimax(game_state, opponent_symbol)
                moves.append({"position": i, "score": result["score"]})
                game_state[i] = " "  # Annuler le coup simulé

        # Choisir le meilleur mouvement
        if current_symbol == "O":  # Maximiser pour le bot
            best_move = max(moves, key=lambda x: x["score"])
        else:  # Minimiser pour l'adversaire
            best_move = min(moves, key=lambda x: x["score"])
        return best_move

class CompetitorAnalyzer(Action):
    def name(self) -> str:
        return "action_competitor_analyzer"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        # Récupérer les données des compétiteurs (fichier CSV simulé)
        competitor_data_path = "data/competitors.csv"  # Remplace par ton fichier réel
        try:
            df = pd.read_csv(competitor_data_path)

            # Analyse des statistiques (exemple : score moyen et performance maximale)
            avg_score = df["score"].mean()
            max_performance = df["performance"].max()
            best_competitor = df.loc[df["performance"].idxmax(), "name"]

            strategy = f"Concentrez-vous sur les compétiteurs avec un score supérieur à {avg_score:.2f}. " \
                       f"Le meilleur compétiteur est {best_competitor} avec une performance de {max_performance}."

            dispatcher.utter_message(text=f"Analyse terminée : {strategy}")
            return [SlotSet("strategy_output", strategy)]
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de l'analyse : {str(e)}")
            return []
        
class PerformancePredictor(Action):
    def name(self) -> str:
        return "action_performance_predictor"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        # Récupérer les données utilisateur
        user_data = tracker.get_slot("user_data")
        if not user_data:
            dispatcher.utter_message(
                text="Je n'ai pas trouvé de données utilisateur pour effectuer une prédiction."
            )
            return []

        try:
            # Charger un modèle pré-entraîné (par ex., modèle hébergé ou intégré)
            pre_trained_model_path = "pretrained/performance_model.pkl"
            model = joblib.load(pre_trained_model_path)

            # Charger les données utilisateur dans un DataFrame
            user_df = pd.DataFrame([user_data])

            # Effectuer une prédiction
            prediction = model.predict(user_df)
            probability = model.predict_proba(user_df).max()

            # Retourner une prédiction avec explications
            if prediction[0] == 1:
                dispatcher.utter_message(
                    text=f"Félicitations ! Tes chances de succès sont élevées ({probability * 100:.2f}%). 🎉"
                )
            else:
                dispatcher.utter_message(
                    text=f"Tes chances de succès sont limitées ({probability * 100:.2f}%). "
                         f"Peut-être que tu peux t'améliorer avec plus de pratique."
                )
            return [SlotSet("performance_prediction", prediction[0])]

        except Exception as e:
            dispatcher.utter_message(
                text=f"Une erreur s'est produite lors de la prédiction : {str(e)}"
            )
            return []

class MasteryOptimizer(Action):
    def name(self) -> str:
        return "action_mastery_optimizer"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        # Récupérer les performances utilisateur depuis les slots
        user_performance = {
            "accuracy": tracker.get_slot("accuracy") or random.uniform(0.5, 0.9),
            "speed": tracker.get_slot("speed") or random.uniform(1, 3),  # Temps moyen pour répondre (en secondes)
            "consistency": tracker.get_slot("consistency") or random.uniform(0.7, 0.95),
        }

        # Analyse des performances
        weaknesses = []
        scores = {
            "accuracy": user_performance["accuracy"] * 100,  # Convertir en pourcentage
            "speed": max(0, 100 - user_performance["speed"] * 30),  # Inverser la logique pour la vitesse
            "consistency": user_performance["consistency"] * 100,
        }
        total_score = (scores["accuracy"] + scores["speed"] + scores["consistency"]) / 3

        if scores["accuracy"] < 80:
            weaknesses.append(
                "Précision : Travaille sur la reconnaissance des erreurs en pratiquant avec des exercices ciblés."
            )
        if scores["speed"] < 60:
            weaknesses.append(
                "Vitesse : Pratique des quiz chronométrés pour améliorer tes temps de réponse."
            )
        if scores["consistency"] < 85:
            weaknesses.append(
                "Cohérence : Révise régulièrement pour maintenir une performance stable."
            )

        # Plan d'amélioration
        if weaknesses:
            improvement_plan = (
                f"Plan d'amélioration (Score global : {total_score:.2f}/100) :\n- "
                + "\n- ".join(weaknesses)
            )
        else:
            improvement_plan = (
                f"Félicitations ! Ton score global est de {total_score:.2f}/100. Continue comme ça, tu es sur la bonne voie !"
            )

        # Génération de simulations pour l'entraînement
        simulated_opponents = self.generate_opponents()
        training_suggestion = self.generate_training_suggestions(simulated_opponents)

        # Retour interactif
        dispatcher.utter_message(text=f"{improvement_plan}\n\n{training_suggestion}")

        return [
            SlotSet("improvement_plan", improvement_plan),
            SlotSet("simulated_opponents", simulated_opponents),
        ]

    def generate_opponents(self):
        """Crée une liste d'adversaires simulés avec des niveaux variés."""
        levels = ["Facile", "Moyen", "Difficile"]
        return [
            {"name": f"Adversaire {i+1}", "level": random.choice(levels), "score": random.randint(50, 100)}
            for i in range(3)
        ]

    def generate_training_suggestions(self, opponents):
        """Génère des suggestions pour battre les adversaires simulés."""
        suggestions = []
        for opponent in opponents:
            if opponent["level"] == "Facile":
                suggestions.append(
                    f"{opponent['name']} ({opponent['level']}) : Idéal pour travailler ta précision."
                )
            elif opponent["level"] == "Moyen":
                suggestions.append(
                    f"{opponent['name']} ({opponent['level']}) : Entraîne-toi sur des questions chronométrées."
                )
            else:
                suggestions.append(
                    f"{opponent['name']} ({opponent['level']}) : Challenge difficile ! Reste cohérent sous pression."
                )
        return "Voici tes adversaires simulés et des stratégies pour les battre :\n" + "\n".join(suggestions)

class CompetitionMasterySuite(Action):
    def name(self) -> str:
        return "action_competition_mastery_suite"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain):
        # Analyse des performances passées
        user_score = tracker.get_slot("accuracy") or random.uniform(0.6, 0.9)
        user_speed = tracker.get_slot("speed") or random.uniform(1, 3)
        user_consistency = tracker.get_slot("consistency") or random.uniform(0.7, 0.95)

        # Analyse des adversaires
        competitor_data_path = "data/competitors.csv"  # Simuler les données
        try:
            competitors = pd.read_csv(competitor_data_path)
        except:
            competitors = pd.DataFrame({
                "name": ["Alice", "Bob", "Charlie"],
                "score": [random.randint(70, 95) for _ in range(3)],
                "speed": [random.uniform(1, 2.5) for _ in range(3)],
                "consistency": [random.uniform(0.6, 0.9) for _ in range(3)],
            })

        # Calculer des comparaisons
        avg_competitor_score = competitors["score"].mean()
        avg_competitor_speed = competitors["speed"].mean()
        avg_competitor_consistency = competitors["consistency"].mean()

        # Suggestions de stratégie
        strategy = []
        if user_score < avg_competitor_score:
            strategy.append("Améliorer la précision en analysant les questions des concurrents.")
        if user_speed > avg_competitor_speed:
            strategy.append("Réduire le temps de réponse avec des entraînements chronométrés.")
        if user_consistency < avg_competitor_consistency:
            strategy.append("Augmenter la régularité en simulant des compétitions longues.")

        # Générer un plan d'entraînement
        training_plan = "\n".join(f"- {s}" for s in strategy) if strategy else "Tu es déjà au top !"

        # Simuler les chances de victoire
        chance_of_victory = np.clip((user_score * 0.4 + user_consistency * 0.4 + (1 / user_speed) * 0.2) * 100, 0, 100)

        # Retourner le résultat
        dispatcher.utter_message(
            text=f"Analyse terminée.\n"
                 f"Plan d'entraînement personnalisé :\n{training_plan}\n\n"
                 f"Chances de victoire actuelles : {chance_of_victory:.2f}%.\n"
                 f"Prépare-toi à simuler une compétition !"
        )
        return [
            SlotSet("training_plan", training_plan),
            SlotSet("chance_of_victory", chance_of_victory)
        ]

class ActionStatisticalSummary(Action):
    def name(self) -> str:
        return "action_statistical_summary"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict]:
        # Récupérer les données utilisateur
        raw_data = tracker.get_slot("numeric_data")

        if not raw_data:
            dispatcher.utter_message(text="Je n'ai pas reçu de données à analyser. Veuillez fournir une liste de nombres.")
            return []

        try:
            # Validation et conversion des données utilisateur
            try:
                data = np.array(eval(raw_data))  # Transformation en numpy array
                if not isinstance(data, np.ndarray) or data.size == 0:
                    raise ValueError("Les données fournies ne sont pas valides.")
            except Exception as e:
                dispatcher.utter_message(text="Les données fournies ne sont pas valides. Veuillez fournir une liste de nombres comme [10, 20, 30].")
                return []

            # Vérifier que les données sont numériques
            if not np.issubdtype(data.dtype, np.number):
                dispatcher.utter_message(text="Les données doivent contenir uniquement des nombres.")
                return []

            # Statistiques descriptives
            mean = np.mean(data)
            median = np.median(data)
            std_dev = np.std(data)
            min_val = np.min(data)
            max_val = np.max(data)
            quartiles = np.percentile(data, [25, 50, 75])

            # Détection des valeurs aberrantes (IQR Method)
            iqr = quartiles[2] - quartiles[0]
            lower_bound = quartiles[0] - 1.5 * iqr
            upper_bound = quartiles[2] + 1.5 * iqr
            outliers = data[(data < lower_bound) | (data > upper_bound)]

            # Génération d'une visualisation (Boxplot)
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "statistical_summary_boxplot.png")
            plt.figure(figsize=(10, 6))
            plt.boxplot(data, vert=False, patch_artist=True, boxprops=dict(facecolor="lightblue"))
            plt.title("Boxplot des données")
            plt.xlabel("Valeurs")
            plt.savefig(file_path)
            plt.close()

            # Résumé des statistiques
            summary = (
                f"Voici les statistiques calculées :\n"
                f"- Moyenne : {mean:.2f}\n"
                f"- Médiane : {median:.2f}\n"
                f"- Écart-type : {std_dev:.2f}\n"
                f"- Min : {min_val}, Max : {max_val}\n"
                f"- Quartiles : Q1={quartiles[0]:.2f}, Q2={quartiles[1]:.2f}, Q3={quartiles[2]:.2f}\n"
                f"- Valeurs aberrantes : {list(outliers)}\n\n"
                f"Un graphique de boxplot a été généré : {file_path}"
            )

            # Réponse à l'utilisateur
            dispatcher.utter_message(text=summary)

        except Exception as e:
            logger.error(f"Erreur dans l'analyse statistique : {e}")
            dispatcher.utter_message(text="Une erreur est survenue lors de l'analyse des données.")
            return []

        return []
class ActionClustering(Action):
    def name(self) -> str:
        return "action_clustering"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict]:
        # Récupérer les données utilisateur ou générer des données fictives
        raw_data = tracker.get_slot("numeric_data")
        if not raw_data:
            dispatcher.utter_message("Aucune donnée fournie, des données fictives seront utilisées pour le clustering.")
            data, _ = make_blobs(n_samples=100, centers=3, random_state=42)
        else:
            try:
                data = np.array(eval(raw_data))
                if data.ndim != 2:
                    raise ValueError("Les données doivent être de forme (n_samples, n_features).")
            except Exception as e:
                dispatcher.utter_message("Les données fournies ne sont pas valides. Fournissez une liste de points en 2D ou plus.")
                logger.error(f"Erreur lors de l'analyse des données : {e}")
                return []

        try:
            # Réduction des dimensions si nécessaire
            if data.shape[1] > 2:
                dispatcher.utter_message("Réduction des dimensions des données en cours...")
                reducer = UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)
                reduced_data = reducer.fit_transform(data)
            else:
                reduced_data = data

            # Application de KMeans
            n_clusters = 3
            kmeans = KMeans(n_clusters=n_clusters, random_state=42)
            labels = kmeans.fit_predict(reduced_data)

            # Visualisation des clusters
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "clustering_result.png")
            plt.figure(figsize=(10, 6))
            plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=labels, cmap="tab10", s=50, alpha=0.8)
            plt.title("Résultat du clustering")
            plt.xlabel("Dimension 1")
            plt.ylabel("Dimension 2")
            plt.colorbar(label="Cluster")
            plt.savefig(file_path)
            plt.close()

            # Résumé des clusters
            cluster_counts = np.bincount(labels)
            centroids = kmeans.cluster_centers_
            summary = (
                f"Clustering effectué avec succès.\n"
                f"Nombre de points par cluster : {cluster_counts.tolist()}.\n"
                f"Centroides des clusters : {centroids.tolist()}.\n"
                f"Un graphique des clusters a été généré : {file_path}."
            )
            dispatcher.utter_message(text=summary)

        except Exception as e:
            dispatcher.utter_message("Une erreur est survenue lors du clustering. Veuillez vérifier vos données.")
            logger.error(f"Erreur lors du clustering : {e}")
            return []

        return []

class ActionGenerateDashboard(Action):
    def name(self) -> str:
        return "action_generate_dashboard"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict]:
        # Récupérer les données utilisateur
        raw_data = tracker.get_slot("data_frame")
        if not raw_data:
            dispatcher.utter_message("Aucune donnée disponible pour générer un tableau de bord. Veuillez fournir des données.")
            return []

        try:
            # Validation et conversion des données
            try:
                data = pd.DataFrame(eval(raw_data))
                if data.empty:
                    raise ValueError("Les données fournies sont vides.")
            except Exception as e:
                dispatcher.utter_message("Les données fournies ne sont pas valides. Fournissez un DataFrame valide.")
                logger.error(f"Erreur dans l'évaluation des données : {e}")
                return []

            # Vérification des colonnes
            if data.shape[1] < 1:
                dispatcher.utter_message("Les données fournies ne contiennent pas suffisamment de colonnes.")
                return []

            # Génération des graphiques
            fig = make_subplots(rows=1, cols=2, subplot_titles=["Histogramme", "Boîte à moustaches"])

            # Histogramme
            fig.add_trace(go.Histogram(x=data.iloc[:, 0], name="Histogramme", marker=dict(color='blue')), row=1, col=1)

            # Boxplot
            fig.add_trace(go.Box(y=data.iloc[:, 0], name="Boxplot", boxmean=True, marker=dict(color='red')), row=1, col=2)

            # Mise en forme du tableau de bord
            fig.update_layout(
                title="Tableau de bord interactif",
                height=600,
                showlegend=False,
                margin=dict(l=40, r=40, t=40, b=40),
                paper_bgcolor="white"
            )

            # Sauvegarde du tableau de bord
            output_dir = "dashboards"
            os.makedirs(output_dir, exist_ok=True)
            file_path = os.path.join(output_dir, "dashboard.html")
            fig.write_html(file_path)

            # Réponse utilisateur
            dispatcher.utter_message("Tableau de bord généré avec succès.")
            dispatcher.utter_message(f"Le tableau de bord est accessible ici : {file_path}")

        except Exception as e:
            logger.error(f"Erreur lors de la génération du tableau de bord : {e}")
            dispatcher.utter_message("Une erreur est survenue lors de la génération du tableau de bord.")
            return []

        return []

class ActionFeatureSelection(Action):
    def name(self) -> str:
        return "action_feature_selection"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        raw_data = tracker.get_slot("preprocessed_data")
        if not raw_data:
            dispatcher.utter_message(text="Aucune donnée prétraitée à analyser.")
            return []

        try:
            # Convertir les données en DataFrame
            data = pd.DataFrame(raw_data)

            # Sélectionner les meilleures caractéristiques (par exemple, en utilisant un modèle comme RandomForest)
            from sklearn.ensemble import RandomForestClassifier
            model = RandomForestClassifier()
            model.fit(data.drop(columns=["target"]), data["target"])

            # Obtenir l'importance des caractéristiques
            importances = model.feature_importances_
            features = data.columns.drop("target")
            important_features = [features[i] for i in range(len(features)) if importances[i] > 0.1]

            dispatcher.utter_message(text=f"Les caractéristiques sélectionnées sont : {important_features}")
            return [SlotSet("important_features", important_features)]
        except Exception as e:
            dispatcher.utter_message(text="Erreur lors de la sélection des caractéristiques.")
            return []

class ActionModelEvaluation(Action):
    def name(self) -> str:
        return "action_model_evaluation"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        model = tracker.get_slot("model")
        X_test = tracker.get_slot("X_test")
        y_test = tracker.get_slot("y_test")

        if not model or not X_test or not y_test:
            dispatcher.utter_message(text="Aucune information sur le modèle ou les données de test.")
            return []

        try:
            # Prédictions du modèle
            y_pred = model.predict(X_test)

            # Calcul de la précision
            accuracy = accuracy_score(y_test, y_pred)

            dispatcher.utter_message(text=f"Précision du modèle : {accuracy * 100:.2f}%")
            return [SlotSet("model_accuracy", accuracy)]
        except Exception as e:
            dispatcher.utter_message(text="Erreur lors de l'évaluation du modèle.")
            return []


class ActionHyperparameterTuning(Action):
    def name(self) -> str:
        return "action_hyperparameter_tuning"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer les données d'entrée pour l'entraînement
        raw_data = tracker.get_slot("training_data")
        if not raw_data:
            dispatcher.utter_message(text="Données d'entraînement non disponibles.")
            return []

        # Définir la grille des hyperparamètres à tester
        param_grid = {
            'n_estimators': [50, 100, 200],
            'max_depth': [5, 10, 20],
            'min_samples_split': [2, 5, 10]
        }

        try:
            # Charger les données et entraîner le modèle
            data = pd.DataFrame(eval(raw_data))
            X_train, X_test, y_train, y_test = train_test_split(data.drop(columns="target"), data["target"],
                                                                test_size=0.2)

            # Instancier le modèle
            model = RandomForestClassifier(random_state=42)

            # Rechercher les meilleurs hyperparamètres
            grid_search = GridSearchCV(model, param_grid, cv=3)
            grid_search.fit(X_train, y_train)

            best_params = grid_search.best_params_
            dispatcher.utter_message(text=f"Les meilleurs hyperparamètres sont : {best_params}")
            return [SlotSet("best_hyperparameters", best_params)]

        except Exception as e:
            dispatcher.utter_message(text="Erreur lors de l'ajustement des hyperparamètres.")
            return []

class ActionModelPerformanceVisualization(Action):
    def name(self) -> str:
        return "action_model_performance_visualization"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        model = tracker.get_slot("model")
        X_test = tracker.get_slot("X_test")
        y_test = tracker.get_slot("y_test")

        if not model or not X_test or not y_test:
            dispatcher.utter_message(text="Aucune information sur le modèle ou les données de test.")
            return []

        try:
            # Matrice de confusion
            y_pred = model.predict(X_test)
            cm = confusion_matrix(y_test, y_pred)

            plt.figure(figsize=(8, 6))
            plt.imshow(cm, interpolation="nearest", cmap=plt.cm.Blues)
            plt.title("Matrice de confusion")
            plt.colorbar()
            plt.ylabel("True Label")
            plt.xlabel("Predicted Label")
            plt.savefig("confusion_matrix.png")
            plt.close()

            dispatcher.utter_message(text="Matrice de confusion générée avec succès.")
            return [SlotSet("confusion_matrix", "confusion_matrix.png")]
        except Exception as e:
            dispatcher.utter_message(text="Erreur lors de la visualisation des performances.")
            return []

class ActionHandleMissingData(Action):
    def name(self) -> str:
        return "action_handle_missing_data"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        raw_data = tracker.get_slot("raw_data")
        if not raw_data:
            dispatcher.utter_message(text="Aucune donnée à traiter.")
            return []

        try:
            # Convertir les données brutes en DataFrame
            data = pd.DataFrame(eval(raw_data))

            # Gérer les valeurs manquantes (exemple : imputer avec la moyenne)
            data.fillna(data.mean(), inplace=True)

            dispatcher.utter_message(text="Les données manquantes ont été traitées avec succès.")
            return [SlotSet("processed_data", data.to_dict())]
        except Exception as e:
            dispatcher.utter_message(text="Erreur lors du traitement des données manquantes.")
            return []

class ActionPreprocessData(Action):
    def name(self) -> str:
        return "action_preprocess_data"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        raw_data = tracker.get_slot("raw_data")
        if not raw_data:
            dispatcher.utter_message(text="Aucune donnée à traiter. Veuillez fournir les données brutes.")
            return []

        try:
            # Convertir les données brutes en DataFrame
            data = pd.DataFrame(eval(raw_data))

            # Prétraitement : gérer les valeurs manquantes, normaliser, etc.
            data.fillna(data.mean(), inplace=True)  # Exemple pour gérer les valeurs manquantes
            data = (data - data.mean()) / data.std()  # Normalisation

            dispatcher.utter_message(text="Données prétraitées avec succès.")
            return [SlotSet("preprocessed_data", data.to_dict())]
        except Exception as e:
            dispatcher.utter_message(text="Une erreur s'est produite lors du prétraitement des données.")
            return []

class ActionBiasDetection(Action):
    def name(self) -> str:
        return "action_bias_detection"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Exemple de récupération de données de prédiction
        predictions = tracker.get_slot("model_predictions")
        ground_truth = tracker.get_slot("true_labels")

        if not predictions or not ground_truth:
            dispatcher.utter_message(text="Aucune donnée de prédiction disponible pour analyser les biais.")
            return []

        try:
            # Analyser le biais en fonction des différences de prédiction entre les groupes
            from sklearn.metrics import confusion_matrix
            cm = confusion_matrix(ground_truth, predictions)
            # Analyse des biais à travers la matrice de confusion ou d'autres métriques
            dispatcher.utter_message(text="Analyse de biais effectuée avec succès.")
            return [SlotSet("bias_analysis", cm)]
        except Exception as e:
            dispatcher.utter_message(text="Erreur lors de l'analyse des biais.")
            return []
class ActionPerformanceOptimization(Action):
    def name(self) -> str:
        return "action_performance_optimization"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        model = tracker.get_slot("model")
        X_train = tracker.get_slot("X_train")
        y_train = tracker.get_slot("y_train")

        if not model or X_train is None or y_train is None:
            dispatcher.utter_message(text="Aucune donnée ou modèle disponible pour l'optimisation des performances.")
            return []

        try:
            # Exemple d'optimisation avec RandomizedSearchCV
            from sklearn.model_selection import RandomizedSearchCV
            param_distributions = {
                'n_estimators': [50, 100, 200],
                'max_depth': [5, 10, 20],
                'min_samples_split': [2, 5, 10]
            }
            search = RandomizedSearchCV(model, param_distributions, n_iter=10, cv=5, random_state=42)
            search.fit(X_train, y_train)

            best_model = search.best_estimator_
            best_params = search.best_params_
            best_score = search.best_score_

            dispatcher.utter_message(text=f"Modèle optimisé avec succès ! Meilleurs paramètres : {best_params}, Meilleur score : {best_score}")
            return [SlotSet("optimized_model", best_model), SlotSet("best_params", best_params)]
        except Exception as e:
            dispatcher.utter_message(text="Erreur lors de l'optimisation des performances.")
            return []

class ActionHandleImbalancedData(Action):
    def name(self) -> str:
        return "action_handle_imbalanced_data"

    def run(self, dispatcher, tracker, domain) -> List[Dict[str, Any]]:
        X_train = tracker.get_slot("X_train")
        y_train = tracker.get_slot("y_train")

        if X_train is None or y_train is None:
            dispatcher.utter_message(text="Aucune donnée disponible pour traiter l'équilibre des classes.")
            return []

        try:
            # Appliquer SMOTE pour suréchantillonner les classes minoritaires
            from imblearn.over_sampling import SMOTE
            smote = SMOTE(random_state=42)
            X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

            dispatcher.utter_message(text="Les données déséquilibrées ont été traitées avec succès.")
            return [SlotSet("X_resampled", X_resampled), SlotSet("y_resampled", y_resampled)]
        except Exception as e:
            dispatcher.utter_message(text="Erreur lors du traitement des données déséquilibrées.")
            return []

class ActionDetectOutliers(Action):
    def name(self) -> str:
        return "action_detect_outliers"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        data = tracker.get_slot("data")

        if not data:
            dispatcher.utter_message(text="Aucune donnée à analyser pour les valeurs aberrantes.")
            return []

        try:
            # Convertir les données en DataFrame
            data = pd.DataFrame(eval(data))

            # Détection des outliers avec l'IQR
            Q1 = data.quantile(0.25)
            Q3 = data.quantile(0.75)
            IQR = Q3 - Q1
            outliers = ((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR)))

            # Résumé des outliers
            outliers_summary = outliers.sum()

            dispatcher.utter_message(
                text=f"Valeurs aberrantes détectées :\n{outliers_summary}"
            )
            return [SlotSet("outliers_summary", outliers_summary)]
        except Exception as e:
            logger.error(f"Erreur lors de la détection des outliers : {e}")
            dispatcher.utter_message(text="Erreur lors de la détection des valeurs aberrantes.")
            return []

class ActionEnsemblePrediction(Action):
    def name(self) -> str:
        return "action_ensemble_prediction"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer les données utilisateur
        X = tracker.get_slot("X_data")
        if not X:
            dispatcher.utter_message(text="Aucune donnée disponible pour la prédiction.")
            return []

        try:
            # Modèles préchargés ou instanciés
            rf_model = tracker.get_slot("rf_model")
            xgb_model = tracker.get_slot("xgb_model")

            if not rf_model or not xgb_model:
                dispatcher.utter_message(text="Les modèles ne sont pas chargés.")
                return []

            # Prédiction avec les deux modèles
            rf_pred = rf_model.predict(X)
            xgb_pred = xgb_model.predict(X)

            # Combinaison des prédictions (par exemple, moyenne ou majorité)
            final_prediction = (rf_pred + xgb_pred) / 2

            dispatcher.utter_message(
                text=f"Prédiction combinée des modèles : {final_prediction}"
            )
            return [SlotSet("ensemble_prediction", final_prediction)]
        except Exception as e:
            logger.error(f"Erreur lors de la prédiction avec les modèles d'ensemble : {e}")
            dispatcher.utter_message(text="Erreur lors de la prédiction avec les modèles.")
            return []

class ActionFeatureEngineering(Action):
    def name(self) -> str:
        return "action_feature_engineering"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        data = tracker.get_slot("data")

        if not data:
            dispatcher.utter_message(text="Aucune donnée disponible pour l'ingénierie des caractéristiques.")
            return []

        try:
            # Convertir les données en DataFrame
            data = pd.DataFrame(eval(data))

            # Création de nouvelles fonctionnalités (exemples : interactions, transformations log)
            data["log_feature"] = data["feature1"].apply(np.log)
            data["interaction_feature"] = data["feature1"] * data["feature2"]

            dispatcher.utter_message(
                text=f"Nouvelles caractéristiques créées : log_feature, interaction_feature"
            )

            return [SlotSet("data_with_features", data.to_dict())]
        except Exception as e:
            logger.error(f"Erreur lors de l'ingénierie des caractéristiques : {e}")
            dispatcher.utter_message(text="Erreur lors de l'ingénierie des caractéristiques.")
            return []

class ActionRealTimePrediction(Action):
    def name(self) -> str:
        return "action_real_time_prediction"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        # Récupérer les données utilisateur
        real_time_data = tracker.get_slot("real_time_data")

        if not real_time_data:
            dispatcher.utter_message(text="Aucune donnée disponible pour la prédiction en temps réel.")
            return []

        try:
            # Charger un modèle pour effectuer la prédiction
            model = tracker.get_slot("model")

            if not model:
                dispatcher.utter_message(text="Le modèle n'est pas chargé.")
                return []

            # Prédiction en temps réel
            prediction = model.predict([real_time_data])

            dispatcher.utter_message(text=f"Prédiction en temps réel : {prediction}")
            return [SlotSet("real_time_prediction", prediction)]
        except Exception as e:
            logger.error(f"Erreur lors de la prédiction en temps réel : {e}")
            dispatcher.utter_message(text="Erreur lors de la prédiction en temps réel.")
            return []

class ActionModelMonitoring(Action):
    def name(self) -> str:
        return "action_model_monitoring"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        model = tracker.get_slot("model")
        X_test = tracker.get_slot("X_test")
        y_test = tracker.get_slot("y_test")

        if not model or X_test is None or y_test is None:
            dispatcher.utter_message(text="Modèle ou données de test manquants pour la surveillance.")
            return []

        try:
            from sklearn.metrics import accuracy_score

            # Prédire sur les données de test
            y_pred = model.predict(X_test)

            # Calculer la précision
            accuracy = accuracy_score(y_test, y_pred)
            dispatcher.utter_message(text=f"Précision du modèle : {accuracy * 100:.2f}%")

            # Surveillance continue
            if accuracy < 0.7:  # Si la précision descend en dessous de 70%, alerte
                dispatcher.utter_message(text="Alerte : la performance du modèle est faible. Envisagez une mise à jour.")

            return [SlotSet("model_accuracy", accuracy)]
        except Exception as e:
            logger.error(f"Erreur dans la surveillance du modèle : {e}")
            dispatcher.utter_message(text="Erreur lors de la surveillance du modèle.")
            return []

class ActionActiveLearningDataPreparation(Action):
    def name(self) -> str:
        return "action_active_learning_data_preparation"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        data = tracker.get_slot("unlabeled_data")

        if not data:
            dispatcher.utter_message(text="Aucune donnée disponible pour l'apprentissage actif.")
            return []

        try:
            # Utiliser un modèle pré-entraîné pour identifier les points les plus incertains
            model = tracker.get_slot("model")

            if not model:
                dispatcher.utter_message(text="Le modèle n'est pas chargé.")
                return []

            # Identifier les instances les plus incertaines
            uncertainty_scores = model.predict_proba(data)  # Probabilités pour chaque classe
            uncertain_samples = data[np.argmax(uncertainty_scores, axis=1) < 0.5]

            dispatcher.utter_message(
                text=f"Instances sélectionnées pour l'apprentissage actif : {uncertain_samples}"
            )

            return [SlotSet("active_learning_data", uncertain_samples)]
        except Exception as e:
            logger.error(f"Erreur dans la préparation des données pour l'apprentissage actif : {e}")
            dispatcher.utter_message(text="Erreur lors de la préparation des données.")
            return []

class ActionModelCrossValidation(Action):
    def name(self) -> str:
        return "action_model_cross_validation"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        model = tracker.get_slot("model")
        X_train = tracker.get_slot("X_train")
        y_train = tracker.get_slot("y_train")

        if not model or X_train is None or y_train is None:
            dispatcher.utter_message(text="Le modèle ou les données d'entraînement manquent.")
            return []

        try:
            from sklearn.model_selection import cross_val_score

            # Validation croisée du modèle
            scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
            mean_score = scores.mean()

            dispatcher.utter_message(text=f"Validation croisée effectuée. Précision moyenne : {mean_score:.2f}")

            return [SlotSet("cross_val_score", mean_score)]
        except Exception as e:
            logger.error(f"Erreur lors de la validation croisée : {e}")
            dispatcher.utter_message(text="Erreur lors de la validation croisée du modèle.")
            return []

class ActionDynamicModelAdjustment(Action):
    def name(self) -> str:
        return "action_dynamic_model_adjustment"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        model = tracker.get_slot("model")
        X_train = tracker.get_slot("X_train")
        y_train = tracker.get_slot("y_train")
        score_threshold = tracker.get_slot("score_threshold") or 0.8

        if not model or X_train is None or y_train is None:
            dispatcher.utter_message(text="Le modèle ou les données d'entraînement manquent.")
            return []

        try:
            model.fit(X_train, y_train)
            accuracy = model.score(X_train, y_train)

            # Ajuster les hyperparamètres si nécessaire
            if accuracy < score_threshold:
                # Par exemple, ajuster le nombre d'arbres dans Random Forest
                model.set_params(n_estimators=200)
                model.fit(X_train, y_train)
                dispatcher.utter_message(
                    text=f"Précision faible ({accuracy * 100:.2f}%). Le modèle a été ajusté. Nouvelle précision : {model.score(X_train, y_train) * 100:.2f}%"
                )
            else:
                dispatcher.utter_message(
                    text=f"Précision satisfaisante ({accuracy * 100:.2f}%). Aucune modification nécessaire."
                )

            return [SlotSet("adjusted_model", model)]
        except Exception as e:
            logger.error(f"Erreur lors de l'ajustement dynamique du modèle : {e}")
            dispatcher.utter_message(text="Erreur lors de l'ajustement du modèle.")
            return []

class ActionMultiLabelPrediction(Action):
    def name(self) -> str:
        return "action_multi_label_prediction"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        model = tracker.get_slot("model")
        X_input = tracker.get_slot("X_input")

        if not model or X_input is None:
            dispatcher.utter_message(text="Le modèle ou les données d'entrée manquent.")
            return []

        try:
            from sklearn.preprocessing import MultiLabelBinarizer

            # Effectuer la prédiction multi-label
            predictions = model.predict(X_input)
            mlb = MultiLabelBinarizer()

            # Appliquer la transformation multi-label sur les prédictions
            labels = mlb.fit_transform(predictions)
            dispatcher.utter_message(text=f"Prédiction multi-label effectuée : {labels}")

            return [SlotSet("multi_label_predictions", labels)]
        except Exception as e:
            logger.error(f"Erreur lors de la prédiction multi-label : {e}")
            dispatcher.utter_message(text="Erreur lors de la prédiction multi-label.")
            return []

class ActionSelectBestModel(Action):
    def name(self) -> str:
        return "action_select_best_model"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        models = tracker.get_slot("models")  # Liste des modèles déjà entraînés
        X_val = tracker.get_slot("X_val")    # Données de validation
        y_val = tracker.get_slot("y_val")    # Étiquettes de validation

        if not models or X_val is None or y_val is None:
            dispatcher.utter_message(text="Les modèles ou les données de validation manquent.")
            return []

        try:
            best_model = None
            best_score = 0

            for model in models:
                model_score = model.score(X_val, y_val)
                if model_score > best_score:
                    best_model = model
                    best_score = model_score

            dispatcher.utter_message(text=f"Le meilleur modèle est : {best_model.__class__.__name__} avec une précision de {best_score * 100:.2f}%.")

            return [SlotSet("best_model", best_model)]
        except Exception as e:
            logger.error(f"Erreur lors de la sélection du meilleur modèle : {e}")
            dispatcher.utter_message(text="Erreur lors de la sélection du meilleur modèle.")
            return []

class ActionModelValidationAndRetraining(Action):
    def name(self) -> str:
        return "action_model_validation_and_retraining"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        model = tracker.get_slot("model")
        X_new_data = tracker.get_slot("X_new_data")
        y_new_data = tracker.get_slot("y_new_data")
        accuracy_threshold = tracker.get_slot("accuracy_threshold") or 0.8

        if not model or X_new_data is None or y_new_data is None:
            dispatcher.utter_message(text="Le modèle ou les nouvelles données manquent.")
            return []

        try:
            # Prédiction sur les nouvelles données
            new_accuracy = model.score(X_new_data, y_new_data)

            if new_accuracy < accuracy_threshold:
                # Réentraîner le modèle si la précision est en dessous du seuil
                model.fit(X_new_data, y_new_data)
                dispatcher.utter_message(text=f"Le modèle a été réentraîné pour améliorer la précision. Nouvelle précision : {new_accuracy * 100:.2f}%.")
            else:
                dispatcher.utter_message(text=f"Le modèle est performant avec une précision de {new_accuracy * 100:.2f}%. Aucun réentraînement nécessaire.")

            return [SlotSet("model", model)]
        except Exception as e:
            logger.error(f"Erreur lors de la validation et du réentraînement du modèle : {e}")
            dispatcher.utter_message(text="Erreur lors de la validation et du réentraînement du modèle.")
            return []

class ActionAutomaticDataPreprocessing(Action):
    def name(self) -> str:
        return "action_automatic_data_preprocessing"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        raw_data = tracker.get_slot("raw_data")
        if not raw_data:
            dispatcher.utter_message("Aucune donnée brute fournie.")
            return []

        try:
            data = pd.DataFrame(eval(raw_data))

            # Prétraitement automatique
            data = data.dropna()  # Suppression des valeurs manquantes
            data = pd.get_dummies(data)  # Encodage des variables catégorielles
            data = (data - data.mean()) / data.std()  # Normalisation des données

            dispatcher.utter_message(f"Prétraitement des données effectué :\n{data.head()}")
            return [SlotSet("preprocessed_data", data)]

        except Exception as e:
            logger.error(f"Erreur lors du prétraitement des données : {e}")
            dispatcher.utter_message("Une erreur est survenue lors du prétraitement des données.")
            return []

class ActionModelEnsemble(Action):
    def name(self) -> str:
        return "action_model_ensemble"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        models = tracker.get_slot("models")  # Liste de modèles à combiner
        X_train = tracker.get_slot("X_train")
        y_train = tracker.get_slot("y_train")

        if not models or X_train is None or y_train is None:
            dispatcher.utter_message("Modèles ou données manquants.")
            return []

        try:
            from sklearn.ensemble import VotingClassifier

            # Créer un modèle d'ensemble
            ensemble_model = VotingClassifier(estimators=[(f"model{i}", model) for i, model in enumerate(models)], voting="hard")
            ensemble_model.fit(X_train, y_train)

            # Évaluer le modèle d'ensemble
            accuracy = ensemble_model.score(X_train, y_train)
            dispatcher.utter_message(f"Modèle d'ensemble créé avec succès. Précision : {accuracy:.2f}")
            return [SlotSet("ensemble_model", ensemble_model)]

        except Exception as e:
            logger.error(f"Erreur lors de la création du modèle d'ensemble : {e}")
            dispatcher.utter_message("Erreur lors de la création du modèle d'ensemble.")
            return []


class ActionModelEvaluationVisualization(Action):
    def name(self) -> str:
        return "action_model_evaluation_visualization"

    def run(self, dispatcher: CollectingDispatcher, tracker, domain) -> List[Dict[str, Any]]:
        model = tracker.get_slot("model")
        X_test = tracker.get_slot("X_test")
        y_test = tracker.get_slot("y_test")

        if not model or X_test is None or y_test is None:
            dispatcher.utter_message("Modèle ou données de test manquants.")
            return []

        try:
            from sklearn.metrics import roc_curve, confusion_matrix, auc
            import seaborn as sns

            # Prédiction et évaluation
            y_pred = model.predict(X_test)
            cm = confusion_matrix(y_test, y_pred)

            # Courbe ROC
            fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])
            roc_auc = auc(fpr, tpr)

            # Visualisation de la matrice de confusion
            sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
            plt.title("Matrice de Confusion")
            plt.savefig("confusion_matrix.png")
            plt.close()

            # Visualisation de la courbe ROC
            plt.figure()
            plt.plot(fpr, tpr, color="darkorange", lw=2, label=f"ROC curve (area = {roc_auc:.2f})")
            plt.plot([0, 1], [0, 1], color="navy", lw=2, linestyle="--")
            plt.xlim([0.0, 1.0])
            plt.ylim([0.0, 1.05])
            plt.xlabel("False Positive Rate")
            plt.ylabel("True Positive Rate")
            plt.title("Receiver Operating Characteristic (ROC) Curve")
            plt.savefig("roc_curve.png")
            plt.close()

            dispatcher.utter_message("Évaluation du modèle effectuée. Graphiques générés : confusion_matrix.png, roc_curve.png.")
            return []

        except Exception as e:
            logger.error(f"Erreur lors de l'évaluation du modèle : {e}")
            dispatcher.utter_message("Erreur lors de l'évaluation du modèle.")
            return []



class AdvancedDataInsightGenerator:
    """
    Classe pour analyser des données avancées, avec des fonctionnalités modulaires telles que :
    - Analyse statistique
    - Détection des anomalies
    - Prévision temporelle
    """

    def __init__(self):
        # Configuration du répertoire pour les visualisations
        self.visualization_dir = "visualizations"
        os.makedirs(self.visualization_dir, exist_ok=True)
        logging.basicConfig(level=logging.INFO)

    def analyze_statistics(self, data: np.ndarray) -> dict:
        """
        Calcule des statistiques descriptives de base.

        Args:
            data (np.ndarray): Tableau numpy contenant les données.

        Returns:
            dict: Résumé des statistiques descriptives.
        """
        try:
            if data.size == 0:
                raise ValueError("Les données fournies sont vides.")

            statistics = {
                "mean": np.mean(data),
                "median": np.median(data),
                "std_dev": np.std(data),
                "variance": np.var(data),
                "min": np.min(data),
                "max": np.max(data),
                "quartiles": np.percentile(data, [25, 50, 75]),
            }

            # Générer un graphique de boxplot
            file_path = os.path.join(self.visualization_dir, "statistics_boxplot.png")
            self._generate_boxplot(data, "Distribution des Données", file_path)

            statistics["boxplot_path"] = file_path
            logging.info("Analyse statistique terminée.")
            return statistics
        except Exception as e:
            logging.error(f"Erreur lors de l'analyse statistique : {e}")
            return {"error": str(e)}

    def detect_anomalies(self, data: np.ndarray, contamination: float = 0.1) -> dict:
        """
        Détecte des anomalies dans les données à l'aide de Isolation Forest.

        Args:
            data (np.ndarray): Tableau numpy contenant les données.
            contamination (float): Proportion de données suspectées d'être des anomalies.

        Returns:
            dict: Résumé des anomalies détectées.
        """
        try:
            if data.size == 0:
                raise ValueError("Les données fournies sont vides.")

            # Normalisation des données
            scaler = StandardScaler()
            data_scaled = scaler.fit_transform(data.reshape(-1, 1))

            # Isolation Forest
            model = IsolationForest(contamination=contamination, random_state=42)
            predictions = model.fit_predict(data_scaled)
            anomalies = data[predictions == -1]

            # Générer un graphique des anomalies
            file_path = os.path.join(self.visualization_dir, "anomalies_scatter.png")
            self._generate_scatter_plot(data, predictions, "Détection des Anomalies", file_path)

            logging.info("Détection des anomalies terminée.")
            return {
                "anomalies": anomalies.tolist(),
                "total_anomalies": len(anomalies),
                "scatterplot_path": file_path,
            }
        except Exception as e:
            logging.error(f"Erreur lors de la détection des anomalies : {e}")
            return {"error": str(e)}

    def forecast_time_series(self, data_series: pd.DataFrame, periods: int = 7) -> dict:
        """
        Effectue une prévision temporelle avec Prophet.

        Args:
            data_series (pd.DataFrame): Série temporelle au format DataFrame (colonnes 'ds', 'y').
            periods (int): Nombre de périodes à prévoir.

        Returns:
            dict: Résultats des prévisions.
        """
        try:
            if not {"ds", "y"}.issubset(data_series.columns):
                raise ValueError("Les colonnes requises ('ds', 'y') ne sont pas présentes.")

            # Modèle Prophet
            model = Prophet()
            model.fit(data_series)

            # Prévision
            future = model.make_future_dataframe(periods=periods)
            forecast = model.predict(future)

            # Générer un graphique des prévisions
            file_path = os.path.join(self.visualization_dir, "forecast_plot.png")
            fig = model.plot(forecast)
            plt.title("Prévisions avec Prophet")
            plt.savefig(file_path)
            plt.close(fig)

            logging.info("Prévision temporelle terminée.")
            return {
                "forecast": forecast[["ds", "yhat"]].tail(periods).to_dict(orient="records"),
                "forecast_plot_path": file_path,
            }
        except Exception as e:
            logging.error(f"Erreur lors de la prévision temporelle : {e}")
            return {"error": str(e)}

    @staticmethod
    def split_data(data: pd.DataFrame, target: str, test_size: float = 0.2) -> tuple:
        """
        Divise les données en ensembles d'entraînement et de test.

        Args:
            data (pd.DataFrame): Données au format DataFrame.
            target (str): Colonne cible.
            test_size (float): Taille de l'ensemble de test.

        Returns:
            tuple: (X_train, X_test, y_train, y_test)
        """
        try:
            X = data.drop(columns=[target])
            y = data[target]
            return train_test_split(X, y, test_size=test_size, random_state=42)
        except Exception as e:
            logging.error(f"Erreur lors de la division des données : {e}")
            return None, None, None, None

    @staticmethod
    def optimize_hyperparameters(model, param_grid: dict, X_train, y_train) -> dict:
        """
        Optimise les hyperparamètres d'un modèle avec RandomizedSearchCV.

        Args:
            model: Modèle à optimiser.
            param_grid (dict): Grille des hyperparamètres.
            X_train: Données d'entraînement.
            y_train: Étiquettes d'entraînement.

        Returns:
            dict: Meilleurs hyperparamètres et modèle optimisé.
        """
        try:
            search = RandomizedSearchCV(model, param_grid, cv=3, n_iter=10, random_state=42)
            search.fit(X_train, y_train)
            return {
                "best_model": search.best_estimator_,
                "best_params": search.best_params_,
                "best_score": search.best_score_,
            }
        except Exception as e:
            logging.error(f"Erreur lors de l'optimisation des hyperparamètres : {e}")
            return {"error": str(e)}

    @staticmethod
    def _generate_boxplot(data, title, file_path):
        """Génère un boxplot et le sauvegarde."""
        plt.figure(figsize=(8, 5))
        plt.boxplot(data, vert=False, patch_artist=True, boxprops=dict(facecolor="lightblue"))
        plt.title(title)
        plt.savefig(file_path)
        plt.close()

    @staticmethod
    def _generate_scatter_plot(data, predictions, title, file_path):
        """Génère un graphique de dispersion et le sauvegarde."""
        plt.figure(figsize=(8, 5))
        plt.scatter(range(len(data)), data, c=predictions, cmap="coolwarm", s=50)
        plt.title(title)
        plt.xlabel("Index")
        plt.ylabel("Valeur")
        plt.savefig(file_path)
        plt.close()

class TimeSeriesProcessor:
    """
    Classe pour analyser, traiter et prévoir des séries temporelles.
    """

    def __init__(self):
        self.visualization_dir = "time_series_visualizations"
        os.makedirs(self.visualization_dir, exist_ok=True)
        logging.basicConfig(level=logging.INFO)

    def handle_missing_values(self, data: pd.DataFrame, method: str = "linear") -> pd.DataFrame:
        """
        Gère les valeurs manquantes dans une série temporelle.

        Args:
            data (pd.DataFrame): Série temporelle avec colonnes "ds" (date) et "y" (valeur).
            method (str): Méthode de remplissage, parmi ["linear", "mean", "median", "ffill", "bfill"].

        Returns:
            pd.DataFrame: Série temporelle avec les valeurs manquantes remplacées.
        """
        try:
            if "y" not in data.columns or "ds" not in data.columns:
                raise ValueError("Les colonnes requises ('ds', 'y') ne sont pas présentes.")

            if method in ["linear", "mean", "median"]:
                imputer = SimpleImputer(strategy=method if method != "linear" else "mean")
                data["y"] = imputer.fit_transform(data[["y"]])
                if method == "linear":
                    data["y"] = data["y"].interpolate(method="linear")
            elif method in ["ffill", "bfill"]:
                data["y"] = data["y"].fillna(method=method)
            else:
                raise ValueError(f"Méthode inconnue : {method}")

            logging.info("Valeurs manquantes traitées avec succès.")
            return data
        except Exception as e:
            logging.error(f"Erreur lors du traitement des valeurs manquantes : {e}")
            return None

    def decompose_series(self, data: pd.DataFrame, model: str = "additive") -> dict:
        """
        Décompose une série temporelle en composantes : tendance, saisonnalité et résidu.

        Args:
            data (pd.DataFrame): Série temporelle avec colonnes "ds" (date) et "y" (valeur).
            model (str): Type de décomposition ("additive" ou "multiplicative").

        Returns:
            dict: Composantes décomposées de la série.
        """
        try:
            if "y" not in data.columns or "ds" not in data.columns:
                raise ValueError("Les colonnes requises ('ds', 'y') ne sont pas présentes.")

            data = data.set_index("ds")
            decomposition = seasonal_decompose(data["y"], model=model, period=12)

            # Générer un graphique des composantes
            file_path = os.path.join(self.visualization_dir, "series_decomposition.png")
            decomposition.plot()
            plt.savefig(file_path)
            plt.close()

            logging.info("Décomposition de la série temporelle effectuée.")
            return {
                "trend": decomposition.trend,
                "seasonal": decomposition.seasonal,
                "residual": decomposition.resid,
                "decomposition_plot": file_path,
            }
        except Exception as e:
            logging.error(f"Erreur lors de la décomposition de la série temporelle : {e}")
            return {"error": str(e)}

    def detect_outliers(self, data: pd.DataFrame, threshold: float = 3.0) -> pd.DataFrame:
        """
        Détecte les valeurs aberrantes dans une série temporelle basée sur un seuil.

        Args:
            data (pd.DataFrame): Série temporelle avec colonnes "ds" et "y".
            threshold (float): Seuil pour détecter les outliers (z-score).

        Returns:
            pd.DataFrame: Série temporelle marquée avec une colonne "is_outlier".
        """
        try:
            if "y" not in data.columns or "ds" not in data.columns:
                raise ValueError("Les colonnes requises ('ds', 'y') ne sont pas présentes.")

            # Calcul du Z-score
            data["z_score"] = (data["y"] - data["y"].mean()) / data["y"].std()
            data["is_outlier"] = abs(data["z_score"]) > threshold

            # Visualisation des outliers
            file_path = os.path.join(self.visualization_dir, "outliers_detection.png")
            plt.figure(figsize=(10, 6))
            plt.plot(data["ds"], data["y"], label="Série temporelle")
            plt.scatter(data.loc[data["is_outlier"], "ds"], data.loc[data["is_outlier"], "y"], color="red", label="Outliers")
            plt.legend()
            plt.title("Détection des valeurs aberrantes")
            plt.savefig(file_path)
            plt.close()

            logging.info("Détection des outliers effectuée avec succès.")
            return data
        except Exception as e:
            logging.error(f"Erreur lors de la détection des outliers : {e}")
            return None

    def forecast(self, data: pd.DataFrame, periods: int = 30) -> dict:
        """
        Effectue une prévision sur la série temporelle.

        Args:
            data (pd.DataFrame): Série temporelle avec colonnes "ds" (date) et "y" (valeur).
            periods (int): Nombre de périodes à prévoir.

        Returns:
            dict: Résultats des prévisions et graphiques.
        """
        try:
            if "y" not in data.columns or "ds" not in data.columns:
                raise ValueError("Les colonnes requises ('ds', 'y') ne sont pas présentes.")

            # Modèle Prophet
            model = Prophet()
            model.fit(data)

            # Prévision
            future = model.make_future_dataframe(periods=periods)
            forecast = model.predict(future)

            # Graphique des prévisions
            forecast_plot_path = os.path.join(self.visualization_dir, "forecast_plot.png")
            fig = model.plot(forecast)
            plt.title("Prévisions des séries temporelles")
            plt.savefig(forecast_plot_path)
            plt.close(fig)

            logging.info("Prévisions terminées avec succès.")
            return {
                "forecast": forecast[["ds", "yhat", "yhat_lower", "yhat_upper"]].tail(periods),
                "forecast_plot_path": forecast_plot_path,
            }
        except Exception as e:
            logging.error(f"Erreur lors de la prévision : {e}")
            return {"error": str(e)}

    def detect_trend_changes(self, data: pd.DataFrame, threshold: float = 0.05) -> pd.DataFrame:
        """
        Détecte les changements de tendance dans une série temporelle.

        Args:
            data (pd.DataFrame): Série temporelle avec colonnes "ds" et "y".
            threshold (float): Seuil pour détecter les changements (en pourcentage).

        Returns:
            pd.DataFrame: Série temporelle avec une colonne "trend_change".
        """
        try:
            if "y" not in data.columns or "ds" not in data.columns:
                raise ValueError("Les colonnes requises ('ds', 'y') ne sont pas présentes.")

            # Calcul des variations relatives
            data["change"] = data["y"].pct_change().fillna(0)
            data["trend_change"] = abs(data["change"]) > threshold

            logging.info("Détection des changements de tendance effectuée.")
            return data
        except Exception as e:
            logging.error(f"Erreur lors de la détection des changements de tendance : {e}")
            return None

class DataExplorer:
    """
    Classe pour effectuer une analyse exploratoire automatisée sur un jeu de données.
    """

    def __init__(self):
        self.output_dir = "data_exploration_reports"
        os.makedirs(self.output_dir, exist_ok=True)

    def detect_missing_values(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        Détecte et résume les valeurs manquantes dans le DataFrame.

        Args:
            data (pd.DataFrame): Jeu de données.

        Returns:
            pd.DataFrame: Résumé des valeurs manquantes.
        """
        try:
            missing_summary = data.isnull().sum()
            missing_percentage = (missing_summary / len(data)) * 100
            missing_report = pd.DataFrame({
                "Feature": missing_summary.index,
                "Missing Values": missing_summary.values,
                "Missing Percentage": missing_percentage.values
            }).sort_values(by="Missing Values", ascending=False)

            logging.info("Résumé des valeurs manquantes généré.")
            return missing_report
        except Exception as e:
            logging.error(f"Erreur lors de la détection des valeurs manquantes : {e}")
            return None

    def visualize_distributions(self, data: pd.DataFrame, save: bool = True) -> str:
        """
        Visualise les distributions des variables numériques.

        Args:
            data (pd.DataFrame): Jeu de données.
            save (bool): Si True, sauvegarde le graphique.

        Returns:
            str: Chemin du fichier graphique.
        """
        try:
            numeric_columns = data.select_dtypes(include=np.number).columns
            if len(numeric_columns) == 0:
                return "Aucune colonne numérique à visualiser."

            plt.figure(figsize=(12, 8))
            for i, column in enumerate(numeric_columns, 1):
                plt.subplot(3, 3, i)
                sns.histplot(data[column], kde=True, bins=30, color="blue", alpha=0.7)
                plt.title(f"Distribution - {column}")
            plt.tight_layout()

            file_path = os.path.join(self.output_dir, "distributions.png")
            if save:
                plt.savefig(file_path)
                plt.close()
                logging.info(f"Visualisation des distributions sauvegardée : {file_path}")
                return file_path
            else:
                plt.show()
        except Exception as e:
            logging.error(f"Erreur lors de la visualisation des distributions : {e}")
            return None

    def generate_correlation_heatmap(self, data: pd.DataFrame, save: bool = True) -> str:
        """
        Génère une carte de chaleur des corrélations.

        Args:
            data (pd.DataFrame): Jeu de données.
            save (bool): Si True, sauvegarde le graphique.

        Returns:
            str: Chemin du fichier graphique.
        """
        try:
            numeric_data = data.select_dtypes(include=np.number)
            if numeric_data.shape[1] < 2:
                return "Pas assez de colonnes numériques pour calculer les corrélations."

            correlation_matrix = numeric_data.corr()
            plt.figure(figsize=(10, 8))
            sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
            plt.title("Carte de chaleur des corrélations")

            file_path = os.path.join(self.output_dir, "correlation_heatmap.png")
            if save:
                plt.savefig(file_path)
                plt.close()
                logging.info(f"Carte de chaleur sauvegardée : {file_path}")
                return file_path
            else:
                plt.show()
        except Exception as e:
            logging.error(f"Erreur lors de la génération de la carte de chaleur : {e}")
            return None

    def perform_pca(self, data: pd.DataFrame, n_components: int = 2) -> pd.DataFrame:
        """
        Effectue une analyse en composantes principales (PCA).

        Args:
            data (pd.DataFrame): Jeu de données.
            n_components (int): Nombre de composantes principales.

        Returns:
            pd.DataFrame: Résultats de la PCA.
        """
        try:
            numeric_data = data.select_dtypes(include=np.number).dropna()
            pca = PCA(n_components=n_components)
            pca_result = pca.fit_transform(numeric_data)

            pca_df = pd.DataFrame(pca_result, columns=[f"PC{i+1}" for i in range(n_components)])
            pca_df["Explained Variance"] = pca.explained_variance_ratio_

            logging.info("PCA effectuée avec succès.")
            return pca_df
        except Exception as e:
            logging.error(f"Erreur lors de l'analyse PCA : {e}")
            return None

    def generate_interactive_report(self, data: pd.DataFrame) -> str:
        """
        Génère un rapport interactif complet pour l'analyse des données.

        Args:
            data (pd.DataFrame): Jeu de données.

        Returns:
            str: Chemin vers le rapport interactif.
        """
        try:
            report = ProfileReport(data, title="Rapport Exploratoire", explorative=True)
            file_path = os.path.join(self.output_dir, "exploratory_report.html")
            report.to_file(file_path)
            logging.info(f"Rapport exploratoire généré : {file_path}")
            return file_path
        except Exception as e:
            logging.error(f"Erreur lors de la génération du rapport interactif : {e}")
            return None

class AdaptiveDataAnalyzer:
    """
    Classe pour une analyse intelligente des données avec des fonctionnalités adaptatives.
    """

    def __init__(self, output_dir="adaptive_analysis_outputs"):
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)

    def summarize_data(self, data: pd.DataFrame) -> dict:
        """
        Génère un résumé statistique intelligent des données.

        Args:
            data (pd.DataFrame): Jeu de données.

        Returns:
            dict: Résumé contenant des statistiques descriptives.
        """
        try:
            numeric_summary = data.describe(include=[np.number]).T
            categorical_summary = data.describe(include=["object"]).T

            summary = {
                "numeric_summary": numeric_summary.to_dict(),
                "categorical_summary": categorical_summary.to_dict(),
                "missing_values": data.isnull().sum().to_dict(),
            }
            return summary
        except Exception as e:
            return {"error": f"Erreur lors du résumé des données : {e}"}

    def detect_anomalies(self, data: pd.DataFrame, contamination: float = 0.1) -> dict:
        """
        Détecte les anomalies dans les données numériques en utilisant Isolation Forest.

        Args:
            data (pd.DataFrame): Jeu de données.
            contamination (float): Proportion des anomalies.

        Returns:
            dict: Résultats de la détection des anomalies.
        """
        try:
            numeric_data = data.select_dtypes(include=np.number).dropna()
            model = IsolationForest(contamination=contamination, random_state=42)
            predictions = model.fit_predict(numeric_data)
            anomalies = numeric_data[predictions == -1]

            return {
                "anomalies": anomalies.to_dict(),
                "anomaly_indices": anomalies.index.tolist(),
            }
        except Exception as e:
            return {"error": f"Erreur lors de la détection des anomalies : {e}"}

    def perform_time_series_analysis(self, data: pd.Series, period: int = None) -> dict:
        """
        Analyse une série temporelle pour détecter des tendances et des variations saisonnières.

        Args:
            data (pd.Series): Série temporelle.
            period (int): Période pour la décomposition (par exemple, 12 pour des données mensuelles).

        Returns:
            dict: Résultats de la décomposition de la série temporelle.
        """
        try:
            decomposition = seasonal_decompose(data, period=period, model="additive")
            decomposition_fig = self._plot_time_series_decomposition(decomposition, data.name)
            return {
                "trend": decomposition.trend.to_dict(),
                "seasonal": decomposition.seasonal.to_dict(),
                "residual": decomposition.resid.to_dict(),
                "decomposition_plot": decomposition_fig,
            }
        except Exception as e:
            return {"error": f"Erreur lors de l'analyse de la série temporelle : {e}"}

    def perform_pca(self, data: pd.DataFrame, n_components: int = 2) -> dict:
        """
        Effectue une analyse en composantes principales (PCA) sur les données.

        Args:
            data (pd.DataFrame): Jeu de données.
            n_components (int): Nombre de composantes principales.

        Returns:
            dict: Résultats de la PCA (composantes principales et variance expliquée).
        """
        try:
            numeric_data = data.select_dtypes(include=np.number).dropna()
            pca = PCA(n_components=n_components)
            components = pca.fit_transform(numeric_data)

            explained_variance = pca.explained_variance_ratio_
            pca_df = pd.DataFrame(components, columns=[f"PC{i+1}" for i in range(n_components)])

            return {
                "components": pca_df.to_dict(),
                "explained_variance": explained_variance.tolist(),
            }
        except Exception as e:
            return {"error": f"Erreur lors de la PCA : {e}"}

    def generate_insights_report(self, data: pd.DataFrame) -> str:
        """
        Génère un rapport contenant les insights principaux des données.

        Args:
            data (pd.DataFrame): Jeu de données.

        Returns:
            str: Chemin du fichier rapport généré.
        """
        try:
            insights = self.summarize_data(data)
            anomalies = self.detect_anomalies(data)
            pca_results = self.perform_pca(data)

            # Générer le rapport
            report_path = os.path.join(self.output_dir, "data_insights_report.txt")
            with open(report_path, "w") as report_file:
                report_file.write("=== Insights Report ===\n\n")
                report_file.write("=== Résumé des données ===\n")
                report_file.write(f"{pd.DataFrame(insights['numeric_summary']).to_string()}\n\n")
                report_file.write("=== Anomalies détectées ===\n")
                report_file.write(f"{anomalies}\n\n")
                report_file.write("=== Résultats de la PCA ===\n")
                report_file.write(f"{pca_results}\n\n")

            return report_path
        except Exception as e:
            return f"Erreur lors de la génération du rapport : {e}"

    def _plot_time_series_decomposition(self, decomposition, series_name: str) -> str:
        """
        Crée un graphique pour la décomposition de la série temporelle.

        Args:
            decomposition: Résultats de la décomposition (statsmodels).
            series_name (str): Nom de la série.

        Returns:
            str: Chemin du fichier du graphique généré.
        """
        fig, axes = plt.subplots(4, 1, figsize=(12, 8), sharex=True)
        axes[0].plot(decomposition.observed, label="Observed")
        axes[1].plot(decomposition.trend, label="Trend")
        axes[2].plot(decomposition.seasonal, label="Seasonal")
        axes[3].plot(decomposition.resid, label="Residual")

        for ax, title in zip(axes, ["Observed", "Trend", "Seasonal", "Residual"]):
            ax.set_title(title)
            ax.legend()

        plt.tight_layout()
        file_path = os.path.join(self.output_dir, f"{series_name}_decomposition.png")
        plt.savefig(file_path)
        plt.close()
        return file_path

class ActionAnalyzeData(Action):
    def name(self):
        return "action_analyze_data"

    def run(self, dispatcher, tracker, domain):
        data = pd.DataFrame(eval(tracker.get_slot("data_frame")))
        analyzer = AdaptiveDataAnalyzer()

        insights_report = analyzer.generate_insights_report(data)
        dispatcher.utter_message(f"Rapport généré : {insights_report}")
        return []

class UltimateDataPipelineManager(Action):
    def name(self) -> str:
        return "action_ultimate_data_pipeline_manager"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]) -> List[Dict[str, Any]]:
        # Étape 1 : Récupérer les données utilisateur
        raw_data = tracker.get_slot("raw_data")
        analysis_goal = tracker.get_slot("analysis_goal") or "exploration"

        if not raw_data:
            dispatcher.utter_message(text="Aucune donnée fournie. Peux-tu me donner tes données ?")
            return []

        try:
            # Étape 2 : Convertir les données en DataFrame
            data = pd.DataFrame(ast.literal_eval(raw_data))

            # Étape 3 : Exécuter le pipeline en fonction de l'objectif
            if analysis_goal == "exploration":
                return self.perform_exploration(data, dispatcher)
            elif analysis_goal == "anomalie":
                return self.detect_anomalies(data, dispatcher)
            elif analysis_goal == "clustering":
                return self.perform_clustering(data, dispatcher)
            elif analysis_goal == "prediction":
                return self.perform_prediction(data, tracker, dispatcher)
            else:
                dispatcher.utter_message(text="Objectif non reconnu. Choisissez : exploration, anomalie, clustering ou prediction.")
                return []

        except Exception as e:
            dispatcher.utter_message(text=f"Une erreur est survenue : {str(e)}")
            return []

    def perform_exploration(self, data: pd.DataFrame, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Analyse exploratoire des données."""
        try:
            summary = data.describe().to_string()
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)

            # Générer des visualisations
            pairplot_path = os.path.join(output_dir, "pairplot.png")
            sns.pairplot(data)
            plt.savefig(pairplot_path)
            plt.close()

            # Retourner le résultat à l'utilisateur
            dispatcher.utter_message(
                text=f"Voici un résumé des données :\n{summary}\nUn graphique des relations a été sauvegardé sous '{pairplot_path}'."
            )
            return []
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de l'analyse exploratoire : {str(e)}")
            return []

    def detect_anomalies(self, data: pd.DataFrame, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Détection des anomalies dans les données."""
        try:
            model = IsolationForest(contamination=0.1, random_state=42)
            predictions = model.fit_predict(data)
            anomalies = data[predictions == -1]

            # Visualisation des anomalies
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            anomaly_path = os.path.join(output_dir, "anomalies.png")

            plt.figure(figsize=(10, 6))
            sns.scatterplot(x=data.iloc[:, 0], y=data.iloc[:, 1], hue=(predictions == -1), palette="coolwarm")
            plt.title("Détection des anomalies")
            plt.savefig(anomaly_path)
            plt.close()

            dispatcher.utter_message(
                text=f"Détection des anomalies terminée. Un graphique a été sauvegardé sous '{anomaly_path}'."
            )
            return []
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de la détection des anomalies : {str(e)}")
            return []

    def perform_clustering(self, data: pd.DataFrame, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Clustering des données."""
        try:
            model = KMeans(n_clusters=3, random_state=42)
            labels = model.fit_predict(data)

            # Visualisation des clusters
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            cluster_path = os.path.join(output_dir, "clusters.png")

            plt.figure(figsize=(10, 6))
            sns.scatterplot(x=data.iloc[:, 0], y=data.iloc[:, 1], hue=labels, palette="tab10")
            plt.title("Résultat du clustering")
            plt.savefig(cluster_path)
            plt.close()

            dispatcher.utter_message(
                text=f"Clustering terminé. Un graphique a été sauvegardé sous '{cluster_path}'."
            )
            return []
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors du clustering : {str(e)}")
            return []

    def perform_prediction(self, data: pd.DataFrame, tracker: Tracker, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Prédictions basées sur un modèle."""
        target = tracker.get_slot("target_variable")
        model_type = tracker.get_slot("model_type") or "random_forest"

        if not target or target not in data.columns:
            dispatcher.utter_message(text="La variable cible est absente ou incorrecte.")
            return []

        try:
            # Préparer les données
            X = data.drop(columns=[target])
            y = data[target]

            # Choisir et entraîner le modèle
            if model_type == "random_forest":
                model = RandomForestRegressor(random_state=42)
            elif model_type == "linear_regression":
                model = LinearRegression()
            else:
                dispatcher.utter_message(text="Type de modèle non reconnu.")
                return []

            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            model.fit(X_train, y_train)

            # Évaluation
            predictions = model.predict(X_test)
            r2 = r2_score(y_test, predictions)

            dispatcher.utter_message(
                text=f"Prédiction terminée avec succès. Coefficient de détermination (R²) : {r2:.2f}"
            )
            return [SlotSet("model_predictions", predictions.tolist())]
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors des prédictions : {str(e)}")
            return []

class ModularPipelineOrchestrator(Action):
    def name(self) -> str:
        return "action_modular_pipeline_orchestrator"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain) -> List[Dict[str, Any]]:
        # 1. Récupérer les données et le but
        raw_data = tracker.get_slot("raw_data")
        analysis_goal = tracker.get_slot("analysis_goal") or "auto_detect"

        if not raw_data:
            dispatcher.utter_message(text="Aucune donnée trouvée. Peux-tu les partager ?")
            return []

        try:
            # 2. Conversion des données
            data = pd.DataFrame(ast.literal_eval(raw_data))

            # 3. Détection automatique si nécessaire
            if analysis_goal == "auto_detect":
                analysis_goal = self.detect_analysis_goal(data)
                dispatcher.utter_message(
                    text=f"Objectif détecté automatiquement : {analysis_goal}."
                )

            # 4. Exécuter l’objectif du pipeline
            if analysis_goal == "exploration":
                return self.perform_exploration(data, dispatcher)
            elif analysis_goal == "anomalie":
                return self.detect_anomalies(data, dispatcher)
            elif analysis_goal == "clustering":
                return self.perform_clustering(data, dispatcher)
            elif analysis_goal == "prediction":
                return self.perform_prediction(data, tracker, dispatcher)
            elif analysis_goal == "rapport":
                return self.generate_pdf_report(data, dispatcher)
            else:
                dispatcher.utter_message(text="Objectif inconnu. Essayez : exploration, anomalie, clustering, prediction, rapport.")
                return []

        except Exception as e:
            dispatcher.utter_message(text=f"Une erreur s'est produite : {str(e)}")
            return []

    def detect_analysis_goal(self, data: pd.DataFrame) -> str:
        """Détecte automatiquement l’objectif selon les données."""
        if {"ds", "y"}.issubset(data.columns):
            return "prediction"
        elif data.select_dtypes(include=["number"]).shape[1] > 0:
            return "exploration"
        elif data.isnull().sum().sum() > 0:
            return "anomalie"
        else:
            return "clustering"

    def perform_exploration(self, data: pd.DataFrame, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Analyse exploratoire des données."""
        try:
            summary = data.describe().to_string()
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)

            # Pairplot
            pairplot_path = os.path.join(output_dir, "pairplot.png")
            sns.pairplot(data)
            plt.savefig(pairplot_path)
            plt.close()

            dispatcher.utter_message(
                text=f"Analyse exploratoire terminée :\n{summary}\nUn graphique des relations a été généré : {pairplot_path}"
            )
            return []
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de l'exploration des données : {str(e)}")
            return []

    def detect_anomalies(self, data: pd.DataFrame, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Détection des anomalies dans les données."""
        try:
            model = IsolationForest(contamination=0.1, random_state=42)
            predictions = model.fit_predict(data)
            anomalies = data[predictions == -1]

            # Graphique anomalies
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            anomaly_path = os.path.join(output_dir, "anomalies.png")

            plt.figure(figsize=(10, 6))
            sns.scatterplot(x=data.iloc[:, 0], y=data.iloc[:, 1], hue=(predictions == -1), palette="coolwarm")
            plt.title("Anomalies détectées")
            plt.savefig(anomaly_path)
            plt.close()

            dispatcher.utter_message(
                text=f"Anomalies détectées. Résultat sauvegardé sous '{anomaly_path}'."
            )
            return []
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de la détection des anomalies : {str(e)}")
            return []

    def perform_clustering(self, data: pd.DataFrame, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Clustering et visualisation."""
        try:
            kmeans = KMeans(n_clusters=3, random_state=42)
            labels = kmeans.fit_predict(data)

            # Graphique clusters
            output_dir = "visualizations"
            os.makedirs(output_dir, exist_ok=True)
            cluster_path = os.path.join(output_dir, "clusters.png")

            plt.figure(figsize=(10, 6))
            sns.scatterplot(x=data.iloc[:, 0], y=data.iloc[:, 1], hue=labels, palette="tab10")
            plt.title("Clusters détectés")
            plt.savefig(cluster_path)
            plt.close()

            dispatcher.utter_message(
                text=f"Clustering terminé. Résultat sauvegardé sous '{cluster_path}'."
            )
            return []
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors du clustering : {str(e)}")
            return []

    def perform_prediction(self, data: pd.DataFrame, tracker: Tracker, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Prédiction automatique basée sur un modèle."""
        target_variable = tracker.get_slot("target_variable")
        model_type = tracker.get_slot("model_type") or "random_forest"

        if not target_variable or target_variable not in data.columns:
            dispatcher.utter_message(text="La variable cible est absente ou incorrecte.")
            return []

        try:
            X = data.drop(columns=[target_variable])
            y = data[target_variable]

            # Choix du modèle
            if model_type == "random_forest":
                model = RandomForestRegressor(random_state=42)
            elif model_type == "linear_regression":
                model = LinearRegression()
            else:
                dispatcher.utter_message(text="Modèle non reconnu.")
                return []

            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            model.fit(X_train, y_train)

            predictions = model.predict(X_test)
            r2 = r2_score(y_test, predictions)

            dispatcher.utter_message(
                text=f"Prédiction effectuée avec succès. R² : {r2:.2f}"
            )
            return [SlotSet("model_predictions", predictions.tolist())]
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors des prédictions : {str(e)}")
            return []

    def generate_pdf_report(self, data: pd.DataFrame, dispatcher: CollectingDispatcher) -> List[Dict[str, Any]]:
        """Génération d’un rapport consolidé en PDF."""
        try:
            output_dir = "reports"
            os.makedirs(output_dir, exist_ok=True)
            report_path = os.path.join(output_dir, "data_report.pdf")

            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", size=12)

            # Résumé des données
            pdf.cell(200, 10, txt="Rapport des données", ln=True, align="C")
            summary = data.describe().to_string()
            pdf.multi_cell(0, 10, txt=summary)

            # Ajouter les graphiques
            for plot_file in os.listdir("visualizations"):
                pdf.add_page()
                pdf.image(os.path.join("visualizations", plot_file), x=10, y=30, w=180)

            # Sauvegarder le PDF
            pdf.output(report_path)

            dispatcher.utter_message(
                text=f"Rapport généré avec succès : {report_path}"
            )
            return []
        except Exception as e:
            dispatcher.utter_message(text=f"Erreur lors de la génération du rapport : {str(e)}")
            return []

class ActionSaveData(Action):
    def name(self) -> str:
        return "action_save_data"

    def run(self, dispatcher, tracker, domain):
        user_data = tracker.get_slot('user_data')
        dispatcher.utter_message(text=f"Vos données {user_data} ont été sauvegardées avec succès!")
        # Simule la sauvegarde
        return [SlotSet("data_saved", True)]

class ActionSearchInfo(Action):
    def name(self) -> str:
        return "action_search_info"

    def run(self, dispatcher, tracker, domain):
        query = tracker.get_slot('search_query')
        response = requests.get(f"https://api.duckduckgo.com/?q={query}&format=json")
        data = response.json()
        dispatcher.utter_message(text=f"Voici ce que j'ai trouvé : {data['AbstractText'] or 'Aucune information trouvée.'}")
        return []

class VisualizationUtils:
    """Classe utilitaire pour la création et la sauvegarde des graphiques."""

    @staticmethod
    def create_output_dir(output_dir="outputs"):
        """Crée un répertoire pour les sorties."""
        os.makedirs(output_dir, exist_ok=True)
        return output_dir

    @staticmethod
    def save_plot(fig, filename, output_dir="outputs"):
        """Sauvegarde un graphique sous forme de fichier."""
        path = os.path.join(output_dir, filename)
        fig.savefig(path)
        plt.close(fig)
        return path

class BasePipeline:
    """
    Classe de base pour les pipelines de traitement de données.
    Fournit des méthodes utilitaires communes.
    """

    def __init__(self):
        self.output_dir = VisualizationUtils.create_output_dir("pipeline_outputs")

    def validate_data(self, data):
        """Valide les données pour s'assurer qu'elles sont exploitables."""
        if data is None or data.empty:
            raise ValueError("Les données fournies sont vides ou invalides.")
        return data

class DataExplorer(BasePipeline):
    """Pipeline d'exploration des données."""

    def analyze_statistics(self, data):
        """Calcule les statistiques descriptives."""
        try:
            data = self.validate_data(data)
            numeric_summary = data.describe(include="number")
            categorical_summary = data.describe(include="object")

            return {
                "numeric_summary": numeric_summary.to_dict(),
                "categorical_summary": categorical_summary.to_dict(),
            }
        except Exception as e:
            raise RuntimeError(f"Erreur dans l'analyse des statistiques : {e}")

    def visualize_distributions(self, data):
        """Génère un histogramme des distributions des colonnes numériques."""
        try:
            data = self.validate_data(data)
            numeric_columns = data.select_dtypes(include="number").columns

            if not numeric_columns.any():
                return "Aucune donnée numérique à visualiser."

            fig, axes = plt.subplots(1, len(numeric_columns), figsize=(15, 5))
            for i, column in enumerate(numeric_columns):
                sns.histplot(data[column], kde=True, ax=axes[i])
                axes[i].set_title(f"Distribution - {column}")

            filename = VisualizationUtils.save_plot(fig, "distributions.png", self.output_dir)
            return {"distribution_plot": filename}
        except Exception as e:
            raise RuntimeError(f"Erreur dans la visualisation des distributions : {e}")

    def generate_correlation_heatmap(self, data):
        """Génère une carte de chaleur des corrélations."""
        try:
            data = self.validate_data(data)
            numeric_data = data.select_dtypes(include="number")

            if numeric_data.shape[1] < 2:
                return "Pas assez de données numériques pour générer la carte de chaleur."

            fig, ax = plt.subplots(figsize=(10, 8))
            sns.heatmap(numeric_data.corr(), annot=True, cmap="coolwarm", ax=ax)
            ax.set_title("Carte de Chaleur des Corrélations")

            filename = VisualizationUtils.save_plot(fig, "correlation_heatmap.png", self.output_dir)
            return {"correlation_heatmap": filename}
        except Exception as e:
            raise RuntimeError(f"Erreur dans la génération de la carte de chaleur : {e}")

class AdvancedDataAnalyzer(BasePipeline):
    """Pipeline d'analyse avancée."""

    def detect_anomalies(self, data, contamination=0.1):
        """Détecte les anomalies à l'aide d'Isolation Forest."""
        try:
            data = self.validate_data(data)
            model = IsolationForest(contamination=contamination, random_state=42)
            predictions = model.fit_predict(data)

            anomalies = data[predictions == -1]
            return {"anomalies": anomalies.to_dict(orient="records")}
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la détection des anomalies : {e}")

    def perform_clustering(self, data, n_clusters=3):
        """Effectue un clustering sur les données."""
        try:
            data = self.validate_data(data)
            model = KMeans(n_clusters=n_clusters, random_state=42)
            labels = model.fit_predict(data)

            data["Cluster"] = labels
            return {"clusters": data.to_dict(orient="records")}
        except Exception as e:
            raise RuntimeError(f"Erreur lors du clustering : {e}")

class ModelTrainer(BasePipeline):
    """Pipeline d'entraînement de modèles prédictifs."""

    def train_model(self, data, target_column, model_type="random_forest"):
        """Entraîne un modèle prédictif."""
        try:
            data = self.validate_data(data)

            if target_column not in data.columns:
                raise ValueError("La colonne cible est absente.")

            X = data.drop(columns=[target_column])
            y = data[target_column]
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

            if model_type == "random_forest":
                model = RandomForestRegressor(random_state=42)
            elif model_type == "linear_regression":
                model = LinearRegression()
            else:
                raise ValueError("Type de modèle non supporté.")

            model.fit(X_train, y_train)
            predictions = model.predict(X_test)
            r2 = r2_score(y_test, predictions)

            return {"model": model, "r2_score": r2, "predictions": predictions.tolist()}
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'entraînement du modèle : {e}")

class TimeSeriesProcessor(BasePipeline):
    """Classe pour analyser, traiter et prévoir des séries temporelles."""

    def decompose_series(self, data, model="additive"):
        """Décompose une série temporelle."""
        try:
            data = self.validate_data(data)
            decomposition = seasonal_decompose(data, model=model)
            return {
                "trend": decomposition.trend,
                "seasonal": decomposition.seasonal,
                "residual": decomposition.resid,
            }
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la décomposition de la série temporelle : {e}")

    def forecast(self, data, periods=7):
        """Effectue une prévision à l'aide de Prophet."""
        try:
            model = Prophet()
            model.fit(data)
            future = model.make_future_dataframe(periods=periods)
            forecast = model.predict(future)

            return forecast
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la prévision : {e}")

class DataPreprocessor(BasePipeline):
    """Pipeline pour le prétraitement des données."""

    def handle_missing_values(self, data, strategy="mean"):
        """Gère les valeurs manquantes dans les colonnes numériques."""
        try:
            data = self.validate_data(data)
            imputer = SimpleImputer(strategy=strategy)
            data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)
            return data
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la gestion des valeurs manquantes : {e}")

    def normalize_data(self, data):
        """Normalise les colonnes numériques."""
        try:
            data = self.validate_data(data)
            scaler = StandardScaler()
            numeric_columns = data.select_dtypes(include=["number"]).columns
            data[numeric_columns] = scaler.fit_transform(data[numeric_columns])
            return data
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la normalisation : {e}")

    def encode_categorical_data(self, data):
        """Encode les colonnes catégoriques en format numérique."""
        try:
            data = self.validate_data(data)
            categorical_columns = data.select_dtypes(include=["object"]).columns
            for column in categorical_columns:
                data[column] = LabelEncoder().fit_transform(data[column])
            return data
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'encodage des données catégoriques : {e}")

class DataExporter:
    """Classe pour exporter les données sous différents formats."""

    @staticmethod
    def export_to_csv(data, filename="data_export.csv", output_dir="exports"):
        """Exporte les données au format CSV."""
        try:
            os.makedirs(output_dir, exist_ok=True)
            path = os.path.join(output_dir, filename)
            data.to_csv(path, index=False)
            return path
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'exportation CSV : {e}")

    @staticmethod
    def export_to_json(data, filename="data_export.json", output_dir="exports"):
        """Exporte les données au format JSON."""
        try:
            os.makedirs(output_dir, exist_ok=True)
            path = os.path.join(output_dir, filename)
            data.to_json(path, orient="records")
            return path
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'exportation JSON : {e}")

class FeatureSelector(BasePipeline):
    """Pipeline pour la sélection des caractéristiques les plus pertinentes."""

    def select_best_features(self, data, target_column, k=5):
        """Sélectionne les k meilleures caractéristiques en fonction de leur importance statistique."""
        try:
            data = self.validate_data(data)
            if target_column not in data.columns:
                raise ValueError("La colonne cible est absente.")

            X = data.drop(columns=[target_column])
            y = data[target_column]
            selector = SelectKBest(score_func=f_classif, k=k)
            selector.fit(X, y)

            selected_columns = X.columns[selector.get_support()]
            return selected_columns.tolist()
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la sélection des caractéristiques : {e}")

class BiasAnalyzer(BasePipeline):
    """Analyse les biais potentiels dans les prédictions d'un modèle."""

    def detect_bias(self, predictions, ground_truth, group_column):
        """Analyse les biais en fonction d'une colonne catégorique."""
        try:
            data = pd.DataFrame({"predictions": predictions, "ground_truth": ground_truth})
            confusion = pd.crosstab(data["predictions"], data["ground_truth"])
            bias_summary = confusion.div(confusion.sum(axis=1), axis=0).round(2)
            return {"confusion_matrix": confusion.to_dict(), "bias_summary": bias_summary.to_dict()}
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'analyse des biais : {e}")

class ActiveLearningManager(BasePipeline):
    """Pipeline pour l'apprentissage actif."""

    def select_uncertain_samples(self, model, data, n_samples=10):
        """Identifie les échantillons avec les prédictions les plus incertaines."""
        try:
            data = self.validate_data(data)
            proba = model.predict_proba(data)
            uncertainty = 1 - proba.max(axis=1)  # Inverse de la confiance
            uncertain_indices = uncertainty.argsort()[-n_samples:]
            return data.iloc[uncertain_indices].to_dict(orient="records")
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la sélection des échantillons incertains : {e}")

class ModelEvaluator:
    """Classe pour évaluer les performances des modèles."""

    @staticmethod
    def evaluate_model(y_true, y_pred, y_proba=None):
        """Évalue un modèle sur plusieurs métriques."""
        try:
            metrics = {
                "accuracy": accuracy_score(y_true, y_pred),
                "f1_score": f1_score(y_true, y_pred, average="weighted"),
            }
            if y_proba is not None:
                metrics["roc_auc"] = roc_auc_score(y_true, y_proba, multi_class="ovr")
            return metrics
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'évaluation du modèle : {e}")

class HyperparameterOptimizer:
    """Pipeline pour optimiser les hyperparamètres des modèles."""

    @staticmethod
    def optimize_model(model, param_grid, X_train, y_train, method="grid", n_iter=10):
        """Optimise les hyperparamètres avec Grid Search ou Randomized Search."""
        try:
            if method == "grid":
                search = GridSearchCV(model, param_grid, cv=3, scoring="accuracy")
            elif method == "random":
                search = RandomizedSearchCV(model, param_grid, n_iter=n_iter, cv=3, scoring="accuracy", random_state=42)
            else:
                raise ValueError("Méthode non supportée : choisissez 'grid' ou 'random'.")

            search.fit(X_train, y_train)
            return {"best_model": search.best_estimator_, "best_params": search.best_params_}
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'optimisation des hyperparamètres : {e}")

class RealTimePredictor:
    """Pipeline pour effectuer des prédictions en temps réel."""

    @staticmethod
    def predict(model, data):
        """Effectue une prédiction avec un modèle donné."""
        try:
            data = pd.DataFrame(data)
            predictions = model.predict(data)
            return {"predictions": predictions.tolist()}
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la prédiction en temps réel : {e}")

class DashboardGenerator:
    """Génère des tableaux de bord interactifs."""

    def create_scatter_dashboard(self, data, x_col, y_col, color_col=None):
        """Génère un graphique de dispersion interactif."""
        try:
            fig = px.scatter(data, x=x_col, y=y_col, color=color_col, title="Tableau de Bord")
            fig.show()
            return fig
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la création du tableau de bord : {e}")

class TimeSeriesForecaster:
    """Classe pour la prévision des séries temporelles."""

    def forecast_with_prophet(self, data, periods=30):
        """
        Prévision avec Prophet.
        Args:
            data (pd.DataFrame): Données avec colonnes 'ds' (date) et 'y' (valeur).
            periods (int): Nombre de périodes à prévoir.
        Returns:
            dict: Résultats de la prévision et graphique.
        """
        try:
            if not {"ds", "y"}.issubset(data.columns):
                raise ValueError("Les colonnes 'ds' et 'y' sont nécessaires.")
            model = Prophet()
            model.fit(data)
            future = model.make_future_dataframe(periods=periods)
            forecast = model.predict(future)

            # Sauvegarder le graphique
            plot_path = "time_series_forecast_prophet.png"
            model.plot(forecast).savefig(plot_path)

            return {"forecast": forecast, "plot_path": plot_path}
        except Exception as e:
            raise RuntimeError(f"Erreur dans la prévision avec Prophet : {e}")

    def forecast_with_arima(self, data, order=(1, 1, 1)):
        """
        Prévision avec ARIMA.
        Args:
            data (pd.Series): Série temporelle.
            order (tuple): Paramètres (p, d, q) pour ARIMA.
        Returns:
            dict: Résultats de la prévision et graphique.
        """
        try:
            model = ARIMA(data, order=order)
            fitted_model = model.fit()
            forecast = fitted_model.forecast(steps=30)

            # Sauvegarder le graphique
            plot_path = "time_series_forecast_arima.png"
            plt.figure()
            plt.plot(data, label="Historique")
            plt.plot(range(len(data), len(data) + len(forecast)), forecast, label="Prévisions")
            plt.legend()
            plt.savefig(plot_path)
            plt.close()

            return {"forecast": forecast.tolist(), "plot_path": plot_path}
        except Exception as e:
            raise RuntimeError(f"Erreur dans la prévision avec ARIMA : {e}")

class CustomPipelineManager:
    """Gère des pipelines personnalisés pour le traitement des données."""

    def __init__(self, steps=None):
        """
        Initialise le pipeline.
        Args:
            steps (list): Liste des étapes du pipeline sous forme de fonctions.
        """
        self.steps = steps or []

    def add_step(self, step):
        """Ajoute une étape au pipeline."""
        self.steps.append(step)

    def execute_pipeline(self, data):
        """Exécute les étapes du pipeline."""
        try:
            for step in self.steps:
                data = step(data)
            return data
        except Exception as e:
            raise RuntimeError(f"Erreur dans l'exécution du pipeline : {e}")

class AutoMLManager:
    """Automatise la sélection du modèle et l'optimisation."""

    def __init__(self, models=None):
        self.models = models or {
            "Random Forest": RandomForestClassifier(),
            "Logistic Regression": LogisticRegression(),
            "Support Vector Machine": SVC(),
        }

    def find_best_model(self, X, y, scoring="accuracy"):
        """
        Trouve le meilleur modèle parmi une liste.
        Args:
            X (pd.DataFrame): Features.
            y (pd.Series): Cible.
            scoring (str): Métrique de score.
        Returns:
            dict: Meilleur modèle et son score.
        """
        results = {}
        for name, model in self.models.items():
            score = cross_val_score(model, X, y, cv=3, scoring=scoring).mean()
            results[name] = score

        best_model_name = max(results, key=results.get)
        best_model = self.models[best_model_name]
        return {"best_model": best_model, "best_score": results[best_model_name]}


class DriftDetector:
    """Détecte les changements dans la distribution des données."""

    def detect_drift(self, reference_data, current_data):
        """
        Compare la distribution des données de référence et des données actuelles.
        Args:
            reference_data (pd.DataFrame): Données de référence.
            current_data (pd.DataFrame): Données actuelles.
        Returns:
            dict: Résumé des résultats du test.
        """
        try:
            drift_summary = {}
            for column in reference_data.columns:
                statistic, p_value = ks_2samp(reference_data[column], current_data[column])
                drift_summary[column] = {"statistic": statistic, "p_value": p_value}
            return drift_summary
        except Exception as e:
            raise RuntimeError(f"Erreur dans la détection de drift : {e}")


class RealTimeMonitor:
    """Classe pour surveiller les performances en temps réel."""

    def monitor_performance(self, model, X, y, threshold=0.8):
        """
        Vérifie si les performances du modèle respectent un seuil.
        Args:
            model: Modèle à évaluer.
            X (pd.DataFrame): Données d'entrée.
            y (pd.Series): Labels réels.
            threshold (float): Seuil de performance minimum.
        Returns:
            bool: Indique si le modèle passe le seuil.
        """
        try:
            score = model.score(X, y)
            return score >= threshold
        except Exception as e:
            raise RuntimeError(f"Erreur dans la surveillance des performances : {e}")

class ScenarioSimulator:
    """Simule différents scénarios pour tester les modèles."""

    def simulate_scenarios(self, model, data, scenarios):
        """
        Simule l'impact de différentes modifications des données.
        Args:
            model: Modèle à évaluer.
            data (pd.DataFrame): Données d'entrée.
            scenarios (list): Liste de scénarios (fonctions de transformation).
        Returns:
            dict: Résultats des simulations.
        """
        try:
            results = {}
            for scenario_name, scenario_function in scenarios.items():
                modified_data = scenario_function(data)
                predictions = model.predict(modified_data)
                results[scenario_name] = predictions
            return results
        except Exception as e:
            raise RuntimeError(f"Erreur dans la simulation des scénarios : {e}")

class DataBalancer:
    """Équilibre les classes avec des techniques d'oversampling."""

    def balance_data(self, X, y):
        """
        Utilise SMOTE pour équilibrer les classes.
        Args:
            X (pd.DataFrame): Features.
            y (pd.Series): Cible.
        Returns:
            tuple: Données équilibrées (X_resampled, y_resampled).
        """
        try:
            smote = SMOTE(random_state=42)
            X_resampled, y_resampled = smote.fit_resample(X, y)
            return X_resampled, y_resampled
        except Exception as e:
            raise RuntimeError(f"Erreur dans l'équilibrage des données : {e}")

class DataVersioningManager:
    """Gère les versions des jeux de données."""

    def __init__(self, storage_path="data_versions"):
        self.storage_path = storage_path
        os.makedirs(self.storage_path, exist_ok=True)

    def save_version(self, data: pd.DataFrame, version_name=None):
        """
        Sauvegarde une version des données.
        Args:
            data (pd.DataFrame): Jeu de données à sauvegarder.
            version_name (str): Nom de la version (optionnel).
        Returns:
            str: Chemin du fichier sauvegardé.
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            version_name = version_name or f"version_{timestamp}.csv"
            file_path = os.path.join(self.storage_path, version_name)
            data.to_csv(file_path, index=False)
            return file_path
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la sauvegarde de la version : {e}")

    def list_versions(self):
        """
        Liste toutes les versions des données sauvegardées.
        Returns:
            list: Liste des fichiers de version disponibles.
        """
        try:
            return [f for f in os.listdir(self.storage_path) if f.endswith(".csv")]
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la liste des versions : {e}")

class OutlierRemover:
    """Détecte et supprime les valeurs aberrantes des données."""

    def remove_outliers(self, data: pd.DataFrame, method="zscore", threshold=3.0):
        """
        Supprime les outliers d'un dataset.
        Args:
            data (pd.DataFrame): Jeu de données.
            method (str): Méthode à utiliser ('zscore' ou 'iqr').
            threshold (float): Seuil pour la détection des outliers.
        Returns:
            pd.DataFrame: Jeu de données nettoyé.
        """
        try:
            if method == "zscore":
                from scipy.stats import zscore
                z_scores = zscore(data.select_dtypes(include=[np.number]))
                mask = (abs(z_scores) < threshold).all(axis=1)
            elif method == "iqr":
                Q1 = data.quantile(0.25)
                Q3 = data.quantile(0.75)
                IQR = Q3 - Q1
                mask = ~((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)
            else:
                raise ValueError("Méthode non reconnue. Choisissez 'zscore' ou 'iqr'.")
            return data[mask]
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la suppression des outliers : {e}")




class FeatureImportanceAnalyzer:
    """Analyse l'importance des caractéristiques pour un modèle."""

    def compute_feature_importance(self, model, feature_names):
        """
        Calcule l'importance des caractéristiques d'un modèle.
        Args:
            model: Modèle entraîné (ex. RandomForestClassifier).
            feature_names (list): Liste des noms des caractéristiques.
        Returns:
            pd.DataFrame: Importances des caractéristiques triées.
        """
        try:
            importances = model.feature_importances_
            importance_df = pd.DataFrame({"Feature": feature_names, "Importance": importances})
            importance_df = importance_df.sort_values(by="Importance", ascending=False)

            # Sauvegarder le graphique
            plt.figure(figsize=(10, 6))
            sns.barplot(data=importance_df, x="Importance", y="Feature", palette="viridis")
            plt.title("Importance des caractéristiques")
            plt.tight_layout()
            plt.savefig(importances_plot_path)
            plt.close()

            return {"importance_df": importance_df, "plot_path": importances_plot_path}
        except Exception as e:
            raise RuntimeError(f"Erreur dans l'analyse d'importance des caractéristiques : {e}")


class DataAugmentationManager:
    """Augmente les données pour les ensembles déséquilibrés."""

    def augment_data(self, X, y, method="smote"):
        """
        Applique des techniques d'augmentation.
        Args:
            X (pd.DataFrame): Features.
            y (pd.Series): Labels.
            method (str): Méthode d'augmentation ('smote').
        Returns:
            tuple: (X_augmented, y_augmented)
        """
        try:
            if method == "smote":
                smote = SMOTE(random_state=42)
                return smote.fit_resample(X, y)
            else:
                raise ValueError("Méthode d'augmentation non supportée.")
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'augmentation des données : {e}")

class BiasMitigator:
    """Détecte et atténue les biais dans les données."""

    def detect_bias(self, data, sensitive_feature, target):
        """
        Détecte les biais en comparant les distributions.
        Args:
            data (pd.DataFrame): Données.
            sensitive_feature (str): Colonne sensible (ex. sexe, ethnie).
            target (str): Colonne cible.
        Returns:
            dict: Résumé des biais détectés.
        """
        try:
            groups = data[sensitive_feature].unique()
            bias_summary = {}
            for group in groups:
                group_data = data[data[sensitive_feature] == group]
                bias_summary[group] = group_data[target].mean()
            return bias_summary
        except Exception as e:
            raise RuntimeError(f"Erreur dans la détection de biais : {e}")

    def mitigate_bias(self, data, sensitive_feature, method="reweighing"):
        """
        Atténue les biais dans les données.
        Args:
            data (pd.DataFrame): Données.
            sensitive_feature (str): Colonne sensible.
            method (str): Méthode d'atténuation ('reweighing').
        Returns:
            pd.DataFrame: Données corrigées.
        """
        try:
            if method == "reweighing":
                weights = data[sensitive_feature].value_counts(normalize=True)
                data["weights"] = data[sensitive_feature].map(weights)
                return data
            else:
                raise ValueError("Méthode non reconnue.")
        except Exception as e:
            raise RuntimeError(f"Erreur dans l'atténuation des biais : {e}")

class IncrementalLearningManager:
    """Gère l'apprentissage incrémental pour des modèles scalables."""

    def __init__(self):
        self.model = SGDClassifier()

    def train_incrementally(self, X_batch, y_batch):
        """
        Entraîne un modèle de manière incrémentale.
        Args:
            X_batch (pd.DataFrame): Données du batch.
            y_batch (pd.Series): Labels du batch.
        """
        try:
            self.model.partial_fit(X_batch, y_batch, classes=np.unique(y_batch))
        except Exception as e:
            raise RuntimeError(f"Erreur dans l'apprentissage incrémental : {e}")

class AdaptiveHyperparameterTuner:
    """Optimise dynamiquement les hyperparamètres."""

    def tune_hyperparameters(self, model, param_grid, X_train, y_train):
        """
        Optimise les hyperparamètres avec GridSearchCV.
        Args:
            model: Modèle à optimiser.
            param_grid (dict): Grille des hyperparamètres.
            X_train: Features d'entraînement.
            y_train: Labels d'entraînement.
        Returns:
            dict: Meilleur modèle et paramètres.
        """
        try:
            grid_search = GridSearchCV(model, param_grid, cv=3)
            grid_search.fit(X_train, y_train)
            return {"best_model": grid_search.best_estimator_, "best_params": grid_search.best_params_}
        except Exception as e:
            raise RuntimeError(f"Erreur dans l'optimisation des hyperparamètres : {e}")


class ExplainableAIManager:
    """Gère l'explicabilité des modèles IA."""

    def explain_with_shap(self, model, X_sample):
        """
        Génère des explications SHAP pour un modèle donné.
        Args:
            model: Modèle entraîné.
            X_sample: Données à expliquer.
        Returns:
            shap_values: Valeurs SHAP.
        """
        try:
            explainer = shap.TreeExplainer(model)
            shap_values = explainer.shap_values(X_sample)

            # Graphique SHAP
            shap.summary_plot(shap_values, X_sample, show=False)
            plt.title("SHAP Summary Plot")
            plt.savefig("shap_summary.png")
            plt.close()

            return {"shap_values": shap_values, "summary_plot": "shap_summary.png"}
        except Exception as e:
            raise RuntimeError(f"Erreur avec SHAP : {e}")

    def explain_with_lime(self, model, X_sample, y_sample):
        """
        Génère des explications LIME pour un modèle donné.
        Args:
            model: Modèle entraîné.
            X_sample: Données à expliquer.
            y_sample: Cible associée.
        Returns:
            lime_explanation: Explications LIME.
        """
        try:
            explainer = lime.lime_tabular.LimeTabularExplainer(
                X_sample.values,
                feature_names=X_sample.columns,
                class_names=y_sample.unique(),
                verbose=True,
                mode="classification",
            )
            explanation = explainer.explain_instance(
                X_sample.iloc[0].values, model.predict_proba
            )
            explanation.save_to_file("lime_explanation.html")
            return {"lime_explanation": "lime_explanation.html"}
        except Exception as e:
            raise RuntimeError(f"Erreur avec LIME : {e}")




class DataPrivacyManager:
    """Gère la confidentialité des données sensibles."""

    def anonymize_data(self, data: pd.DataFrame, sensitive_columns: list):
        """
        Anonymise les colonnes sensibles d'un jeu de données.
        Args:
            data (pd.DataFrame): Données originales.
            sensitive_columns (list): Colonnes à anonymiser.
        Returns:
            pd.DataFrame: Données anonymisées.
        """
        try:
            fake = Faker()
            anonymized_data = data.copy()
            for column in sensitive_columns:
                anonymized_data[column] = anonymized_data[column].apply(lambda _: fake.name())
            return anonymized_data
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'anonymisation : {e}")

    def mask_data(self, data: pd.DataFrame, sensitive_columns: list, mask_char="*"):
        """
        Masque les colonnes sensibles en remplaçant les valeurs par des caractères masqués.
        Args:
            data (pd.DataFrame): Données originales.
            sensitive_columns (list): Colonnes à masquer.
            mask_char (str): Caractère de masquage.
        Returns:
            pd.DataFrame: Données masquées.
        """
        try:
            masked_data = data.copy()
            for column in sensitive_columns:
                masked_data[column] = masked_data[column].apply(lambda x: mask_char * len(str(x)))
            return masked_data
        except Exception as e:
            raise RuntimeError(f"Erreur lors du masquage : {e}")


class FederatedLearningManager:
    """Gère l'apprentissage fédéré entre plusieurs clients."""

    def aggregate_models(self, models: list):
        """
        Agrège les modèles en combinant leurs poids.
        Args:
            models (list): Liste de modèles entraînés.
        Returns:
            model: Modèle agrégé.
        """
        try:
            weights = [model.coef_ for model in models]
            average_weights = np.mean(weights, axis=0)

            # Utiliser le premier modèle comme base
            aggregated_model = models[0]
            aggregated_model.coef_ = average_weights
            return aggregated_model
        except Exception as e:
            raise RuntimeError(f"Erreur lors de l'agrégation des modèles : {e}")

    def simulate_federated_learning(self, data_clients: list, model):
        """
        Simule un apprentissage fédéré entre plusieurs clients.
        Args:
            data_clients (list): Liste de tuples (X_client, y_client).
            model: Modèle à entraîner.
        Returns:
            aggregated_model: Modèle fédéré.
        """
        try:
            trained_models = []
            for X_client, y_client in data_clients:
                model.fit(X_client, y_client)
                trained_models.append(model)
            return self.aggregate_models(trained_models)
        except Exception as e:
            raise RuntimeError(f"Erreur dans l'apprentissage fédéré : {e}")



class RealTimeDashboardManager:
    """Génère des tableaux de bord interactifs en temps réel."""

    def __init__(self, data: pd.DataFrame):
        self.data = data

    def start_dashboard(self):
        """
        Démarre une application Dash pour visualiser les données.
        """
        app = dash.Dash(__name__)

        app.layout = html.Div([
            dcc.Dropdown(
                id="feature-dropdown",
                options=[{"label": col, "value": col} for col in self.data.columns],
                value=self.data.columns[0],
            ),
            dcc.Graph(id="real-time-graph"),
        ])

        @app.callback(
            Output("real-time-graph", "figure"),
            [Input("feature-dropdown", "value")]
        )
        def update_graph(selected_feature):
            fig = px.histogram(self.data, x=selected_feature, title=f"Distribution de {selected_feature}")
            return fig

        app.run_server(debug=True)




class NeuralNetworkBuilder:
    """Construit des réseaux de neurones personnalisés."""

    def build_model(self, input_dim, output_dim, layers=[64, 32], activation="relu", dropout_rate=0.2):
        """
        Construit un modèle de réseau de neurones.
        Args:
            input_dim (int): Dimension de l'entrée.
            output_dim (int): Dimension de la sortie.
            layers (list): Nombre de neurones par couche.
            activation (str): Fonction d'activation.
            dropout_rate (float): Taux de dropout.
        Returns:
            model: Modèle de réseau de neurones.
        """
        try:
            model = Sequential()
            model.add(Dense(layers[0], input_dim=input_dim, activation=activation))
            for units in layers[1:]:
                model.add(Dense(units, activation=activation))
                model.add(Dropout(dropout_rate))
            model.add(Dense(output_dim, activation="softmax"))
            model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])
            return model
        except Exception as e:
            raise RuntimeError(f"Erreur lors de la construction du modèle : {e}")



class AutoMLPipelineManager:
    """Gère les pipelines AutoML."""

    def run_automl(self, X_train, y_train, X_test, y_test, generations=5, population_size=20):
        """
        Exécute AutoML pour optimiser un modèle.
        Args:
            X_train, y_train: Données d'entraînement.
            X_test, y_test: Données de test.
            generations (int): Nombre de générations.
            population_size (int): Taille de la population.
        Returns:
            dict: Meilleur pipeline et score.
        """
        try:
            automl = TPOTClassifier(generations=generations, population_size=population_size, verbosity=2, random_state=42)
            automl.fit(X_train, y_train)
            score = automl.score(X_test, y_test)
            return {"best_pipeline": automl.fitted_pipeline_, "score": score}
        except Exception as e:
            raise RuntimeError(f"Erreur dans AutoML : {e}")


class QuantumMachineLearningManager:
    """Gère les modèles de Machine Learning quantique."""

    def build_quantum_circuit(self, num_qubits):
        """
        Construit un circuit quantique simple.
        Args:
            num_qubits (int): Nombre de qubits.
        Returns:
            QuantumCircuit: Circuit quantique.
        """
        circuit = QuantumCircuit(num_qubits)
        for qubit in range(num_qubits):
            circuit.h(qubit)  # Applique une porte Hadamard
        return circuit

    def train_quantum_model(self, X, y, num_qubits=3):
        """
        Entraîne un modèle quantique pour une tâche de classification.
        Args:
            X (ndarray): Données d'entraînement.
            y (ndarray): Étiquettes.
            num_qubits (int): Nombre de qubits pour le circuit quantique.
        Returns:
            dict: Résultats de l'entraînement.
        """
        try:
            circuit = RealAmplitudes(num_qubits, reps=2)
            quantum_kernel = QuantumKernel(feature_map=circuit, quantum_instance=Aer.get_backend('qasm_simulator'))
            quantum_model = VQC(quantum_kernel=quantum_kernel, optimizer=None, feature_map=circuit)

            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            quantum_model.fit(X_train, y_train)
            score = quantum_model.score(X_test, y_test)
            return {"model": quantum_model, "accuracy": score}
        except Exception as e:
            raise RuntimeError(f"Erreur dans le modèle quantique : {e}")


class ReinforcementLearningManager:
    """Gère des agents d'apprentissage par renforcement."""

    def __init__(self, state_space, action_space, learning_rate=0.1, discount_factor=0.99, exploration_rate=1.0):
        self.state_space = state_space
        self.action_space = action_space
        self.q_table = np.zeros((state_space, action_space))
        self.learning_rate = learning_rate
        self.discount_factor = discount_factor
        self.exploration_rate = exploration_rate
        self.exploration_decay = 0.99

    def choose_action(self, state):
        """
        Choisit une action en fonction de l'exploration/exploitation.
        Args:
            state (int): État actuel.
        Returns:
            int: Action choisie.
        """
        if random.uniform(0, 1) < self.exploration_rate:
            return random.randint(0, self.action_space - 1)
        return np.argmax(self.q_table[state, :])

    def update_q_table(self, state, action, reward, next_state):
        """
        Met à jour la Q-table en fonction de la récompense reçue.
        """
        best_next_action = np.argmax(self.q_table[next_state, :])
        td_target = reward + self.discount_factor * self.q_table[next_state, best_next_action]
        td_error = td_target - self.q_table[state, action]
        self.q_table[state, action] += self.learning_rate * td_error

    def train(self, environment, episodes=1000):
        """
        Entraîne un agent dans l'environnement spécifié.
        Args:
            environment: Environnement compatible OpenAI Gym.
            episodes (int): Nombre d'épisodes d'entraînement.
        Returns:
            list: Historique des récompenses.
        """
        rewards = []
        for episode in range(episodes):
            state = environment.reset()
            total_reward = 0
            done = False
            while not done:
                action = self.choose_action(state)
                next_state, reward, done, _ = environment.step(action)
                self.update_q_table(state, action, reward, next_state)
                total_reward += reward
                state = next_state
            self.exploration_rate *= self.exploration_decay
            rewards.append(total_reward)
        return rewards



class SyntheticDataGenerator:
    """Génère des données artificielles avec des GANs."""

    def build_generator(self, input_dim, output_dim):
        """
        Construit le générateur d'un GAN.
        """
        model = Sequential([
            Dense(128, activation='relu', input_dim=input_dim),
            Dense(output_dim, activation='tanh'),
        ])
        return model

    def build_discriminator(self, input_dim):
        """
        Construit le discriminateur d'un GAN.
        """
        model = Sequential([
            Dense(128, activation='relu', input_dim=input_dim),
            Dense(1, activation='sigmoid'),
        ])
        return model

    def train_gan(self, real_data, epochs=10000, batch_size=32):
        """
        Entraîne un GAN pour générer des données.
        """
        input_dim = real_data.shape[1]
        generator = self.build_generator(input_dim=100, output_dim=input_dim)
        discriminator = self.build_discriminator(input_dim=input_dim)

        discriminator.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])
        discriminator.trainable = False

        gan = Sequential([generator, discriminator])
        gan.compile(optimizer="adam", loss="binary_crossentropy")

        for epoch in range(epochs):
            noise = np.random.normal(0, 1, (batch_size, 100))
            generated_data = generator.predict(noise)

            real_labels = np.ones((batch_size, 1))
            fake_labels = np.zeros((batch_size, 1))

            d_loss_real = discriminator.train_on_batch(real_data, real_labels)
            d_loss_fake = discriminator.train_on_batch(generated_data, fake_labels)

            noise = np.random.normal(0, 1, (batch_size, 100))
            gan_loss = gan.train_on_batch(noise, real_labels)

        return generator




class DistributedDataPipelineManager:
    """Gère le traitement distribué de données avec Dask."""

    def load_large_data(self, file_path):
        """
        Charge un fichier de grande taille avec Dask.
        """
        return dd.read_csv(file_path)

    def distributed_processing(self, data):
        """
        Applique un traitement distribué.
        """
        data["new_column"] = data["column"].map(lambda x: x**2)
        return data.compute()

    def save_processed_data(self, data, file_path):
        """
        Sauvegarde les données traitées.
        """
        data.to_csv(file_path, single_file=True)


class DynamicKnowledgeGraphBuilder:
    """Construit un graphe de connaissance à partir de données textuelles."""

    def build_graph(self, entities, relations):
        """
        Construit un graphe à partir d'entités et de relations.
        """
        graph = nx.Graph()
        for entity in entities:
            graph.add_node(entity)
        for (entity1, entity2, relation) in relations:
            graph.add_edge(entity1, entity2, label=relation)
        return graph

    def visualize_graph(self, graph):
        """
        Visualise le graphe de connaissance.
        """
        pos = nx.spring_layout(graph)
        labels = nx.get_edge_attributes(graph, "label")
        nx.draw(graph, pos, with_labels=True, node_color="lightblue", edge_color="gray")
        nx.draw_networkx_edge_labels(graph, pos, edge_labels=labels)
        plt.show()

class AutonomousResearchAgent:
    """Agent autonome de recherche scientifique."""

    def __init__(self):
        self.hypothesis_generator = pipeline("text-generation", model="gpt-3.5-turbo")
        self.results = {}

    def generate_hypothesis(self, topic, num_hypotheses=3):
        """
        Génère des hypothèses à tester basées sur un sujet donné.
        Args:
            topic (str): Sujet de recherche.
            num_hypotheses (int): Nombre d'hypothèses à générer.
        Returns:
            list: Hypothèses générées.
        """
        prompts = [f"Génère une hypothèse scientifique sur : {topic}" for _ in range(num_hypotheses)]
        hypotheses = [self.hypothesis_generator(prompt, max_length=50)[0]["generated_text"] for prompt in prompts]
        return hypotheses

    def test_hypotheses(self, hypotheses, data):
        """
        Teste les hypothèses générées sur les données.
        Args:
            hypotheses (list): Liste d'hypothèses.
            data (pd.DataFrame): Données à utiliser pour le test.
        Returns:
            dict: Résultats des tests.
        """
        self.results = {hypothesis: self._simulate_test(hypothesis, data) for hypothesis in hypotheses}
        return self.results

    def _simulate_test(self, hypothesis, data):
        """
        Simule un test pour une hypothèse.
        """
        return {"p_value": np.random.uniform(0, 1), "support": np.random.choice([True, False])}

    def generate_report(self):
        """
        Génère un rapport basé sur les résultats.
        """
        report = "=== Résultats de l'agent de recherche ===\n"
        for hypothesis, result in self.results.items():
            report += f"Hypothèse : {hypothesis}\n"
            report += f"- p-value : {result['p_value']:.3f}\n"
            report += f"- Support : {'Oui' if result['support'] else 'Non'}\n\n"
        return report



class GenerativeModelArtisan:
    """Crée des œuvres d'art génératives avec des modèles IA."""

    def generate_image(self, prompt, api_url="https://api.openai.com/v1/images/generations", api_key="YOUR_API_KEY"):
        """
        Génère une image à partir d'un prompt.
        Args:
            prompt (str): Description de l'image.
        Returns:
            Image: Image générée.
        """
        headers = {"Authorization": f"Bearer {api_key}"}
        data = {"prompt": prompt, "n": 1, "size": "1024x1024"}
        response = requests.post(api_url, headers=headers, json=data)
        image_url = response.json()["data"][0]["url"]
        image = Image.open(BytesIO(requests.get(image_url).content))
        return image

    def create_interactive_art(self, prompts, iterations=5):
        """
        Crée une œuvre d'art interactive basée sur des itérations.
        Args:
            prompts (list): Liste de prompts pour guider la création.
        Returns:
            list: Liste d'images générées.
        """
        images = []
        for i in range(iterations):
            prompt = prompts[i % len(prompts)]
            images.append(self.generate_image(prompt))
        return images

class SelfImprovingAgent:
    """Agent qui apprend de ses erreurs et s'améliore en continu."""

    def __init__(self):
        self.performance_log = []
        self.current_strategy = None

    def evaluate_performance(self, metric):
        """
        Évalue la performance actuelle selon un métrique donné.
        """
        performance = np.random.uniform(0, 1)  # Simulation
        self.performance_log.append(performance)
        return performance

    def improve_strategy(self):
        """
        Modifie la stratégie actuelle en fonction des performances passées.
        """
        if len(self.performance_log) < 2:
            return "Pas assez de données pour améliorer la stratégie."

        delta = self.performance_log[-1] - self.performance_log[-2]
        if delta < 0:
            self.current_strategy = "Stratégie alternative"  # Exemple d'ajustement
        return f"Nouvelle stratégie appliquée : {self.current_strategy}"

    def train_on_feedback(self, feedback):
        """
        S'entraîne sur les retours reçus.
        """
        return f"Agent entraîné sur : {feedback}"



class NeuroInspiredAI:
    """Intelligence artificielle inspirée par le cerveau humain."""

    def simulate_neural_activity(self, neurons=100, duration=1000):
        """
        Simule une activité neuronale.
        """
        eqs = """
        dv/dt = (ge + gi - v) / (10*ms) : volt
        dge/dt = -ge / (5*ms) : volt
        dgi/dt = -gi / (10*ms) : volt
        """
        G = NeuronGroup(neurons, eqs, threshold="v > -50*mV", reset="v = -60*mV", method="exact")
        S = Synapses(G, G, on_pre="ge += 1.62*mV")
        S.connect(p=0.1)
        run(duration)
        return "Simulation terminée."


class EcosystemSimulationManager:
    """Simule un écosystème complexe avec interactions dynamiques."""

    def __init__(self, prey_population=50, predator_population=10, growth_rate=0.1, predation_rate=0.01):
        self.prey_population = prey_population
        self.predator_population = predator_population
        self.growth_rate = growth_rate
        self.predation_rate = predation_rate
        self.history = []

    def simulate_step(self):
        """
        Simule une étape de l'écosystème.
        """
        prey_growth = self.prey_population * self.growth_rate
        predation_loss = self.predation_rate * self.prey_population * self.predator_population
        predator_gain = predation_loss * 0.1

        self.prey_population += prey_growth - predation_loss
        self.predator_population += predator_gain - 0.05 * self.predator_population

        self.history.append((self.prey_population, self.predator_population))

    def run_simulation(self, steps=100):
        """
        Simule plusieurs étapes.
        """
        for _ in range(steps):
            self.simulate_step()

        prey, predators = zip(*self.history)
        plt.plot(prey, label="Proies")
        plt.plot(predators, label="Prédateurs")
        plt.legend()
        plt.title("Simulation Écosystème")
        plt.show()


class MetaIntelligenceOrchestrator:
    """Orchestrateur d'intelligence artificielle auto-évolutif."""

    def __init__(self):
        self.agents = []
        self.global_metrics = {"efficiency": [], "accuracy": []}

    def add_agent(self, agent):
        """
        Ajoute un nouvel agent à l'orchestrateur.
        Args:
            agent (object): Instance d'un agent IA.
        """
        self.agents.append(agent)

    def evaluate_agents(self):
        """
        Évalue tous les agents en fonction de leurs métriques.
        """
        for agent in self.agents:
            metrics = agent.evaluate_performance()
            self.global_metrics["efficiency"].append(metrics.get("efficiency", 0))
            self.global_metrics["accuracy"].append(metrics.get("accuracy", 0))

    def optimize_collaboration(self):
        """
        Optimise la collaboration entre les agents pour maximiser les performances.
        """
        efficiency_avg = sum(self.global_metrics["efficiency"]) / len(self.global_metrics["efficiency"])
        accuracy_avg = sum(self.global_metrics["accuracy"]) / len(self.global_metrics["accuracy"])
        return {"efficiency_avg": efficiency_avg, "accuracy_avg": accuracy_avg}

    def execute_global_task(self, task):
        """
        Répartit une tâche complexe entre les agents.
        Args:
            task (dict): Détails de la tâche.
        """
        results = []
        for agent in self.agents:
            results.append(agent.run_task(task))
        return results

class HoloSimulatedRealityManager:
    """Gestionnaire de simulations en réalité augmentée et holographiques."""

    def __init__(self):
        self.simulated_worlds = []

    def create_simulated_world(self, name, parameters):
        """
        Crée un monde simulé avec des paramètres spécifiques.
        Args:
            name (str): Nom du monde.
            parameters (dict): Paramètres du monde (gravité, météo, population...).
        """
        world = {"name": name, "parameters": parameters, "entities": []}
        self.simulated_worlds.append(world)
        return world

    def add_entity(self, world_name, entity):
        """
        Ajoute une entité à un monde simulé.
        Args:
            world_name (str): Nom du monde cible.
            entity (dict): Entité avec ses caractéristiques.
        """
        world = next((w for w in self.simulated_worlds if w["name"] == world_name), None)
        if world:
            world["entities"].append(entity)

    def simulate_step(self, world_name, iterations=1):
        """
        Simule des étapes dans le temps pour un monde.
        Args:
            world_name (str): Nom du monde.
            iterations (int): Nombre d'étapes à simuler.
        """
        world = next((w for w in self.simulated_worlds if w["name"] == world_name), None)
        if world:
            for _ in range(iterations):
                # Simule les interactions entre entités (simplifié ici)
                for entity in world["entities"]:
                    entity["state"] = "active"
        return world


class QuantumComputingSimulator:
    """Simule des algorithmes quantiques pour des applications avancées."""

    def __init__(self):
        self.circuit = QuantumCircuit(2)  # Circuit avec 2 qubits

    def apply_quantum_entanglement(self):
        """Applique un enchevêtrement quantique."""
        self.circuit.h(0)  # Applique une porte Hadamard
        self.circuit.cx(0, 1)  # Applique une porte CNOT pour l'entanglement

    def measure(self):
        """Ajoute des mesures au circuit."""
        self.circuit.measure_all()

    def simulate(self):
        """Simule le circuit quantique."""
        simulator = Aer.get_backend("qasm_simulator")
        job = execute(self.circuit, simulator, shots=1024)
        result = job.result()
        counts = result.get_counts(self.circuit)
        return counts


class CosmicDataAnalyzer:
    """Analyse des données cosmiques pour l'astronomie avancée."""

    def __init__(self):
        self.data = None

    def load_cosmic_data(self, file_path):
        """
        Charge des données astronomiques depuis un fichier.
        Args:
            file_path (str): Chemin vers le fichier de données.
        """
        self.data = Table.read(file_path, format="ascii")
        return self.data

    def plot_stellar_distribution(self):
        """
        Trace la distribution des étoiles dans le ciel.
        """
        if self.data:
            coords = SkyCoord(self.data["ra"], self.data["dec"], unit="deg")
            plt.scatter(coords.ra.deg, coords.dec.deg, alpha=0.5)
            plt.xlabel("Ascension Droite (RA)")
            plt.ylabel("Déclinaison (Dec)")
            plt.title("Distribution des étoiles")
            plt.show()

class AIDrivenPolicyOptimizer:
    """Optimise les politiques publiques à l'aide de simulations IA."""

    def __init__(self, population_data):
        self.population_data = pd.DataFrame(population_data)

    def simulate_policy(self, policy, iterations=10):
        """
        Simule l'impact d'une politique donnée.
        Args:
            policy (dict): Détails de la politique.
            iterations (int): Nombre d'itérations.
        """
        results = []
        for _ in range(iterations):
            impact = self._evaluate_policy_impact(policy)
            results.append(impact)
        return results

    def _evaluate_policy_impact(self, policy):
        """
        Évalue l'impact d'une politique.
        """
        # Exemple : Appliquer une taxe ou un subside
        self.population_data["income"] *= 1 - policy.get("tax_rate", 0)
        gini_index = 1 - (self.population_data["income"].var() / self.population_data["income"].mean())
        return {"gini_index": gini_index}

    def optimize_policy(self, objective="maximize_gini"):
        """
        Optimise une politique pour un objectif donné.
        """
        best_policy = {"tax_rate": 0.0}
        best_gini = 0
        for tax_rate in np.linspace(0, 0.5, 20):
            gini = self._evaluate_policy_impact({"tax_rate": tax_rate})["gini_index"]
            if gini > best_gini:
                best_gini = gini
                best_policy = {"tax_rate": tax_rate}
        return best_policy

class UniversalAIOrchestrator:
    """Orchestrateur universel supervisant des intelligences artificielles multi-domaines."""

    def __init__(self):
        self.domains = {}

    def register_ai(self, domain_name, ai_agent):
        """
        Enregistre une IA dans un domaine spécifique.
        Args:
            domain_name (str): Nom du domaine (santé, climat, etc.).
            ai_agent (object): Instance de l'agent IA.
        """
        if domain_name not in self.domains:
            self.domains[domain_name] = []
        self.domains[domain_name].append(ai_agent)

    def execute_global_strategy(self, strategy):
        """
        Exécute une stratégie globale en déléguant aux IA spécifiques.
        Args:
            strategy (dict): Décrit les tâches par domaine.
        """
        results = {}
        for domain, tasks in strategy.items():
            if domain in self.domains:
                results[domain] = [agent.run_task(task) for agent, task in zip(self.domains[domain], tasks)]
        return results

    def generate_universal_report(self):
        """
        Génère un rapport consolidé de toutes les IA enregistrées.
        """
        report = {}
        for domain, agents in self.domains.items():
            report[domain] = [agent.get_status() for agent in agents]
        return report

class ExoPlanetDiscoveryAI:
    """IA dédiée à l'exploration de planètes habitables dans des données astronomiques."""

    def __init__(self):
        self.discovered_planets = []

    def analyze_star_system(self, data):
        """
        Analyse un système stellaire pour y trouver des exoplanètes.
        Args:
            data (DataFrame): Données du système stellaire.
        """
        habitable_zone = data[(data["distance"] > 0.8) & (data["distance"] < 2.5)]
        potential_planets = habitable_zone[habitable_zone["atmosphere"] == "oxygen-rich"]
        self.discovered_planets.extend(potential_planets["name"].tolist())

    def get_discoveries(self):
        """Retourne les planètes découvertes."""
        return self.discovered_planets

class AIForSocialHarmony:
    """IA visant à réduire les inégalités sociales tout en améliorant la prospérité générale."""

    def __init__(self, population_data):
        self.population_data = pd.DataFrame(population_data)

    def simulate_policy_impact(self, policy):
        """
        Simule l'impact d'une politique sociale ou économique.
        Args:
            policy (dict): Détails de la politique.
        """
        self.population_data["income"] *= (1 - policy.get("tax_rate", 0.1))
        self.population_data["happiness"] += policy.get("subsidy", 0.05) * 100

    def optimize_policies(self):
        """
        Trouve la meilleure combinaison de taxes et subventions.
        """
        best_policy = {"tax_rate": 0.0, "subsidy": 0.0}
        best_happiness = 0
        for tax_rate in np.linspace(0, 0.5, 10):
            for subsidy in np.linspace(0, 0.2, 5):
                self.simulate_policy_impact({"tax_rate": tax_rate, "subsidy": subsidy})
                avg_happiness = self.population_data["happiness"].mean()
                if avg_happiness > best_happiness:
                    best_happiness = avg_happiness
                    best_policy = {"tax_rate": tax_rate, "subsidy": subsidy}
        return best_policy


class OmniFunctionalAI:
    """Une IA capable d'apprendre et de résoudre tout type de problème."""

    def __init__(self):
        self.modules = {
            "image_processing": None,
            "natural_language": None,
            "time_series_forecasting": None,
            "music_generation": None,
        }

    def load_module(self, module_name, module):
        """
        Charge un module spécialisé.
        Args:
            module_name (str): Nom du module (image_processing, natural_language, etc.).
            module (object): Instance du module IA.
        """
        if module_name in self.modules:
            self.modules[module_name] = module
        else:
            raise ValueError("Module inconnu.")

    def execute_task(self, task_type, **kwargs):
        """
        Exécute une tâche spécifique avec le module approprié.
        Args:
            task_type (str): Type de tâche (image_processing, natural_language, etc.).
        """
        module = self.modules.get(task_type)
        if not module:
            raise ValueError(f"Module {task_type} non chargé.")
        return module.run(**kwargs)

    def universal_report(self):
        """Génère un rapport des performances de chaque module."""
        report = {module: (mod.get_status() if mod else "Non chargé") for module, mod in self.modules.items()}
        return report


#from qiskit import Aer, QuantumCircuit, transpile, execute


class QuantumDataAnalyzer:
    """Analyseur de données exploitant la mécanique quantique."""

    def __init__(self):
        self.backend = Aer.get_backend('statevector_simulator')

    def prepare_circuit(self, data):
        """
        Prépare un circuit quantique basé sur les données.
        Args:
            data (np.ndarray): Tableau de données.
        """
        circuit = QuantumCircuit(len(data))
        for i, value in enumerate(data):
            circuit.h(i)  # Applique une porte Hadamard pour chaque bit
            circuit.rz(value, i)  # Rotation basée sur les données
        return circuit

    def analyze(self, data):
        """
        Effectue une analyse quantique des données.
        Args:
            data (np.ndarray): Tableau de données.
        """
        circuit = self.prepare_circuit(data)
        transpiled_circuit = transpile(circuit, self.backend)
        result = execute(transpiled_circuit, self.backend).result()
        state_vector = result.get_statevector()
        return {"state_vector": state_vector}


class IntergalacticNavigator:
    """IA dédiée à la navigation intergalactique."""

    def __init__(self):
        self.current_position = {"x": 0, "y": 0, "z": 0}
        self.known_destinations = []

    def add_destination(self, name, coordinates):
        """
        Ajoute une destination connue.
        Args:
            name (str): Nom de la destination.
            coordinates (dict): Coordonnées {x, y, z}.
        """
        self.known_destinations.append({"name": name, "coordinates": coordinates})

    def calculate_trajectory(self, destination_name):
        """
        Calcule la trajectoire optimale vers une destination.
        Args:
            destination_name (str): Nom de la destination.
        """
        destination = next((d for d in self.known_destinations if d["name"] == destination_name), None)
        if not destination:
            raise ValueError(f"Destination {destination_name} inconnue.")

        trajectory = {
            "start": self.current_position,
            "end": destination["coordinates"],
            "time_estimation": self.estimate_time(destination["coordinates"]),
        }
        return trajectory

    def estimate_time(self, coordinates):
        """
        Estime le temps de trajet.
        Args:
            coordinates (dict): Coordonnées {x, y, z}.
        """
        distance = sum((self.current_position[axis] - coordinates[axis]) ** 2 for axis in coordinates)
        return distance ** 0.5 / 299792  # Division par la vitesse de la lumière (en km/s)


class AIForUniversalSustainability:
    """IA optimisée pour la durabilité écologique et sociale à l'échelle mondiale."""

    def __init__(self):
        self.environmental_data = []

    def collect_data(self, data_source):
        """
        Collecte les données environnementales.
        Args:
            data_source (str): Chemin ou API pour les données.
        """
        data = pd.read_csv(data_source)  # Exemple simple
        self.environmental_data.append(data)

    def optimize_resource_allocation(self):
        """
        Propose des stratégies d'optimisation pour l'utilisation des ressources.
        """
        # Exemple d'optimisation : réduire les émissions de CO2
        total_emissions = sum(data["CO2_emissions"] for data in self.environmental_data)
        strategies = {"solar_energy_investment": total_emissions * 0.5, "carbon_capture": total_emissions * 0.3}
        return strategies

    def predict_future_outcomes(self, years=50):
        """
        Prévoit les résultats climatiques dans un futur donné.
        Args:
            years (int): Nombre d'années à prévoir.
        """
        # Modèle de prévision simplifié
        return {"temperature_increase": 1.5 * years / 100}


class LifeSimulatorAI:
    """Simule l'évolution de la vie sur des millions d'années."""

    def __init__(self, initial_population=1000):
        self.population = initial_population
        self.environment_factors = {"resources": 1.0, "climate_stability": 1.0}

    def simulate_generation(self):
        """
        Simule une génération de vie en fonction des facteurs environnementaux.
        """
        survival_rate = self.environment_factors["resources"] * self.environment_factors["climate_stability"]
        self.population = int(self.population * survival_rate)
        return self.population

    def introduce_event(self, event_name, impact):
        """
        Introduit un événement modifiant les conditions de vie.
        Args:
            event_name (str): Nom de l'événement.
            impact (dict): Impact sur les facteurs environnementaux.
        """
        for key, value in impact.items():
            if key in self.environment_factors:
                self.environment_factors[key] *= value

    def simulate_millions_of_years(self, years):
        """
        Simule l'évolution sur des millions d'années.
        Args:
            years (int): Nombre d'années à simuler.
        """
        for _ in range(years):
            self.simulate_generation()
        return {"population": self.population, "environment": self.environment_factors}

class EmotionallyAwareAssistant:
    """IA capable de détecter les émotions et d'adapter ses réponses."""

    def __init__(self):
        from transformers import pipeline
        self.emotion_analyzer = pipeline("sentiment-analysis")

    def detect_emotion(self, user_message: str) -> str:
        """
        Détecte l'émotion dans un message utilisateur.
        Args:
            user_message (str): Message de l'utilisateur.
        Returns:
            str: Emotion détectée.
        """
        emotions = self.emotion_analyzer(user_message)
        return emotions[0]["label"]

    def respond_with_empathy(self, user_message: str) -> str:
        """
        Génère une réponse empathique basée sur l'émotion détectée.
        Args:
            user_message (str): Message de l'utilisateur.
        Returns:
            str: Réponse empathique.
        """
        emotion = self.detect_emotion(user_message)
        responses = {
            "POSITIVE": "Je suis ravi d'entendre cela ! 😊 Que puis-je faire pour rendre votre journée encore meilleure ?",
            "NEGATIVE": "Je suis désolé que vous vous sentiez ainsi. 💔 Parlez-moi, je suis là pour vous aider.",
            "NEUTRAL": "Je comprends. N'hésitez pas à me dire en quoi je peux vous être utile. 🙂",
        }
        return responses.get(emotion, "Je suis là pour vous !")

import networkx as nx

class KnowledgeGraphAssistant:
    """Assistant utilisant un graphe de connaissances pour des réponses intelligentes."""

    def __init__(self):
        self.graph = nx.DiGraph()

    def add_knowledge(self, subject: str, relationship: str, obj: str):
        """
        Ajoute une relation au graphe de connaissances.
        Args:
            subject (str): Sujet.
            relationship (str): Relation entre les nœuds.
            obj (str): Objet.
        """
        self.graph.add_edge(subject, obj, relationship=relationship)

    def query_knowledge(self, subject: str) -> list:
        """
        Retourne toutes les relations d'un sujet.
        Args:
            subject (str): Sujet à rechercher.
        Returns:
            list: Relations du sujet.
        """
        if subject in self.graph:
            return [
                f"{subject} --({d['relationship']})--> {nbr}"
                for nbr, d in self.graph[subject].items()
            ]
        return ["Aucune information trouvée."]

    def display_graph(self):
        """Affiche le graphe avec matplotlib."""
        import matplotlib.pyplot as plt
        plt.figure(figsize=(12, 8))
        pos = nx.spring_layout(self.graph)
        nx.draw(self.graph, pos, with_labels=True, node_color="skyblue", font_size=10)
        labels = nx.get_edge_attributes(self.graph, "relationship")
        nx.draw_networkx_edge_labels(self.graph, pos, edge_labels=labels)
        plt.show()

# Utilisation
# assistant = KnowledgeGraphAssistant()
# assistant.add_knowledge("ChatGPT", "is_a", "AI assistant")
# print(assistant.query_knowledge("ChatGPT"))
# assistant.display_graph()


class DynamicWorkflowOrchestrator:
    """Orchestrateur de workflows dynamiques."""

    def __init__(self):
        self.workflow_steps = []

    def add_step(self, step_name: str, action):
        """
        Ajoute une étape au workflow.
        Args:
            step_name (str): Nom de l'étape.
            action (callable): Fonction à exécuter pour cette étape.
        """
        self.workflow_steps.append({"name": step_name, "action": action})

    def execute_workflow(self, input_data):
        """
        Exécute le workflow avec des données d'entrée.
        Args:
            input_data (dict): Données d'entrée initiales.
        Returns:
            dict: Résultats du workflow.
        """
        results = input_data
        for step in self.workflow_steps:
            results = step["action"](results)
        return results

# Exemple d'action
def clean_data(data):
    return {k: v.strip().lower() for k, v in data.items()}

def enrich_data(data):
    data["enriched"] = True
    return data

# Utilisation
# orchestrator = DynamicWorkflowOrchestrator()
# orchestrator.add_step("Nettoyage des données", clean_data)
# orchestrator.add_step("Enrichissement des données", enrich_data)
# result = orchestrator.execute_workflow({"Nom": " ChatGPT ", "Age": " OpenAI "})

class VirtualMentorAssistant:
    """Un mentor virtuel pour guider l'utilisateur dans ses apprentissages."""

    def __init__(self):
        self.skills = {}

    def add_skill(self, skill_name: str, learning_steps: list):
        """
        Ajoute une compétence avec des étapes d'apprentissage.
        Args:
            skill_name (str): Nom de la compétence.
            learning_steps (list): Étapes pour maîtriser la compétence.
        """
        self.skills[skill_name] = {"steps": learning_steps, "progress": 0}

    def track_progress(self, skill_name: str):
        """
        Suit le progrès dans une compétence.
        Args:
            skill_name (str): Compétence à suivre.
        Returns:
            str: État actuel du progrès.
        """
        if skill_name not in self.skills:
            return "Compétence non trouvée."
        skill = self.skills[skill_name]
        progress = skill["progress"]
        steps = skill["steps"]
        return f"Progression {progress}/{len(steps)} : {steps[progress] if progress < len(steps) else 'Terminé !'}"

    def complete_step(self, skill_name: str):
        """
        Marque une étape comme complétée.
        Args:
            skill_name (str): Compétence concernée.
        """
        if skill_name in self.skills and self.skills[skill_name]["progress"] < len(self.skills[skill_name]["steps"]):
            self.skills[skill_name]["progress"] += 1

# Utilisation
# mentor = VirtualMentorAssistant()
# mentor.add_skill("Apprendre Python", ["Variables", "Boucles", "Classes", "Modules"])
# print(mentor.track_progress("Apprendre Python"))
# mentor.complete_step("Apprendre Python")
# print(mentor.track_progress("Apprendre Python"))

from PIL import Image

class MultimodalAssistant:
    """Assistant capable de traiter texte, images et audio."""

    def process_text(self, text: str) -> str:
        return f"Vous avez dit : {text}"

    def process_image(self, image_path: str) -> str:
        img = Image.open(image_path)
        return f"Image analysée. Dimensions : {img.size}, Format : {img.format}"

    def process_audio(self, audio_path: str) -> str:
        return f"Fichier audio {audio_path} analysé."

# Utilisation
# assistant = MultimodalAssistant()
# print(assistant.process_text("Bonjour !"))
# print(assistant.process_image("image.png"))
# print(assistant.process_audio("audio.wav"))

class DreamGeneratorAssistant:
    """Assistant créatif capable de générer des histoires, de l'art ou de la musique."""

    def generate_story(self, theme: str, length: int = 500) -> str:
        """
        Génère une histoire basée sur un thème.
        Args:
            theme (str): Thème de l'histoire.
            length (int): Longueur approximative de l'histoire.
        Returns:
            str: Histoire générée.
        """
        return f"Voici une histoire sur le thème '{theme}':\n" + " ".join(["Il était une fois..."] * length)

    def generate_music(self, mood: str, duration: int = 60) -> str:
        """
        Génère une piste musicale.
        Args:
            mood (str): Ambiance de la musique (joyeux, triste...).
            duration (int): Durée en secondes.
        Returns:
            str: Description de la musique générée.
        """
        return f"Génération d'une musique de {duration}s avec une ambiance '{mood}'. (Musique synthétisée à venir !)"

    def generate_art(self, prompt: str) -> str:
        """
        Génère une œuvre d'art basée sur un prompt.
        Args:
            prompt (str): Description de l'art.
        Returns:
            str: Confirmation de la génération d'art.
        """
        return f"Une œuvre d'art basée sur '{prompt}' est en cours de création (illustration générée)."

# Utilisation
# dreamer = DreamGeneratorAssistant()
# print(dreamer.generate_story("aventure fantastique"))
# print(dreamer.generate_music("calme"))
# print(dreamer.generate_art("un coucher de soleil sur une plage"))

from transformers import MarianMTModel, MarianTokenizer

class UniversalTranslator:
    """Assistant multilingue avec traduction intelligente."""

    def __init__(self):
        self.models = {}
        self.tokenizers = {}

    def load_model(self, src_lang: str, tgt_lang: str):
        """Charge un modèle de traduction pour une paire de langues."""
        model_name = f"Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}"
        if model_name not in self.models:
            self.tokenizers[model_name] = MarianTokenizer.from_pretrained(model_name)
            self.models[model_name] = MarianMTModel.from_pretrained(model_name)

    def translate(self, text: str, src_lang: str, tgt_lang: str) -> str:
        """
        Traduit un texte d'une langue à une autre.
        Args:
            text (str): Texte à traduire.
            src_lang (str): Langue source.
            tgt_lang (str): Langue cible.
        Returns:
            str: Texte traduit.
        """
        self.load_model(src_lang, tgt_lang)
        model_name = f"Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}"
        tokenizer = self.tokenizers[model_name]
        model = self.models[model_name]
        encoded = tokenizer(text, return_tensors="pt", padding=True)
        translated = model.generate(**encoded)
        return tokenizer.decode(translated[0], skip_special_tokens=True)

# Utilisation
# translator = UniversalTranslator()
# print(translator.translate("Bonjour, comment allez-vous ?", "fr", "en"))

class HyperAssistantManager:
    """Un orchestrateur d'assistants pour gérer des tâches multiples."""

    def __init__(self):
        self.assistants = {}

    def register_assistant(self, name: str, assistant):
        """
        Enregistre un assistant dans le système.
        Args:
            name (str): Nom de l'assistant.
            assistant: Instance de l'assistant.
        """
        self.assistants[name] = assistant

    def execute_task(self, assistant_name: str, task_name: str, *args, **kwargs):
        """
        Exécute une tâche via un assistant enregistré.
        Args:
            assistant_name (str): Nom de l'assistant.
            task_name (str): Nom de la méthode à appeler.
        Returns:
            Résultat de la méthode exécutée.
        """
        if assistant_name in self.assistants:
            assistant = self.assistants[assistant_name]
            task = getattr(assistant, task_name, None)
            if callable(task):
                return task(*args, **kwargs)
        return f"L'assistant {assistant_name} ou la tâche {task_name} est introuvable."

# Utilisation
# manager = HyperAssistantManager()
# translator = UniversalTranslator()
# manager.register_assistant("translator", translator)
# print(manager.execute_task("translator", "translate", "Hola, ¿cómo estás?", "es", "en"))

class CrisisManagerAssistant:
    """Assistant pour gérer des situations de crise."""

    def handle_emergency(self, emergency_type: str):
        """
        Gère une situation d'urgence.
        Args:
            emergency_type (str): Type d'urgence.
        Returns:
            str: Conseils ou actions recommandées.
        """
        responses = {
            "medical": "Appelez immédiatement le 112. Si la personne ne respire pas, commencez un massage cardiaque.",
            "technical": "Essayez de redémarrer l'appareil. Si le problème persiste, contactez le support technique.",
            "security": "Restez calme. Contactez les forces de l'ordre ou un service de sécurité.",
        }
        return responses.get(emergency_type, "Type d'urgence inconnu. Fournissez plus d'informations.")

# Utilisation
# crisis_assistant = CrisisManagerAssistant()
# print(crisis_assistant.handle_emergency("medical"))

class UserContext:
    def __init__(self):
        self.memory = {}

    def update_context(self, user_id, key, value):
        if user_id not in self.memory:
            self.memory[user_id] = {}
        self.memory[user_id][key] = value

    def get_context(self, user_id):
        return self.memory.get(user_id, {})

class DatasetManager:
    """
    Classe pour gérer les ensembles de données, incluant la division en training, validation et test.
    """

    def __init__(self, test_size=0.2, val_size=0.1, random_state=42):
        self.test_size = test_size
        self.val_size = val_size
        self.random_state = random_state

    def split_data(self, data, target_column):
        """
        Divise les données en ensembles d'entraînement, validation et test.

        Args:
            data (pd.DataFrame): Données à diviser.
            target_column (str): Colonne cible.

        Returns:
            dict: Dictionnaire contenant les ensembles train, val et test.
        """
        X = data.drop(columns=[target_column])
        y = data[target_column]

        X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=self.test_size, random_state=self.random_state)
        val_size_adjusted = self.val_size / (1 - self.test_size)
        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=val_size_adjusted, random_state=self.random_state)

        return {
            "train": (X_train, y_train),
            "val": (X_val, y_val),
            "test": (X_test, y_test)
        }

class ModelManager:
    """
    Classe pour gérer les modèles machine learning, incluant l'entraînement,
    l'évaluation, et la persistance des modèles.
    """

    def __init__(self, model):
        self.model = model

    def train(self, X_train, y_train):
        """
        Entraîne le modèle.

        Args:
            X_train (pd.DataFrame): Features d'entraînement.
            y_train (pd.Series): Cible d'entraînement.

        Returns:
            self: Modèle entraîné.
        """
        self.model.fit(X_train, y_train)
        return self

    def evaluate(self, X_test, y_test, metric="accuracy"):
        """
        Évalue le modèle sur des données de test.

        Args:
            X_test (pd.DataFrame): Features de test.
            y_test (pd.Series): Cible de test.
            metric (str): Métrique d'évaluation ('accuracy', 'mse', 'r2').

        Returns:
            float: Score de la métrique choisie.
        """
        predictions = self.model.predict(X_test)
        if metric == "accuracy":
            return accuracy_score(y_test, predictions)
        elif metric == "mse":
            return mean_squared_error(y_test, predictions)
        elif metric == "r2":
            return r2_score(y_test, predictions)
        else:
            raise ValueError(f"Métrique inconnue : {metric}")

    def save_model(self, filepath):
        """
        Sauvegarde le modèle sur le disque.

        Args:
            filepath (str): Chemin de sauvegarde.
        """
        joblib.dump(self.model, filepath)

    def load_model(self, filepath):
        """
        Charge un modèle depuis le disque.

        Args:
            filepath (str): Chemin du modèle sauvegardé.

        Returns:
            ModelManager: Instance de ModelManager avec le modèle chargé.
        """
        self.model = joblib.load(filepath)
        return self

class AutoPipeline:
    """
    Classe pour automatiser les pipelines ML, de la préparation des données à l'évaluation des modèles.
    """

    def __init__(self, model):
        self.preprocessor = DataPreprocessor()
        self.dataset_manager = DatasetManager()
        self.model_manager = ModelManager(model)

    def execute_pipeline(self, data, target_column, metric="accuracy"):
        """
        Exécute le pipeline complet.

        Args:
            data (pd.DataFrame): Données brutes.
            target_column (str): Colonne cible.
            metric (str): Métrique d'évaluation.

        Returns:
            float: Score du modèle sur l'ensemble de test.
        """
        # Prétraitement des données
        preprocessed_data = self.preprocessor.preprocess(data)

        # Division des données
        datasets = self.dataset_manager.split_data(preprocessed_data, target_column)

        # Entraînement
        self.model_manager.train(*datasets["train"])

        # Évaluation
        return self.model_manager.evaluate(*datasets["test"], metric=metric)

class HyperparameterTuner:
    """
    Classe pour l'optimisation des hyperparamètres avec Optuna.
    """

    def __init__(self, model, X_train, y_train, metric="accuracy"):
        self.model = model
        self.X_train = X_train
        self.y_train = y_train
        self.metric = metric

    def tune(self, param_distributions, n_trials=50):
        """
        Optimise les hyperparamètres du modèle.

        Args:
            param_distributions (dict): Hyperparamètres à tester.
            n_trials (int): Nombre d'itérations d'optimisation.

        Returns:
            dict: Meilleurs hyperparamètres.
        """
        def objective(trial):
            params = {key: trial.suggest_categorical(key, value) for key, value in param_distributions.items()}
            self.model.set_params(**params)
            score = cross_val_score(self.model, self.X_train, self.y_train, cv=5, scoring=self.metric).mean()
            return score

        study = optuna.create_study(direction="maximize")
        study.optimize(objective, n_trials=n_trials)
        return study.best_params

class AutoMLBot:
    """
    Classe pour effectuer une exploration AutoML avec H2O.
    """

    def __init__(self):
        h2o.init()

    def train(self, data, target, max_models=20, max_runtime_secs=300):
        """
        Entraîne plusieurs modèles pour trouver le meilleur.

        Args:
            data (pd.DataFrame): Données avec la colonne cible.
            target (str): Nom de la colonne cible.
            max_models (int): Nombre maximal de modèles à tester.
            max_runtime_secs (int): Temps maximal d'entraînement.

        Returns:
            h2o.automl.H2OAutoML: Objet AutoML avec les meilleurs modèles.
        """
        h2o_data = h2o.H2OFrame(data)
        train, test = h2o_data.split_frame(ratios=[.8])
        aml = H2OAutoML(max_models=max_models, max_runtime_secs=max_runtime_secs)
        aml.train(y=target, training_frame=train)
        return aml.leaderboard

    def predict(self, model, data):
        """
        Effectue une prédiction avec le meilleur modèle.

        Args:
            model (h2o.automl.H2OAutoML): Modèle H2O entraîné.
            data (pd.DataFrame): Données de test.

        Returns:
            h2o.H2OFrame: Prédictions.
        """
        h2o_data = h2o.H2OFrame(data)
        return model.predict(h2o_data)

class ModelAPI:
    """
    Classe pour gérer l'entraînement et l'exposition de modèles via une API REST.
    """

    def __init__(self, model):
        self.model = model
        self.app = Flask(__name__)

        @self.app.route("/train", methods=["POST"])
        def train():
            data = request.get_json()
            X = pd.DataFrame(data["X"])
            y = pd.Series(data["y"])
            self.model.fit(X, y)
            return jsonify({"message": "Modèle entraîné avec succès."})

        @self.app.route("/predict", methods=["POST"])
        def predict():
            data = request.get_json()
            X = pd.DataFrame(data["X"])
            predictions = self.model.predict(X).tolist()
            return jsonify({"predictions": predictions})

        @self.app.route("/save", methods=["POST"])
        def save():
            filepath = request.json["filepath"]
            joblib.dump(self.model, filepath)
            return jsonify({"message": f"Modèle sauvegardé sous {filepath}"})

    def run(self, port=5000):
        self.app.run(port=port)

class AutoAdaptivePipeline:
    """
    Pipeline dynamique qui ajuste automatiquement ses étapes en fonction des données.
    """

    def __init__(self):
        self.pipeline = None

    def build_pipeline(self, data, target):
        """
        Configure le pipeline automatiquement selon les types de colonnes.

        Args:
            data (pd.DataFrame): Données d'entrée.
            target (str): Colonne cible.

        Returns:
            Pipeline: Pipeline complet.
        """
        numeric_features = data.select_dtypes(include=['number']).columns.tolist()
        categorical_features = data.select_dtypes(exclude=['number']).columns.tolist()

        numeric_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='mean')),
            ('scaler', StandardScaler())
        ])

        categorical_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
            ('onehot', OneHotEncoder(handle_unknown='ignore'))
        ])

        preprocessor = ColumnTransformer(
            transformers=[
                ('num', numeric_transformer, numeric_features),
                ('cat', categorical_transformer, categorical_features)
            ]
        )

        self.pipeline = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('classifier', RandomForestClassifier())
        ])

    def train_and_evaluate(self, data, target):
        """
        Entraîne et évalue automatiquement le modèle sur des données.

        Args:
            data (pd.DataFrame): Données d'entrée.
            target (str): Nom de la colonne cible.

        Returns:
            dict: Scores d'évaluation.
        """
        X = data.drop(columns=[target])
        y = data[target]
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        self.build_pipeline(X, target)
        self.pipeline.fit(X_train, y_train)

        accuracy = self.pipeline.score(X_test, y_test)
        return {"accuracy": accuracy}

    def predict(self, data):
        """
        Effectue des prédictions sur de nouvelles données.

        Args:
            data (pd.DataFrame): Données à prédire.

        Returns:
            list: Prédictions.
        """
        return self.pipeline.predict(data)



class DataAugmenter:
    """
    Classe pour augmenter les données automatiquement pour les images ou les textes.
    """

    def __init__(self):
        self.augmentation_pipeline = Compose([
            HorizontalFlip(p=0.5),
            Rotate(limit=15, p=0.7),
            RandomBrightnessContrast(p=0.3)
        ])

    def augment_image(self, image):
        """
        Augmente une image en appliquant des transformations.

        Args:
            image (np.array): Image à augmenter.

        Returns:
            np.array: Image augmentée.
        """
        return self.augmentation_pipeline(image=image)['image']

    def augment_text(self, text):
        """
        Augmente un texte en paraphrasant ou en générant des variations.

        Args:
            text (str): Texte d'entrée.

        Returns:
            list: Variations du texte.
        """
        from transformers import pipeline
        paraphraser = pipeline("text2text-generation", model="t5-small")
        augmented_texts = paraphraser(f"paraphrase: {text}", num_return_sequences=3)
        return [t['generated_text'] for t in augmented_texts]

class PreTrainedModelIntegrator:
    """
    Intègre des modèles pré-entraînés pour le traitement avancé.
    """

    def __init__(self):
        self.text_model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased")
        self.tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
        self.image_model = fasterrcnn_resnet50_fpn(pretrained=True)

    def classify_text(self, text):
        """
        Classifie un texte en utilisant BERT.

        Args:
            text (str): Texte d'entrée.

        Returns:
            dict: Résultats de classification.
        """
        inputs = self.tokenizer(text, return_tensors="pt")
        outputs = self.text_model(**inputs)
        return outputs.logits.softmax(dim=-1).detach().numpy()

    def detect_objects(self, image_path):
        """
        Détecte des objets dans une image.

        Args:
            image_path (str): Chemin de l'image.

        Returns:
            dict: Résultats de détection.
        """
        image = Image.open(image_path).convert("RGB")
        image_tensor = torchvision.transforms.ToTensor()(image)
        predictions = self.image_model([image_tensor])
        return predictions[0]

class MultiModalAnalyzer:
    """
    Analyse des données multimodales (texte, image, tableau).
    """

    def analyze(self, text_data, image_path, tabular_data):
        """
        Combine texte, image et tableau dans une seule analyse.

        Args:
            text_data (str): Texte à analyser.
            image_path (str): Chemin de l'image.
            tabular_data (pd.DataFrame): Données tabulaires.

        Returns:
            dict: Résultats combinés.
        """
        pre_trained = PreTrainedModelIntegrator()

        text_result = pre_trained.classify_text(text_data)
        image_result = pre_trained.detect_objects(image_path)
        tabular_summary = tabular_data.describe().to_dict()

        return {
            "text_analysis": text_result,
            "image_analysis": image_result,
            "tabular_analysis": tabular_summary
        }


class InteractiveDashboard:
    """
    Crée un tableau de bord interactif pour visualiser les résultats.
    """

    def display(self, data, predictions, metrics):
        """
        Affiche les données et les résultats de manière interactive.

        Args:
            data (pd.DataFrame): Données utilisées.
            predictions (list): Résultats des prédictions.
            metrics (dict): Métriques d'évaluation.
        """
        st.title("Analyse Interactive des Données")
        st.write("### Données d'entrée")
        st.dataframe(data)

        st.write("### Prédictions")
        st.write(predictions)

        st.write("### Métriques d'évaluation")
        for metric, value in metrics.items():
            st.metric(metric, value)

from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC

class ParallelFusionLearning:
    """
    Apprentissage fusionnel parallèle avec plusieurs modèles.
    """

    def __init__(self):
        self.models = [
            ("decision_tree", DecisionTreeClassifier()),
            ("svm", SVC(probability=True))
        ]
        self.stack_model = None

    def train(self, X, y):
        """
        Entraîne des modèles et construit un empilement.
        """
        meta_model = LogisticRegression()
        self.stack_model = StackingClassifier(estimators=self.models, final_estimator=meta_model)
        self.stack_model.fit(X, y)

    def predict(self, X):
        """
        Prédit les résultats en fusionnant les modèles.
        """
        return self.stack_model.predict(X)

    def explain_decision(self, X):
        """
        Explique la décision à l’aide de SHAP.
        """
        import shap
        explainer = shap.Explainer(self.stack_model, X)
        shap_values = explainer(X)
        return shap_values

class SmartModelManager:
    """
    Gestion dynamique des modèles selon leurs performances.
    """

    def __init__(self):
        self.models = {}
        self.best_model = None
        self.best_score = 0

    def add_model(self, name, model):
        """
        Ajoute un modèle à la gestion.
        """
        self.models[name] = model

    def evaluate_models(self, X_train, X_test, y_train, y_test):
        """
        Évalue tous les modèles et sélectionne le meilleur.
        """
        for name, model in self.models.items():
            model.fit(X_train, y_train)
            score = model.score(X_test, y_test)
            if score > self.best_score:
                self.best_score = score
                self.best_model = (name, model)
        return self.best_model

    def replace_underperforming_models(self, X_train, y_train):
        """
        Remplace les modèles sous-performants par des alternatives.
        """
        for name, model in self.models.items():
            score = model.score(X_train, y_train)
            if score < 0.7:  # Seuil de sous-performance
                self.models[name] = self._get_alternative_model(name)

    def _get_alternative_model(self, model_name):
        """
        Renvoie un modèle alternatif basé sur son nom.
        """
        if "tree" in model_name:
            return RandomForestClassifier()
        elif "svm" in model_name:
            return LogisticRegression()
        else:
            return GradientBoostingClassifier()

import numpy as np
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt

class SpatialAnalyzer3D:
    """
    Classe pour analyser et visualiser des données 3D.
    """

    def analyze_clusters(self, data, n_clusters=3):
        """
        Effectue un clustering 3D et visualise les résultats.
        """
        from sklearn.cluster import KMeans
        kmeans = KMeans(n_clusters=n_clusters)
        labels = kmeans.fit_predict(data)

        # Visualisation
        fig = plt.figure()
        ax = fig.add_subplot(111, projection='3d')
        ax.scatter(data[:, 0], data[:, 1], data[:, 2], c=labels, cmap='viridis')
        plt.show()

        return {"clusters": labels, "centroids": kmeans.cluster_centers_}

    def simulate_trajectory(self, start, end, steps):
        """
        Simule un trajet 3D entre deux points.
        """
        x = np.linspace(start[0], end[0], steps)
        y = np.linspace(start[1], end[1], steps)
        z = np.linspace(start[2], end[2], steps)

        fig = plt.figure()
        ax = fig.add_subplot(111, projection='3d')
        ax.plot(x, y, z, label="Trajectoire simulée")
        ax.legend()
        plt.show()

        return np.vstack([x, y, z]).T

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LeakyReLU
import numpy as np

class SyntheticDataGenerator:
    """
    Génère des données synthétiques réalistes avec des GANs.
    """

    def __init__(self):
        self.generator = self._build_generator()
        self.discriminator = self._build_discriminator()
        self.gan = self._build_gan()

    def _build_generator(self):
        """
        Construit le générateur.
        """
        model = Sequential([
            Dense(128, input_dim=100),
            LeakyReLU(alpha=0.2),
            Dense(256),
            LeakyReLU(alpha=0.2),
            Dense(2, activation='tanh')  # Génère 2D (ou modifier pour d'autres dimensions)
        ])
        return model

    def _build_discriminator(self):
        """
        Construit le discriminateur.
        """
        model = Sequential([
            Dense(256, input_dim=2),
            LeakyReLU(alpha=0.2),
            Dense(1, activation='sigmoid')
        ])
        model.compile(optimizer="adam", loss="binary_crossentropy")
        return model

    def _build_gan(self):
        """
        Combine générateur et discriminateur.
        """
        self.discriminator.trainable = False
        model = Sequential([self.generator, self.discriminator])
        model.compile(optimizer="adam", loss="binary_crossentropy")
        return model

    def train(self, real_data, epochs=1000, batch_size=32):
        """
        Entraîne le GAN pour générer des données synthétiques.
        """
        for epoch in range(epochs):
            # Sélection des vraies données
            idx = np.random.randint(0, real_data.shape[0], batch_size)
            real_samples = real_data[idx]

            # Génération des fausses données
            noise = np.random.normal(0, 1, (batch_size, 100))
            fake_samples = self.generator.predict(noise)

            # Entraîne le discriminateur
            d_loss_real = self.discriminator.train_on_batch(real_samples, np.ones((batch_size, 1)))
            d_loss_fake = self.discriminator.train_on_batch(fake_samples, np.zeros((batch_size, 1)))

            # Entraîne le générateur
            noise = np.random.normal(0, 1, (batch_size, 100))
            g_loss = self.gan.train_on_batch(noise, np.ones((batch_size, 1)))

            if epoch % 100 == 0:
                print(f"Epoch {epoch}: D Loss = {d_loss_real + d_loss_fake}, G Loss = {g_loss}")

    def generate(self, n_samples=100):
        """
        Génère de nouvelles données.
        """
        noise = np.random.normal(0, 1, (n_samples, 100))
        return self.generator.predict(noise)

class MultiAgentSystem:
    """
    Système multi-agent pour exécuter des tâches complexes.
    """

    def __init__(self):
        self.agents = {}

    def register_agent(self, name, function):
        """
        Ajoute un agent avec une tâche spécifique.
        """
        self.agents[name] = function

    def execute(self, task_name, *args, **kwargs):
        """
        Exécute une tâche par un agent spécifique.
        """
        if task_name in self.agents:
            return self.agents[task_name](*args, **kwargs)
        else:
            raise ValueError(f"Agent '{task_name}' non trouvé.")

    def collaborate(self, tasks, *args, **kwargs):
        """
        Coordonne plusieurs agents pour collaborer.
        """
        results = {}
        for task_name in tasks:
            if task_name in self.agents:
                results[task_name] = self.agents[task_name](*args, **kwargs)
        return results

#from autosklearn.classification import AutoSklearnClassifier

class AutoMLPipeline:
    """
    Pipeline AutoML pour automatiser l'apprentissage et l'évaluation.
    """

    def __init__(self, time_limit=360):
        self.model = AutoSklearnClassifier(time_left_for_this_task=time_limit)

    def fit(self, X_train, y_train):
        """
        Entraîne automatiquement plusieurs modèles.
        """
        self.model.fit(X_train, y_train)

    def predict(self, X_test):
        """
        Prédit avec le meilleur modèle trouvé.
        """
        return self.model.predict(X_test)

    def leaderboard(self):
        """
        Retourne les performances des modèles explorés.
        """
        return self.model.sprint_statistics()

from transformers import AutoModelForCausalLM, AutoTokenizer

class GenerativeConversationalAgent:
    """
    Agent basé sur GPT pour des réponses conversationnelles intelligentes.
    """

    def __init__(self, model_name="gpt2"):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForCausalLM.from_pretrained(model_name)

    def generate_response(self, prompt, max_length=50):
        """
        Génère une réponse basée sur un prompt donné.
        """
        inputs = self.tokenizer(prompt, return_tensors="pt")
        outputs = self.model.generate(inputs.input_ids, max_length=max_length, num_return_sequences=1)
        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)

from sklearn.metrics import confusion_matrix

class BiasFairnessAnalyzer:
    """
    Analyse les biais et garantit l'équité dans les prédictions.
    """

    def __init__(self, sensitive_feature):
        self.sensitive_feature = sensitive_feature

    def evaluate_fairness(self, data, labels, predictions):
        """
        Évalue l'équité du modèle selon une caractéristique sensible.
        """
        groups = data[self.sensitive_feature].unique()
        fairness_report = {}
        for group in groups:
            group_indices = data[self.sensitive_feature] == group
            cm = confusion_matrix(labels[group_indices], predictions[group_indices])
            accuracy = cm.diagonal().sum() / cm.sum()
            fairness_report[group] = accuracy
        return fairness_report

from surprise import SVD, Dataset, Reader
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

class HybridRecommender:
    """
    Système de recommandation hybride.
    """

    def __init__(self):
        self.collaborative_model = SVD()
        self.content_similarity = None

    def fit(self, ratings, content_data):
        """
        Entraîne le modèle collaboratif et calcule les similarités de contenu.
        """
        reader = Reader(rating_scale=(1, 5))
        data = Dataset.load_from_df(ratings[['userId', 'itemId', 'rating']], reader)
        self.collaborative_model.fit(data.build_full_trainset())

        vectorizer = TfidfVectorizer()
        self.content_similarity = cosine_similarity(vectorizer.fit_transform(content_data))

    def recommend(self, user_id, item_id):
        """
        Recommande un mélange de contenu similaire et de suggestions collaboratives.
        """
        collaborative_score = self.collaborative_model.predict(user_id, item_id).est
        content_score = self.content_similarity[item_id].mean()
        return (collaborative_score + content_score) / 2

import shap
import plotly.express as px

class InteractiveExplainability:
    """
    Classe pour des visualisations interactives avec SHAP.
    """

    def __init__(self, model, data):
        self.explainer = shap.Explainer(model, data)
        self.data = data

    def plot_summary(self):
        """
        Affiche un résumé interactif des explications.
        """
        shap_values = self.explainer(self.data)
        shap.summary_plot(shap_values, self.data)

    def interactive_scatter(self):
        """
        Crée un graphique interactif des impacts des caractéristiques.
        """
        shap_values = self.explainer(self.data)
        shap_df = pd.DataFrame(shap_values.values, columns=self.data.columns)
        shap_df["Impact"] = shap_values.values.mean(axis=1)

        fig = px.scatter(shap_df, x="Impact", y=self.data.columns[0], color=self.data.columns[1])
        fig.show()

class MetaLearningAgent:
    """
    Agent de méta-apprentissage qui ajuste ses algorithmes selon la tâche.
    """

    def __init__(self, base_model):
        self.base_model = base_model
        self.meta_weights = {}

    def learn(self, task_data, task_labels):
        """
        Apprend des méta-poids pour ajuster le modèle de base.
        """
        self.meta_weights = self._compute_meta_weights(task_data, task_labels)

    def predict(self, data):
        """
        Prédit en utilisant les méta-poids.
        """
        adjusted_model = self._adjust_model(self.base_model, self.meta_weights)
        return adjusted_model.predict(data)

    def _compute_meta_weights(self, task_data, task_labels):
        # Simule le calcul des méta-poids
        return {feature: weight for feature, weight in enumerate(range(len(task_data.columns)))}

    def _adjust_model(self, model, weights):
        # Ajuste dynamiquement le modèle
        model.set_params(**weights)
        return model

class ActiveFeedbackLoop:
    """
    Pipeline pour inclure le retour utilisateur dans le modèle.
    """

    def __init__(self, model):
        self.model = model
        self.feedback_data = []

    def get_feedback(self, user_input, predicted_output):
        """
        Demande à l'utilisateur si la prédiction est correcte.
        """
        is_correct = input(f"La prédiction '{predicted_output}' est-elle correcte (oui/non) ? ").lower()
        self.feedback_data.append((user_input, predicted_output, is_correct == "oui"))

    def update_model(self):
        """
        Met à jour le modèle en fonction du retour.
        """
        corrected_data = [data for data in self.feedback_data if data[2]]
        if corrected_data:
            X, y = zip(*[(d[0], d[1]) for d in corrected_data])
            self.model.fit(X, y)

import gym
import numpy as np

class ReinforcementLearningAgent:
    """
    Agent d'apprentissage par renforcement pour résoudre des tâches complexes.
    """

    def __init__(self, env_name="CartPole-v1"):
        self.env = gym.make(env_name)
        self.q_table = np.zeros((self.env.observation_space.n, self.env.action_space.n))
        self.alpha = 0.1  # Taux d'apprentissage
        self.gamma = 0.99  # Facteur d'actualisation
        self.epsilon = 1.0  # Exploration initiale

    def train(self, episodes=1000):
        """
        Entraîne l'agent avec Q-Learning.
        """
        for episode in range(episodes):
            state = self.env.reset()
            done = False

            while not done:
                if np.random.uniform(0, 1) < self.epsilon:
                    action = self.env.action_space.sample()  # Exploration
                else:
                    action = np.argmax(self.q_table[state])  # Exploitation

                next_state, reward, done, _ = self.env.step(action)
                self.q_table[state, action] = self.q_table[state, action] + \
                    self.alpha * (reward + self.gamma * np.max(self.q_table[next_state]) - self.q_table[state, action])
                state = next_state

            self.epsilon = max(0.01, self.epsilon * 0.995)  # Réduction de l'exploration

    def choose_action(self, state):
        """
        Choisit une action basée sur la Q-Table.
        """
        return np.argmax(self.q_table[state])

class ContextualDialogManager:
    """
    Gère le contexte des conversations pour un dialogue multi-turn.
    """

    def __init__(self):
        self.context = {}

    def update_context(self, user_message, bot_response):
        """
        Met à jour le contexte avec les messages utilisateur et bot.
        """
        self.context["last_user_message"] = user_message
        self.context["last_bot_response"] = bot_response

    def generate_response(self, user_message):
        """
        Génère une réponse basée sur le contexte.
        """
        if "last_user_message" in self.context:
            return f"En réponse à votre précédente question : {self.context['last_user_message']}, voici ma réponse : ..."
        else:
            return "Bonjour, comment puis-je vous aider ?"

from concurrent.futures import ThreadPoolExecutor

class MultiTaskPipeline:
    """
    Exécute plusieurs tâches simultanément pour maximiser l'efficacité.
    """

    def __init__(self):
        self.tasks = []

    def add_task(self, function, *args):
        """
        Ajoute une tâche à la pipeline.
        """
        self.tasks.append((function, args))

    def execute(self):
        """
        Exécute toutes les tâches en parallèle.
        """
        results = []
        with ThreadPoolExecutor() as executor:
            futures = [executor.submit(task[0], *task[1]) for task in self.tasks]
            for future in futures:
                results.append(future.result())
        return results

from flask import Flask, request, jsonify

class RealTimeDeployment:
    """
    Déploie un modèle en temps réel via une API REST.
    """

    def __init__(self, model):
        self.model = model
        self.app = Flask(__name__)

        @self.app.route("/predict", methods=["POST"])
        def predict():
            data = request.json
            prediction = self.model.predict([data['features']])
            return jsonify({"prediction": prediction.tolist()})

    def run(self, host="0.0.0.0", port=5000):
        self.app.run(host=host, port=port)

import shap

class ExplainableAIAgent:
    """
    Explique les décisions des modèles avec SHAP.
    """

    def __init__(self, model, data):
        self.explainer = shap.Explainer(model, data)

    def explain(self, instance):
        """
        Génère une explication pour une instance donnée.
        """
        shap_values = self.explainer(instance)
        shap.plots.waterfall(shap_values[0])

import spacy
from sklearn.feature_extraction.text import TfidfVectorizer

class SemanticTextAnalyzer:
    """
    Analyse avancée de texte avec embeddings et modèles NLP.
    """

    def __init__(self, model_name="en_core_web_sm"):
        self.nlp = spacy.load(model_name)

    def extract_keywords(self, text, top_n=5):
        """
        Extrait les mots-clés importants d'un texte.
        """
        doc = self.nlp(text)
        tfidf = TfidfVectorizer()
        tfidf_matrix = tfidf.fit_transform([token.text for token in doc if not token.is_stop and not token.is_punct])
        keywords = tfidf.get_feature_names_out()
        return keywords[:top_n]

    def summarize(self, text):
        """
        Génère un résumé basé sur des phrases clés.
        """
        doc = self.nlp(text)
        sentences = [sent.text for sent in doc.sents]
        return sentences[:2]  # Les deux premières phrases comme résumé

import ray
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

@ray.remote
class DistributedTrainingManager:
    """
    Gère l'entraînement distribué des modèles en parallèle.
    """

    def __init__(self, model_class, params):
        self.model = model_class(**params)

    def train(self, X_train, y_train):
        self.model.fit(X_train, y_train)
        return self.model

    def evaluate(self, X_test, y_test):
        return self.model.score(X_test, y_test)

#import autosklearn.classification

class AutoMLModelSearcher:
    """
    Automatisation de la recherche de modèles avec Auto-sklearn.
    """

    def __init__(self, time_limit=360):
        self.model = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=time_limit)

    def train(self, X_train, y_train):
        """
        Entraîne le modèle AutoML.
        """
        self.model.fit(X_train, y_train)
        return self.model

    def evaluate(self, X_test, y_test):
        """
        Évalue le modèle sur un ensemble de test.
        """
        return self.model.score(X_test, y_test)

import torch
from diffusers import StableDiffusionPipeline

class ImageGenerator:
    """
    Génère des images basées sur du texte avec un modèle de diffusion.
    """

    def __init__(self, model_name="runwayml/stable-diffusion-v1-5"):
        self.pipeline = StableDiffusionPipeline.from_pretrained(model_name, torch_dtype=torch.float16)
        self.pipeline.to("cuda")

    def generate_image(self, prompt, output_path="generated_image.png"):
        """
        Génère une image à partir d'une description textuelle.
        """
        image = self.pipeline(prompt).images[0]
        image.save(output_path)
        return output_path

from transformers import pipeline

class TaskPlannerGPT:
    """
    Planifie automatiquement des tâches avec un modèle GPT.
    """

    def __init__(self, model_name="gpt-3.5-turbo"):
        self.generator = pipeline("text-generation", model=model_name)

    def plan_tasks(self, goal, context=""):
        """
        Planifie des tâches basées sur un objectif donné.
        """
        prompt = f"Planifie les étapes pour atteindre l'objectif suivant : {goal}. Contexte : {context}"
        result = self.generator(prompt, max_length=200, num_return_sequences=1)
        return result[0]["generated_text"]

import networkx as nx

class KnowledgeGraphRecommender:
    """
    Génère des recommandations basées sur un graphe de connaissances.
    """

    def __init__(self):
        self.graph = nx.Graph()

    def add_relationship(self, entity1, entity2, weight=1):
        """
        Ajoute une relation entre deux entités.
        """
        self.graph.add_edge(entity1, entity2, weight=weight)

    def recommend(self, entity, top_n=5):
        """
        Recommande les entités les plus liées à l'entité donnée.
        """
        neighbors = sorted(self.graph[entity], key=lambda x: self.graph[entity][x]["weight"], reverse=True)
        return neighbors[:top_n]

class DynamicLearningBot:
    """
    Chatbot qui apprend dynamiquement des interactions utilisateur.
    """

    def __init__(self):
        self.knowledge_base = {}

    def learn(self, user_input, bot_response):
        """
        Apprend une nouvelle paire question-réponse.
        """
        self.knowledge_base[user_input] = bot_response

    def respond(self, user_input):
        """
        Répond à une question, ou apprend si inconnu.
        """
        if user_input in self.knowledge_base:
            return self.knowledge_base[user_input]
        else:
            return "Je ne sais pas encore répondre à cela. Veux-tu m'apprendre ?"

from feature_engine.creation import MathFeatures

class AutomaticFeatureEngineer:
    """
    Crée des caractéristiques avancées automatiquement.
    """

    def __init__(self):
        self.pipeline = MathFeatures(variables=None, math_operations=["sum", "prod", "mean", "std", "max", "min"])

    def fit_transform(self, data):
        """
        Applique les transformations mathématiques sur les données.
        """
        return self.pipeline.fit_transform(data)

from pandas_profiling import ProfileReport

class DataStoryteller:
    """
    Génère des rapports narratifs interactifs basés sur les données.
    """

    def __init__(self):
        self.output_dir = "reports"
        os.makedirs(self.output_dir, exist_ok=True)

    def generate_story(self, data: pd.DataFrame, report_name="data_story"):
        """
        Crée un rapport interactif complet.
        """
        try:
            report = ProfileReport(data, title="Data Story", explorative=True)
            file_path = os.path.join(self.output_dir, f"{report_name}.html")
            report.to_file(file_path)
            return file_path
        except Exception as e:
            return f"Erreur lors de la création du rapport : {e}"

from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer

class DeepRecommender:
    """
    Système de recommandation avancé utilisant des embeddings de texte.
    """

    def __init__(self, model_name="all-MiniLM-L6-v2"):
        self.model = SentenceTransformer(model_name)

    def generate_embeddings(self, items):
        """
        Génère des embeddings pour une liste d'items (e.g., textes ou titres).
        """
        return self.model.encode(items)

    def recommend(self, query, items, top_n=5):
        """
        Recommande des items similaires à une requête donnée.
        """
        query_embedding = self.generate_embeddings([query])
        item_embeddings = self.generate_embeddings(items)
        similarities = cosine_similarity(query_embedding, item_embeddings)[0]
        recommendations = sorted(zip(items, similarities), key=lambda x: x[1], reverse=True)[:top_n]
        return recommendations

from PIL import Image
from transformers import pipeline

class VisionAssistant:
    """
    Assistant capable de comprendre et décrire des images.
    """

    def __init__(self, model_name="google/vit-base-patch16-224"):
        self.vision_model = pipeline("image-classification", model=model_name)

    def analyze_image(self, image_path):
        """
        Analyse et décrit une image.
        """
        image = Image.open(image_path)
        results = self.vision_model(image)
        return results

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense

class MultiTaskForecaster:
    """
    Modèle de prévision multitâches (classification et régression).
    """

    def __init__(self, input_shape):
        inputs = Input(shape=(input_shape,))
        common = Dense(128, activation="relu")(inputs)

        # Tâche 1 : Classification
        classification_output = Dense(1, activation="sigmoid", name="classification")(common)

        # Tâche 2 : Régression
        regression_output = Dense(1, name="regression")(common)

        self.model = Model(inputs=inputs, outputs=[classification_output, regression_output])

    def compile(self):
        self.model.compile(optimizer="adam",
                           loss={"classification": "binary_crossentropy", "regression": "mse"},
                           metrics={"classification": "accuracy", "regression": "mae"})

class ConversationalMemoryManager:
    """
    Gère la mémoire à long terme des conversations du bot.
    """

    def __init__(self):
        self.memory = []

    def add_interaction(self, user_message, bot_response):
        """
        Ajoute une interaction dans la mémoire.
        """
        self.memory.append({"user": user_message, "bot": bot_response})

    def retrieve_context(self, keyword, max_results=5):
        """
        Recherche des interactions passées liées à un mot-clé.
        """
        return [item for item in self.memory if keyword.lower() in item["user"].lower()][:max_results]

from haystack.document_stores import InMemoryDocumentStore
from haystack.nodes import FARMReader, DensePassageRetriever
from haystack.pipelines import ExtractiveQAPipeline

class DocumentQA:
    """
    Répond aux questions en recherchant dans des documents.
    """

    def __init__(self):
        self.document_store = InMemoryDocumentStore()
        self.retriever = DensePassageRetriever(self.document_store)
        self.reader = FARMReader("deepset/roberta-base-squad2")
        self.pipeline = ExtractiveQAPipeline(reader=self.reader, retriever=self.retriever)

    def add_documents(self, docs):
        """
        Ajoute des documents à la base.
        """
        self.document_store.write_documents(docs)

    def answer_question(self, question):
        """
        Répond à une question en cherchant dans les documents.
        """
        return self.pipeline.run(query=question, params={"Retriever": {"top_k": 5}})

from gtts import gTTS

class SpeechGenerator:
    """
    Génère de l'audio à partir de texte.
    """

    def __init__(self, lang="fr"):
        self.lang = lang

    def text_to_speech(self, text, output_path="output.mp3"):
        """
        Convertit un texte en fichier audio.
        """
        tts = gTTS(text=text, lang=self.lang)
        tts.save(output_path)
        return output_path

from pyspark.sql import SparkSession

class RealTimeDataProcessor:
    """
    Analyse des données en temps réel avec Spark Streaming.
    """

    def __init__(self):
        self.spark = SparkSession.builder.appName("RealTimeProcessor").getOrCreate()

    def process_stream(self, stream_source):
        """
        Lit et traite un flux en continu.
        """
        df = self.spark.readStream.format("socket").option("host", "localhost").option("port", 9999).load()
        query = df.writeStream.outputMode("append").format("console").start()
        query.awaitTermination()

#from modAL.models import ActiveLearner
from sklearn.ensemble import RandomForestClassifier

class ActiveLearningManager:
    """
    Implémente un gestionnaire d'apprentissage actif.
    """

    def __init__(self, X_pool, y_pool):
        self.learner = ActiveLearner(estimator=RandomForestClassifier(), X_training=X_pool, y_training=y_pool)

    def query_next(self):
        """
        Sélectionne l'échantillon le plus incertain pour l'annotation.
        """
        query_idx, _ = self.learner.query(X_pool)
        return query_idx

import plotly.express as px

class Interactive3DVisualizer:
    """
    Génère des visualisations interactives en 3D.
    """

    def plot_3d(self, data, x_col, y_col, z_col, color_col):
        """
        Génère un graphique 3D interactif.
        """
        fig = px.scatter_3d(data, x=x_col, y=y_col, z=z_col, color=color_col)
        fig.show()

class ActionEncryptFile(Action):
    def name(self) -> str:
        return "action_encrypt_file"

    async def run(self, dispatcher, tracker, domain) -> list[EventType]:
        dispatcher.utter_message(text="Encrypting the file...")
        # Logique d'encryption ici
        return []




class SomeAction(Action):
    def name(self) -> str:
        return "some_action"

    def run(
            self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        Orchestrateur universel pour exécuter dynamiquement toutes les actions existantes.
        """

        # Extraire l'action cible et les paramètres
        target_action = tracker.get_slot("target_action")  # Nom de l'action cible
        action_params = tracker.get_slot("action_params")  # Paramètres sous forme JSON

        if not target_action:
            dispatcher.utter_message(text="Erreur : aucune action cible spécifiée.")
            return []

        try:
            # Charger dynamiquement l'action cible
            action_instance = self.load_action(target_action)

            if not action_instance:
                dispatcher.utter_message(
                    text=f"Action '{target_action}' introuvable. Assurez-vous qu'elle est bien enregistrée."
                )
                return []

            # Décoder les paramètres
            params = self.decode_params(action_params)

            # Exécuter l'action
            result = action_instance.run(dispatcher, tracker, domain, **params)

            # Informer l'utilisateur
            dispatcher.utter_message(text=f"Résultat de l'action '{target_action}' : {result}")
            return result
        except Exception as e:
            logging.exception(f"Erreur lors de l'exécution de '{target_action}': {e}")
            dispatcher.utter_message(
                text=f"Erreur lors de l'exécution de l'action '{target_action}': {str(e)}"
            )
            return []

    def load_action(self, action_name: str) -> Any:
        """
        Charge dynamiquement une action basée sur son nom.
        """
        try:
            # Identifier le module Python de l'action
            module_name = action_name.replace("action_", "")
            module_path = f"actions.{module_name}"

            # Importer dynamiquement le module
            module = importlib.import_module(module_path)

            # Instancier la classe correspondante
            action_class_name = module_name.capitalize()
            action_class = getattr(module, action_class_name, None)

            if action_class:
                return action_class()

            logging.error(f"Classe '{action_class_name}' non trouvée dans le module '{module_path}'.")
            return None
        except ModuleNotFoundError:
            logging.error(f"Module '{action_name}' introuvable.")
            return None

    def decode_params(self, params: str) -> Dict[str, Any]:
        """
        Décodage des paramètres JSON pour les convertir en dictionnaire.
        """
        try:
            return json.loads(params) if params else {}
        except json.JSONDecodeError:
            logging.error(f"Impossible de décoder les paramètres JSON : {params}")
            return {}

